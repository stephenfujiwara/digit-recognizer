{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations to be applied to raw data\n",
    "# converts (PIL, target) to (tensor, target)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "# load datsets from Internet\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# provide an iterable over datasets\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(dataset=testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model sucks on binary for some reason, create custom Transform object to binarize images\n",
    "\n",
    "class Binarize():\n",
    "    def __call__(self, sample):\n",
    "        return (sample > 0.5).float()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    Binarize()\n",
    "])\n",
    "\n",
    "# load datsets from Internet\n",
    "b_trainset = datasets.MNIST(root='./binarized', train=True, download=True, transform=transform)\n",
    "b_testset = datasets.MNIST(root='./binarized', train=False, download=True, transform=transform)\n",
    "\n",
    "b_trainloader = DataLoader(dataset=b_trainset, batch_size=32, shuffle=True)\n",
    "b_testloader = DataLoader(dataset=b_testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(trainset[3][0].squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(b_trainset[3][0].squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BobNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # flatten all dimensions, except the batch dimension.\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        # process output of net into probabilities\n",
    "        out = F.log_softmax(x, dim=1)\n",
    "        return out\n",
    "\n",
    "model = BobNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(params=model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss: 2.3122193813323975\n",
      "epoch: 0, batch: 1, loss: 2.2755775451660156\n",
      "epoch: 0, batch: 2, loss: 2.2844340801239014\n",
      "epoch: 0, batch: 3, loss: 2.3175175189971924\n",
      "epoch: 0, batch: 4, loss: 2.2979817390441895\n",
      "epoch: 0, batch: 5, loss: 2.2733590602874756\n",
      "epoch: 0, batch: 6, loss: 2.2913930416107178\n",
      "epoch: 0, batch: 7, loss: 2.3245134353637695\n",
      "epoch: 0, batch: 8, loss: 2.3020431995391846\n",
      "epoch: 0, batch: 9, loss: 2.302034854888916\n",
      "epoch: 0, batch: 10, loss: 2.3025333881378174\n",
      "epoch: 0, batch: 11, loss: 2.3330700397491455\n",
      "epoch: 0, batch: 12, loss: 2.304440498352051\n",
      "epoch: 0, batch: 13, loss: 2.3071446418762207\n",
      "epoch: 0, batch: 14, loss: 2.3043107986450195\n",
      "epoch: 0, batch: 15, loss: 2.300518035888672\n",
      "epoch: 0, batch: 16, loss: 2.3101751804351807\n",
      "epoch: 0, batch: 17, loss: 2.298325777053833\n",
      "epoch: 0, batch: 18, loss: 2.3255820274353027\n",
      "epoch: 0, batch: 19, loss: 2.280940055847168\n",
      "epoch: 0, batch: 20, loss: 2.2948052883148193\n",
      "epoch: 0, batch: 21, loss: 2.299348831176758\n",
      "epoch: 0, batch: 22, loss: 2.3336029052734375\n",
      "epoch: 0, batch: 23, loss: 2.3320980072021484\n",
      "epoch: 0, batch: 24, loss: 2.327867269515991\n",
      "epoch: 0, batch: 25, loss: 2.3238673210144043\n",
      "epoch: 0, batch: 26, loss: 2.305272102355957\n",
      "epoch: 0, batch: 27, loss: 2.306285858154297\n",
      "epoch: 0, batch: 28, loss: 2.2988929748535156\n",
      "epoch: 0, batch: 29, loss: 2.3198742866516113\n",
      "epoch: 0, batch: 30, loss: 2.298645496368408\n",
      "epoch: 0, batch: 31, loss: 2.2912778854370117\n",
      "epoch: 0, batch: 32, loss: 2.309404134750366\n",
      "epoch: 0, batch: 33, loss: 2.2952399253845215\n",
      "epoch: 0, batch: 34, loss: 2.3133020401000977\n",
      "epoch: 0, batch: 35, loss: 2.3048861026763916\n",
      "epoch: 0, batch: 36, loss: 2.271075963973999\n",
      "epoch: 0, batch: 37, loss: 2.3166422843933105\n",
      "epoch: 0, batch: 38, loss: 2.300217628479004\n",
      "epoch: 0, batch: 39, loss: 2.330045700073242\n",
      "epoch: 0, batch: 40, loss: 2.3011972904205322\n",
      "epoch: 0, batch: 41, loss: 2.3284993171691895\n",
      "epoch: 0, batch: 42, loss: 2.3134384155273438\n",
      "epoch: 0, batch: 43, loss: 2.331873655319214\n",
      "epoch: 0, batch: 44, loss: 2.2918944358825684\n",
      "epoch: 0, batch: 45, loss: 2.3304593563079834\n",
      "epoch: 0, batch: 46, loss: 2.297499895095825\n",
      "epoch: 0, batch: 47, loss: 2.3168487548828125\n",
      "epoch: 0, batch: 48, loss: 2.2955658435821533\n",
      "epoch: 0, batch: 49, loss: 2.2876763343811035\n",
      "epoch: 0, batch: 50, loss: 2.296126127243042\n",
      "epoch: 0, batch: 51, loss: 2.3070597648620605\n",
      "epoch: 0, batch: 52, loss: 2.2938244342803955\n",
      "epoch: 0, batch: 53, loss: 2.2931079864501953\n",
      "epoch: 0, batch: 54, loss: 2.2757935523986816\n",
      "epoch: 0, batch: 55, loss: 2.329592704772949\n",
      "epoch: 0, batch: 56, loss: 2.2986576557159424\n",
      "epoch: 0, batch: 57, loss: 2.318690538406372\n",
      "epoch: 0, batch: 58, loss: 2.315758228302002\n",
      "epoch: 0, batch: 59, loss: 2.2778780460357666\n",
      "epoch: 0, batch: 60, loss: 2.3174543380737305\n",
      "epoch: 0, batch: 61, loss: 2.3261187076568604\n",
      "epoch: 0, batch: 62, loss: 2.3132288455963135\n",
      "epoch: 0, batch: 63, loss: 2.285141944885254\n",
      "epoch: 0, batch: 64, loss: 2.3137857913970947\n",
      "epoch: 0, batch: 65, loss: 2.3149209022521973\n",
      "epoch: 0, batch: 66, loss: 2.3161814212799072\n",
      "epoch: 0, batch: 67, loss: 2.284065008163452\n",
      "epoch: 0, batch: 68, loss: 2.3155150413513184\n",
      "epoch: 0, batch: 69, loss: 2.293114185333252\n",
      "epoch: 0, batch: 70, loss: 2.2815439701080322\n",
      "epoch: 0, batch: 71, loss: 2.3249871730804443\n",
      "epoch: 0, batch: 72, loss: 2.340052604675293\n",
      "epoch: 0, batch: 73, loss: 2.325582265853882\n",
      "epoch: 0, batch: 74, loss: 2.299020767211914\n",
      "epoch: 0, batch: 75, loss: 2.3161966800689697\n",
      "epoch: 0, batch: 76, loss: 2.3059334754943848\n",
      "epoch: 0, batch: 77, loss: 2.2720565795898438\n",
      "epoch: 0, batch: 78, loss: 2.3210160732269287\n",
      "epoch: 0, batch: 79, loss: 2.3357350826263428\n",
      "epoch: 0, batch: 80, loss: 2.288921594619751\n",
      "epoch: 0, batch: 81, loss: 2.3041703701019287\n",
      "epoch: 0, batch: 82, loss: 2.296712875366211\n",
      "epoch: 0, batch: 83, loss: 2.318129777908325\n",
      "epoch: 0, batch: 84, loss: 2.3132383823394775\n",
      "epoch: 0, batch: 85, loss: 2.3138599395751953\n",
      "epoch: 0, batch: 86, loss: 2.324414014816284\n",
      "epoch: 0, batch: 87, loss: 2.312725782394409\n",
      "epoch: 0, batch: 88, loss: 2.299973487854004\n",
      "epoch: 0, batch: 89, loss: 2.2859573364257812\n",
      "epoch: 0, batch: 90, loss: 2.3169662952423096\n",
      "epoch: 0, batch: 91, loss: 2.313182830810547\n",
      "epoch: 0, batch: 92, loss: 2.3151378631591797\n",
      "epoch: 0, batch: 93, loss: 2.3477160930633545\n",
      "epoch: 0, batch: 94, loss: 2.3003487586975098\n",
      "epoch: 0, batch: 95, loss: 2.313171148300171\n",
      "epoch: 0, batch: 96, loss: 2.3056509494781494\n",
      "epoch: 0, batch: 97, loss: 2.313007354736328\n",
      "epoch: 0, batch: 98, loss: 2.3033792972564697\n",
      "epoch: 0, batch: 99, loss: 2.3005869388580322\n",
      "epoch: 0, batch: 100, loss: 2.302079439163208\n",
      "epoch: 0, batch: 101, loss: 2.2790637016296387\n",
      "epoch: 0, batch: 102, loss: 2.329521656036377\n",
      "epoch: 0, batch: 103, loss: 2.3090744018554688\n",
      "epoch: 0, batch: 104, loss: 2.275047540664673\n",
      "epoch: 0, batch: 105, loss: 2.286648988723755\n",
      "epoch: 0, batch: 106, loss: 2.2906103134155273\n",
      "epoch: 0, batch: 107, loss: 2.3000760078430176\n",
      "epoch: 0, batch: 108, loss: 2.301409959793091\n",
      "epoch: 0, batch: 109, loss: 2.314469814300537\n",
      "epoch: 0, batch: 110, loss: 2.3044662475585938\n",
      "epoch: 0, batch: 111, loss: 2.3133554458618164\n",
      "epoch: 0, batch: 112, loss: 2.311673879623413\n",
      "epoch: 0, batch: 113, loss: 2.3091094493865967\n",
      "epoch: 0, batch: 114, loss: 2.323627471923828\n",
      "epoch: 0, batch: 115, loss: 2.2941479682922363\n",
      "epoch: 0, batch: 116, loss: 2.311687707901001\n",
      "epoch: 0, batch: 117, loss: 2.310230016708374\n",
      "epoch: 0, batch: 118, loss: 2.323519468307495\n",
      "epoch: 0, batch: 119, loss: 2.3011910915374756\n",
      "epoch: 0, batch: 120, loss: 2.3099887371063232\n",
      "epoch: 0, batch: 121, loss: 2.285646915435791\n",
      "epoch: 0, batch: 122, loss: 2.3182361125946045\n",
      "epoch: 0, batch: 123, loss: 2.3019356727600098\n",
      "epoch: 0, batch: 124, loss: 2.3018789291381836\n",
      "epoch: 0, batch: 125, loss: 2.2992539405822754\n",
      "epoch: 0, batch: 126, loss: 2.2861039638519287\n",
      "epoch: 0, batch: 127, loss: 2.3249258995056152\n",
      "epoch: 0, batch: 128, loss: 2.304365396499634\n",
      "epoch: 0, batch: 129, loss: 2.31982421875\n",
      "epoch: 0, batch: 130, loss: 2.2936534881591797\n",
      "epoch: 0, batch: 131, loss: 2.3133411407470703\n",
      "epoch: 0, batch: 132, loss: 2.318568706512451\n",
      "epoch: 0, batch: 133, loss: 2.3305673599243164\n",
      "epoch: 0, batch: 134, loss: 2.3193325996398926\n",
      "epoch: 0, batch: 135, loss: 2.289321184158325\n",
      "epoch: 0, batch: 136, loss: 2.31083607673645\n",
      "epoch: 0, batch: 137, loss: 2.3096582889556885\n",
      "epoch: 0, batch: 138, loss: 2.3245229721069336\n",
      "epoch: 0, batch: 139, loss: 2.306537628173828\n",
      "epoch: 0, batch: 140, loss: 2.29390811920166\n",
      "epoch: 0, batch: 141, loss: 2.309802532196045\n",
      "epoch: 0, batch: 142, loss: 2.2970316410064697\n",
      "epoch: 0, batch: 143, loss: 2.321597099304199\n",
      "epoch: 0, batch: 144, loss: 2.2945010662078857\n",
      "epoch: 0, batch: 145, loss: 2.2976956367492676\n",
      "epoch: 0, batch: 146, loss: 2.291337728500366\n",
      "epoch: 0, batch: 147, loss: 2.3009941577911377\n",
      "epoch: 0, batch: 148, loss: 2.292506217956543\n",
      "epoch: 0, batch: 149, loss: 2.2913269996643066\n",
      "epoch: 0, batch: 150, loss: 2.3004062175750732\n",
      "epoch: 0, batch: 151, loss: 2.308652400970459\n",
      "epoch: 0, batch: 152, loss: 2.3337509632110596\n",
      "epoch: 0, batch: 153, loss: 2.302541732788086\n",
      "epoch: 0, batch: 154, loss: 2.3120028972625732\n",
      "epoch: 0, batch: 155, loss: 2.310009002685547\n",
      "epoch: 0, batch: 156, loss: 2.3141374588012695\n",
      "epoch: 0, batch: 157, loss: 2.291872024536133\n",
      "epoch: 0, batch: 158, loss: 2.318011999130249\n",
      "epoch: 0, batch: 159, loss: 2.3252739906311035\n",
      "epoch: 0, batch: 160, loss: 2.328965663909912\n",
      "epoch: 0, batch: 161, loss: 2.290710926055908\n",
      "epoch: 0, batch: 162, loss: 2.308091402053833\n",
      "epoch: 0, batch: 163, loss: 2.302288293838501\n",
      "epoch: 0, batch: 164, loss: 2.29931378364563\n",
      "epoch: 0, batch: 165, loss: 2.31697678565979\n",
      "epoch: 0, batch: 166, loss: 2.3050894737243652\n",
      "epoch: 0, batch: 167, loss: 2.2995243072509766\n",
      "epoch: 0, batch: 168, loss: 2.3184666633605957\n",
      "epoch: 0, batch: 169, loss: 2.2684898376464844\n",
      "epoch: 0, batch: 170, loss: 2.306790590286255\n",
      "epoch: 0, batch: 171, loss: 2.3090860843658447\n",
      "epoch: 0, batch: 172, loss: 2.3115200996398926\n",
      "epoch: 0, batch: 173, loss: 2.2961080074310303\n",
      "epoch: 0, batch: 174, loss: 2.329221725463867\n",
      "epoch: 0, batch: 175, loss: 2.3246958255767822\n",
      "epoch: 0, batch: 176, loss: 2.29000186920166\n",
      "epoch: 0, batch: 177, loss: 2.291857957839966\n",
      "epoch: 0, batch: 178, loss: 2.324021577835083\n",
      "epoch: 0, batch: 179, loss: 2.321715831756592\n",
      "epoch: 0, batch: 180, loss: 2.293715238571167\n",
      "epoch: 0, batch: 181, loss: 2.2914493083953857\n",
      "epoch: 0, batch: 182, loss: 2.29044771194458\n",
      "epoch: 0, batch: 183, loss: 2.294328451156616\n",
      "epoch: 0, batch: 184, loss: 2.2734036445617676\n",
      "epoch: 0, batch: 185, loss: 2.315622329711914\n",
      "epoch: 0, batch: 186, loss: 2.2976865768432617\n",
      "epoch: 0, batch: 187, loss: 2.3061623573303223\n",
      "epoch: 0, batch: 188, loss: 2.3267815113067627\n",
      "epoch: 0, batch: 189, loss: 2.284900188446045\n",
      "epoch: 0, batch: 190, loss: 2.285365104675293\n",
      "epoch: 0, batch: 191, loss: 2.3003196716308594\n",
      "epoch: 0, batch: 192, loss: 2.2781753540039062\n",
      "epoch: 0, batch: 193, loss: 2.2942042350769043\n",
      "epoch: 0, batch: 194, loss: 2.3462603092193604\n",
      "epoch: 0, batch: 195, loss: 2.3053014278411865\n",
      "epoch: 0, batch: 196, loss: 2.3039276599884033\n",
      "epoch: 0, batch: 197, loss: 2.3221182823181152\n",
      "epoch: 0, batch: 198, loss: 2.3201487064361572\n",
      "epoch: 0, batch: 199, loss: 2.273648500442505\n",
      "epoch: 0, batch: 200, loss: 2.3119022846221924\n",
      "epoch: 0, batch: 201, loss: 2.278686761856079\n",
      "epoch: 0, batch: 202, loss: 2.2783005237579346\n",
      "epoch: 0, batch: 203, loss: 2.3048202991485596\n",
      "epoch: 0, batch: 204, loss: 2.298943519592285\n",
      "epoch: 0, batch: 205, loss: 2.287142515182495\n",
      "epoch: 0, batch: 206, loss: 2.2854137420654297\n",
      "epoch: 0, batch: 207, loss: 2.290605068206787\n",
      "epoch: 0, batch: 208, loss: 2.2824645042419434\n",
      "epoch: 0, batch: 209, loss: 2.2914090156555176\n",
      "epoch: 0, batch: 210, loss: 2.2938551902770996\n",
      "epoch: 0, batch: 211, loss: 2.2825887203216553\n",
      "epoch: 0, batch: 212, loss: 2.3139545917510986\n",
      "epoch: 0, batch: 213, loss: 2.3158345222473145\n",
      "epoch: 0, batch: 214, loss: 2.2777352333068848\n",
      "epoch: 0, batch: 215, loss: 2.292799472808838\n",
      "epoch: 0, batch: 216, loss: 2.310483932495117\n",
      "epoch: 0, batch: 217, loss: 2.2936174869537354\n",
      "epoch: 0, batch: 218, loss: 2.3206334114074707\n",
      "epoch: 0, batch: 219, loss: 2.3294167518615723\n",
      "epoch: 0, batch: 220, loss: 2.2971911430358887\n",
      "epoch: 0, batch: 221, loss: 2.267338991165161\n",
      "epoch: 0, batch: 222, loss: 2.305631399154663\n",
      "epoch: 0, batch: 223, loss: 2.279245376586914\n",
      "epoch: 0, batch: 224, loss: 2.2962112426757812\n",
      "epoch: 0, batch: 225, loss: 2.334754467010498\n",
      "epoch: 0, batch: 226, loss: 2.292567491531372\n",
      "epoch: 0, batch: 227, loss: 2.286236524581909\n",
      "epoch: 0, batch: 228, loss: 2.295220375061035\n",
      "epoch: 0, batch: 229, loss: 2.31002140045166\n",
      "epoch: 0, batch: 230, loss: 2.2639272212982178\n",
      "epoch: 0, batch: 231, loss: 2.3005738258361816\n",
      "epoch: 0, batch: 232, loss: 2.3087546825408936\n",
      "epoch: 0, batch: 233, loss: 2.306040048599243\n",
      "epoch: 0, batch: 234, loss: 2.2661120891571045\n",
      "epoch: 0, batch: 235, loss: 2.296426773071289\n",
      "epoch: 0, batch: 236, loss: 2.3158068656921387\n",
      "epoch: 0, batch: 237, loss: 2.280066728591919\n",
      "epoch: 0, batch: 238, loss: 2.3017330169677734\n",
      "epoch: 0, batch: 239, loss: 2.29095721244812\n",
      "epoch: 0, batch: 240, loss: 2.3152050971984863\n",
      "epoch: 0, batch: 241, loss: 2.3186607360839844\n",
      "epoch: 0, batch: 242, loss: 2.2770581245422363\n",
      "epoch: 0, batch: 243, loss: 2.3316128253936768\n",
      "epoch: 0, batch: 244, loss: 2.2905454635620117\n",
      "epoch: 0, batch: 245, loss: 2.3163352012634277\n",
      "epoch: 0, batch: 246, loss: 2.292552947998047\n",
      "epoch: 0, batch: 247, loss: 2.2984907627105713\n",
      "epoch: 0, batch: 248, loss: 2.3033924102783203\n",
      "epoch: 0, batch: 249, loss: 2.292407751083374\n",
      "epoch: 0, batch: 250, loss: 2.31418514251709\n",
      "epoch: 0, batch: 251, loss: 2.2941133975982666\n",
      "epoch: 0, batch: 252, loss: 2.29866623878479\n",
      "epoch: 0, batch: 253, loss: 2.3025386333465576\n",
      "epoch: 0, batch: 254, loss: 2.3098762035369873\n",
      "epoch: 0, batch: 255, loss: 2.302833080291748\n",
      "epoch: 0, batch: 256, loss: 2.3010380268096924\n",
      "epoch: 0, batch: 257, loss: 2.300187587738037\n",
      "epoch: 0, batch: 258, loss: 2.3023300170898438\n",
      "epoch: 0, batch: 259, loss: 2.3059451580047607\n",
      "epoch: 0, batch: 260, loss: 2.2773053646087646\n",
      "epoch: 0, batch: 261, loss: 2.2896203994750977\n",
      "epoch: 0, batch: 262, loss: 2.2871193885803223\n",
      "epoch: 0, batch: 263, loss: 2.298762559890747\n",
      "epoch: 0, batch: 264, loss: 2.305551052093506\n",
      "epoch: 0, batch: 265, loss: 2.314466714859009\n",
      "epoch: 0, batch: 266, loss: 2.297015428543091\n",
      "epoch: 0, batch: 267, loss: 2.2728843688964844\n",
      "epoch: 0, batch: 268, loss: 2.3150534629821777\n",
      "epoch: 0, batch: 269, loss: 2.2666337490081787\n",
      "epoch: 0, batch: 270, loss: 2.318366289138794\n",
      "epoch: 0, batch: 271, loss: 2.284045934677124\n",
      "epoch: 0, batch: 272, loss: 2.2955994606018066\n",
      "epoch: 0, batch: 273, loss: 2.3291144371032715\n",
      "epoch: 0, batch: 274, loss: 2.27390456199646\n",
      "epoch: 0, batch: 275, loss: 2.2800700664520264\n",
      "epoch: 0, batch: 276, loss: 2.3062615394592285\n",
      "epoch: 0, batch: 277, loss: 2.3094804286956787\n",
      "epoch: 0, batch: 278, loss: 2.2750680446624756\n",
      "epoch: 0, batch: 279, loss: 2.2788374423980713\n",
      "epoch: 0, batch: 280, loss: 2.3007586002349854\n",
      "epoch: 0, batch: 281, loss: 2.289559841156006\n",
      "epoch: 0, batch: 282, loss: 2.2798216342926025\n",
      "epoch: 0, batch: 283, loss: 2.302114248275757\n",
      "epoch: 0, batch: 284, loss: 2.295596122741699\n",
      "epoch: 0, batch: 285, loss: 2.3026621341705322\n",
      "epoch: 0, batch: 286, loss: 2.279967784881592\n",
      "epoch: 0, batch: 287, loss: 2.314549446105957\n",
      "epoch: 0, batch: 288, loss: 2.3041470050811768\n",
      "epoch: 0, batch: 289, loss: 2.2787482738494873\n",
      "epoch: 0, batch: 290, loss: 2.3042428493499756\n",
      "epoch: 0, batch: 291, loss: 2.2917580604553223\n",
      "epoch: 0, batch: 292, loss: 2.3004000186920166\n",
      "epoch: 0, batch: 293, loss: 2.295344352722168\n",
      "epoch: 0, batch: 294, loss: 2.3088767528533936\n",
      "epoch: 0, batch: 295, loss: 2.3007755279541016\n",
      "epoch: 0, batch: 296, loss: 2.3180370330810547\n",
      "epoch: 0, batch: 297, loss: 2.2819690704345703\n",
      "epoch: 0, batch: 298, loss: 2.3057949542999268\n",
      "epoch: 0, batch: 299, loss: 2.2971696853637695\n",
      "epoch: 0, batch: 300, loss: 2.3152613639831543\n",
      "epoch: 0, batch: 301, loss: 2.329500675201416\n",
      "epoch: 0, batch: 302, loss: 2.313917636871338\n",
      "epoch: 0, batch: 303, loss: 2.283149003982544\n",
      "epoch: 0, batch: 304, loss: 2.314920663833618\n",
      "epoch: 0, batch: 305, loss: 2.305119276046753\n",
      "epoch: 0, batch: 306, loss: 2.2995874881744385\n",
      "epoch: 0, batch: 307, loss: 2.286978006362915\n",
      "epoch: 0, batch: 308, loss: 2.322287082672119\n",
      "epoch: 0, batch: 309, loss: 2.2825520038604736\n",
      "epoch: 0, batch: 310, loss: 2.2889320850372314\n",
      "epoch: 0, batch: 311, loss: 2.2995176315307617\n",
      "epoch: 0, batch: 312, loss: 2.2990827560424805\n",
      "epoch: 0, batch: 313, loss: 2.3074190616607666\n",
      "epoch: 0, batch: 314, loss: 2.312608242034912\n",
      "epoch: 0, batch: 315, loss: 2.3003957271575928\n",
      "epoch: 0, batch: 316, loss: 2.2946183681488037\n",
      "epoch: 0, batch: 317, loss: 2.297680377960205\n",
      "epoch: 0, batch: 318, loss: 2.2768208980560303\n",
      "epoch: 0, batch: 319, loss: 2.2868621349334717\n",
      "epoch: 0, batch: 320, loss: 2.315985918045044\n",
      "epoch: 0, batch: 321, loss: 2.3034520149230957\n",
      "epoch: 0, batch: 322, loss: 2.3181917667388916\n",
      "epoch: 0, batch: 323, loss: 2.286377429962158\n",
      "epoch: 0, batch: 324, loss: 2.2737956047058105\n",
      "epoch: 0, batch: 325, loss: 2.3212475776672363\n",
      "epoch: 0, batch: 326, loss: 2.2793760299682617\n",
      "epoch: 0, batch: 327, loss: 2.2631351947784424\n",
      "epoch: 0, batch: 328, loss: 2.311269998550415\n",
      "epoch: 0, batch: 329, loss: 2.297865152359009\n",
      "epoch: 0, batch: 330, loss: 2.26350736618042\n",
      "epoch: 0, batch: 331, loss: 2.281100273132324\n",
      "epoch: 0, batch: 332, loss: 2.3066792488098145\n",
      "epoch: 0, batch: 333, loss: 2.3349907398223877\n",
      "epoch: 0, batch: 334, loss: 2.322866678237915\n",
      "epoch: 0, batch: 335, loss: 2.274700164794922\n",
      "epoch: 0, batch: 336, loss: 2.2809395790100098\n",
      "epoch: 0, batch: 337, loss: 2.28464412689209\n",
      "epoch: 0, batch: 338, loss: 2.316556930541992\n",
      "epoch: 0, batch: 339, loss: 2.2730515003204346\n",
      "epoch: 0, batch: 340, loss: 2.28537917137146\n",
      "epoch: 0, batch: 341, loss: 2.274545669555664\n",
      "epoch: 0, batch: 342, loss: 2.3066585063934326\n",
      "epoch: 0, batch: 343, loss: 2.3068134784698486\n",
      "epoch: 0, batch: 344, loss: 2.3105900287628174\n",
      "epoch: 0, batch: 345, loss: 2.291822910308838\n",
      "epoch: 0, batch: 346, loss: 2.2756834030151367\n",
      "epoch: 0, batch: 347, loss: 2.291097640991211\n",
      "epoch: 0, batch: 348, loss: 2.2838010787963867\n",
      "epoch: 0, batch: 349, loss: 2.2902281284332275\n",
      "epoch: 0, batch: 350, loss: 2.305175542831421\n",
      "epoch: 0, batch: 351, loss: 2.2909750938415527\n",
      "epoch: 0, batch: 352, loss: 2.29860520362854\n",
      "epoch: 0, batch: 353, loss: 2.276170253753662\n",
      "epoch: 0, batch: 354, loss: 2.2853734493255615\n",
      "epoch: 0, batch: 355, loss: 2.275892734527588\n",
      "epoch: 0, batch: 356, loss: 2.3176615238189697\n",
      "epoch: 0, batch: 357, loss: 2.307877540588379\n",
      "epoch: 0, batch: 358, loss: 2.2973647117614746\n",
      "epoch: 0, batch: 359, loss: 2.300800323486328\n",
      "epoch: 0, batch: 360, loss: 2.3092153072357178\n",
      "epoch: 0, batch: 361, loss: 2.297912120819092\n",
      "epoch: 0, batch: 362, loss: 2.2908835411071777\n",
      "epoch: 0, batch: 363, loss: 2.2936508655548096\n",
      "epoch: 0, batch: 364, loss: 2.3338003158569336\n",
      "epoch: 0, batch: 365, loss: 2.3076114654541016\n",
      "epoch: 0, batch: 366, loss: 2.341045618057251\n",
      "epoch: 0, batch: 367, loss: 2.306349039077759\n",
      "epoch: 0, batch: 368, loss: 2.329737663269043\n",
      "epoch: 0, batch: 369, loss: 2.2925684452056885\n",
      "epoch: 0, batch: 370, loss: 2.3063032627105713\n",
      "epoch: 0, batch: 371, loss: 2.3134524822235107\n",
      "epoch: 0, batch: 372, loss: 2.293426275253296\n",
      "epoch: 0, batch: 373, loss: 2.3145804405212402\n",
      "epoch: 0, batch: 374, loss: 2.3035998344421387\n",
      "epoch: 0, batch: 375, loss: 2.28369402885437\n",
      "epoch: 0, batch: 376, loss: 2.2931742668151855\n",
      "epoch: 0, batch: 377, loss: 2.3021605014801025\n",
      "epoch: 0, batch: 378, loss: 2.301908493041992\n",
      "epoch: 0, batch: 379, loss: 2.2973926067352295\n",
      "epoch: 0, batch: 380, loss: 2.2946531772613525\n",
      "epoch: 0, batch: 381, loss: 2.270756244659424\n",
      "epoch: 0, batch: 382, loss: 2.2908976078033447\n",
      "epoch: 0, batch: 383, loss: 2.303853750228882\n",
      "epoch: 0, batch: 384, loss: 2.313344717025757\n",
      "epoch: 0, batch: 385, loss: 2.3056397438049316\n",
      "epoch: 0, batch: 386, loss: 2.280059814453125\n",
      "epoch: 0, batch: 387, loss: 2.3049490451812744\n",
      "epoch: 0, batch: 388, loss: 2.2645387649536133\n",
      "epoch: 0, batch: 389, loss: 2.2814831733703613\n",
      "epoch: 0, batch: 390, loss: 2.309291124343872\n",
      "epoch: 0, batch: 391, loss: 2.270472764968872\n",
      "epoch: 0, batch: 392, loss: 2.321045398712158\n",
      "epoch: 0, batch: 393, loss: 2.2997522354125977\n",
      "epoch: 0, batch: 394, loss: 2.2862157821655273\n",
      "epoch: 0, batch: 395, loss: 2.292168617248535\n",
      "epoch: 0, batch: 396, loss: 2.2824785709381104\n",
      "epoch: 0, batch: 397, loss: 2.2983973026275635\n",
      "epoch: 0, batch: 398, loss: 2.2985193729400635\n",
      "epoch: 0, batch: 399, loss: 2.300726890563965\n",
      "epoch: 0, batch: 400, loss: 2.302058458328247\n",
      "epoch: 0, batch: 401, loss: 2.318192958831787\n",
      "epoch: 0, batch: 402, loss: 2.3159472942352295\n",
      "epoch: 0, batch: 403, loss: 2.314774513244629\n",
      "epoch: 0, batch: 404, loss: 2.293597459793091\n",
      "epoch: 0, batch: 405, loss: 2.303393840789795\n",
      "epoch: 0, batch: 406, loss: 2.27321457862854\n",
      "epoch: 0, batch: 407, loss: 2.3026139736175537\n",
      "epoch: 0, batch: 408, loss: 2.3159518241882324\n",
      "epoch: 0, batch: 409, loss: 2.291595935821533\n",
      "epoch: 0, batch: 410, loss: 2.2865335941314697\n",
      "epoch: 0, batch: 411, loss: 2.3115243911743164\n",
      "epoch: 0, batch: 412, loss: 2.305673122406006\n",
      "epoch: 0, batch: 413, loss: 2.3019893169403076\n",
      "epoch: 0, batch: 414, loss: 2.2937984466552734\n",
      "epoch: 0, batch: 415, loss: 2.26239013671875\n",
      "epoch: 0, batch: 416, loss: 2.285250663757324\n",
      "epoch: 0, batch: 417, loss: 2.2842464447021484\n",
      "epoch: 0, batch: 418, loss: 2.311293363571167\n",
      "epoch: 0, batch: 419, loss: 2.2904281616210938\n",
      "epoch: 0, batch: 420, loss: 2.2694900035858154\n",
      "epoch: 0, batch: 421, loss: 2.3021717071533203\n",
      "epoch: 0, batch: 422, loss: 2.2732858657836914\n",
      "epoch: 0, batch: 423, loss: 2.2925240993499756\n",
      "epoch: 0, batch: 424, loss: 2.278082847595215\n",
      "epoch: 0, batch: 425, loss: 2.284583806991577\n",
      "epoch: 0, batch: 426, loss: 2.3118178844451904\n",
      "epoch: 0, batch: 427, loss: 2.282529830932617\n",
      "epoch: 0, batch: 428, loss: 2.266092538833618\n",
      "epoch: 0, batch: 429, loss: 2.29451060295105\n",
      "epoch: 0, batch: 430, loss: 2.3035647869110107\n",
      "epoch: 0, batch: 431, loss: 2.2742695808410645\n",
      "epoch: 0, batch: 432, loss: 2.3161559104919434\n",
      "epoch: 0, batch: 433, loss: 2.292837619781494\n",
      "epoch: 0, batch: 434, loss: 2.281381368637085\n",
      "epoch: 0, batch: 435, loss: 2.2952721118927\n",
      "epoch: 0, batch: 436, loss: 2.275707721710205\n",
      "epoch: 0, batch: 437, loss: 2.2902917861938477\n",
      "epoch: 0, batch: 438, loss: 2.2858591079711914\n",
      "epoch: 0, batch: 439, loss: 2.300971269607544\n",
      "epoch: 0, batch: 440, loss: 2.280573844909668\n",
      "epoch: 0, batch: 441, loss: 2.302915096282959\n",
      "epoch: 0, batch: 442, loss: 2.30981183052063\n",
      "epoch: 0, batch: 443, loss: 2.2852230072021484\n",
      "epoch: 0, batch: 444, loss: 2.3108274936676025\n",
      "epoch: 0, batch: 445, loss: 2.3304367065429688\n",
      "epoch: 0, batch: 446, loss: 2.2968971729278564\n",
      "epoch: 0, batch: 447, loss: 2.280482053756714\n",
      "epoch: 0, batch: 448, loss: 2.284691572189331\n",
      "epoch: 0, batch: 449, loss: 2.282167911529541\n",
      "epoch: 0, batch: 450, loss: 2.3059067726135254\n",
      "epoch: 0, batch: 451, loss: 2.2833027839660645\n",
      "epoch: 0, batch: 452, loss: 2.296236038208008\n",
      "epoch: 0, batch: 453, loss: 2.2845561504364014\n",
      "epoch: 0, batch: 454, loss: 2.312918186187744\n",
      "epoch: 0, batch: 455, loss: 2.2745041847229004\n",
      "epoch: 0, batch: 456, loss: 2.307377815246582\n",
      "epoch: 0, batch: 457, loss: 2.300128221511841\n",
      "epoch: 0, batch: 458, loss: 2.2936830520629883\n",
      "epoch: 0, batch: 459, loss: 2.297635078430176\n",
      "epoch: 0, batch: 460, loss: 2.2784311771392822\n",
      "epoch: 0, batch: 461, loss: 2.3003487586975098\n",
      "epoch: 0, batch: 462, loss: 2.310350179672241\n",
      "epoch: 0, batch: 463, loss: 2.304731845855713\n",
      "epoch: 0, batch: 464, loss: 2.302431344985962\n",
      "epoch: 0, batch: 465, loss: 2.3035213947296143\n",
      "epoch: 0, batch: 466, loss: 2.2715883255004883\n",
      "epoch: 0, batch: 467, loss: 2.2887823581695557\n",
      "epoch: 0, batch: 468, loss: 2.2778377532958984\n",
      "epoch: 0, batch: 469, loss: 2.306189775466919\n",
      "epoch: 0, batch: 470, loss: 2.2857370376586914\n",
      "epoch: 0, batch: 471, loss: 2.3074138164520264\n",
      "epoch: 0, batch: 472, loss: 2.295560836791992\n",
      "epoch: 0, batch: 473, loss: 2.2792305946350098\n",
      "epoch: 0, batch: 474, loss: 2.276611566543579\n",
      "epoch: 0, batch: 475, loss: 2.2960188388824463\n",
      "epoch: 0, batch: 476, loss: 2.2766904830932617\n",
      "epoch: 0, batch: 477, loss: 2.2886295318603516\n",
      "epoch: 0, batch: 478, loss: 2.300625801086426\n",
      "epoch: 0, batch: 479, loss: 2.3210089206695557\n",
      "epoch: 0, batch: 480, loss: 2.2997002601623535\n",
      "epoch: 0, batch: 481, loss: 2.299790382385254\n",
      "epoch: 0, batch: 482, loss: 2.2707011699676514\n",
      "epoch: 0, batch: 483, loss: 2.280679225921631\n",
      "epoch: 0, batch: 484, loss: 2.287637710571289\n",
      "epoch: 0, batch: 485, loss: 2.2972991466522217\n",
      "epoch: 0, batch: 486, loss: 2.286165952682495\n",
      "epoch: 0, batch: 487, loss: 2.285372018814087\n",
      "epoch: 0, batch: 488, loss: 2.275479555130005\n",
      "epoch: 0, batch: 489, loss: 2.2908248901367188\n",
      "epoch: 0, batch: 490, loss: 2.281442880630493\n",
      "epoch: 0, batch: 491, loss: 2.3161771297454834\n",
      "epoch: 0, batch: 492, loss: 2.2958831787109375\n",
      "epoch: 0, batch: 493, loss: 2.2841594219207764\n",
      "epoch: 0, batch: 494, loss: 2.2908644676208496\n",
      "epoch: 0, batch: 495, loss: 2.2622644901275635\n",
      "epoch: 0, batch: 496, loss: 2.2909438610076904\n",
      "epoch: 0, batch: 497, loss: 2.3157894611358643\n",
      "epoch: 0, batch: 498, loss: 2.282543659210205\n",
      "epoch: 0, batch: 499, loss: 2.3151228427886963\n",
      "epoch: 0, batch: 500, loss: 2.277238368988037\n",
      "epoch: 0, batch: 501, loss: 2.3165581226348877\n",
      "epoch: 0, batch: 502, loss: 2.2889482975006104\n",
      "epoch: 0, batch: 503, loss: 2.306185245513916\n",
      "epoch: 0, batch: 504, loss: 2.2692766189575195\n",
      "epoch: 0, batch: 505, loss: 2.283576726913452\n",
      "epoch: 0, batch: 506, loss: 2.294461965560913\n",
      "epoch: 0, batch: 507, loss: 2.3035550117492676\n",
      "epoch: 0, batch: 508, loss: 2.307870626449585\n",
      "epoch: 0, batch: 509, loss: 2.3216328620910645\n",
      "epoch: 0, batch: 510, loss: 2.314568042755127\n",
      "epoch: 0, batch: 511, loss: 2.2770397663116455\n",
      "epoch: 0, batch: 512, loss: 2.2719807624816895\n",
      "epoch: 0, batch: 513, loss: 2.2845005989074707\n",
      "epoch: 0, batch: 514, loss: 2.2928028106689453\n",
      "epoch: 0, batch: 515, loss: 2.314347505569458\n",
      "epoch: 0, batch: 516, loss: 2.2728075981140137\n",
      "epoch: 0, batch: 517, loss: 2.318032741546631\n",
      "epoch: 0, batch: 518, loss: 2.3172247409820557\n",
      "epoch: 0, batch: 519, loss: 2.299078941345215\n",
      "epoch: 0, batch: 520, loss: 2.2957763671875\n",
      "epoch: 0, batch: 521, loss: 2.2817487716674805\n",
      "epoch: 0, batch: 522, loss: 2.29537034034729\n",
      "epoch: 0, batch: 523, loss: 2.3102803230285645\n",
      "epoch: 0, batch: 524, loss: 2.2807257175445557\n",
      "epoch: 0, batch: 525, loss: 2.281576633453369\n",
      "epoch: 0, batch: 526, loss: 2.2735979557037354\n",
      "epoch: 0, batch: 527, loss: 2.2773935794830322\n",
      "epoch: 0, batch: 528, loss: 2.2921929359436035\n",
      "epoch: 0, batch: 529, loss: 2.2992231845855713\n",
      "epoch: 0, batch: 530, loss: 2.2998719215393066\n",
      "epoch: 0, batch: 531, loss: 2.282644510269165\n",
      "epoch: 0, batch: 532, loss: 2.2762253284454346\n",
      "epoch: 0, batch: 533, loss: 2.296660900115967\n",
      "epoch: 0, batch: 534, loss: 2.2575795650482178\n",
      "epoch: 0, batch: 535, loss: 2.2746429443359375\n",
      "epoch: 0, batch: 536, loss: 2.271186590194702\n",
      "epoch: 0, batch: 537, loss: 2.300177574157715\n",
      "epoch: 0, batch: 538, loss: 2.270526885986328\n",
      "epoch: 0, batch: 539, loss: 2.2884292602539062\n",
      "epoch: 0, batch: 540, loss: 2.2826099395751953\n",
      "epoch: 0, batch: 541, loss: 2.2803173065185547\n",
      "epoch: 0, batch: 542, loss: 2.2820217609405518\n",
      "epoch: 0, batch: 543, loss: 2.2903218269348145\n",
      "epoch: 0, batch: 544, loss: 2.2701170444488525\n",
      "epoch: 0, batch: 545, loss: 2.2794268131256104\n",
      "epoch: 0, batch: 546, loss: 2.2865042686462402\n",
      "epoch: 0, batch: 547, loss: 2.283775568008423\n",
      "epoch: 0, batch: 548, loss: 2.3160836696624756\n",
      "epoch: 0, batch: 549, loss: 2.300623655319214\n",
      "epoch: 0, batch: 550, loss: 2.299788475036621\n",
      "epoch: 0, batch: 551, loss: 2.299994468688965\n",
      "epoch: 0, batch: 552, loss: 2.2667043209075928\n",
      "epoch: 0, batch: 553, loss: 2.2911336421966553\n",
      "epoch: 0, batch: 554, loss: 2.3082799911499023\n",
      "epoch: 0, batch: 555, loss: 2.290748357772827\n",
      "epoch: 0, batch: 556, loss: 2.2717747688293457\n",
      "epoch: 0, batch: 557, loss: 2.298933982849121\n",
      "epoch: 0, batch: 558, loss: 2.263615369796753\n",
      "epoch: 0, batch: 559, loss: 2.3146345615386963\n",
      "epoch: 0, batch: 560, loss: 2.294839859008789\n",
      "epoch: 0, batch: 561, loss: 2.2883315086364746\n",
      "epoch: 0, batch: 562, loss: 2.3075664043426514\n",
      "epoch: 0, batch: 563, loss: 2.305671453475952\n",
      "epoch: 0, batch: 564, loss: 2.2877628803253174\n",
      "epoch: 0, batch: 565, loss: 2.3028621673583984\n",
      "epoch: 0, batch: 566, loss: 2.2780003547668457\n",
      "epoch: 0, batch: 567, loss: 2.3198280334472656\n",
      "epoch: 0, batch: 568, loss: 2.3116631507873535\n",
      "epoch: 0, batch: 569, loss: 2.2808120250701904\n",
      "epoch: 0, batch: 570, loss: 2.2655718326568604\n",
      "epoch: 0, batch: 571, loss: 2.274252414703369\n",
      "epoch: 0, batch: 572, loss: 2.2763869762420654\n",
      "epoch: 0, batch: 573, loss: 2.292541980743408\n",
      "epoch: 0, batch: 574, loss: 2.2834689617156982\n",
      "epoch: 0, batch: 575, loss: 2.3140761852264404\n",
      "epoch: 0, batch: 576, loss: 2.269948720932007\n",
      "epoch: 0, batch: 577, loss: 2.28983736038208\n",
      "epoch: 0, batch: 578, loss: 2.2810118198394775\n",
      "epoch: 0, batch: 579, loss: 2.315903902053833\n",
      "epoch: 0, batch: 580, loss: 2.2719149589538574\n",
      "epoch: 0, batch: 581, loss: 2.3083198070526123\n",
      "epoch: 0, batch: 582, loss: 2.2841081619262695\n",
      "epoch: 0, batch: 583, loss: 2.290161371231079\n",
      "epoch: 0, batch: 584, loss: 2.279885768890381\n",
      "epoch: 0, batch: 585, loss: 2.284384250640869\n",
      "epoch: 0, batch: 586, loss: 2.3009371757507324\n",
      "epoch: 0, batch: 587, loss: 2.2699806690216064\n",
      "epoch: 0, batch: 588, loss: 2.275655508041382\n",
      "epoch: 0, batch: 589, loss: 2.2910778522491455\n",
      "epoch: 0, batch: 590, loss: 2.2821412086486816\n",
      "epoch: 0, batch: 591, loss: 2.2991862297058105\n",
      "epoch: 0, batch: 592, loss: 2.300967216491699\n",
      "epoch: 0, batch: 593, loss: 2.2907297611236572\n",
      "epoch: 0, batch: 594, loss: 2.3097071647644043\n",
      "epoch: 0, batch: 595, loss: 2.2988393306732178\n",
      "epoch: 0, batch: 596, loss: 2.280730724334717\n",
      "epoch: 0, batch: 597, loss: 2.2864267826080322\n",
      "epoch: 0, batch: 598, loss: 2.2995662689208984\n",
      "epoch: 0, batch: 599, loss: 2.295203447341919\n",
      "epoch: 0, batch: 600, loss: 2.310124635696411\n",
      "epoch: 0, batch: 601, loss: 2.3010551929473877\n",
      "epoch: 0, batch: 602, loss: 2.294424295425415\n",
      "epoch: 0, batch: 603, loss: 2.284196615219116\n",
      "epoch: 0, batch: 604, loss: 2.287132978439331\n",
      "epoch: 0, batch: 605, loss: 2.250819444656372\n",
      "epoch: 0, batch: 606, loss: 2.294381856918335\n",
      "epoch: 0, batch: 607, loss: 2.287945032119751\n",
      "epoch: 0, batch: 608, loss: 2.3177711963653564\n",
      "epoch: 0, batch: 609, loss: 2.2788283824920654\n",
      "epoch: 0, batch: 610, loss: 2.2912633419036865\n",
      "epoch: 0, batch: 611, loss: 2.271117687225342\n",
      "epoch: 0, batch: 612, loss: 2.268110752105713\n",
      "epoch: 0, batch: 613, loss: 2.300116539001465\n",
      "epoch: 0, batch: 614, loss: 2.2779812812805176\n",
      "epoch: 0, batch: 615, loss: 2.2937064170837402\n",
      "epoch: 0, batch: 616, loss: 2.285062551498413\n",
      "epoch: 0, batch: 617, loss: 2.305964469909668\n",
      "epoch: 0, batch: 618, loss: 2.310612678527832\n",
      "epoch: 0, batch: 619, loss: 2.3135273456573486\n",
      "epoch: 0, batch: 620, loss: 2.2803454399108887\n",
      "epoch: 0, batch: 621, loss: 2.276376724243164\n",
      "epoch: 0, batch: 622, loss: 2.285447597503662\n",
      "epoch: 0, batch: 623, loss: 2.291093349456787\n",
      "epoch: 0, batch: 624, loss: 2.2910492420196533\n",
      "epoch: 0, batch: 625, loss: 2.302067279815674\n",
      "epoch: 0, batch: 626, loss: 2.2966208457946777\n",
      "epoch: 0, batch: 627, loss: 2.2879891395568848\n",
      "epoch: 0, batch: 628, loss: 2.3007888793945312\n",
      "epoch: 0, batch: 629, loss: 2.2890517711639404\n",
      "epoch: 0, batch: 630, loss: 2.287709951400757\n",
      "epoch: 0, batch: 631, loss: 2.290712594985962\n",
      "epoch: 0, batch: 632, loss: 2.2898967266082764\n",
      "epoch: 0, batch: 633, loss: 2.2744457721710205\n",
      "epoch: 0, batch: 634, loss: 2.2610654830932617\n",
      "epoch: 0, batch: 635, loss: 2.284491539001465\n",
      "epoch: 0, batch: 636, loss: 2.290576696395874\n",
      "epoch: 0, batch: 637, loss: 2.317913770675659\n",
      "epoch: 0, batch: 638, loss: 2.2944514751434326\n",
      "epoch: 0, batch: 639, loss: 2.287379741668701\n",
      "epoch: 0, batch: 640, loss: 2.302089214324951\n",
      "epoch: 0, batch: 641, loss: 2.273933172225952\n",
      "epoch: 0, batch: 642, loss: 2.2723798751831055\n",
      "epoch: 0, batch: 643, loss: 2.26666259765625\n",
      "epoch: 0, batch: 644, loss: 2.2662880420684814\n",
      "epoch: 0, batch: 645, loss: 2.2853453159332275\n",
      "epoch: 0, batch: 646, loss: 2.289797306060791\n",
      "epoch: 0, batch: 647, loss: 2.2911057472229004\n",
      "epoch: 0, batch: 648, loss: 2.2858777046203613\n",
      "epoch: 0, batch: 649, loss: 2.308612108230591\n",
      "epoch: 0, batch: 650, loss: 2.263253688812256\n",
      "epoch: 0, batch: 651, loss: 2.286238193511963\n",
      "epoch: 0, batch: 652, loss: 2.303615093231201\n",
      "epoch: 0, batch: 653, loss: 2.293760299682617\n",
      "epoch: 0, batch: 654, loss: 2.2704527378082275\n",
      "epoch: 0, batch: 655, loss: 2.2651801109313965\n",
      "epoch: 0, batch: 656, loss: 2.269768714904785\n",
      "epoch: 0, batch: 657, loss: 2.2780401706695557\n",
      "epoch: 0, batch: 658, loss: 2.269139528274536\n",
      "epoch: 0, batch: 659, loss: 2.267825126647949\n",
      "epoch: 0, batch: 660, loss: 2.267305612564087\n",
      "epoch: 0, batch: 661, loss: 2.314817190170288\n",
      "epoch: 0, batch: 662, loss: 2.2884585857391357\n",
      "epoch: 0, batch: 663, loss: 2.2681007385253906\n",
      "epoch: 0, batch: 664, loss: 2.259984254837036\n",
      "epoch: 0, batch: 665, loss: 2.2875285148620605\n",
      "epoch: 0, batch: 666, loss: 2.281395435333252\n",
      "epoch: 0, batch: 667, loss: 2.3189494609832764\n",
      "epoch: 0, batch: 668, loss: 2.2696266174316406\n",
      "epoch: 0, batch: 669, loss: 2.268770933151245\n",
      "epoch: 0, batch: 670, loss: 2.3161380290985107\n",
      "epoch: 0, batch: 671, loss: 2.2690439224243164\n",
      "epoch: 0, batch: 672, loss: 2.3160250186920166\n",
      "epoch: 0, batch: 673, loss: 2.2684967517852783\n",
      "epoch: 0, batch: 674, loss: 2.2653231620788574\n",
      "epoch: 0, batch: 675, loss: 2.297668933868408\n",
      "epoch: 0, batch: 676, loss: 2.2795357704162598\n",
      "epoch: 0, batch: 677, loss: 2.3157527446746826\n",
      "epoch: 0, batch: 678, loss: 2.280320167541504\n",
      "epoch: 0, batch: 679, loss: 2.3204987049102783\n",
      "epoch: 0, batch: 680, loss: 2.293290615081787\n",
      "epoch: 0, batch: 681, loss: 2.279895544052124\n",
      "epoch: 0, batch: 682, loss: 2.3035237789154053\n",
      "epoch: 0, batch: 683, loss: 2.30167293548584\n",
      "epoch: 0, batch: 684, loss: 2.3089869022369385\n",
      "epoch: 0, batch: 685, loss: 2.2918331623077393\n",
      "epoch: 0, batch: 686, loss: 2.281385898590088\n",
      "epoch: 0, batch: 687, loss: 2.2675392627716064\n",
      "epoch: 0, batch: 688, loss: 2.2700297832489014\n",
      "epoch: 0, batch: 689, loss: 2.2985498905181885\n",
      "epoch: 0, batch: 690, loss: 2.2930967807769775\n",
      "epoch: 0, batch: 691, loss: 2.2984778881073\n",
      "epoch: 0, batch: 692, loss: 2.2893214225769043\n",
      "epoch: 0, batch: 693, loss: 2.3175606727600098\n",
      "epoch: 0, batch: 694, loss: 2.278902769088745\n",
      "epoch: 0, batch: 695, loss: 2.2967841625213623\n",
      "epoch: 0, batch: 696, loss: 2.2875919342041016\n",
      "epoch: 0, batch: 697, loss: 2.2680442333221436\n",
      "epoch: 0, batch: 698, loss: 2.2886877059936523\n",
      "epoch: 0, batch: 699, loss: 2.277634859085083\n",
      "epoch: 0, batch: 700, loss: 2.3158838748931885\n",
      "epoch: 0, batch: 701, loss: 2.270979166030884\n",
      "epoch: 0, batch: 702, loss: 2.2732415199279785\n",
      "epoch: 0, batch: 703, loss: 2.302079916000366\n",
      "epoch: 0, batch: 704, loss: 2.2677488327026367\n",
      "epoch: 0, batch: 705, loss: 2.2846295833587646\n",
      "epoch: 0, batch: 706, loss: 2.2707149982452393\n",
      "epoch: 0, batch: 707, loss: 2.2904703617095947\n",
      "epoch: 0, batch: 708, loss: 2.293915033340454\n",
      "epoch: 0, batch: 709, loss: 2.2836949825286865\n",
      "epoch: 0, batch: 710, loss: 2.297441005706787\n",
      "epoch: 0, batch: 711, loss: 2.302769184112549\n",
      "epoch: 0, batch: 712, loss: 2.3022258281707764\n",
      "epoch: 0, batch: 713, loss: 2.2810921669006348\n",
      "epoch: 0, batch: 714, loss: 2.2774319648742676\n",
      "epoch: 0, batch: 715, loss: 2.263781785964966\n",
      "epoch: 0, batch: 716, loss: 2.314908981323242\n",
      "epoch: 0, batch: 717, loss: 2.27838134765625\n",
      "epoch: 0, batch: 718, loss: 2.2856242656707764\n",
      "epoch: 0, batch: 719, loss: 2.311246871948242\n",
      "epoch: 0, batch: 720, loss: 2.2820932865142822\n",
      "epoch: 0, batch: 721, loss: 2.2906527519226074\n",
      "epoch: 0, batch: 722, loss: 2.2809035778045654\n",
      "epoch: 0, batch: 723, loss: 2.3074638843536377\n",
      "epoch: 0, batch: 724, loss: 2.27677321434021\n",
      "epoch: 0, batch: 725, loss: 2.2917933464050293\n",
      "epoch: 0, batch: 726, loss: 2.3023228645324707\n",
      "epoch: 0, batch: 727, loss: 2.28849458694458\n",
      "epoch: 0, batch: 728, loss: 2.283285140991211\n",
      "epoch: 0, batch: 729, loss: 2.28183650970459\n",
      "epoch: 0, batch: 730, loss: 2.3137412071228027\n",
      "epoch: 0, batch: 731, loss: 2.278531551361084\n",
      "epoch: 0, batch: 732, loss: 2.30375599861145\n",
      "epoch: 0, batch: 733, loss: 2.3017680644989014\n",
      "epoch: 0, batch: 734, loss: 2.293226957321167\n",
      "epoch: 0, batch: 735, loss: 2.303947925567627\n",
      "epoch: 0, batch: 736, loss: 2.2907052040100098\n",
      "epoch: 0, batch: 737, loss: 2.273895025253296\n",
      "epoch: 0, batch: 738, loss: 2.279672622680664\n",
      "epoch: 0, batch: 739, loss: 2.298583507537842\n",
      "epoch: 0, batch: 740, loss: 2.288837194442749\n",
      "epoch: 0, batch: 741, loss: 2.276447296142578\n",
      "epoch: 0, batch: 742, loss: 2.29612398147583\n",
      "epoch: 0, batch: 743, loss: 2.288516044616699\n",
      "epoch: 0, batch: 744, loss: 2.259328603744507\n",
      "epoch: 0, batch: 745, loss: 2.272101402282715\n",
      "epoch: 0, batch: 746, loss: 2.311896562576294\n",
      "epoch: 0, batch: 747, loss: 2.284480094909668\n",
      "epoch: 0, batch: 748, loss: 2.2865257263183594\n",
      "epoch: 0, batch: 749, loss: 2.281323194503784\n",
      "epoch: 0, batch: 750, loss: 2.282844305038452\n",
      "epoch: 0, batch: 751, loss: 2.285722494125366\n",
      "epoch: 0, batch: 752, loss: 2.2808022499084473\n",
      "epoch: 0, batch: 753, loss: 2.3065507411956787\n",
      "epoch: 0, batch: 754, loss: 2.2569313049316406\n",
      "epoch: 0, batch: 755, loss: 2.27837872505188\n",
      "epoch: 0, batch: 756, loss: 2.287579298019409\n",
      "epoch: 0, batch: 757, loss: 2.279397964477539\n",
      "epoch: 0, batch: 758, loss: 2.2621309757232666\n",
      "epoch: 0, batch: 759, loss: 2.2761025428771973\n",
      "epoch: 0, batch: 760, loss: 2.263956308364868\n",
      "epoch: 0, batch: 761, loss: 2.290264844894409\n",
      "epoch: 0, batch: 762, loss: 2.2861530780792236\n",
      "epoch: 0, batch: 763, loss: 2.2732505798339844\n",
      "epoch: 0, batch: 764, loss: 2.272878885269165\n",
      "epoch: 0, batch: 765, loss: 2.2882823944091797\n",
      "epoch: 0, batch: 766, loss: 2.2869889736175537\n",
      "epoch: 0, batch: 767, loss: 2.2844200134277344\n",
      "epoch: 0, batch: 768, loss: 2.274942636489868\n",
      "epoch: 0, batch: 769, loss: 2.2937986850738525\n",
      "epoch: 0, batch: 770, loss: 2.3060476779937744\n",
      "epoch: 0, batch: 771, loss: 2.290301561355591\n",
      "epoch: 0, batch: 772, loss: 2.289236068725586\n",
      "epoch: 0, batch: 773, loss: 2.2906250953674316\n",
      "epoch: 0, batch: 774, loss: 2.2831695079803467\n",
      "epoch: 0, batch: 775, loss: 2.2833609580993652\n",
      "epoch: 0, batch: 776, loss: 2.291832208633423\n",
      "epoch: 0, batch: 777, loss: 2.3042092323303223\n",
      "epoch: 0, batch: 778, loss: 2.2734808921813965\n",
      "epoch: 0, batch: 779, loss: 2.2937991619110107\n",
      "epoch: 0, batch: 780, loss: 2.28939151763916\n",
      "epoch: 0, batch: 781, loss: 2.2974853515625\n",
      "epoch: 0, batch: 782, loss: 2.2688028812408447\n",
      "epoch: 0, batch: 783, loss: 2.3020944595336914\n",
      "epoch: 0, batch: 784, loss: 2.2703044414520264\n",
      "epoch: 0, batch: 785, loss: 2.2502455711364746\n",
      "epoch: 0, batch: 786, loss: 2.300628900527954\n",
      "epoch: 0, batch: 787, loss: 2.2686800956726074\n",
      "epoch: 0, batch: 788, loss: 2.322237491607666\n",
      "epoch: 0, batch: 789, loss: 2.2977802753448486\n",
      "epoch: 0, batch: 790, loss: 2.2899441719055176\n",
      "epoch: 0, batch: 791, loss: 2.28080153465271\n",
      "epoch: 0, batch: 792, loss: 2.2936718463897705\n",
      "epoch: 0, batch: 793, loss: 2.304023265838623\n",
      "epoch: 0, batch: 794, loss: 2.274670362472534\n",
      "epoch: 0, batch: 795, loss: 2.277486801147461\n",
      "epoch: 0, batch: 796, loss: 2.3051693439483643\n",
      "epoch: 0, batch: 797, loss: 2.280592441558838\n",
      "epoch: 0, batch: 798, loss: 2.296487331390381\n",
      "epoch: 0, batch: 799, loss: 2.28293776512146\n",
      "epoch: 0, batch: 800, loss: 2.281271457672119\n",
      "epoch: 0, batch: 801, loss: 2.2617015838623047\n",
      "epoch: 0, batch: 802, loss: 2.262516736984253\n",
      "epoch: 0, batch: 803, loss: 2.2810401916503906\n",
      "epoch: 0, batch: 804, loss: 2.315077304840088\n",
      "epoch: 0, batch: 805, loss: 2.300443410873413\n",
      "epoch: 0, batch: 806, loss: 2.2665317058563232\n",
      "epoch: 0, batch: 807, loss: 2.277953863143921\n",
      "epoch: 0, batch: 808, loss: 2.2689530849456787\n",
      "epoch: 0, batch: 809, loss: 2.2815451622009277\n",
      "epoch: 0, batch: 810, loss: 2.2937800884246826\n",
      "epoch: 0, batch: 811, loss: 2.266591787338257\n",
      "epoch: 0, batch: 812, loss: 2.3073678016662598\n",
      "epoch: 0, batch: 813, loss: 2.2815024852752686\n",
      "epoch: 0, batch: 814, loss: 2.2712817192077637\n",
      "epoch: 0, batch: 815, loss: 2.2951231002807617\n",
      "epoch: 0, batch: 816, loss: 2.290527820587158\n",
      "epoch: 0, batch: 817, loss: 2.29280161857605\n",
      "epoch: 0, batch: 818, loss: 2.2670977115631104\n",
      "epoch: 0, batch: 819, loss: 2.31011962890625\n",
      "epoch: 0, batch: 820, loss: 2.299731731414795\n",
      "epoch: 0, batch: 821, loss: 2.2705307006835938\n",
      "epoch: 0, batch: 822, loss: 2.2695629596710205\n",
      "epoch: 0, batch: 823, loss: 2.2575674057006836\n",
      "epoch: 0, batch: 824, loss: 2.295088768005371\n",
      "epoch: 0, batch: 825, loss: 2.3055331707000732\n",
      "epoch: 0, batch: 826, loss: 2.2843446731567383\n",
      "epoch: 0, batch: 827, loss: 2.273163080215454\n",
      "epoch: 0, batch: 828, loss: 2.287724256515503\n",
      "epoch: 0, batch: 829, loss: 2.296788454055786\n",
      "epoch: 0, batch: 830, loss: 2.292313814163208\n",
      "epoch: 0, batch: 831, loss: 2.2717597484588623\n",
      "epoch: 0, batch: 832, loss: 2.279337167739868\n",
      "epoch: 0, batch: 833, loss: 2.292508602142334\n",
      "epoch: 0, batch: 834, loss: 2.3043324947357178\n",
      "epoch: 0, batch: 835, loss: 2.248767375946045\n",
      "epoch: 0, batch: 836, loss: 2.3092432022094727\n",
      "epoch: 0, batch: 837, loss: 2.2711610794067383\n",
      "epoch: 0, batch: 838, loss: 2.2910993099212646\n",
      "epoch: 0, batch: 839, loss: 2.2765848636627197\n",
      "epoch: 0, batch: 840, loss: 2.293391227722168\n",
      "epoch: 0, batch: 841, loss: 2.2743308544158936\n",
      "epoch: 0, batch: 842, loss: 2.2832396030426025\n",
      "epoch: 0, batch: 843, loss: 2.2873892784118652\n",
      "epoch: 0, batch: 844, loss: 2.282607316970825\n",
      "epoch: 0, batch: 845, loss: 2.2837650775909424\n",
      "epoch: 0, batch: 846, loss: 2.3055622577667236\n",
      "epoch: 0, batch: 847, loss: 2.3042995929718018\n",
      "epoch: 0, batch: 848, loss: 2.2693958282470703\n",
      "epoch: 0, batch: 849, loss: 2.282327890396118\n",
      "epoch: 0, batch: 850, loss: 2.255906581878662\n",
      "epoch: 0, batch: 851, loss: 2.2748141288757324\n",
      "epoch: 0, batch: 852, loss: 2.310173511505127\n",
      "epoch: 0, batch: 853, loss: 2.2921009063720703\n",
      "epoch: 0, batch: 854, loss: 2.2845935821533203\n",
      "epoch: 0, batch: 855, loss: 2.290801525115967\n",
      "epoch: 0, batch: 856, loss: 2.275864601135254\n",
      "epoch: 0, batch: 857, loss: 2.2943859100341797\n",
      "epoch: 0, batch: 858, loss: 2.260758876800537\n",
      "epoch: 0, batch: 859, loss: 2.256117820739746\n",
      "epoch: 0, batch: 860, loss: 2.2937357425689697\n",
      "epoch: 0, batch: 861, loss: 2.2735848426818848\n",
      "epoch: 0, batch: 862, loss: 2.2816953659057617\n",
      "epoch: 0, batch: 863, loss: 2.2999484539031982\n",
      "epoch: 0, batch: 864, loss: 2.252777099609375\n",
      "epoch: 0, batch: 865, loss: 2.3059403896331787\n",
      "epoch: 0, batch: 866, loss: 2.311234712600708\n",
      "epoch: 0, batch: 867, loss: 2.2902867794036865\n",
      "epoch: 0, batch: 868, loss: 2.314021110534668\n",
      "epoch: 0, batch: 869, loss: 2.2757747173309326\n",
      "epoch: 0, batch: 870, loss: 2.2883036136627197\n",
      "epoch: 0, batch: 871, loss: 2.288922071456909\n",
      "epoch: 0, batch: 872, loss: 2.2731783390045166\n",
      "epoch: 0, batch: 873, loss: 2.2881572246551514\n",
      "epoch: 0, batch: 874, loss: 2.281092643737793\n",
      "epoch: 0, batch: 875, loss: 2.2735440731048584\n",
      "epoch: 0, batch: 876, loss: 2.2832322120666504\n",
      "epoch: 0, batch: 877, loss: 2.264232873916626\n",
      "epoch: 0, batch: 878, loss: 2.309056520462036\n",
      "epoch: 0, batch: 879, loss: 2.2900500297546387\n",
      "epoch: 0, batch: 880, loss: 2.2662947177886963\n",
      "epoch: 0, batch: 881, loss: 2.285968542098999\n",
      "epoch: 0, batch: 882, loss: 2.2815568447113037\n",
      "epoch: 0, batch: 883, loss: 2.287494659423828\n",
      "epoch: 0, batch: 884, loss: 2.292593240737915\n",
      "epoch: 0, batch: 885, loss: 2.2928121089935303\n",
      "epoch: 0, batch: 886, loss: 2.275820732116699\n",
      "epoch: 0, batch: 887, loss: 2.278272867202759\n",
      "epoch: 0, batch: 888, loss: 2.282254695892334\n",
      "epoch: 0, batch: 889, loss: 2.3003954887390137\n",
      "epoch: 0, batch: 890, loss: 2.317493200302124\n",
      "epoch: 0, batch: 891, loss: 2.288189649581909\n",
      "epoch: 0, batch: 892, loss: 2.2631149291992188\n",
      "epoch: 0, batch: 893, loss: 2.2572169303894043\n",
      "epoch: 0, batch: 894, loss: 2.2713208198547363\n",
      "epoch: 0, batch: 895, loss: 2.304854393005371\n",
      "epoch: 0, batch: 896, loss: 2.284733295440674\n",
      "epoch: 0, batch: 897, loss: 2.2914509773254395\n",
      "epoch: 0, batch: 898, loss: 2.2785143852233887\n",
      "epoch: 0, batch: 899, loss: 2.2893285751342773\n",
      "epoch: 0, batch: 900, loss: 2.2827634811401367\n",
      "epoch: 0, batch: 901, loss: 2.2543413639068604\n",
      "epoch: 0, batch: 902, loss: 2.261052370071411\n",
      "epoch: 0, batch: 903, loss: 2.2678701877593994\n",
      "epoch: 0, batch: 904, loss: 2.2695798873901367\n",
      "epoch: 0, batch: 905, loss: 2.240398645401001\n",
      "epoch: 0, batch: 906, loss: 2.2745718955993652\n",
      "epoch: 0, batch: 907, loss: 2.2586722373962402\n",
      "epoch: 0, batch: 908, loss: 2.2400734424591064\n",
      "epoch: 0, batch: 909, loss: 2.278055191040039\n",
      "epoch: 0, batch: 910, loss: 2.277569055557251\n",
      "epoch: 0, batch: 911, loss: 2.232369899749756\n",
      "epoch: 0, batch: 912, loss: 2.2625837326049805\n",
      "epoch: 0, batch: 913, loss: 2.28029727935791\n",
      "epoch: 0, batch: 914, loss: 2.2918059825897217\n",
      "epoch: 0, batch: 915, loss: 2.2864582538604736\n",
      "epoch: 0, batch: 916, loss: 2.275940418243408\n",
      "epoch: 0, batch: 917, loss: 2.282036304473877\n",
      "epoch: 0, batch: 918, loss: 2.2723355293273926\n",
      "epoch: 0, batch: 919, loss: 2.285551071166992\n",
      "epoch: 0, batch: 920, loss: 2.287621259689331\n",
      "epoch: 0, batch: 921, loss: 2.2737486362457275\n",
      "epoch: 0, batch: 922, loss: 2.279855728149414\n",
      "epoch: 0, batch: 923, loss: 2.2527079582214355\n",
      "epoch: 0, batch: 924, loss: 2.278054714202881\n",
      "epoch: 0, batch: 925, loss: 2.276873826980591\n",
      "epoch: 0, batch: 926, loss: 2.2808964252471924\n",
      "epoch: 0, batch: 927, loss: 2.2509608268737793\n",
      "epoch: 0, batch: 928, loss: 2.2635278701782227\n",
      "epoch: 0, batch: 929, loss: 2.2548062801361084\n",
      "epoch: 0, batch: 930, loss: 2.276470899581909\n",
      "epoch: 0, batch: 931, loss: 2.304286003112793\n",
      "epoch: 0, batch: 932, loss: 2.2802629470825195\n",
      "epoch: 0, batch: 933, loss: 2.2674968242645264\n",
      "epoch: 0, batch: 934, loss: 2.2917275428771973\n",
      "epoch: 0, batch: 935, loss: 2.285451889038086\n",
      "epoch: 0, batch: 936, loss: 2.278979778289795\n",
      "epoch: 0, batch: 937, loss: 2.294769287109375\n",
      "epoch: 0, batch: 938, loss: 2.2859768867492676\n",
      "epoch: 0, batch: 939, loss: 2.265808343887329\n",
      "epoch: 0, batch: 940, loss: 2.2707855701446533\n",
      "epoch: 0, batch: 941, loss: 2.2649085521698\n",
      "epoch: 0, batch: 942, loss: 2.282686710357666\n",
      "epoch: 0, batch: 943, loss: 2.2627556324005127\n",
      "epoch: 0, batch: 944, loss: 2.2619876861572266\n",
      "epoch: 0, batch: 945, loss: 2.264470338821411\n",
      "epoch: 0, batch: 946, loss: 2.2872183322906494\n",
      "epoch: 0, batch: 947, loss: 2.273097515106201\n",
      "epoch: 0, batch: 948, loss: 2.289816379547119\n",
      "epoch: 0, batch: 949, loss: 2.283280611038208\n",
      "epoch: 0, batch: 950, loss: 2.279317617416382\n",
      "epoch: 0, batch: 951, loss: 2.2665934562683105\n",
      "epoch: 0, batch: 952, loss: 2.254025459289551\n",
      "epoch: 0, batch: 953, loss: 2.2590389251708984\n",
      "epoch: 0, batch: 954, loss: 2.2737531661987305\n",
      "epoch: 0, batch: 955, loss: 2.2844929695129395\n",
      "epoch: 0, batch: 956, loss: 2.271655321121216\n",
      "epoch: 0, batch: 957, loss: 2.2501590251922607\n",
      "epoch: 0, batch: 958, loss: 2.274010419845581\n",
      "epoch: 0, batch: 959, loss: 2.2771084308624268\n",
      "epoch: 0, batch: 960, loss: 2.298851251602173\n",
      "epoch: 0, batch: 961, loss: 2.25937819480896\n",
      "epoch: 0, batch: 962, loss: 2.284250020980835\n",
      "epoch: 0, batch: 963, loss: 2.2795255184173584\n",
      "epoch: 0, batch: 964, loss: 2.224276304244995\n",
      "epoch: 0, batch: 965, loss: 2.280595302581787\n",
      "epoch: 0, batch: 966, loss: 2.2662782669067383\n",
      "epoch: 0, batch: 967, loss: 2.2628514766693115\n",
      "epoch: 0, batch: 968, loss: 2.3117270469665527\n",
      "epoch: 0, batch: 969, loss: 2.2677969932556152\n",
      "epoch: 0, batch: 970, loss: 2.249598979949951\n",
      "epoch: 0, batch: 971, loss: 2.3083949089050293\n",
      "epoch: 0, batch: 972, loss: 2.291193962097168\n",
      "epoch: 0, batch: 973, loss: 2.314707040786743\n",
      "epoch: 0, batch: 974, loss: 2.255152702331543\n",
      "epoch: 0, batch: 975, loss: 2.275237560272217\n",
      "epoch: 0, batch: 976, loss: 2.249504327774048\n",
      "epoch: 0, batch: 977, loss: 2.2965478897094727\n",
      "epoch: 0, batch: 978, loss: 2.2697436809539795\n",
      "epoch: 0, batch: 979, loss: 2.2760627269744873\n",
      "epoch: 0, batch: 980, loss: 2.2775018215179443\n",
      "epoch: 0, batch: 981, loss: 2.2877309322357178\n",
      "epoch: 0, batch: 982, loss: 2.27315354347229\n",
      "epoch: 0, batch: 983, loss: 2.278244972229004\n",
      "epoch: 0, batch: 984, loss: 2.287665843963623\n",
      "epoch: 0, batch: 985, loss: 2.2929975986480713\n",
      "epoch: 0, batch: 986, loss: 2.2815186977386475\n",
      "epoch: 0, batch: 987, loss: 2.2922983169555664\n",
      "epoch: 0, batch: 988, loss: 2.2681825160980225\n",
      "epoch: 0, batch: 989, loss: 2.2769501209259033\n",
      "epoch: 0, batch: 990, loss: 2.259366035461426\n",
      "epoch: 0, batch: 991, loss: 2.284975051879883\n",
      "epoch: 0, batch: 992, loss: 2.326052188873291\n",
      "epoch: 0, batch: 993, loss: 2.278010368347168\n",
      "epoch: 0, batch: 994, loss: 2.295016288757324\n",
      "epoch: 0, batch: 995, loss: 2.3000431060791016\n",
      "epoch: 0, batch: 996, loss: 2.2864255905151367\n",
      "epoch: 0, batch: 997, loss: 2.2668206691741943\n",
      "epoch: 0, batch: 998, loss: 2.262570381164551\n",
      "epoch: 0, batch: 999, loss: 2.282776117324829\n",
      "epoch: 0, batch: 1000, loss: 2.2707700729370117\n",
      "epoch: 0, batch: 1001, loss: 2.2657880783081055\n",
      "epoch: 0, batch: 1002, loss: 2.271190881729126\n",
      "epoch: 0, batch: 1003, loss: 2.277463674545288\n",
      "epoch: 0, batch: 1004, loss: 2.288313627243042\n",
      "epoch: 0, batch: 1005, loss: 2.269745349884033\n",
      "epoch: 0, batch: 1006, loss: 2.2687761783599854\n",
      "epoch: 0, batch: 1007, loss: 2.2709882259368896\n",
      "epoch: 0, batch: 1008, loss: 2.262612819671631\n",
      "epoch: 0, batch: 1009, loss: 2.309924602508545\n",
      "epoch: 0, batch: 1010, loss: 2.2740135192871094\n",
      "epoch: 0, batch: 1011, loss: 2.262173891067505\n",
      "epoch: 0, batch: 1012, loss: 2.30183744430542\n",
      "epoch: 0, batch: 1013, loss: 2.317959785461426\n",
      "epoch: 0, batch: 1014, loss: 2.2621138095855713\n",
      "epoch: 0, batch: 1015, loss: 2.2942628860473633\n",
      "epoch: 0, batch: 1016, loss: 2.283663034439087\n",
      "epoch: 0, batch: 1017, loss: 2.2577953338623047\n",
      "epoch: 0, batch: 1018, loss: 2.2836081981658936\n",
      "epoch: 0, batch: 1019, loss: 2.268587350845337\n",
      "epoch: 0, batch: 1020, loss: 2.287731647491455\n",
      "epoch: 0, batch: 1021, loss: 2.2879838943481445\n",
      "epoch: 0, batch: 1022, loss: 2.2577526569366455\n",
      "epoch: 0, batch: 1023, loss: 2.288074016571045\n",
      "epoch: 0, batch: 1024, loss: 2.271411180496216\n",
      "epoch: 0, batch: 1025, loss: 2.3084328174591064\n",
      "epoch: 0, batch: 1026, loss: 2.303903818130493\n",
      "epoch: 0, batch: 1027, loss: 2.2577016353607178\n",
      "epoch: 0, batch: 1028, loss: 2.2689459323883057\n",
      "epoch: 0, batch: 1029, loss: 2.27933931350708\n",
      "epoch: 0, batch: 1030, loss: 2.283130168914795\n",
      "epoch: 0, batch: 1031, loss: 2.2623889446258545\n",
      "epoch: 0, batch: 1032, loss: 2.2826578617095947\n",
      "epoch: 0, batch: 1033, loss: 2.2908859252929688\n",
      "epoch: 0, batch: 1034, loss: 2.3008503913879395\n",
      "epoch: 0, batch: 1035, loss: 2.2915573120117188\n",
      "epoch: 0, batch: 1036, loss: 2.2633345127105713\n",
      "epoch: 0, batch: 1037, loss: 2.2809970378875732\n",
      "epoch: 0, batch: 1038, loss: 2.288443088531494\n",
      "epoch: 0, batch: 1039, loss: 2.278339385986328\n",
      "epoch: 0, batch: 1040, loss: 2.2630207538604736\n",
      "epoch: 0, batch: 1041, loss: 2.270150899887085\n",
      "epoch: 0, batch: 1042, loss: 2.2840816974639893\n",
      "epoch: 0, batch: 1043, loss: 2.241861343383789\n",
      "epoch: 0, batch: 1044, loss: 2.2573466300964355\n",
      "epoch: 0, batch: 1045, loss: 2.2661595344543457\n",
      "epoch: 0, batch: 1046, loss: 2.2323007583618164\n",
      "epoch: 0, batch: 1047, loss: 2.297325611114502\n",
      "epoch: 0, batch: 1048, loss: 2.2504725456237793\n",
      "epoch: 0, batch: 1049, loss: 2.261536121368408\n",
      "epoch: 0, batch: 1050, loss: 2.2634360790252686\n",
      "epoch: 0, batch: 1051, loss: 2.282177448272705\n",
      "epoch: 0, batch: 1052, loss: 2.2723350524902344\n",
      "epoch: 0, batch: 1053, loss: 2.2744619846343994\n",
      "epoch: 0, batch: 1054, loss: 2.288311004638672\n",
      "epoch: 0, batch: 1055, loss: 2.2628750801086426\n",
      "epoch: 0, batch: 1056, loss: 2.2741308212280273\n",
      "epoch: 0, batch: 1057, loss: 2.2739648818969727\n",
      "epoch: 0, batch: 1058, loss: 2.2878031730651855\n",
      "epoch: 0, batch: 1059, loss: 2.2685093879699707\n",
      "epoch: 0, batch: 1060, loss: 2.2681870460510254\n",
      "epoch: 0, batch: 1061, loss: 2.2631685733795166\n",
      "epoch: 0, batch: 1062, loss: 2.2647218704223633\n",
      "epoch: 0, batch: 1063, loss: 2.257603883743286\n",
      "epoch: 0, batch: 1064, loss: 2.23996901512146\n",
      "epoch: 0, batch: 1065, loss: 2.262641429901123\n",
      "epoch: 0, batch: 1066, loss: 2.2699291706085205\n",
      "epoch: 0, batch: 1067, loss: 2.258676528930664\n",
      "epoch: 0, batch: 1068, loss: 2.27851939201355\n",
      "epoch: 0, batch: 1069, loss: 2.263948678970337\n",
      "epoch: 0, batch: 1070, loss: 2.320035934448242\n",
      "epoch: 0, batch: 1071, loss: 2.255622386932373\n",
      "epoch: 0, batch: 1072, loss: 2.253645181655884\n",
      "epoch: 0, batch: 1073, loss: 2.2651987075805664\n",
      "epoch: 0, batch: 1074, loss: 2.268458366394043\n",
      "epoch: 0, batch: 1075, loss: 2.2602732181549072\n",
      "epoch: 0, batch: 1076, loss: 2.2597618103027344\n",
      "epoch: 0, batch: 1077, loss: 2.2867836952209473\n",
      "epoch: 0, batch: 1078, loss: 2.273183584213257\n",
      "epoch: 0, batch: 1079, loss: 2.2741003036499023\n",
      "epoch: 0, batch: 1080, loss: 2.297140121459961\n",
      "epoch: 0, batch: 1081, loss: 2.274808406829834\n",
      "epoch: 0, batch: 1082, loss: 2.2869434356689453\n",
      "epoch: 0, batch: 1083, loss: 2.2477877140045166\n",
      "epoch: 0, batch: 1084, loss: 2.251993179321289\n",
      "epoch: 0, batch: 1085, loss: 2.2924435138702393\n",
      "epoch: 0, batch: 1086, loss: 2.2746224403381348\n",
      "epoch: 0, batch: 1087, loss: 2.2726707458496094\n",
      "epoch: 0, batch: 1088, loss: 2.277904987335205\n",
      "epoch: 0, batch: 1089, loss: 2.2560930252075195\n",
      "epoch: 0, batch: 1090, loss: 2.2748546600341797\n",
      "epoch: 0, batch: 1091, loss: 2.2889137268066406\n",
      "epoch: 0, batch: 1092, loss: 2.2766354084014893\n",
      "epoch: 0, batch: 1093, loss: 2.2844760417938232\n",
      "epoch: 0, batch: 1094, loss: 2.2626609802246094\n",
      "epoch: 0, batch: 1095, loss: 2.288565158843994\n",
      "epoch: 0, batch: 1096, loss: 2.2847728729248047\n",
      "epoch: 0, batch: 1097, loss: 2.2667126655578613\n",
      "epoch: 0, batch: 1098, loss: 2.2567825317382812\n",
      "epoch: 0, batch: 1099, loss: 2.2761995792388916\n",
      "epoch: 0, batch: 1100, loss: 2.295210838317871\n",
      "epoch: 0, batch: 1101, loss: 2.2864320278167725\n",
      "epoch: 0, batch: 1102, loss: 2.2850658893585205\n",
      "epoch: 0, batch: 1103, loss: 2.2992537021636963\n",
      "epoch: 0, batch: 1104, loss: 2.269897937774658\n",
      "epoch: 0, batch: 1105, loss: 2.262397050857544\n",
      "epoch: 0, batch: 1106, loss: 2.266035556793213\n",
      "epoch: 0, batch: 1107, loss: 2.2911763191223145\n",
      "epoch: 0, batch: 1108, loss: 2.2762978076934814\n",
      "epoch: 0, batch: 1109, loss: 2.3169589042663574\n",
      "epoch: 0, batch: 1110, loss: 2.2797927856445312\n",
      "epoch: 0, batch: 1111, loss: 2.304147243499756\n",
      "epoch: 0, batch: 1112, loss: 2.277998685836792\n",
      "epoch: 0, batch: 1113, loss: 2.2947165966033936\n",
      "epoch: 0, batch: 1114, loss: 2.26953125\n",
      "epoch: 0, batch: 1115, loss: 2.289900779724121\n",
      "epoch: 0, batch: 1116, loss: 2.286389112472534\n",
      "epoch: 0, batch: 1117, loss: 2.30737566947937\n",
      "epoch: 0, batch: 1118, loss: 2.261199474334717\n",
      "epoch: 0, batch: 1119, loss: 2.256603240966797\n",
      "epoch: 0, batch: 1120, loss: 2.2773642539978027\n",
      "epoch: 0, batch: 1121, loss: 2.2784247398376465\n",
      "epoch: 0, batch: 1122, loss: 2.2621443271636963\n",
      "epoch: 0, batch: 1123, loss: 2.248296022415161\n",
      "epoch: 0, batch: 1124, loss: 2.2933945655822754\n",
      "epoch: 0, batch: 1125, loss: 2.309328317642212\n",
      "epoch: 0, batch: 1126, loss: 2.263409376144409\n",
      "epoch: 0, batch: 1127, loss: 2.288168430328369\n",
      "epoch: 0, batch: 1128, loss: 2.277599334716797\n",
      "epoch: 0, batch: 1129, loss: 2.242764472961426\n",
      "epoch: 0, batch: 1130, loss: 2.267585277557373\n",
      "epoch: 0, batch: 1131, loss: 2.259286642074585\n",
      "epoch: 0, batch: 1132, loss: 2.2377171516418457\n",
      "epoch: 0, batch: 1133, loss: 2.2515742778778076\n",
      "epoch: 0, batch: 1134, loss: 2.234408140182495\n",
      "epoch: 0, batch: 1135, loss: 2.2933504581451416\n",
      "epoch: 0, batch: 1136, loss: 2.2654802799224854\n",
      "epoch: 0, batch: 1137, loss: 2.2495980262756348\n",
      "epoch: 0, batch: 1138, loss: 2.2960104942321777\n",
      "epoch: 0, batch: 1139, loss: 2.2690300941467285\n",
      "epoch: 0, batch: 1140, loss: 2.256463050842285\n",
      "epoch: 0, batch: 1141, loss: 2.267354726791382\n",
      "epoch: 0, batch: 1142, loss: 2.293940782546997\n",
      "epoch: 0, batch: 1143, loss: 2.2736785411834717\n",
      "epoch: 0, batch: 1144, loss: 2.2706551551818848\n",
      "epoch: 0, batch: 1145, loss: 2.2624990940093994\n",
      "epoch: 0, batch: 1146, loss: 2.2722742557525635\n",
      "epoch: 0, batch: 1147, loss: 2.2675065994262695\n",
      "epoch: 0, batch: 1148, loss: 2.3009743690490723\n",
      "epoch: 0, batch: 1149, loss: 2.2815189361572266\n",
      "epoch: 0, batch: 1150, loss: 2.267699956893921\n",
      "epoch: 0, batch: 1151, loss: 2.301647186279297\n",
      "epoch: 0, batch: 1152, loss: 2.2835891246795654\n",
      "epoch: 0, batch: 1153, loss: 2.2520980834960938\n",
      "epoch: 0, batch: 1154, loss: 2.249326467514038\n",
      "epoch: 0, batch: 1155, loss: 2.2753829956054688\n",
      "epoch: 0, batch: 1156, loss: 2.272768020629883\n",
      "epoch: 0, batch: 1157, loss: 2.2423956394195557\n",
      "epoch: 0, batch: 1158, loss: 2.2748146057128906\n",
      "epoch: 0, batch: 1159, loss: 2.2628748416900635\n",
      "epoch: 0, batch: 1160, loss: 2.30853271484375\n",
      "epoch: 0, batch: 1161, loss: 2.2850217819213867\n",
      "epoch: 0, batch: 1162, loss: 2.2840447425842285\n",
      "epoch: 0, batch: 1163, loss: 2.3128316402435303\n",
      "epoch: 0, batch: 1164, loss: 2.328531265258789\n",
      "epoch: 0, batch: 1165, loss: 2.2657384872436523\n",
      "epoch: 0, batch: 1166, loss: 2.2687418460845947\n",
      "epoch: 0, batch: 1167, loss: 2.282522201538086\n",
      "epoch: 0, batch: 1168, loss: 2.275308847427368\n",
      "epoch: 0, batch: 1169, loss: 2.2762868404388428\n",
      "epoch: 0, batch: 1170, loss: 2.2977936267852783\n",
      "epoch: 0, batch: 1171, loss: 2.296588897705078\n",
      "epoch: 0, batch: 1172, loss: 2.297560453414917\n",
      "epoch: 0, batch: 1173, loss: 2.2847325801849365\n",
      "epoch: 0, batch: 1174, loss: 2.275419235229492\n",
      "epoch: 0, batch: 1175, loss: 2.3033673763275146\n",
      "epoch: 0, batch: 1176, loss: 2.2442073822021484\n",
      "epoch: 0, batch: 1177, loss: 2.2597296237945557\n",
      "epoch: 0, batch: 1178, loss: 2.264221429824829\n",
      "epoch: 0, batch: 1179, loss: 2.254664421081543\n",
      "epoch: 0, batch: 1180, loss: 2.278217077255249\n",
      "epoch: 0, batch: 1181, loss: 2.277540445327759\n",
      "epoch: 0, batch: 1182, loss: 2.262610912322998\n",
      "epoch: 0, batch: 1183, loss: 2.2684977054595947\n",
      "epoch: 0, batch: 1184, loss: 2.2525408267974854\n",
      "epoch: 0, batch: 1185, loss: 2.2656242847442627\n",
      "epoch: 0, batch: 1186, loss: 2.2757627964019775\n",
      "epoch: 0, batch: 1187, loss: 2.2809228897094727\n",
      "epoch: 0, batch: 1188, loss: 2.238710880279541\n",
      "epoch: 0, batch: 1189, loss: 2.2835137844085693\n",
      "epoch: 0, batch: 1190, loss: 2.28462815284729\n",
      "epoch: 0, batch: 1191, loss: 2.2687747478485107\n",
      "epoch: 0, batch: 1192, loss: 2.284572124481201\n",
      "epoch: 0, batch: 1193, loss: 2.263617515563965\n",
      "epoch: 0, batch: 1194, loss: 2.2599036693573\n",
      "epoch: 0, batch: 1195, loss: 2.2824602127075195\n",
      "epoch: 0, batch: 1196, loss: 2.284227132797241\n",
      "epoch: 0, batch: 1197, loss: 2.2664101123809814\n",
      "epoch: 0, batch: 1198, loss: 2.261282444000244\n",
      "epoch: 0, batch: 1199, loss: 2.3026180267333984\n",
      "epoch: 0, batch: 1200, loss: 2.291409492492676\n",
      "epoch: 0, batch: 1201, loss: 2.279578447341919\n",
      "epoch: 0, batch: 1202, loss: 2.241933822631836\n",
      "epoch: 0, batch: 1203, loss: 2.289154052734375\n",
      "epoch: 0, batch: 1204, loss: 2.2621002197265625\n",
      "epoch: 0, batch: 1205, loss: 2.301088809967041\n",
      "epoch: 0, batch: 1206, loss: 2.269906759262085\n",
      "epoch: 0, batch: 1207, loss: 2.306729316711426\n",
      "epoch: 0, batch: 1208, loss: 2.2825465202331543\n",
      "epoch: 0, batch: 1209, loss: 2.2599658966064453\n",
      "epoch: 0, batch: 1210, loss: 2.227173089981079\n",
      "epoch: 0, batch: 1211, loss: 2.2663414478302\n",
      "epoch: 0, batch: 1212, loss: 2.2534189224243164\n",
      "epoch: 0, batch: 1213, loss: 2.266798734664917\n",
      "epoch: 0, batch: 1214, loss: 2.2733957767486572\n",
      "epoch: 0, batch: 1215, loss: 2.258847713470459\n",
      "epoch: 0, batch: 1216, loss: 2.2519679069519043\n",
      "epoch: 0, batch: 1217, loss: 2.2485544681549072\n",
      "epoch: 0, batch: 1218, loss: 2.282946825027466\n",
      "epoch: 0, batch: 1219, loss: 2.272444248199463\n",
      "epoch: 0, batch: 1220, loss: 2.278024911880493\n",
      "epoch: 0, batch: 1221, loss: 2.2508351802825928\n",
      "epoch: 0, batch: 1222, loss: 2.2335004806518555\n",
      "epoch: 0, batch: 1223, loss: 2.288386583328247\n",
      "epoch: 0, batch: 1224, loss: 2.3009109497070312\n",
      "epoch: 0, batch: 1225, loss: 2.250661611557007\n",
      "epoch: 0, batch: 1226, loss: 2.2719597816467285\n",
      "epoch: 0, batch: 1227, loss: 2.240391969680786\n",
      "epoch: 0, batch: 1228, loss: 2.2283740043640137\n",
      "epoch: 0, batch: 1229, loss: 2.2882723808288574\n",
      "epoch: 0, batch: 1230, loss: 2.2678918838500977\n",
      "epoch: 0, batch: 1231, loss: 2.241894483566284\n",
      "epoch: 0, batch: 1232, loss: 2.2605581283569336\n",
      "epoch: 0, batch: 1233, loss: 2.265582323074341\n",
      "epoch: 0, batch: 1234, loss: 2.266859769821167\n",
      "epoch: 0, batch: 1235, loss: 2.282095193862915\n",
      "epoch: 0, batch: 1236, loss: 2.271662950515747\n",
      "epoch: 0, batch: 1237, loss: 2.266395330429077\n",
      "epoch: 0, batch: 1238, loss: 2.2702271938323975\n",
      "epoch: 0, batch: 1239, loss: 2.2724571228027344\n",
      "epoch: 0, batch: 1240, loss: 2.266906261444092\n",
      "epoch: 0, batch: 1241, loss: 2.26274037361145\n",
      "epoch: 0, batch: 1242, loss: 2.2712056636810303\n",
      "epoch: 0, batch: 1243, loss: 2.2684249877929688\n",
      "epoch: 0, batch: 1244, loss: 2.2854676246643066\n",
      "epoch: 0, batch: 1245, loss: 2.2964909076690674\n",
      "epoch: 0, batch: 1246, loss: 2.2567341327667236\n",
      "epoch: 0, batch: 1247, loss: 2.269299030303955\n",
      "epoch: 0, batch: 1248, loss: 2.265880584716797\n",
      "epoch: 0, batch: 1249, loss: 2.2969472408294678\n",
      "epoch: 0, batch: 1250, loss: 2.2965407371520996\n",
      "epoch: 0, batch: 1251, loss: 2.270042896270752\n",
      "epoch: 0, batch: 1252, loss: 2.272768497467041\n",
      "epoch: 0, batch: 1253, loss: 2.2680904865264893\n",
      "epoch: 0, batch: 1254, loss: 2.263218879699707\n",
      "epoch: 0, batch: 1255, loss: 2.2730190753936768\n",
      "epoch: 0, batch: 1256, loss: 2.290846586227417\n",
      "epoch: 0, batch: 1257, loss: 2.268012285232544\n",
      "epoch: 0, batch: 1258, loss: 2.265481948852539\n",
      "epoch: 0, batch: 1259, loss: 2.247687339782715\n",
      "epoch: 0, batch: 1260, loss: 2.281196117401123\n",
      "epoch: 0, batch: 1261, loss: 2.2933804988861084\n",
      "epoch: 0, batch: 1262, loss: 2.255509376525879\n",
      "epoch: 0, batch: 1263, loss: 2.286332607269287\n",
      "epoch: 0, batch: 1264, loss: 2.28159236907959\n",
      "epoch: 0, batch: 1265, loss: 2.288388729095459\n",
      "epoch: 0, batch: 1266, loss: 2.3021962642669678\n",
      "epoch: 0, batch: 1267, loss: 2.242323637008667\n",
      "epoch: 0, batch: 1268, loss: 2.2690112590789795\n",
      "epoch: 0, batch: 1269, loss: 2.2865023612976074\n",
      "epoch: 0, batch: 1270, loss: 2.2780210971832275\n",
      "epoch: 0, batch: 1271, loss: 2.251999855041504\n",
      "epoch: 0, batch: 1272, loss: 2.273399829864502\n",
      "epoch: 0, batch: 1273, loss: 2.2814464569091797\n",
      "epoch: 0, batch: 1274, loss: 2.2460105419158936\n",
      "epoch: 0, batch: 1275, loss: 2.295116901397705\n",
      "epoch: 0, batch: 1276, loss: 2.273603677749634\n",
      "epoch: 0, batch: 1277, loss: 2.241220474243164\n",
      "epoch: 0, batch: 1278, loss: 2.269071578979492\n",
      "epoch: 0, batch: 1279, loss: 2.276864767074585\n",
      "epoch: 0, batch: 1280, loss: 2.2567880153656006\n",
      "epoch: 0, batch: 1281, loss: 2.2506678104400635\n",
      "epoch: 0, batch: 1282, loss: 2.222066640853882\n",
      "epoch: 0, batch: 1283, loss: 2.250380039215088\n",
      "epoch: 0, batch: 1284, loss: 2.29209566116333\n",
      "epoch: 0, batch: 1285, loss: 2.2598423957824707\n",
      "epoch: 0, batch: 1286, loss: 2.2640204429626465\n",
      "epoch: 0, batch: 1287, loss: 2.2410166263580322\n",
      "epoch: 0, batch: 1288, loss: 2.2493937015533447\n",
      "epoch: 0, batch: 1289, loss: 2.2620935440063477\n",
      "epoch: 0, batch: 1290, loss: 2.2783024311065674\n",
      "epoch: 0, batch: 1291, loss: 2.278369903564453\n",
      "epoch: 0, batch: 1292, loss: 2.2688379287719727\n",
      "epoch: 0, batch: 1293, loss: 2.279521942138672\n",
      "epoch: 0, batch: 1294, loss: 2.2732348442077637\n",
      "epoch: 0, batch: 1295, loss: 2.266240358352661\n",
      "epoch: 0, batch: 1296, loss: 2.2618818283081055\n",
      "epoch: 0, batch: 1297, loss: 2.2909770011901855\n",
      "epoch: 0, batch: 1298, loss: 2.2572438716888428\n",
      "epoch: 0, batch: 1299, loss: 2.2353105545043945\n",
      "epoch: 0, batch: 1300, loss: 2.237921714782715\n",
      "epoch: 0, batch: 1301, loss: 2.246427536010742\n",
      "epoch: 0, batch: 1302, loss: 2.267409324645996\n",
      "epoch: 0, batch: 1303, loss: 2.232081651687622\n",
      "epoch: 0, batch: 1304, loss: 2.262768030166626\n",
      "epoch: 0, batch: 1305, loss: 2.262406826019287\n",
      "epoch: 0, batch: 1306, loss: 2.2809739112854004\n",
      "epoch: 0, batch: 1307, loss: 2.2899487018585205\n",
      "epoch: 0, batch: 1308, loss: 2.2449398040771484\n",
      "epoch: 0, batch: 1309, loss: 2.2402572631835938\n",
      "epoch: 0, batch: 1310, loss: 2.2491416931152344\n",
      "epoch: 0, batch: 1311, loss: 2.268282890319824\n",
      "epoch: 0, batch: 1312, loss: 2.2696914672851562\n",
      "epoch: 0, batch: 1313, loss: 2.2674121856689453\n",
      "epoch: 0, batch: 1314, loss: 2.2489418983459473\n",
      "epoch: 0, batch: 1315, loss: 2.263552188873291\n",
      "epoch: 0, batch: 1316, loss: 2.257286787033081\n",
      "epoch: 0, batch: 1317, loss: 2.272102117538452\n",
      "epoch: 0, batch: 1318, loss: 2.26171612739563\n",
      "epoch: 0, batch: 1319, loss: 2.2405970096588135\n",
      "epoch: 0, batch: 1320, loss: 2.2496938705444336\n",
      "epoch: 0, batch: 1321, loss: 2.2713725566864014\n",
      "epoch: 0, batch: 1322, loss: 2.262453317642212\n",
      "epoch: 0, batch: 1323, loss: 2.275061845779419\n",
      "epoch: 0, batch: 1324, loss: 2.2461860179901123\n",
      "epoch: 0, batch: 1325, loss: 2.266277313232422\n",
      "epoch: 0, batch: 1326, loss: 2.250793933868408\n",
      "epoch: 0, batch: 1327, loss: 2.2634940147399902\n",
      "epoch: 0, batch: 1328, loss: 2.259045124053955\n",
      "epoch: 0, batch: 1329, loss: 2.272606134414673\n",
      "epoch: 0, batch: 1330, loss: 2.275700330734253\n",
      "epoch: 0, batch: 1331, loss: 2.2729549407958984\n",
      "epoch: 0, batch: 1332, loss: 2.250439167022705\n",
      "epoch: 0, batch: 1333, loss: 2.2836053371429443\n",
      "epoch: 0, batch: 1334, loss: 2.268354654312134\n",
      "epoch: 0, batch: 1335, loss: 2.2616124153137207\n",
      "epoch: 0, batch: 1336, loss: 2.2713468074798584\n",
      "epoch: 0, batch: 1337, loss: 2.261502981185913\n",
      "epoch: 0, batch: 1338, loss: 2.261643409729004\n",
      "epoch: 0, batch: 1339, loss: 2.2535998821258545\n",
      "epoch: 0, batch: 1340, loss: 2.270381450653076\n",
      "epoch: 0, batch: 1341, loss: 2.272321939468384\n",
      "epoch: 0, batch: 1342, loss: 2.2686691284179688\n",
      "epoch: 0, batch: 1343, loss: 2.253577709197998\n",
      "epoch: 0, batch: 1344, loss: 2.254835844039917\n",
      "epoch: 0, batch: 1345, loss: 2.2523183822631836\n",
      "epoch: 0, batch: 1346, loss: 2.2644455432891846\n",
      "epoch: 0, batch: 1347, loss: 2.271965742111206\n",
      "epoch: 0, batch: 1348, loss: 2.25225567817688\n",
      "epoch: 0, batch: 1349, loss: 2.2656469345092773\n",
      "epoch: 0, batch: 1350, loss: 2.270378828048706\n",
      "epoch: 0, batch: 1351, loss: 2.2670469284057617\n",
      "epoch: 0, batch: 1352, loss: 2.2606287002563477\n",
      "epoch: 0, batch: 1353, loss: 2.2700090408325195\n",
      "epoch: 0, batch: 1354, loss: 2.2295799255371094\n",
      "epoch: 0, batch: 1355, loss: 2.2378928661346436\n",
      "epoch: 0, batch: 1356, loss: 2.2360711097717285\n",
      "epoch: 0, batch: 1357, loss: 2.2736012935638428\n",
      "epoch: 0, batch: 1358, loss: 2.2513387203216553\n",
      "epoch: 0, batch: 1359, loss: 2.2649075984954834\n",
      "epoch: 0, batch: 1360, loss: 2.2641961574554443\n",
      "epoch: 0, batch: 1361, loss: 2.2396998405456543\n",
      "epoch: 0, batch: 1362, loss: 2.285067081451416\n",
      "epoch: 0, batch: 1363, loss: 2.2281250953674316\n",
      "epoch: 0, batch: 1364, loss: 2.2418131828308105\n",
      "epoch: 0, batch: 1365, loss: 2.231797933578491\n",
      "epoch: 0, batch: 1366, loss: 2.275516986846924\n",
      "epoch: 0, batch: 1367, loss: 2.234013795852661\n",
      "epoch: 0, batch: 1368, loss: 2.2706246376037598\n",
      "epoch: 0, batch: 1369, loss: 2.2587475776672363\n",
      "epoch: 0, batch: 1370, loss: 2.279329299926758\n",
      "epoch: 0, batch: 1371, loss: 2.280735731124878\n",
      "epoch: 0, batch: 1372, loss: 2.258420705795288\n",
      "epoch: 0, batch: 1373, loss: 2.2695119380950928\n",
      "epoch: 0, batch: 1374, loss: 2.2651052474975586\n",
      "epoch: 0, batch: 1375, loss: 2.247465133666992\n",
      "epoch: 0, batch: 1376, loss: 2.235549211502075\n",
      "epoch: 0, batch: 1377, loss: 2.232562303543091\n",
      "epoch: 0, batch: 1378, loss: 2.2625584602355957\n",
      "epoch: 0, batch: 1379, loss: 2.2759735584259033\n",
      "epoch: 0, batch: 1380, loss: 2.274894952774048\n",
      "epoch: 0, batch: 1381, loss: 2.2449750900268555\n",
      "epoch: 0, batch: 1382, loss: 2.2784743309020996\n",
      "epoch: 0, batch: 1383, loss: 2.2565619945526123\n",
      "epoch: 0, batch: 1384, loss: 2.2754359245300293\n",
      "epoch: 0, batch: 1385, loss: 2.2949678897857666\n",
      "epoch: 0, batch: 1386, loss: 2.2487082481384277\n",
      "epoch: 0, batch: 1387, loss: 2.273993730545044\n",
      "epoch: 0, batch: 1388, loss: 2.2668514251708984\n",
      "epoch: 0, batch: 1389, loss: 2.2606849670410156\n",
      "epoch: 0, batch: 1390, loss: 2.259868621826172\n",
      "epoch: 0, batch: 1391, loss: 2.290280818939209\n",
      "epoch: 0, batch: 1392, loss: 2.27872371673584\n",
      "epoch: 0, batch: 1393, loss: 2.2692112922668457\n",
      "epoch: 0, batch: 1394, loss: 2.2666337490081787\n",
      "epoch: 0, batch: 1395, loss: 2.2495555877685547\n",
      "epoch: 0, batch: 1396, loss: 2.2725489139556885\n",
      "epoch: 0, batch: 1397, loss: 2.2679383754730225\n",
      "epoch: 0, batch: 1398, loss: 2.2539992332458496\n",
      "epoch: 0, batch: 1399, loss: 2.2579128742218018\n",
      "epoch: 0, batch: 1400, loss: 2.2748827934265137\n",
      "epoch: 0, batch: 1401, loss: 2.255197525024414\n",
      "epoch: 0, batch: 1402, loss: 2.2497167587280273\n",
      "epoch: 0, batch: 1403, loss: 2.2377960681915283\n",
      "epoch: 0, batch: 1404, loss: 2.260432720184326\n",
      "epoch: 0, batch: 1405, loss: 2.2678146362304688\n",
      "epoch: 0, batch: 1406, loss: 2.2530834674835205\n",
      "epoch: 0, batch: 1407, loss: 2.242830514907837\n",
      "epoch: 0, batch: 1408, loss: 2.276221990585327\n",
      "epoch: 0, batch: 1409, loss: 2.311501979827881\n",
      "epoch: 0, batch: 1410, loss: 2.2624170780181885\n",
      "epoch: 0, batch: 1411, loss: 2.279069185256958\n",
      "epoch: 0, batch: 1412, loss: 2.265807628631592\n",
      "epoch: 0, batch: 1413, loss: 2.238994598388672\n",
      "epoch: 0, batch: 1414, loss: 2.2594058513641357\n",
      "epoch: 0, batch: 1415, loss: 2.2783191204071045\n",
      "epoch: 0, batch: 1416, loss: 2.2427477836608887\n",
      "epoch: 0, batch: 1417, loss: 2.29321551322937\n",
      "epoch: 0, batch: 1418, loss: 2.2649612426757812\n",
      "epoch: 0, batch: 1419, loss: 2.266221284866333\n",
      "epoch: 0, batch: 1420, loss: 2.2576003074645996\n",
      "epoch: 0, batch: 1421, loss: 2.2771785259246826\n",
      "epoch: 0, batch: 1422, loss: 2.254258394241333\n",
      "epoch: 0, batch: 1423, loss: 2.24699330329895\n",
      "epoch: 0, batch: 1424, loss: 2.272564649581909\n",
      "epoch: 0, batch: 1425, loss: 2.2381184101104736\n",
      "epoch: 0, batch: 1426, loss: 2.2259879112243652\n",
      "epoch: 0, batch: 1427, loss: 2.2673661708831787\n",
      "epoch: 0, batch: 1428, loss: 2.2652246952056885\n",
      "epoch: 0, batch: 1429, loss: 2.265759229660034\n",
      "epoch: 0, batch: 1430, loss: 2.235812187194824\n",
      "epoch: 0, batch: 1431, loss: 2.253647804260254\n",
      "epoch: 0, batch: 1432, loss: 2.2578072547912598\n",
      "epoch: 0, batch: 1433, loss: 2.2753660678863525\n",
      "epoch: 0, batch: 1434, loss: 2.2405292987823486\n",
      "epoch: 0, batch: 1435, loss: 2.246596574783325\n",
      "epoch: 0, batch: 1436, loss: 2.253840446472168\n",
      "epoch: 0, batch: 1437, loss: 2.2727835178375244\n",
      "epoch: 0, batch: 1438, loss: 2.2621190547943115\n",
      "epoch: 0, batch: 1439, loss: 2.2524962425231934\n",
      "epoch: 0, batch: 1440, loss: 2.2534751892089844\n",
      "epoch: 0, batch: 1441, loss: 2.2775285243988037\n",
      "epoch: 0, batch: 1442, loss: 2.2575042247772217\n",
      "epoch: 0, batch: 1443, loss: 2.2474076747894287\n",
      "epoch: 0, batch: 1444, loss: 2.2784271240234375\n",
      "epoch: 0, batch: 1445, loss: 2.2755000591278076\n",
      "epoch: 0, batch: 1446, loss: 2.256739854812622\n",
      "epoch: 0, batch: 1447, loss: 2.2585220336914062\n",
      "epoch: 0, batch: 1448, loss: 2.2209837436676025\n",
      "epoch: 0, batch: 1449, loss: 2.2892675399780273\n",
      "epoch: 0, batch: 1450, loss: 2.268284559249878\n",
      "epoch: 0, batch: 1451, loss: 2.2333078384399414\n",
      "epoch: 0, batch: 1452, loss: 2.2677528858184814\n",
      "epoch: 0, batch: 1453, loss: 2.243635654449463\n",
      "epoch: 0, batch: 1454, loss: 2.2614428997039795\n",
      "epoch: 0, batch: 1455, loss: 2.240025281906128\n",
      "epoch: 0, batch: 1456, loss: 2.244731903076172\n",
      "epoch: 0, batch: 1457, loss: 2.272005319595337\n",
      "epoch: 0, batch: 1458, loss: 2.2648260593414307\n",
      "epoch: 0, batch: 1459, loss: 2.273686408996582\n",
      "epoch: 0, batch: 1460, loss: 2.259519100189209\n",
      "epoch: 0, batch: 1461, loss: 2.253124237060547\n",
      "epoch: 0, batch: 1462, loss: 2.262963056564331\n",
      "epoch: 0, batch: 1463, loss: 2.2456395626068115\n",
      "epoch: 0, batch: 1464, loss: 2.264827013015747\n",
      "epoch: 0, batch: 1465, loss: 2.2345988750457764\n",
      "epoch: 0, batch: 1466, loss: 2.2240357398986816\n",
      "epoch: 0, batch: 1467, loss: 2.251124382019043\n",
      "epoch: 0, batch: 1468, loss: 2.2513668537139893\n",
      "epoch: 0, batch: 1469, loss: 2.2479095458984375\n",
      "epoch: 0, batch: 1470, loss: 2.257011890411377\n",
      "epoch: 0, batch: 1471, loss: 2.284827470779419\n",
      "epoch: 0, batch: 1472, loss: 2.263521671295166\n",
      "epoch: 0, batch: 1473, loss: 2.2875406742095947\n",
      "epoch: 0, batch: 1474, loss: 2.271629810333252\n",
      "epoch: 0, batch: 1475, loss: 2.267585277557373\n",
      "epoch: 0, batch: 1476, loss: 2.252995491027832\n",
      "epoch: 0, batch: 1477, loss: 2.2694454193115234\n",
      "epoch: 0, batch: 1478, loss: 2.2592031955718994\n",
      "epoch: 0, batch: 1479, loss: 2.254737615585327\n",
      "epoch: 0, batch: 1480, loss: 2.237222194671631\n",
      "epoch: 0, batch: 1481, loss: 2.262768030166626\n",
      "epoch: 0, batch: 1482, loss: 2.2575931549072266\n",
      "epoch: 0, batch: 1483, loss: 2.24410080909729\n",
      "epoch: 0, batch: 1484, loss: 2.260281562805176\n",
      "epoch: 0, batch: 1485, loss: 2.2482595443725586\n",
      "epoch: 0, batch: 1486, loss: 2.2709739208221436\n",
      "epoch: 0, batch: 1487, loss: 2.277458429336548\n",
      "epoch: 0, batch: 1488, loss: 2.2388665676116943\n",
      "epoch: 0, batch: 1489, loss: 2.2663733959198\n",
      "epoch: 0, batch: 1490, loss: 2.2372334003448486\n",
      "epoch: 0, batch: 1491, loss: 2.266383171081543\n",
      "epoch: 0, batch: 1492, loss: 2.2644619941711426\n",
      "epoch: 0, batch: 1493, loss: 2.243479013442993\n",
      "epoch: 0, batch: 1494, loss: 2.2800889015197754\n",
      "epoch: 0, batch: 1495, loss: 2.246565818786621\n",
      "epoch: 0, batch: 1496, loss: 2.2320938110351562\n",
      "epoch: 0, batch: 1497, loss: 2.25484299659729\n",
      "epoch: 0, batch: 1498, loss: 2.259223461151123\n",
      "epoch: 0, batch: 1499, loss: 2.2957494258880615\n",
      "epoch: 0, batch: 1500, loss: 2.2213761806488037\n",
      "epoch: 0, batch: 1501, loss: 2.261943817138672\n",
      "epoch: 0, batch: 1502, loss: 2.236517906188965\n",
      "epoch: 0, batch: 1503, loss: 2.2620644569396973\n",
      "epoch: 0, batch: 1504, loss: 2.2807774543762207\n",
      "epoch: 0, batch: 1505, loss: 2.2177786827087402\n",
      "epoch: 0, batch: 1506, loss: 2.265578508377075\n",
      "epoch: 0, batch: 1507, loss: 2.282780647277832\n",
      "epoch: 0, batch: 1508, loss: 2.217256546020508\n",
      "epoch: 0, batch: 1509, loss: 2.241589069366455\n",
      "epoch: 0, batch: 1510, loss: 2.24639630317688\n",
      "epoch: 0, batch: 1511, loss: 2.2923641204833984\n",
      "epoch: 0, batch: 1512, loss: 2.250563621520996\n",
      "epoch: 0, batch: 1513, loss: 2.2344021797180176\n",
      "epoch: 0, batch: 1514, loss: 2.260622501373291\n",
      "epoch: 0, batch: 1515, loss: 2.2462098598480225\n",
      "epoch: 0, batch: 1516, loss: 2.248631000518799\n",
      "epoch: 0, batch: 1517, loss: 2.2551116943359375\n",
      "epoch: 0, batch: 1518, loss: 2.253317356109619\n",
      "epoch: 0, batch: 1519, loss: 2.260817766189575\n",
      "epoch: 0, batch: 1520, loss: 2.2470970153808594\n",
      "epoch: 0, batch: 1521, loss: 2.2715160846710205\n",
      "epoch: 0, batch: 1522, loss: 2.273737907409668\n",
      "epoch: 0, batch: 1523, loss: 2.278252124786377\n",
      "epoch: 0, batch: 1524, loss: 2.2739572525024414\n",
      "epoch: 0, batch: 1525, loss: 2.2627949714660645\n",
      "epoch: 0, batch: 1526, loss: 2.293415069580078\n",
      "epoch: 0, batch: 1527, loss: 2.21588397026062\n",
      "epoch: 0, batch: 1528, loss: 2.2696170806884766\n",
      "epoch: 0, batch: 1529, loss: 2.245152711868286\n",
      "epoch: 0, batch: 1530, loss: 2.254124164581299\n",
      "epoch: 0, batch: 1531, loss: 2.2439017295837402\n",
      "epoch: 0, batch: 1532, loss: 2.254786729812622\n",
      "epoch: 0, batch: 1533, loss: 2.260654926300049\n",
      "epoch: 0, batch: 1534, loss: 2.2388672828674316\n",
      "epoch: 0, batch: 1535, loss: 2.241835594177246\n",
      "epoch: 0, batch: 1536, loss: 2.27266001701355\n",
      "epoch: 0, batch: 1537, loss: 2.252401113510132\n",
      "epoch: 0, batch: 1538, loss: 2.25659441947937\n",
      "epoch: 0, batch: 1539, loss: 2.2318308353424072\n",
      "epoch: 0, batch: 1540, loss: 2.2453761100769043\n",
      "epoch: 0, batch: 1541, loss: 2.2663588523864746\n",
      "epoch: 0, batch: 1542, loss: 2.2496390342712402\n",
      "epoch: 0, batch: 1543, loss: 2.250030517578125\n",
      "epoch: 0, batch: 1544, loss: 2.251338005065918\n",
      "epoch: 0, batch: 1545, loss: 2.230684757232666\n",
      "epoch: 0, batch: 1546, loss: 2.241309404373169\n",
      "epoch: 0, batch: 1547, loss: 2.2524638175964355\n",
      "epoch: 0, batch: 1548, loss: 2.255375385284424\n",
      "epoch: 0, batch: 1549, loss: 2.25835919380188\n",
      "epoch: 0, batch: 1550, loss: 2.240382671356201\n",
      "epoch: 0, batch: 1551, loss: 2.2641818523406982\n",
      "epoch: 0, batch: 1552, loss: 2.2410576343536377\n",
      "epoch: 0, batch: 1553, loss: 2.2448883056640625\n",
      "epoch: 0, batch: 1554, loss: 2.2567896842956543\n",
      "epoch: 0, batch: 1555, loss: 2.2497198581695557\n",
      "epoch: 0, batch: 1556, loss: 2.2594006061553955\n",
      "epoch: 0, batch: 1557, loss: 2.2629706859588623\n",
      "epoch: 0, batch: 1558, loss: 2.2517077922821045\n",
      "epoch: 0, batch: 1559, loss: 2.2689969539642334\n",
      "epoch: 0, batch: 1560, loss: 2.272658586502075\n",
      "epoch: 0, batch: 1561, loss: 2.2598061561584473\n",
      "epoch: 0, batch: 1562, loss: 2.238633871078491\n",
      "epoch: 0, batch: 1563, loss: 2.280031442642212\n",
      "epoch: 0, batch: 1564, loss: 2.2434277534484863\n",
      "epoch: 0, batch: 1565, loss: 2.288773775100708\n",
      "epoch: 0, batch: 1566, loss: 2.2711102962493896\n",
      "epoch: 0, batch: 1567, loss: 2.2421278953552246\n",
      "epoch: 0, batch: 1568, loss: 2.2493748664855957\n",
      "epoch: 0, batch: 1569, loss: 2.259746551513672\n",
      "epoch: 0, batch: 1570, loss: 2.2132623195648193\n",
      "epoch: 0, batch: 1571, loss: 2.237550735473633\n",
      "epoch: 0, batch: 1572, loss: 2.26684308052063\n",
      "epoch: 0, batch: 1573, loss: 2.21791934967041\n",
      "epoch: 0, batch: 1574, loss: 2.226135492324829\n",
      "epoch: 0, batch: 1575, loss: 2.267953395843506\n",
      "epoch: 0, batch: 1576, loss: 2.216867208480835\n",
      "epoch: 0, batch: 1577, loss: 2.248687982559204\n",
      "epoch: 0, batch: 1578, loss: 2.2433884143829346\n",
      "epoch: 0, batch: 1579, loss: 2.239013671875\n",
      "epoch: 0, batch: 1580, loss: 2.2238528728485107\n",
      "epoch: 0, batch: 1581, loss: 2.2456984519958496\n",
      "epoch: 0, batch: 1582, loss: 2.2504210472106934\n",
      "epoch: 0, batch: 1583, loss: 2.241323947906494\n",
      "epoch: 0, batch: 1584, loss: 2.2536184787750244\n",
      "epoch: 0, batch: 1585, loss: 2.2537484169006348\n",
      "epoch: 0, batch: 1586, loss: 2.26192307472229\n",
      "epoch: 0, batch: 1587, loss: 2.2628390789031982\n",
      "epoch: 0, batch: 1588, loss: 2.2467684745788574\n",
      "epoch: 0, batch: 1589, loss: 2.256221294403076\n",
      "epoch: 0, batch: 1590, loss: 2.2590699195861816\n",
      "epoch: 0, batch: 1591, loss: 2.2559521198272705\n",
      "epoch: 0, batch: 1592, loss: 2.27068829536438\n",
      "epoch: 0, batch: 1593, loss: 2.2626073360443115\n",
      "epoch: 0, batch: 1594, loss: 2.264902353286743\n",
      "epoch: 0, batch: 1595, loss: 2.259019613265991\n",
      "epoch: 0, batch: 1596, loss: 2.2657251358032227\n",
      "epoch: 0, batch: 1597, loss: 2.264331102371216\n",
      "epoch: 0, batch: 1598, loss: 2.2717862129211426\n",
      "epoch: 0, batch: 1599, loss: 2.2359867095947266\n",
      "epoch: 0, batch: 1600, loss: 2.2558465003967285\n",
      "epoch: 0, batch: 1601, loss: 2.2653613090515137\n",
      "epoch: 0, batch: 1602, loss: 2.242889165878296\n",
      "epoch: 0, batch: 1603, loss: 2.2603342533111572\n",
      "epoch: 0, batch: 1604, loss: 2.2555017471313477\n",
      "epoch: 0, batch: 1605, loss: 2.2491025924682617\n",
      "epoch: 0, batch: 1606, loss: 2.268378973007202\n",
      "epoch: 0, batch: 1607, loss: 2.2406086921691895\n",
      "epoch: 0, batch: 1608, loss: 2.2487051486968994\n",
      "epoch: 0, batch: 1609, loss: 2.2450177669525146\n",
      "epoch: 0, batch: 1610, loss: 2.2312512397766113\n",
      "epoch: 0, batch: 1611, loss: 2.2375950813293457\n",
      "epoch: 0, batch: 1612, loss: 2.2630302906036377\n",
      "epoch: 0, batch: 1613, loss: 2.2400035858154297\n",
      "epoch: 0, batch: 1614, loss: 2.250483274459839\n",
      "epoch: 0, batch: 1615, loss: 2.2425198554992676\n",
      "epoch: 0, batch: 1616, loss: 2.2428252696990967\n",
      "epoch: 0, batch: 1617, loss: 2.2543857097625732\n",
      "epoch: 0, batch: 1618, loss: 2.2888565063476562\n",
      "epoch: 0, batch: 1619, loss: 2.2535276412963867\n",
      "epoch: 0, batch: 1620, loss: 2.2533609867095947\n",
      "epoch: 0, batch: 1621, loss: 2.2245166301727295\n",
      "epoch: 0, batch: 1622, loss: 2.2611844539642334\n",
      "epoch: 0, batch: 1623, loss: 2.2694499492645264\n",
      "epoch: 0, batch: 1624, loss: 2.194690227508545\n",
      "epoch: 0, batch: 1625, loss: 2.234879732131958\n",
      "epoch: 0, batch: 1626, loss: 2.2530558109283447\n",
      "epoch: 0, batch: 1627, loss: 2.2537264823913574\n",
      "epoch: 0, batch: 1628, loss: 2.2166478633880615\n",
      "epoch: 0, batch: 1629, loss: 2.2652218341827393\n",
      "epoch: 0, batch: 1630, loss: 2.254689931869507\n",
      "epoch: 0, batch: 1631, loss: 2.247739791870117\n",
      "epoch: 0, batch: 1632, loss: 2.2335405349731445\n",
      "epoch: 0, batch: 1633, loss: 2.240955114364624\n",
      "epoch: 0, batch: 1634, loss: 2.212181568145752\n",
      "epoch: 0, batch: 1635, loss: 2.228618621826172\n",
      "epoch: 0, batch: 1636, loss: 2.2115819454193115\n",
      "epoch: 0, batch: 1637, loss: 2.2863082885742188\n",
      "epoch: 0, batch: 1638, loss: 2.2376651763916016\n",
      "epoch: 0, batch: 1639, loss: 2.254652976989746\n",
      "epoch: 0, batch: 1640, loss: 2.2734925746917725\n",
      "epoch: 0, batch: 1641, loss: 2.2544102668762207\n",
      "epoch: 0, batch: 1642, loss: 2.278170108795166\n",
      "epoch: 0, batch: 1643, loss: 2.254601001739502\n",
      "epoch: 0, batch: 1644, loss: 2.2669284343719482\n",
      "epoch: 0, batch: 1645, loss: 2.2333474159240723\n",
      "epoch: 0, batch: 1646, loss: 2.2540721893310547\n",
      "epoch: 0, batch: 1647, loss: 2.2362968921661377\n",
      "epoch: 0, batch: 1648, loss: 2.2498514652252197\n",
      "epoch: 0, batch: 1649, loss: 2.2584619522094727\n",
      "epoch: 0, batch: 1650, loss: 2.2795238494873047\n",
      "epoch: 0, batch: 1651, loss: 2.2730085849761963\n",
      "epoch: 0, batch: 1652, loss: 2.2676126956939697\n",
      "epoch: 0, batch: 1653, loss: 2.249021291732788\n",
      "epoch: 0, batch: 1654, loss: 2.2723476886749268\n",
      "epoch: 0, batch: 1655, loss: 2.2884433269500732\n",
      "epoch: 0, batch: 1656, loss: 2.259382724761963\n",
      "epoch: 0, batch: 1657, loss: 2.2184298038482666\n",
      "epoch: 0, batch: 1658, loss: 2.2410287857055664\n",
      "epoch: 0, batch: 1659, loss: 2.2036550045013428\n",
      "epoch: 0, batch: 1660, loss: 2.2449591159820557\n",
      "epoch: 0, batch: 1661, loss: 2.265310764312744\n",
      "epoch: 0, batch: 1662, loss: 2.2472105026245117\n",
      "epoch: 0, batch: 1663, loss: 2.2584171295166016\n",
      "epoch: 0, batch: 1664, loss: 2.264249324798584\n",
      "epoch: 0, batch: 1665, loss: 2.255683183670044\n",
      "epoch: 0, batch: 1666, loss: 2.2376346588134766\n",
      "epoch: 0, batch: 1667, loss: 2.2329208850860596\n",
      "epoch: 0, batch: 1668, loss: 2.2602732181549072\n",
      "epoch: 0, batch: 1669, loss: 2.214747905731201\n",
      "epoch: 0, batch: 1670, loss: 2.238877296447754\n",
      "epoch: 0, batch: 1671, loss: 2.2482216358184814\n",
      "epoch: 0, batch: 1672, loss: 2.219275951385498\n",
      "epoch: 0, batch: 1673, loss: 2.23017954826355\n",
      "epoch: 0, batch: 1674, loss: 2.2742514610290527\n",
      "epoch: 0, batch: 1675, loss: 2.2508883476257324\n",
      "epoch: 0, batch: 1676, loss: 2.2258052825927734\n",
      "epoch: 0, batch: 1677, loss: 2.2081730365753174\n",
      "epoch: 0, batch: 1678, loss: 2.264512538909912\n",
      "epoch: 0, batch: 1679, loss: 2.2522432804107666\n",
      "epoch: 0, batch: 1680, loss: 2.2234225273132324\n",
      "epoch: 0, batch: 1681, loss: 2.2170658111572266\n",
      "epoch: 0, batch: 1682, loss: 2.213465929031372\n",
      "epoch: 0, batch: 1683, loss: 2.215973377227783\n",
      "epoch: 0, batch: 1684, loss: 2.239628314971924\n",
      "epoch: 0, batch: 1685, loss: 2.265906810760498\n",
      "epoch: 0, batch: 1686, loss: 2.2424049377441406\n",
      "epoch: 0, batch: 1687, loss: 2.2210781574249268\n",
      "epoch: 0, batch: 1688, loss: 2.2456634044647217\n",
      "epoch: 0, batch: 1689, loss: 2.241605758666992\n",
      "epoch: 0, batch: 1690, loss: 2.2271993160247803\n",
      "epoch: 0, batch: 1691, loss: 2.268930673599243\n",
      "epoch: 0, batch: 1692, loss: 2.231872081756592\n",
      "epoch: 0, batch: 1693, loss: 2.2479190826416016\n",
      "epoch: 0, batch: 1694, loss: 2.222224712371826\n",
      "epoch: 0, batch: 1695, loss: 2.243166446685791\n",
      "epoch: 0, batch: 1696, loss: 2.2557010650634766\n",
      "epoch: 0, batch: 1697, loss: 2.2404658794403076\n",
      "epoch: 0, batch: 1698, loss: 2.236581563949585\n",
      "epoch: 0, batch: 1699, loss: 2.2331130504608154\n",
      "epoch: 0, batch: 1700, loss: 2.264508008956909\n",
      "epoch: 0, batch: 1701, loss: 2.2500486373901367\n",
      "epoch: 0, batch: 1702, loss: 2.255554676055908\n",
      "epoch: 0, batch: 1703, loss: 2.255049705505371\n",
      "epoch: 0, batch: 1704, loss: 2.2263565063476562\n",
      "epoch: 0, batch: 1705, loss: 2.2408862113952637\n",
      "epoch: 0, batch: 1706, loss: 2.2595746517181396\n",
      "epoch: 0, batch: 1707, loss: 2.2387423515319824\n",
      "epoch: 0, batch: 1708, loss: 2.2472221851348877\n",
      "epoch: 0, batch: 1709, loss: 2.2367522716522217\n",
      "epoch: 0, batch: 1710, loss: 2.226799488067627\n",
      "epoch: 0, batch: 1711, loss: 2.2603156566619873\n",
      "epoch: 0, batch: 1712, loss: 2.2286694049835205\n",
      "epoch: 0, batch: 1713, loss: 2.2454590797424316\n",
      "epoch: 0, batch: 1714, loss: 2.271817207336426\n",
      "epoch: 0, batch: 1715, loss: 2.2518844604492188\n",
      "epoch: 0, batch: 1716, loss: 2.2575879096984863\n",
      "epoch: 0, batch: 1717, loss: 2.2344114780426025\n",
      "epoch: 0, batch: 1718, loss: 2.260220527648926\n",
      "epoch: 0, batch: 1719, loss: 2.258871078491211\n",
      "epoch: 0, batch: 1720, loss: 2.225895404815674\n",
      "epoch: 0, batch: 1721, loss: 2.2313108444213867\n",
      "epoch: 0, batch: 1722, loss: 2.229245662689209\n",
      "epoch: 0, batch: 1723, loss: 2.242069721221924\n",
      "epoch: 0, batch: 1724, loss: 2.274707078933716\n",
      "epoch: 0, batch: 1725, loss: 2.23821759223938\n",
      "epoch: 0, batch: 1726, loss: 2.2888216972351074\n",
      "epoch: 0, batch: 1727, loss: 2.232919931411743\n",
      "epoch: 0, batch: 1728, loss: 2.2425389289855957\n",
      "epoch: 0, batch: 1729, loss: 2.245591878890991\n",
      "epoch: 0, batch: 1730, loss: 2.218905448913574\n",
      "epoch: 0, batch: 1731, loss: 2.2397711277008057\n",
      "epoch: 0, batch: 1732, loss: 2.2589454650878906\n",
      "epoch: 0, batch: 1733, loss: 2.2573955059051514\n",
      "epoch: 0, batch: 1734, loss: 2.2387468814849854\n",
      "epoch: 0, batch: 1735, loss: 2.2527599334716797\n",
      "epoch: 0, batch: 1736, loss: 2.252514600753784\n",
      "epoch: 0, batch: 1737, loss: 2.2565276622772217\n",
      "epoch: 0, batch: 1738, loss: 2.273264169692993\n",
      "epoch: 0, batch: 1739, loss: 2.2576141357421875\n",
      "epoch: 0, batch: 1740, loss: 2.2675974369049072\n",
      "epoch: 0, batch: 1741, loss: 2.2659857273101807\n",
      "epoch: 0, batch: 1742, loss: 2.228123188018799\n",
      "epoch: 0, batch: 1743, loss: 2.221605062484741\n",
      "epoch: 0, batch: 1744, loss: 2.2480897903442383\n",
      "epoch: 0, batch: 1745, loss: 2.2277750968933105\n",
      "epoch: 0, batch: 1746, loss: 2.262317657470703\n",
      "epoch: 0, batch: 1747, loss: 2.226717472076416\n",
      "epoch: 0, batch: 1748, loss: 2.2226037979125977\n",
      "epoch: 0, batch: 1749, loss: 2.266752243041992\n",
      "epoch: 0, batch: 1750, loss: 2.2737481594085693\n",
      "epoch: 0, batch: 1751, loss: 2.2568469047546387\n",
      "epoch: 0, batch: 1752, loss: 2.2496285438537598\n",
      "epoch: 0, batch: 1753, loss: 2.236194610595703\n",
      "epoch: 0, batch: 1754, loss: 2.232653856277466\n",
      "epoch: 0, batch: 1755, loss: 2.221146583557129\n",
      "epoch: 0, batch: 1756, loss: 2.249042510986328\n",
      "epoch: 0, batch: 1757, loss: 2.2371928691864014\n",
      "epoch: 0, batch: 1758, loss: 2.236126661300659\n",
      "epoch: 0, batch: 1759, loss: 2.2125368118286133\n",
      "epoch: 0, batch: 1760, loss: 2.2021729946136475\n",
      "epoch: 0, batch: 1761, loss: 2.244605779647827\n",
      "epoch: 0, batch: 1762, loss: 2.247983455657959\n",
      "epoch: 0, batch: 1763, loss: 2.2678868770599365\n",
      "epoch: 0, batch: 1764, loss: 2.2845215797424316\n",
      "epoch: 0, batch: 1765, loss: 2.2711048126220703\n",
      "epoch: 0, batch: 1766, loss: 2.228405237197876\n",
      "epoch: 0, batch: 1767, loss: 2.2265336513519287\n",
      "epoch: 0, batch: 1768, loss: 2.2605254650115967\n",
      "epoch: 0, batch: 1769, loss: 2.232126235961914\n",
      "epoch: 0, batch: 1770, loss: 2.2336905002593994\n",
      "epoch: 0, batch: 1771, loss: 2.2500951290130615\n",
      "epoch: 0, batch: 1772, loss: 2.2088043689727783\n",
      "epoch: 0, batch: 1773, loss: 2.219864845275879\n",
      "epoch: 0, batch: 1774, loss: 2.235884666442871\n",
      "epoch: 0, batch: 1775, loss: 2.2806289196014404\n",
      "epoch: 0, batch: 1776, loss: 2.25394344329834\n",
      "epoch: 0, batch: 1777, loss: 2.276289701461792\n",
      "epoch: 0, batch: 1778, loss: 2.2356841564178467\n",
      "epoch: 0, batch: 1779, loss: 2.228853225708008\n",
      "epoch: 0, batch: 1780, loss: 2.2281606197357178\n",
      "epoch: 0, batch: 1781, loss: 2.2341673374176025\n",
      "epoch: 0, batch: 1782, loss: 2.2356200218200684\n",
      "epoch: 0, batch: 1783, loss: 2.247220277786255\n",
      "epoch: 0, batch: 1784, loss: 2.221557378768921\n",
      "epoch: 0, batch: 1785, loss: 2.225480318069458\n",
      "epoch: 0, batch: 1786, loss: 2.237506866455078\n",
      "epoch: 0, batch: 1787, loss: 2.2268991470336914\n",
      "epoch: 0, batch: 1788, loss: 2.262618064880371\n",
      "epoch: 0, batch: 1789, loss: 2.2365517616271973\n",
      "epoch: 0, batch: 1790, loss: 2.243898391723633\n",
      "epoch: 0, batch: 1791, loss: 2.2531824111938477\n",
      "epoch: 0, batch: 1792, loss: 2.247840404510498\n",
      "epoch: 0, batch: 1793, loss: 2.208702325820923\n",
      "epoch: 0, batch: 1794, loss: 2.230273723602295\n",
      "epoch: 0, batch: 1795, loss: 2.2044498920440674\n",
      "epoch: 0, batch: 1796, loss: 2.2341296672821045\n",
      "epoch: 0, batch: 1797, loss: 2.261988401412964\n",
      "epoch: 0, batch: 1798, loss: 2.2518181800842285\n",
      "epoch: 0, batch: 1799, loss: 2.237806797027588\n",
      "epoch: 0, batch: 1800, loss: 2.256681203842163\n",
      "epoch: 0, batch: 1801, loss: 2.2370665073394775\n",
      "epoch: 0, batch: 1802, loss: 2.2147529125213623\n",
      "epoch: 0, batch: 1803, loss: 2.234340190887451\n",
      "epoch: 0, batch: 1804, loss: 2.2278714179992676\n",
      "epoch: 0, batch: 1805, loss: 2.233822822570801\n",
      "epoch: 0, batch: 1806, loss: 2.22890043258667\n",
      "epoch: 0, batch: 1807, loss: 2.2263200283050537\n",
      "epoch: 0, batch: 1808, loss: 2.2373857498168945\n",
      "epoch: 0, batch: 1809, loss: 2.250182628631592\n",
      "epoch: 0, batch: 1810, loss: 2.2296881675720215\n",
      "epoch: 0, batch: 1811, loss: 2.2317614555358887\n",
      "epoch: 0, batch: 1812, loss: 2.2644810676574707\n",
      "epoch: 0, batch: 1813, loss: 2.248253107070923\n",
      "epoch: 0, batch: 1814, loss: 2.2379798889160156\n",
      "epoch: 0, batch: 1815, loss: 2.257725954055786\n",
      "epoch: 0, batch: 1816, loss: 2.2028932571411133\n",
      "epoch: 0, batch: 1817, loss: 2.245621681213379\n",
      "epoch: 0, batch: 1818, loss: 2.2800378799438477\n",
      "epoch: 0, batch: 1819, loss: 2.249135732650757\n",
      "epoch: 0, batch: 1820, loss: 2.2475502490997314\n",
      "epoch: 0, batch: 1821, loss: 2.240575075149536\n",
      "epoch: 0, batch: 1822, loss: 2.2101707458496094\n",
      "epoch: 0, batch: 1823, loss: 2.231215238571167\n",
      "epoch: 0, batch: 1824, loss: 2.2552435398101807\n",
      "epoch: 0, batch: 1825, loss: 2.193267345428467\n",
      "epoch: 0, batch: 1826, loss: 2.2533204555511475\n",
      "epoch: 0, batch: 1827, loss: 2.221710681915283\n",
      "epoch: 0, batch: 1828, loss: 2.244497537612915\n",
      "epoch: 0, batch: 1829, loss: 2.2329213619232178\n",
      "epoch: 0, batch: 1830, loss: 2.2229292392730713\n",
      "epoch: 0, batch: 1831, loss: 2.236827850341797\n",
      "epoch: 0, batch: 1832, loss: 2.2428605556488037\n",
      "epoch: 0, batch: 1833, loss: 2.2444918155670166\n",
      "epoch: 0, batch: 1834, loss: 2.2620081901550293\n",
      "epoch: 0, batch: 1835, loss: 2.2264294624328613\n",
      "epoch: 0, batch: 1836, loss: 2.2516002655029297\n",
      "epoch: 0, batch: 1837, loss: 2.259305238723755\n",
      "epoch: 0, batch: 1838, loss: 2.247213125228882\n",
      "epoch: 0, batch: 1839, loss: 2.2666704654693604\n",
      "epoch: 0, batch: 1840, loss: 2.2674641609191895\n",
      "epoch: 0, batch: 1841, loss: 2.247321367263794\n",
      "epoch: 0, batch: 1842, loss: 2.24619460105896\n",
      "epoch: 0, batch: 1843, loss: 2.2111706733703613\n",
      "epoch: 0, batch: 1844, loss: 2.213559627532959\n",
      "epoch: 0, batch: 1845, loss: 2.236707925796509\n",
      "epoch: 0, batch: 1846, loss: 2.243987560272217\n",
      "epoch: 0, batch: 1847, loss: 2.225924253463745\n",
      "epoch: 0, batch: 1848, loss: 2.2320706844329834\n",
      "epoch: 0, batch: 1849, loss: 2.2276203632354736\n",
      "epoch: 0, batch: 1850, loss: 2.2921836376190186\n",
      "epoch: 0, batch: 1851, loss: 2.237983465194702\n",
      "epoch: 0, batch: 1852, loss: 2.2197964191436768\n",
      "epoch: 0, batch: 1853, loss: 2.240734577178955\n",
      "epoch: 0, batch: 1854, loss: 2.263223648071289\n",
      "epoch: 0, batch: 1855, loss: 2.216517686843872\n",
      "epoch: 0, batch: 1856, loss: 2.228370189666748\n",
      "epoch: 0, batch: 1857, loss: 2.236165761947632\n",
      "epoch: 0, batch: 1858, loss: 2.2438273429870605\n",
      "epoch: 0, batch: 1859, loss: 2.2480320930480957\n",
      "epoch: 0, batch: 1860, loss: 2.2307984828948975\n",
      "epoch: 0, batch: 1861, loss: 2.2267236709594727\n",
      "epoch: 0, batch: 1862, loss: 2.2344014644622803\n",
      "epoch: 0, batch: 1863, loss: 2.2347023487091064\n",
      "epoch: 0, batch: 1864, loss: 2.2168915271759033\n",
      "epoch: 0, batch: 1865, loss: 2.2303152084350586\n",
      "epoch: 0, batch: 1866, loss: 2.2326409816741943\n",
      "epoch: 0, batch: 1867, loss: 2.237673759460449\n",
      "epoch: 0, batch: 1868, loss: 2.244140386581421\n",
      "epoch: 0, batch: 1869, loss: 2.2286205291748047\n",
      "epoch: 0, batch: 1870, loss: 2.258657693862915\n",
      "epoch: 0, batch: 1871, loss: 2.241295337677002\n",
      "epoch: 0, batch: 1872, loss: 2.278669595718384\n",
      "epoch: 0, batch: 1873, loss: 2.2554306983947754\n",
      "epoch: 0, batch: 1874, loss: 2.250958204269409\n",
      "epoch: 1, batch: 0, loss: 2.2539007663726807\n",
      "epoch: 1, batch: 1, loss: 2.2417263984680176\n",
      "epoch: 1, batch: 2, loss: 2.232832431793213\n",
      "epoch: 1, batch: 3, loss: 2.228959798812866\n",
      "epoch: 1, batch: 4, loss: 2.250830888748169\n",
      "epoch: 1, batch: 5, loss: 2.2814087867736816\n",
      "epoch: 1, batch: 6, loss: 2.2432801723480225\n",
      "epoch: 1, batch: 7, loss: 2.211271047592163\n",
      "epoch: 1, batch: 8, loss: 2.225789785385132\n",
      "epoch: 1, batch: 9, loss: 2.2219724655151367\n",
      "epoch: 1, batch: 10, loss: 2.2619099617004395\n",
      "epoch: 1, batch: 11, loss: 2.2656426429748535\n",
      "epoch: 1, batch: 12, loss: 2.2546496391296387\n",
      "epoch: 1, batch: 13, loss: 2.2625296115875244\n",
      "epoch: 1, batch: 14, loss: 2.234009265899658\n",
      "epoch: 1, batch: 15, loss: 2.233839273452759\n",
      "epoch: 1, batch: 16, loss: 2.2686524391174316\n",
      "epoch: 1, batch: 17, loss: 2.178483009338379\n",
      "epoch: 1, batch: 18, loss: 2.204716205596924\n",
      "epoch: 1, batch: 19, loss: 2.227088689804077\n",
      "epoch: 1, batch: 20, loss: 2.2123069763183594\n",
      "epoch: 1, batch: 21, loss: 2.2475028038024902\n",
      "epoch: 1, batch: 22, loss: 2.213489055633545\n",
      "epoch: 1, batch: 23, loss: 2.193159818649292\n",
      "epoch: 1, batch: 24, loss: 2.2411181926727295\n",
      "epoch: 1, batch: 25, loss: 2.1888113021850586\n",
      "epoch: 1, batch: 26, loss: 2.252617120742798\n",
      "epoch: 1, batch: 27, loss: 2.24763822555542\n",
      "epoch: 1, batch: 28, loss: 2.2472269535064697\n",
      "epoch: 1, batch: 29, loss: 2.2418761253356934\n",
      "epoch: 1, batch: 30, loss: 2.2021703720092773\n",
      "epoch: 1, batch: 31, loss: 2.2286176681518555\n",
      "epoch: 1, batch: 32, loss: 2.2463700771331787\n",
      "epoch: 1, batch: 33, loss: 2.208465099334717\n",
      "epoch: 1, batch: 34, loss: 2.226269245147705\n",
      "epoch: 1, batch: 35, loss: 2.231016159057617\n",
      "epoch: 1, batch: 36, loss: 2.2305493354797363\n",
      "epoch: 1, batch: 37, loss: 2.2602481842041016\n",
      "epoch: 1, batch: 38, loss: 2.283297300338745\n",
      "epoch: 1, batch: 39, loss: 2.2408478260040283\n",
      "epoch: 1, batch: 40, loss: 2.2253715991973877\n",
      "epoch: 1, batch: 41, loss: 2.223661422729492\n",
      "epoch: 1, batch: 42, loss: 2.2271955013275146\n",
      "epoch: 1, batch: 43, loss: 2.2548279762268066\n",
      "epoch: 1, batch: 44, loss: 2.213552951812744\n",
      "epoch: 1, batch: 45, loss: 2.2363884449005127\n",
      "epoch: 1, batch: 46, loss: 2.2617294788360596\n",
      "epoch: 1, batch: 47, loss: 2.225813627243042\n",
      "epoch: 1, batch: 48, loss: 2.2239012718200684\n",
      "epoch: 1, batch: 49, loss: 2.2145838737487793\n",
      "epoch: 1, batch: 50, loss: 2.2031166553497314\n",
      "epoch: 1, batch: 51, loss: 2.2365715503692627\n",
      "epoch: 1, batch: 52, loss: 2.216193675994873\n",
      "epoch: 1, batch: 53, loss: 2.218519449234009\n",
      "epoch: 1, batch: 54, loss: 2.2071785926818848\n",
      "epoch: 1, batch: 55, loss: 2.2509377002716064\n",
      "epoch: 1, batch: 56, loss: 2.2128891944885254\n",
      "epoch: 1, batch: 57, loss: 2.254070281982422\n",
      "epoch: 1, batch: 58, loss: 2.2499871253967285\n",
      "epoch: 1, batch: 59, loss: 2.232872724533081\n",
      "epoch: 1, batch: 60, loss: 2.2174739837646484\n",
      "epoch: 1, batch: 61, loss: 2.191408395767212\n",
      "epoch: 1, batch: 62, loss: 2.2565832138061523\n",
      "epoch: 1, batch: 63, loss: 2.2436957359313965\n",
      "epoch: 1, batch: 64, loss: 2.253875255584717\n",
      "epoch: 1, batch: 65, loss: 2.232748508453369\n",
      "epoch: 1, batch: 66, loss: 2.240213394165039\n",
      "epoch: 1, batch: 67, loss: 2.2188663482666016\n",
      "epoch: 1, batch: 68, loss: 2.2134740352630615\n",
      "epoch: 1, batch: 69, loss: 2.2683308124542236\n",
      "epoch: 1, batch: 70, loss: 2.242767095565796\n",
      "epoch: 1, batch: 71, loss: 2.2371408939361572\n",
      "epoch: 1, batch: 72, loss: 2.219080686569214\n",
      "epoch: 1, batch: 73, loss: 2.241884708404541\n",
      "epoch: 1, batch: 74, loss: 2.241867780685425\n",
      "epoch: 1, batch: 75, loss: 2.2512664794921875\n",
      "epoch: 1, batch: 76, loss: 2.2390267848968506\n",
      "epoch: 1, batch: 77, loss: 2.209887981414795\n",
      "epoch: 1, batch: 78, loss: 2.2159841060638428\n",
      "epoch: 1, batch: 79, loss: 2.2418863773345947\n",
      "epoch: 1, batch: 80, loss: 2.1993093490600586\n",
      "epoch: 1, batch: 81, loss: 2.241466522216797\n",
      "epoch: 1, batch: 82, loss: 2.252687454223633\n",
      "epoch: 1, batch: 83, loss: 2.2320713996887207\n",
      "epoch: 1, batch: 84, loss: 2.2346365451812744\n",
      "epoch: 1, batch: 85, loss: 2.204303503036499\n",
      "epoch: 1, batch: 86, loss: 2.2624001502990723\n",
      "epoch: 1, batch: 87, loss: 2.223659038543701\n",
      "epoch: 1, batch: 88, loss: 2.2083797454833984\n",
      "epoch: 1, batch: 89, loss: 2.230489730834961\n",
      "epoch: 1, batch: 90, loss: 2.209092855453491\n",
      "epoch: 1, batch: 91, loss: 2.205392360687256\n",
      "epoch: 1, batch: 92, loss: 2.221728801727295\n",
      "epoch: 1, batch: 93, loss: 2.219029188156128\n",
      "epoch: 1, batch: 94, loss: 2.2350006103515625\n",
      "epoch: 1, batch: 95, loss: 2.2066214084625244\n",
      "epoch: 1, batch: 96, loss: 2.20525860786438\n",
      "epoch: 1, batch: 97, loss: 2.233402967453003\n",
      "epoch: 1, batch: 98, loss: 2.2114341259002686\n",
      "epoch: 1, batch: 99, loss: 2.216567277908325\n",
      "epoch: 1, batch: 100, loss: 2.2428910732269287\n",
      "epoch: 1, batch: 101, loss: 2.2217328548431396\n",
      "epoch: 1, batch: 102, loss: 2.220513105392456\n",
      "epoch: 1, batch: 103, loss: 2.2251999378204346\n",
      "epoch: 1, batch: 104, loss: 2.236762523651123\n",
      "epoch: 1, batch: 105, loss: 2.250692129135132\n",
      "epoch: 1, batch: 106, loss: 2.2339820861816406\n",
      "epoch: 1, batch: 107, loss: 2.231675624847412\n",
      "epoch: 1, batch: 108, loss: 2.2390570640563965\n",
      "epoch: 1, batch: 109, loss: 2.244431972503662\n",
      "epoch: 1, batch: 110, loss: 2.2378437519073486\n",
      "epoch: 1, batch: 111, loss: 2.243776559829712\n",
      "epoch: 1, batch: 112, loss: 2.2542364597320557\n",
      "epoch: 1, batch: 113, loss: 2.206779956817627\n",
      "epoch: 1, batch: 114, loss: 2.2409913539886475\n",
      "epoch: 1, batch: 115, loss: 2.2174229621887207\n",
      "epoch: 1, batch: 116, loss: 2.2290897369384766\n",
      "epoch: 1, batch: 117, loss: 2.242244005203247\n",
      "epoch: 1, batch: 118, loss: 2.1841447353363037\n",
      "epoch: 1, batch: 119, loss: 2.213273525238037\n",
      "epoch: 1, batch: 120, loss: 2.2685089111328125\n",
      "epoch: 1, batch: 121, loss: 2.253614664077759\n",
      "epoch: 1, batch: 122, loss: 2.204460382461548\n",
      "epoch: 1, batch: 123, loss: 2.2036261558532715\n",
      "epoch: 1, batch: 124, loss: 2.215622901916504\n",
      "epoch: 1, batch: 125, loss: 2.213698387145996\n",
      "epoch: 1, batch: 126, loss: 2.2027063369750977\n",
      "epoch: 1, batch: 127, loss: 2.2132322788238525\n",
      "epoch: 1, batch: 128, loss: 2.2402164936065674\n",
      "epoch: 1, batch: 129, loss: 2.2260403633117676\n",
      "epoch: 1, batch: 130, loss: 2.2434804439544678\n",
      "epoch: 1, batch: 131, loss: 2.197817325592041\n",
      "epoch: 1, batch: 132, loss: 2.199310541152954\n",
      "epoch: 1, batch: 133, loss: 2.2391741275787354\n",
      "epoch: 1, batch: 134, loss: 2.242940902709961\n",
      "epoch: 1, batch: 135, loss: 2.2363128662109375\n",
      "epoch: 1, batch: 136, loss: 2.2431509494781494\n",
      "epoch: 1, batch: 137, loss: 2.2198948860168457\n",
      "epoch: 1, batch: 138, loss: 2.2273359298706055\n",
      "epoch: 1, batch: 139, loss: 2.229248046875\n",
      "epoch: 1, batch: 140, loss: 2.2565348148345947\n",
      "epoch: 1, batch: 141, loss: 2.228971481323242\n",
      "epoch: 1, batch: 142, loss: 2.2380552291870117\n",
      "epoch: 1, batch: 143, loss: 2.253038167953491\n",
      "epoch: 1, batch: 144, loss: 2.2352383136749268\n",
      "epoch: 1, batch: 145, loss: 2.230262279510498\n",
      "epoch: 1, batch: 146, loss: 2.2471671104431152\n",
      "epoch: 1, batch: 147, loss: 2.2176411151885986\n",
      "epoch: 1, batch: 148, loss: 2.229668378829956\n",
      "epoch: 1, batch: 149, loss: 2.2140302658081055\n",
      "epoch: 1, batch: 150, loss: 2.226813554763794\n",
      "epoch: 1, batch: 151, loss: 2.2146153450012207\n",
      "epoch: 1, batch: 152, loss: 2.2211790084838867\n",
      "epoch: 1, batch: 153, loss: 2.2187793254852295\n",
      "epoch: 1, batch: 154, loss: 2.20414400100708\n",
      "epoch: 1, batch: 155, loss: 2.2412919998168945\n",
      "epoch: 1, batch: 156, loss: 2.19138765335083\n",
      "epoch: 1, batch: 157, loss: 2.2576732635498047\n",
      "epoch: 1, batch: 158, loss: 2.1996169090270996\n",
      "epoch: 1, batch: 159, loss: 2.2050282955169678\n",
      "epoch: 1, batch: 160, loss: 2.216237783432007\n",
      "epoch: 1, batch: 161, loss: 2.2195169925689697\n",
      "epoch: 1, batch: 162, loss: 2.2194223403930664\n",
      "epoch: 1, batch: 163, loss: 2.1707210540771484\n",
      "epoch: 1, batch: 164, loss: 2.21006178855896\n",
      "epoch: 1, batch: 165, loss: 2.2644784450531006\n",
      "epoch: 1, batch: 166, loss: 2.2579903602600098\n",
      "epoch: 1, batch: 167, loss: 2.221113443374634\n",
      "epoch: 1, batch: 168, loss: 2.198638916015625\n",
      "epoch: 1, batch: 169, loss: 2.223862648010254\n",
      "epoch: 1, batch: 170, loss: 2.231757879257202\n",
      "epoch: 1, batch: 171, loss: 2.228433847427368\n",
      "epoch: 1, batch: 172, loss: 2.2414638996124268\n",
      "epoch: 1, batch: 173, loss: 2.2060635089874268\n",
      "epoch: 1, batch: 174, loss: 2.224644899368286\n",
      "epoch: 1, batch: 175, loss: 2.2668910026550293\n",
      "epoch: 1, batch: 176, loss: 2.2545711994171143\n",
      "epoch: 1, batch: 177, loss: 2.251185178756714\n",
      "epoch: 1, batch: 178, loss: 2.207315444946289\n",
      "epoch: 1, batch: 179, loss: 2.2276759147644043\n",
      "epoch: 1, batch: 180, loss: 2.241353988647461\n",
      "epoch: 1, batch: 181, loss: 2.2465808391571045\n",
      "epoch: 1, batch: 182, loss: 2.2236275672912598\n",
      "epoch: 1, batch: 183, loss: 2.212803840637207\n",
      "epoch: 1, batch: 184, loss: 2.2455618381500244\n",
      "epoch: 1, batch: 185, loss: 2.2517848014831543\n",
      "epoch: 1, batch: 186, loss: 2.2666375637054443\n",
      "epoch: 1, batch: 187, loss: 2.2146241664886475\n",
      "epoch: 1, batch: 188, loss: 2.245530605316162\n",
      "epoch: 1, batch: 189, loss: 2.210611343383789\n",
      "epoch: 1, batch: 190, loss: 2.2431139945983887\n",
      "epoch: 1, batch: 191, loss: 2.2159979343414307\n",
      "epoch: 1, batch: 192, loss: 2.223585367202759\n",
      "epoch: 1, batch: 193, loss: 2.196122169494629\n",
      "epoch: 1, batch: 194, loss: 2.2536563873291016\n",
      "epoch: 1, batch: 195, loss: 2.2189998626708984\n",
      "epoch: 1, batch: 196, loss: 2.2567522525787354\n",
      "epoch: 1, batch: 197, loss: 2.2435624599456787\n",
      "epoch: 1, batch: 198, loss: 2.2492194175720215\n",
      "epoch: 1, batch: 199, loss: 2.2324182987213135\n",
      "epoch: 1, batch: 200, loss: 2.2066798210144043\n",
      "epoch: 1, batch: 201, loss: 2.2537753582000732\n",
      "epoch: 1, batch: 202, loss: 2.225879669189453\n",
      "epoch: 1, batch: 203, loss: 2.2238574028015137\n",
      "epoch: 1, batch: 204, loss: 2.217827796936035\n",
      "epoch: 1, batch: 205, loss: 2.2087643146514893\n",
      "epoch: 1, batch: 206, loss: 2.2387475967407227\n",
      "epoch: 1, batch: 207, loss: 2.2198686599731445\n",
      "epoch: 1, batch: 208, loss: 2.252443313598633\n",
      "epoch: 1, batch: 209, loss: 2.1916518211364746\n",
      "epoch: 1, batch: 210, loss: 2.244002103805542\n",
      "epoch: 1, batch: 211, loss: 2.2313640117645264\n",
      "epoch: 1, batch: 212, loss: 2.2507596015930176\n",
      "epoch: 1, batch: 213, loss: 2.250119209289551\n",
      "epoch: 1, batch: 214, loss: 2.2252535820007324\n",
      "epoch: 1, batch: 215, loss: 2.2343714237213135\n",
      "epoch: 1, batch: 216, loss: 2.2469003200531006\n",
      "epoch: 1, batch: 217, loss: 2.204522132873535\n",
      "epoch: 1, batch: 218, loss: 2.240429401397705\n",
      "epoch: 1, batch: 219, loss: 2.244316577911377\n",
      "epoch: 1, batch: 220, loss: 2.240550994873047\n",
      "epoch: 1, batch: 221, loss: 2.2150583267211914\n",
      "epoch: 1, batch: 222, loss: 2.254119634628296\n",
      "epoch: 1, batch: 223, loss: 2.22418212890625\n",
      "epoch: 1, batch: 224, loss: 2.2261931896209717\n",
      "epoch: 1, batch: 225, loss: 2.2337145805358887\n",
      "epoch: 1, batch: 226, loss: 2.228712320327759\n",
      "epoch: 1, batch: 227, loss: 2.242845296859741\n",
      "epoch: 1, batch: 228, loss: 2.2293124198913574\n",
      "epoch: 1, batch: 229, loss: 2.2340900897979736\n",
      "epoch: 1, batch: 230, loss: 2.215369701385498\n",
      "epoch: 1, batch: 231, loss: 2.205522060394287\n",
      "epoch: 1, batch: 232, loss: 2.246819019317627\n",
      "epoch: 1, batch: 233, loss: 2.2266831398010254\n",
      "epoch: 1, batch: 234, loss: 2.2032535076141357\n",
      "epoch: 1, batch: 235, loss: 2.242593765258789\n",
      "epoch: 1, batch: 236, loss: 2.209517478942871\n",
      "epoch: 1, batch: 237, loss: 2.203831672668457\n",
      "epoch: 1, batch: 238, loss: 2.236574411392212\n",
      "epoch: 1, batch: 239, loss: 2.2586655616760254\n",
      "epoch: 1, batch: 240, loss: 2.2200376987457275\n",
      "epoch: 1, batch: 241, loss: 2.2454962730407715\n",
      "epoch: 1, batch: 242, loss: 2.2052149772644043\n",
      "epoch: 1, batch: 243, loss: 2.2352192401885986\n",
      "epoch: 1, batch: 244, loss: 2.2217066287994385\n",
      "epoch: 1, batch: 245, loss: 2.2354836463928223\n",
      "epoch: 1, batch: 246, loss: 2.2181200981140137\n",
      "epoch: 1, batch: 247, loss: 2.257537841796875\n",
      "epoch: 1, batch: 248, loss: 2.2387900352478027\n",
      "epoch: 1, batch: 249, loss: 2.155940532684326\n",
      "epoch: 1, batch: 250, loss: 2.210510730743408\n",
      "epoch: 1, batch: 251, loss: 2.177064895629883\n",
      "epoch: 1, batch: 252, loss: 2.2376646995544434\n",
      "epoch: 1, batch: 253, loss: 2.2018744945526123\n",
      "epoch: 1, batch: 254, loss: 2.2309324741363525\n",
      "epoch: 1, batch: 255, loss: 2.186307668685913\n",
      "epoch: 1, batch: 256, loss: 2.224581718444824\n",
      "epoch: 1, batch: 257, loss: 2.1997478008270264\n",
      "epoch: 1, batch: 258, loss: 2.2288243770599365\n",
      "epoch: 1, batch: 259, loss: 2.2019190788269043\n",
      "epoch: 1, batch: 260, loss: 2.2323453426361084\n",
      "epoch: 1, batch: 261, loss: 2.225796937942505\n",
      "epoch: 1, batch: 262, loss: 2.195174217224121\n",
      "epoch: 1, batch: 263, loss: 2.244558572769165\n",
      "epoch: 1, batch: 264, loss: 2.1853902339935303\n",
      "epoch: 1, batch: 265, loss: 2.1833794116973877\n",
      "epoch: 1, batch: 266, loss: 2.22072434425354\n",
      "epoch: 1, batch: 267, loss: 2.238046169281006\n",
      "epoch: 1, batch: 268, loss: 2.2054150104522705\n",
      "epoch: 1, batch: 269, loss: 2.1929702758789062\n",
      "epoch: 1, batch: 270, loss: 2.2258799076080322\n",
      "epoch: 1, batch: 271, loss: 2.2106809616088867\n",
      "epoch: 1, batch: 272, loss: 2.19368052482605\n",
      "epoch: 1, batch: 273, loss: 2.1878082752227783\n",
      "epoch: 1, batch: 274, loss: 2.2571916580200195\n",
      "epoch: 1, batch: 275, loss: 2.2309000492095947\n",
      "epoch: 1, batch: 276, loss: 2.2279000282287598\n",
      "epoch: 1, batch: 277, loss: 2.2382001876831055\n",
      "epoch: 1, batch: 278, loss: 2.234187364578247\n",
      "epoch: 1, batch: 279, loss: 2.227933406829834\n",
      "epoch: 1, batch: 280, loss: 2.2121880054473877\n",
      "epoch: 1, batch: 281, loss: 2.2462689876556396\n",
      "epoch: 1, batch: 282, loss: 2.2208824157714844\n",
      "epoch: 1, batch: 283, loss: 2.241180896759033\n",
      "epoch: 1, batch: 284, loss: 2.2013094425201416\n",
      "epoch: 1, batch: 285, loss: 2.1848456859588623\n",
      "epoch: 1, batch: 286, loss: 2.221587896347046\n",
      "epoch: 1, batch: 287, loss: 2.1871097087860107\n",
      "epoch: 1, batch: 288, loss: 2.215766429901123\n",
      "epoch: 1, batch: 289, loss: 2.2178432941436768\n",
      "epoch: 1, batch: 290, loss: 2.197234630584717\n",
      "epoch: 1, batch: 291, loss: 2.2163078784942627\n",
      "epoch: 1, batch: 292, loss: 2.198699474334717\n",
      "epoch: 1, batch: 293, loss: 2.227445602416992\n",
      "epoch: 1, batch: 294, loss: 2.2116928100585938\n",
      "epoch: 1, batch: 295, loss: 2.204606056213379\n",
      "epoch: 1, batch: 296, loss: 2.2217013835906982\n",
      "epoch: 1, batch: 297, loss: 2.239370346069336\n",
      "epoch: 1, batch: 298, loss: 2.2268550395965576\n",
      "epoch: 1, batch: 299, loss: 2.198061466217041\n",
      "epoch: 1, batch: 300, loss: 2.2128243446350098\n",
      "epoch: 1, batch: 301, loss: 2.1758363246917725\n",
      "epoch: 1, batch: 302, loss: 2.1928904056549072\n",
      "epoch: 1, batch: 303, loss: 2.192009925842285\n",
      "epoch: 1, batch: 304, loss: 2.2706305980682373\n",
      "epoch: 1, batch: 305, loss: 2.2201147079467773\n",
      "epoch: 1, batch: 306, loss: 2.249908447265625\n",
      "epoch: 1, batch: 307, loss: 2.1952383518218994\n",
      "epoch: 1, batch: 308, loss: 2.2646708488464355\n",
      "epoch: 1, batch: 309, loss: 2.2387938499450684\n",
      "epoch: 1, batch: 310, loss: 2.2091360092163086\n",
      "epoch: 1, batch: 311, loss: 2.2040629386901855\n",
      "epoch: 1, batch: 312, loss: 2.236745834350586\n",
      "epoch: 1, batch: 313, loss: 2.224461793899536\n",
      "epoch: 1, batch: 314, loss: 2.2201004028320312\n",
      "epoch: 1, batch: 315, loss: 2.199606418609619\n",
      "epoch: 1, batch: 316, loss: 2.2293543815612793\n",
      "epoch: 1, batch: 317, loss: 2.205460786819458\n",
      "epoch: 1, batch: 318, loss: 2.196239471435547\n",
      "epoch: 1, batch: 319, loss: 2.230340003967285\n",
      "epoch: 1, batch: 320, loss: 2.225985527038574\n",
      "epoch: 1, batch: 321, loss: 2.2165887355804443\n",
      "epoch: 1, batch: 322, loss: 2.2194783687591553\n",
      "epoch: 1, batch: 323, loss: 2.230006217956543\n",
      "epoch: 1, batch: 324, loss: 2.2399590015411377\n",
      "epoch: 1, batch: 325, loss: 2.21781849861145\n",
      "epoch: 1, batch: 326, loss: 2.1852550506591797\n",
      "epoch: 1, batch: 327, loss: 2.174863338470459\n",
      "epoch: 1, batch: 328, loss: 2.166842222213745\n",
      "epoch: 1, batch: 329, loss: 2.2085254192352295\n",
      "epoch: 1, batch: 330, loss: 2.2603394985198975\n",
      "epoch: 1, batch: 331, loss: 2.252340316772461\n",
      "epoch: 1, batch: 332, loss: 2.217346429824829\n",
      "epoch: 1, batch: 333, loss: 2.255357265472412\n",
      "epoch: 1, batch: 334, loss: 2.2585573196411133\n",
      "epoch: 1, batch: 335, loss: 2.176605224609375\n",
      "epoch: 1, batch: 336, loss: 2.206634044647217\n",
      "epoch: 1, batch: 337, loss: 2.2325778007507324\n",
      "epoch: 1, batch: 338, loss: 2.2164676189422607\n",
      "epoch: 1, batch: 339, loss: 2.194164752960205\n",
      "epoch: 1, batch: 340, loss: 2.2485196590423584\n",
      "epoch: 1, batch: 341, loss: 2.181610584259033\n",
      "epoch: 1, batch: 342, loss: 2.2127461433410645\n",
      "epoch: 1, batch: 343, loss: 2.2121596336364746\n",
      "epoch: 1, batch: 344, loss: 2.242462635040283\n",
      "epoch: 1, batch: 345, loss: 2.2222585678100586\n",
      "epoch: 1, batch: 346, loss: 2.1840169429779053\n",
      "epoch: 1, batch: 347, loss: 2.2452378273010254\n",
      "epoch: 1, batch: 348, loss: 2.244767665863037\n",
      "epoch: 1, batch: 349, loss: 2.2517638206481934\n",
      "epoch: 1, batch: 350, loss: 2.2466795444488525\n",
      "epoch: 1, batch: 351, loss: 2.2199718952178955\n",
      "epoch: 1, batch: 352, loss: 2.2092936038970947\n",
      "epoch: 1, batch: 353, loss: 2.26000714302063\n",
      "epoch: 1, batch: 354, loss: 2.207364320755005\n",
      "epoch: 1, batch: 355, loss: 2.1971380710601807\n",
      "epoch: 1, batch: 356, loss: 2.2033183574676514\n",
      "epoch: 1, batch: 357, loss: 2.2189254760742188\n",
      "epoch: 1, batch: 358, loss: 2.1781554222106934\n",
      "epoch: 1, batch: 359, loss: 2.199129104614258\n",
      "epoch: 1, batch: 360, loss: 2.2211735248565674\n",
      "epoch: 1, batch: 361, loss: 2.214590072631836\n",
      "epoch: 1, batch: 362, loss: 2.2227931022644043\n",
      "epoch: 1, batch: 363, loss: 2.2064833641052246\n",
      "epoch: 1, batch: 364, loss: 2.236480236053467\n",
      "epoch: 1, batch: 365, loss: 2.1934735774993896\n",
      "epoch: 1, batch: 366, loss: 2.2143032550811768\n",
      "epoch: 1, batch: 367, loss: 2.253896713256836\n",
      "epoch: 1, batch: 368, loss: 2.2206504344940186\n",
      "epoch: 1, batch: 369, loss: 2.224689483642578\n",
      "epoch: 1, batch: 370, loss: 2.1820478439331055\n",
      "epoch: 1, batch: 371, loss: 2.2154815196990967\n",
      "epoch: 1, batch: 372, loss: 2.2066948413848877\n",
      "epoch: 1, batch: 373, loss: 2.2202372550964355\n",
      "epoch: 1, batch: 374, loss: 2.224820375442505\n",
      "epoch: 1, batch: 375, loss: 2.1803336143493652\n",
      "epoch: 1, batch: 376, loss: 2.2106730937957764\n",
      "epoch: 1, batch: 377, loss: 2.2020084857940674\n",
      "epoch: 1, batch: 378, loss: 2.1944949626922607\n",
      "epoch: 1, batch: 379, loss: 2.196059465408325\n",
      "epoch: 1, batch: 380, loss: 2.2263731956481934\n",
      "epoch: 1, batch: 381, loss: 2.1896729469299316\n",
      "epoch: 1, batch: 382, loss: 2.2384767532348633\n",
      "epoch: 1, batch: 383, loss: 2.219278335571289\n",
      "epoch: 1, batch: 384, loss: 2.214125394821167\n",
      "epoch: 1, batch: 385, loss: 2.1600279808044434\n",
      "epoch: 1, batch: 386, loss: 2.185476541519165\n",
      "epoch: 1, batch: 387, loss: 2.2680609226226807\n",
      "epoch: 1, batch: 388, loss: 2.2000393867492676\n",
      "epoch: 1, batch: 389, loss: 2.194406747817993\n",
      "epoch: 1, batch: 390, loss: 2.2367238998413086\n",
      "epoch: 1, batch: 391, loss: 2.2254836559295654\n",
      "epoch: 1, batch: 392, loss: 2.232645034790039\n",
      "epoch: 1, batch: 393, loss: 2.199094295501709\n",
      "epoch: 1, batch: 394, loss: 2.2077393531799316\n",
      "epoch: 1, batch: 395, loss: 2.205498456954956\n",
      "epoch: 1, batch: 396, loss: 2.2276368141174316\n",
      "epoch: 1, batch: 397, loss: 2.207423686981201\n",
      "epoch: 1, batch: 398, loss: 2.2134718894958496\n",
      "epoch: 1, batch: 399, loss: 2.1992197036743164\n",
      "epoch: 1, batch: 400, loss: 2.2355551719665527\n",
      "epoch: 1, batch: 401, loss: 2.211904287338257\n",
      "epoch: 1, batch: 402, loss: 2.191632032394409\n",
      "epoch: 1, batch: 403, loss: 2.227540969848633\n",
      "epoch: 1, batch: 404, loss: 2.19064998626709\n",
      "epoch: 1, batch: 405, loss: 2.221712827682495\n",
      "epoch: 1, batch: 406, loss: 2.174804449081421\n",
      "epoch: 1, batch: 407, loss: 2.206677198410034\n",
      "epoch: 1, batch: 408, loss: 2.239184856414795\n",
      "epoch: 1, batch: 409, loss: 2.218636989593506\n",
      "epoch: 1, batch: 410, loss: 2.208801507949829\n",
      "epoch: 1, batch: 411, loss: 2.196662425994873\n",
      "epoch: 1, batch: 412, loss: 2.207280158996582\n",
      "epoch: 1, batch: 413, loss: 2.208786964416504\n",
      "epoch: 1, batch: 414, loss: 2.198302745819092\n",
      "epoch: 1, batch: 415, loss: 2.2062923908233643\n",
      "epoch: 1, batch: 416, loss: 2.192915678024292\n",
      "epoch: 1, batch: 417, loss: 2.2463932037353516\n",
      "epoch: 1, batch: 418, loss: 2.2451703548431396\n",
      "epoch: 1, batch: 419, loss: 2.2259714603424072\n",
      "epoch: 1, batch: 420, loss: 2.1839234828948975\n",
      "epoch: 1, batch: 421, loss: 2.19901180267334\n",
      "epoch: 1, batch: 422, loss: 2.2070536613464355\n",
      "epoch: 1, batch: 423, loss: 2.2100038528442383\n",
      "epoch: 1, batch: 424, loss: 2.178335189819336\n",
      "epoch: 1, batch: 425, loss: 2.176865577697754\n",
      "epoch: 1, batch: 426, loss: 2.2275280952453613\n",
      "epoch: 1, batch: 427, loss: 2.2151925563812256\n",
      "epoch: 1, batch: 428, loss: 2.183190107345581\n",
      "epoch: 1, batch: 429, loss: 2.198206663131714\n",
      "epoch: 1, batch: 430, loss: 2.188375473022461\n",
      "epoch: 1, batch: 431, loss: 2.244288444519043\n",
      "epoch: 1, batch: 432, loss: 2.1789345741271973\n",
      "epoch: 1, batch: 433, loss: 2.209628105163574\n",
      "epoch: 1, batch: 434, loss: 2.2349085807800293\n",
      "epoch: 1, batch: 435, loss: 2.214146375656128\n",
      "epoch: 1, batch: 436, loss: 2.2088851928710938\n",
      "epoch: 1, batch: 437, loss: 2.2039546966552734\n",
      "epoch: 1, batch: 438, loss: 2.2193334102630615\n",
      "epoch: 1, batch: 439, loss: 2.179746389389038\n",
      "epoch: 1, batch: 440, loss: 2.2104885578155518\n",
      "epoch: 1, batch: 441, loss: 2.2408924102783203\n",
      "epoch: 1, batch: 442, loss: 2.208407163619995\n",
      "epoch: 1, batch: 443, loss: 2.205965280532837\n",
      "epoch: 1, batch: 444, loss: 2.224599599838257\n",
      "epoch: 1, batch: 445, loss: 2.2110283374786377\n",
      "epoch: 1, batch: 446, loss: 2.2252142429351807\n",
      "epoch: 1, batch: 447, loss: 2.2032361030578613\n",
      "epoch: 1, batch: 448, loss: 2.20204758644104\n",
      "epoch: 1, batch: 449, loss: 2.215501546859741\n",
      "epoch: 1, batch: 450, loss: 2.1951425075531006\n",
      "epoch: 1, batch: 451, loss: 2.191336154937744\n",
      "epoch: 1, batch: 452, loss: 2.1960461139678955\n",
      "epoch: 1, batch: 453, loss: 2.218879222869873\n",
      "epoch: 1, batch: 454, loss: 2.234402656555176\n",
      "epoch: 1, batch: 455, loss: 2.19998836517334\n",
      "epoch: 1, batch: 456, loss: 2.216723680496216\n",
      "epoch: 1, batch: 457, loss: 2.1764767169952393\n",
      "epoch: 1, batch: 458, loss: 2.2294578552246094\n",
      "epoch: 1, batch: 459, loss: 2.1905932426452637\n",
      "epoch: 1, batch: 460, loss: 2.179457902908325\n",
      "epoch: 1, batch: 461, loss: 2.207468271255493\n",
      "epoch: 1, batch: 462, loss: 2.2088475227355957\n",
      "epoch: 1, batch: 463, loss: 2.173424005508423\n",
      "epoch: 1, batch: 464, loss: 2.271090030670166\n",
      "epoch: 1, batch: 465, loss: 2.2541024684906006\n",
      "epoch: 1, batch: 466, loss: 2.2231388092041016\n",
      "epoch: 1, batch: 467, loss: 2.2475576400756836\n",
      "epoch: 1, batch: 468, loss: 2.2327606678009033\n",
      "epoch: 1, batch: 469, loss: 2.1634786128997803\n",
      "epoch: 1, batch: 470, loss: 2.1971607208251953\n",
      "epoch: 1, batch: 471, loss: 2.204073190689087\n",
      "epoch: 1, batch: 472, loss: 2.242652177810669\n",
      "epoch: 1, batch: 473, loss: 2.1660397052764893\n",
      "epoch: 1, batch: 474, loss: 2.263855218887329\n",
      "epoch: 1, batch: 475, loss: 2.2321081161499023\n",
      "epoch: 1, batch: 476, loss: 2.221076488494873\n",
      "epoch: 1, batch: 477, loss: 2.212646484375\n",
      "epoch: 1, batch: 478, loss: 2.1904430389404297\n",
      "epoch: 1, batch: 479, loss: 2.189641237258911\n",
      "epoch: 1, batch: 480, loss: 2.209397077560425\n",
      "epoch: 1, batch: 481, loss: 2.2060928344726562\n",
      "epoch: 1, batch: 482, loss: 2.2132415771484375\n",
      "epoch: 1, batch: 483, loss: 2.246098041534424\n",
      "epoch: 1, batch: 484, loss: 2.1841273307800293\n",
      "epoch: 1, batch: 485, loss: 2.1914353370666504\n",
      "epoch: 1, batch: 486, loss: 2.2161879539489746\n",
      "epoch: 1, batch: 487, loss: 2.2535738945007324\n",
      "epoch: 1, batch: 488, loss: 2.2176690101623535\n",
      "epoch: 1, batch: 489, loss: 2.226665496826172\n",
      "epoch: 1, batch: 490, loss: 2.212313175201416\n",
      "epoch: 1, batch: 491, loss: 2.2233808040618896\n",
      "epoch: 1, batch: 492, loss: 2.2025070190429688\n",
      "epoch: 1, batch: 493, loss: 2.1625149250030518\n",
      "epoch: 1, batch: 494, loss: 2.2228844165802\n",
      "epoch: 1, batch: 495, loss: 2.2214059829711914\n",
      "epoch: 1, batch: 496, loss: 2.206965923309326\n",
      "epoch: 1, batch: 497, loss: 2.216320753097534\n",
      "epoch: 1, batch: 498, loss: 2.146458625793457\n",
      "epoch: 1, batch: 499, loss: 2.20947003364563\n",
      "epoch: 1, batch: 500, loss: 2.1886813640594482\n",
      "epoch: 1, batch: 501, loss: 2.208380937576294\n",
      "epoch: 1, batch: 502, loss: 2.198077440261841\n",
      "epoch: 1, batch: 503, loss: 2.2127416133880615\n",
      "epoch: 1, batch: 504, loss: 2.2254157066345215\n",
      "epoch: 1, batch: 505, loss: 2.2159910202026367\n",
      "epoch: 1, batch: 506, loss: 2.234574794769287\n",
      "epoch: 1, batch: 507, loss: 2.1780662536621094\n",
      "epoch: 1, batch: 508, loss: 2.2125155925750732\n",
      "epoch: 1, batch: 509, loss: 2.1910996437072754\n",
      "epoch: 1, batch: 510, loss: 2.186262369155884\n",
      "epoch: 1, batch: 511, loss: 2.153540849685669\n",
      "epoch: 1, batch: 512, loss: 2.193831443786621\n",
      "epoch: 1, batch: 513, loss: 2.2042670249938965\n",
      "epoch: 1, batch: 514, loss: 2.217664957046509\n",
      "epoch: 1, batch: 515, loss: 2.191270589828491\n",
      "epoch: 1, batch: 516, loss: 2.204641580581665\n",
      "epoch: 1, batch: 517, loss: 2.207171678543091\n",
      "epoch: 1, batch: 518, loss: 2.1916489601135254\n",
      "epoch: 1, batch: 519, loss: 2.1745986938476562\n",
      "epoch: 1, batch: 520, loss: 2.200434446334839\n",
      "epoch: 1, batch: 521, loss: 2.2199182510375977\n",
      "epoch: 1, batch: 522, loss: 2.182952404022217\n",
      "epoch: 1, batch: 523, loss: 2.2297275066375732\n",
      "epoch: 1, batch: 524, loss: 2.214630365371704\n",
      "epoch: 1, batch: 525, loss: 2.21915340423584\n",
      "epoch: 1, batch: 526, loss: 2.1893553733825684\n",
      "epoch: 1, batch: 527, loss: 2.239391803741455\n",
      "epoch: 1, batch: 528, loss: 2.1964612007141113\n",
      "epoch: 1, batch: 529, loss: 2.196540355682373\n",
      "epoch: 1, batch: 530, loss: 2.1849498748779297\n",
      "epoch: 1, batch: 531, loss: 2.2135486602783203\n",
      "epoch: 1, batch: 532, loss: 2.1577913761138916\n",
      "epoch: 1, batch: 533, loss: 2.21293306350708\n",
      "epoch: 1, batch: 534, loss: 2.229194402694702\n",
      "epoch: 1, batch: 535, loss: 2.2125561237335205\n",
      "epoch: 1, batch: 536, loss: 2.1992595195770264\n",
      "epoch: 1, batch: 537, loss: 2.2207186222076416\n",
      "epoch: 1, batch: 538, loss: 2.1830391883850098\n",
      "epoch: 1, batch: 539, loss: 2.1690897941589355\n",
      "epoch: 1, batch: 540, loss: 2.211428165435791\n",
      "epoch: 1, batch: 541, loss: 2.209352970123291\n",
      "epoch: 1, batch: 542, loss: 2.2161200046539307\n",
      "epoch: 1, batch: 543, loss: 2.1841464042663574\n",
      "epoch: 1, batch: 544, loss: 2.1630733013153076\n",
      "epoch: 1, batch: 545, loss: 2.177305221557617\n",
      "epoch: 1, batch: 546, loss: 2.2093238830566406\n",
      "epoch: 1, batch: 547, loss: 2.186018466949463\n",
      "epoch: 1, batch: 548, loss: 2.196326732635498\n",
      "epoch: 1, batch: 549, loss: 2.14912486076355\n",
      "epoch: 1, batch: 550, loss: 2.183656930923462\n",
      "epoch: 1, batch: 551, loss: 2.2377614974975586\n",
      "epoch: 1, batch: 552, loss: 2.2247278690338135\n",
      "epoch: 1, batch: 553, loss: 2.1864869594573975\n",
      "epoch: 1, batch: 554, loss: 2.2523415088653564\n",
      "epoch: 1, batch: 555, loss: 2.252608060836792\n",
      "epoch: 1, batch: 556, loss: 2.223193645477295\n",
      "epoch: 1, batch: 557, loss: 2.2015655040740967\n",
      "epoch: 1, batch: 558, loss: 2.2188663482666016\n",
      "epoch: 1, batch: 559, loss: 2.1872944831848145\n",
      "epoch: 1, batch: 560, loss: 2.2002041339874268\n",
      "epoch: 1, batch: 561, loss: 2.198519706726074\n",
      "epoch: 1, batch: 562, loss: 2.1815481185913086\n",
      "epoch: 1, batch: 563, loss: 2.1783361434936523\n",
      "epoch: 1, batch: 564, loss: 2.1949546337127686\n",
      "epoch: 1, batch: 565, loss: 2.1895530223846436\n",
      "epoch: 1, batch: 566, loss: 2.1879477500915527\n",
      "epoch: 1, batch: 567, loss: 2.2128078937530518\n",
      "epoch: 1, batch: 568, loss: 2.2349536418914795\n",
      "epoch: 1, batch: 569, loss: 2.2058212757110596\n",
      "epoch: 1, batch: 570, loss: 2.2133073806762695\n",
      "epoch: 1, batch: 571, loss: 2.1977651119232178\n",
      "epoch: 1, batch: 572, loss: 2.184680223464966\n",
      "epoch: 1, batch: 573, loss: 2.210451126098633\n",
      "epoch: 1, batch: 574, loss: 2.1660680770874023\n",
      "epoch: 1, batch: 575, loss: 2.165245771408081\n",
      "epoch: 1, batch: 576, loss: 2.174100875854492\n",
      "epoch: 1, batch: 577, loss: 2.241345167160034\n",
      "epoch: 1, batch: 578, loss: 2.170837163925171\n",
      "epoch: 1, batch: 579, loss: 2.212294340133667\n",
      "epoch: 1, batch: 580, loss: 2.204637289047241\n",
      "epoch: 1, batch: 581, loss: 2.192575693130493\n",
      "epoch: 1, batch: 582, loss: 2.226985216140747\n",
      "epoch: 1, batch: 583, loss: 2.193688154220581\n",
      "epoch: 1, batch: 584, loss: 2.1878867149353027\n",
      "epoch: 1, batch: 585, loss: 2.1920673847198486\n",
      "epoch: 1, batch: 586, loss: 2.180001974105835\n",
      "epoch: 1, batch: 587, loss: 2.1750431060791016\n",
      "epoch: 1, batch: 588, loss: 2.158543825149536\n",
      "epoch: 1, batch: 589, loss: 2.165132999420166\n",
      "epoch: 1, batch: 590, loss: 2.204441547393799\n",
      "epoch: 1, batch: 591, loss: 2.177332639694214\n",
      "epoch: 1, batch: 592, loss: 2.157021999359131\n",
      "epoch: 1, batch: 593, loss: 2.1825332641601562\n",
      "epoch: 1, batch: 594, loss: 2.125994920730591\n",
      "epoch: 1, batch: 595, loss: 2.1843438148498535\n",
      "epoch: 1, batch: 596, loss: 2.228178024291992\n",
      "epoch: 1, batch: 597, loss: 2.203798770904541\n",
      "epoch: 1, batch: 598, loss: 2.1989452838897705\n",
      "epoch: 1, batch: 599, loss: 2.173567295074463\n",
      "epoch: 1, batch: 600, loss: 2.2189671993255615\n",
      "epoch: 1, batch: 601, loss: 2.187094211578369\n",
      "epoch: 1, batch: 602, loss: 2.1755380630493164\n",
      "epoch: 1, batch: 603, loss: 2.198071002960205\n",
      "epoch: 1, batch: 604, loss: 2.1744630336761475\n",
      "epoch: 1, batch: 605, loss: 2.1876609325408936\n",
      "epoch: 1, batch: 606, loss: 2.2047948837280273\n",
      "epoch: 1, batch: 607, loss: 2.1549408435821533\n",
      "epoch: 1, batch: 608, loss: 2.1943180561065674\n",
      "epoch: 1, batch: 609, loss: 2.1319189071655273\n",
      "epoch: 1, batch: 610, loss: 2.193169116973877\n",
      "epoch: 1, batch: 611, loss: 2.2008726596832275\n",
      "epoch: 1, batch: 612, loss: 2.195730209350586\n",
      "epoch: 1, batch: 613, loss: 2.139796733856201\n",
      "epoch: 1, batch: 614, loss: 2.1530704498291016\n",
      "epoch: 1, batch: 615, loss: 2.191222906112671\n",
      "epoch: 1, batch: 616, loss: 2.2111849784851074\n",
      "epoch: 1, batch: 617, loss: 2.1512598991394043\n",
      "epoch: 1, batch: 618, loss: 2.137644052505493\n",
      "epoch: 1, batch: 619, loss: 2.165315866470337\n",
      "epoch: 1, batch: 620, loss: 2.197561025619507\n",
      "epoch: 1, batch: 621, loss: 2.2231781482696533\n",
      "epoch: 1, batch: 622, loss: 2.2120184898376465\n",
      "epoch: 1, batch: 623, loss: 2.1588714122772217\n",
      "epoch: 1, batch: 624, loss: 2.1998417377471924\n",
      "epoch: 1, batch: 625, loss: 2.204200506210327\n",
      "epoch: 1, batch: 626, loss: 2.193002462387085\n",
      "epoch: 1, batch: 627, loss: 2.2305519580841064\n",
      "epoch: 1, batch: 628, loss: 2.1899423599243164\n",
      "epoch: 1, batch: 629, loss: 2.2260775566101074\n",
      "epoch: 1, batch: 630, loss: 2.175492525100708\n",
      "epoch: 1, batch: 631, loss: 2.167436361312866\n",
      "epoch: 1, batch: 632, loss: 2.2285614013671875\n",
      "epoch: 1, batch: 633, loss: 2.1573987007141113\n",
      "epoch: 1, batch: 634, loss: 2.206166982650757\n",
      "epoch: 1, batch: 635, loss: 2.223667621612549\n",
      "epoch: 1, batch: 636, loss: 2.1668570041656494\n",
      "epoch: 1, batch: 637, loss: 2.166219472885132\n",
      "epoch: 1, batch: 638, loss: 2.1938822269439697\n",
      "epoch: 1, batch: 639, loss: 2.1830689907073975\n",
      "epoch: 1, batch: 640, loss: 2.2131564617156982\n",
      "epoch: 1, batch: 641, loss: 2.229250192642212\n",
      "epoch: 1, batch: 642, loss: 2.1781342029571533\n",
      "epoch: 1, batch: 643, loss: 2.198772430419922\n",
      "epoch: 1, batch: 644, loss: 2.1850497722625732\n",
      "epoch: 1, batch: 645, loss: 2.2132863998413086\n",
      "epoch: 1, batch: 646, loss: 2.1493566036224365\n",
      "epoch: 1, batch: 647, loss: 2.174417734146118\n",
      "epoch: 1, batch: 648, loss: 2.1619889736175537\n",
      "epoch: 1, batch: 649, loss: 2.286184310913086\n",
      "epoch: 1, batch: 650, loss: 2.190885543823242\n",
      "epoch: 1, batch: 651, loss: 2.180436372756958\n",
      "epoch: 1, batch: 652, loss: 2.1983513832092285\n",
      "epoch: 1, batch: 653, loss: 2.206026554107666\n",
      "epoch: 1, batch: 654, loss: 2.210550308227539\n",
      "epoch: 1, batch: 655, loss: 2.159785747528076\n",
      "epoch: 1, batch: 656, loss: 2.204580068588257\n",
      "epoch: 1, batch: 657, loss: 2.1879711151123047\n",
      "epoch: 1, batch: 658, loss: 2.1694626808166504\n",
      "epoch: 1, batch: 659, loss: 2.1671817302703857\n",
      "epoch: 1, batch: 660, loss: 2.1818528175354004\n",
      "epoch: 1, batch: 661, loss: 2.208908796310425\n",
      "epoch: 1, batch: 662, loss: 2.1786441802978516\n",
      "epoch: 1, batch: 663, loss: 2.216698408126831\n",
      "epoch: 1, batch: 664, loss: 2.2458345890045166\n",
      "epoch: 1, batch: 665, loss: 2.2537851333618164\n",
      "epoch: 1, batch: 666, loss: 2.2363462448120117\n",
      "epoch: 1, batch: 667, loss: 2.183358669281006\n",
      "epoch: 1, batch: 668, loss: 2.2043254375457764\n",
      "epoch: 1, batch: 669, loss: 2.174891233444214\n",
      "epoch: 1, batch: 670, loss: 2.2405834197998047\n",
      "epoch: 1, batch: 671, loss: 2.176826000213623\n",
      "epoch: 1, batch: 672, loss: 2.220254421234131\n",
      "epoch: 1, batch: 673, loss: 2.2020263671875\n",
      "epoch: 1, batch: 674, loss: 2.1841585636138916\n",
      "epoch: 1, batch: 675, loss: 2.2599804401397705\n",
      "epoch: 1, batch: 676, loss: 2.1716041564941406\n",
      "epoch: 1, batch: 677, loss: 2.1983397006988525\n",
      "epoch: 1, batch: 678, loss: 2.1781866550445557\n",
      "epoch: 1, batch: 679, loss: 2.208615779876709\n",
      "epoch: 1, batch: 680, loss: 2.162588119506836\n",
      "epoch: 1, batch: 681, loss: 2.2095768451690674\n",
      "epoch: 1, batch: 682, loss: 2.1871869564056396\n",
      "epoch: 1, batch: 683, loss: 2.192307472229004\n",
      "epoch: 1, batch: 684, loss: 2.174295425415039\n",
      "epoch: 1, batch: 685, loss: 2.2011044025421143\n",
      "epoch: 1, batch: 686, loss: 2.2043190002441406\n",
      "epoch: 1, batch: 687, loss: 2.238132953643799\n",
      "epoch: 1, batch: 688, loss: 2.2122650146484375\n",
      "epoch: 1, batch: 689, loss: 2.1850011348724365\n",
      "epoch: 1, batch: 690, loss: 2.200284719467163\n",
      "epoch: 1, batch: 691, loss: 2.1891896724700928\n",
      "epoch: 1, batch: 692, loss: 2.1933183670043945\n",
      "epoch: 1, batch: 693, loss: 2.1241812705993652\n",
      "epoch: 1, batch: 694, loss: 2.241905689239502\n",
      "epoch: 1, batch: 695, loss: 2.2019968032836914\n",
      "epoch: 1, batch: 696, loss: 2.1707160472869873\n",
      "epoch: 1, batch: 697, loss: 2.1853137016296387\n",
      "epoch: 1, batch: 698, loss: 2.1665127277374268\n",
      "epoch: 1, batch: 699, loss: 2.1918346881866455\n",
      "epoch: 1, batch: 700, loss: 2.1965062618255615\n",
      "epoch: 1, batch: 701, loss: 2.1930744647979736\n",
      "epoch: 1, batch: 702, loss: 2.2198667526245117\n",
      "epoch: 1, batch: 703, loss: 2.2364189624786377\n",
      "epoch: 1, batch: 704, loss: 2.181335210800171\n",
      "epoch: 1, batch: 705, loss: 2.2379798889160156\n",
      "epoch: 1, batch: 706, loss: 2.184936761856079\n",
      "epoch: 1, batch: 707, loss: 2.175004005432129\n",
      "epoch: 1, batch: 708, loss: 2.211716413497925\n",
      "epoch: 1, batch: 709, loss: 2.161956548690796\n",
      "epoch: 1, batch: 710, loss: 2.2025933265686035\n",
      "epoch: 1, batch: 711, loss: 2.234715461730957\n",
      "epoch: 1, batch: 712, loss: 2.1882872581481934\n",
      "epoch: 1, batch: 713, loss: 2.183771848678589\n",
      "epoch: 1, batch: 714, loss: 2.206907272338867\n",
      "epoch: 1, batch: 715, loss: 2.2088050842285156\n",
      "epoch: 1, batch: 716, loss: 2.1719586849212646\n",
      "epoch: 1, batch: 717, loss: 2.211066484451294\n",
      "epoch: 1, batch: 718, loss: 2.2002220153808594\n",
      "epoch: 1, batch: 719, loss: 2.209455966949463\n",
      "epoch: 1, batch: 720, loss: 2.2184555530548096\n",
      "epoch: 1, batch: 721, loss: 2.1460394859313965\n",
      "epoch: 1, batch: 722, loss: 2.1722731590270996\n",
      "epoch: 1, batch: 723, loss: 2.174954891204834\n",
      "epoch: 1, batch: 724, loss: 2.199237585067749\n",
      "epoch: 1, batch: 725, loss: 2.1733670234680176\n",
      "epoch: 1, batch: 726, loss: 2.1680092811584473\n",
      "epoch: 1, batch: 727, loss: 2.1598381996154785\n",
      "epoch: 1, batch: 728, loss: 2.209001302719116\n",
      "epoch: 1, batch: 729, loss: 2.211613655090332\n",
      "epoch: 1, batch: 730, loss: 2.1859922409057617\n",
      "epoch: 1, batch: 731, loss: 2.191160202026367\n",
      "epoch: 1, batch: 732, loss: 2.215836763381958\n",
      "epoch: 1, batch: 733, loss: 2.179412841796875\n",
      "epoch: 1, batch: 734, loss: 2.203389883041382\n",
      "epoch: 1, batch: 735, loss: 2.1748147010803223\n",
      "epoch: 1, batch: 736, loss: 2.222407817840576\n",
      "epoch: 1, batch: 737, loss: 2.1740407943725586\n",
      "epoch: 1, batch: 738, loss: 2.19016170501709\n",
      "epoch: 1, batch: 739, loss: 2.1856601238250732\n",
      "epoch: 1, batch: 740, loss: 2.241150140762329\n",
      "epoch: 1, batch: 741, loss: 2.182807207107544\n",
      "epoch: 1, batch: 742, loss: 2.1840243339538574\n",
      "epoch: 1, batch: 743, loss: 2.209554433822632\n",
      "epoch: 1, batch: 744, loss: 2.1569530963897705\n",
      "epoch: 1, batch: 745, loss: 2.1883835792541504\n",
      "epoch: 1, batch: 746, loss: 2.1871085166931152\n",
      "epoch: 1, batch: 747, loss: 2.1840920448303223\n",
      "epoch: 1, batch: 748, loss: 2.183910369873047\n",
      "epoch: 1, batch: 749, loss: 2.1366121768951416\n",
      "epoch: 1, batch: 750, loss: 2.1644277572631836\n",
      "epoch: 1, batch: 751, loss: 2.2063443660736084\n",
      "epoch: 1, batch: 752, loss: 2.2182555198669434\n",
      "epoch: 1, batch: 753, loss: 2.1603786945343018\n",
      "epoch: 1, batch: 754, loss: 2.186440944671631\n",
      "epoch: 1, batch: 755, loss: 2.1960830688476562\n",
      "epoch: 1, batch: 756, loss: 2.1724627017974854\n",
      "epoch: 1, batch: 757, loss: 2.165804624557495\n",
      "epoch: 1, batch: 758, loss: 2.194739580154419\n",
      "epoch: 1, batch: 759, loss: 2.2206549644470215\n",
      "epoch: 1, batch: 760, loss: 2.1794583797454834\n",
      "epoch: 1, batch: 761, loss: 2.215451240539551\n",
      "epoch: 1, batch: 762, loss: 2.192521810531616\n",
      "epoch: 1, batch: 763, loss: 2.159100294113159\n",
      "epoch: 1, batch: 764, loss: 2.2023096084594727\n",
      "epoch: 1, batch: 765, loss: 2.1904854774475098\n",
      "epoch: 1, batch: 766, loss: 2.18458890914917\n",
      "epoch: 1, batch: 767, loss: 2.2207443714141846\n",
      "epoch: 1, batch: 768, loss: 2.1993324756622314\n",
      "epoch: 1, batch: 769, loss: 2.187598466873169\n",
      "epoch: 1, batch: 770, loss: 2.14840030670166\n",
      "epoch: 1, batch: 771, loss: 2.1674509048461914\n",
      "epoch: 1, batch: 772, loss: 2.2486047744750977\n",
      "epoch: 1, batch: 773, loss: 2.1593399047851562\n",
      "epoch: 1, batch: 774, loss: 2.2194340229034424\n",
      "epoch: 1, batch: 775, loss: 2.142350435256958\n",
      "epoch: 1, batch: 776, loss: 2.136685609817505\n",
      "epoch: 1, batch: 777, loss: 2.196540594100952\n",
      "epoch: 1, batch: 778, loss: 2.1954345703125\n",
      "epoch: 1, batch: 779, loss: 2.1851375102996826\n",
      "epoch: 1, batch: 780, loss: 2.1752121448516846\n",
      "epoch: 1, batch: 781, loss: 2.195284843444824\n",
      "epoch: 1, batch: 782, loss: 2.217160701751709\n",
      "epoch: 1, batch: 783, loss: 2.208108901977539\n",
      "epoch: 1, batch: 784, loss: 2.224968433380127\n",
      "epoch: 1, batch: 785, loss: 2.1716840267181396\n",
      "epoch: 1, batch: 786, loss: 2.186469793319702\n",
      "epoch: 1, batch: 787, loss: 2.179323673248291\n",
      "epoch: 1, batch: 788, loss: 2.214829683303833\n",
      "epoch: 1, batch: 789, loss: 2.1541411876678467\n",
      "epoch: 1, batch: 790, loss: 2.1930394172668457\n",
      "epoch: 1, batch: 791, loss: 2.162923812866211\n",
      "epoch: 1, batch: 792, loss: 2.189772605895996\n",
      "epoch: 1, batch: 793, loss: 2.166935920715332\n",
      "epoch: 1, batch: 794, loss: 2.1696298122406006\n",
      "epoch: 1, batch: 795, loss: 2.2044131755828857\n",
      "epoch: 1, batch: 796, loss: 2.202298641204834\n",
      "epoch: 1, batch: 797, loss: 2.2048134803771973\n",
      "epoch: 1, batch: 798, loss: 2.2030975818634033\n",
      "epoch: 1, batch: 799, loss: 2.174236536026001\n",
      "epoch: 1, batch: 800, loss: 2.171370506286621\n",
      "epoch: 1, batch: 801, loss: 2.1833784580230713\n",
      "epoch: 1, batch: 802, loss: 2.1334991455078125\n",
      "epoch: 1, batch: 803, loss: 2.2009520530700684\n",
      "epoch: 1, batch: 804, loss: 2.2042081356048584\n",
      "epoch: 1, batch: 805, loss: 2.141456127166748\n",
      "epoch: 1, batch: 806, loss: 2.1246073246002197\n",
      "epoch: 1, batch: 807, loss: 2.186082363128662\n",
      "epoch: 1, batch: 808, loss: 2.173287868499756\n",
      "epoch: 1, batch: 809, loss: 2.150517702102661\n",
      "epoch: 1, batch: 810, loss: 2.1657636165618896\n",
      "epoch: 1, batch: 811, loss: 2.1860227584838867\n",
      "epoch: 1, batch: 812, loss: 2.1353724002838135\n",
      "epoch: 1, batch: 813, loss: 2.1853392124176025\n",
      "epoch: 1, batch: 814, loss: 2.220296621322632\n",
      "epoch: 1, batch: 815, loss: 2.189750909805298\n",
      "epoch: 1, batch: 816, loss: 2.170549154281616\n",
      "epoch: 1, batch: 817, loss: 2.2085063457489014\n",
      "epoch: 1, batch: 818, loss: 2.1595706939697266\n",
      "epoch: 1, batch: 819, loss: 2.2150118350982666\n",
      "epoch: 1, batch: 820, loss: 2.2110588550567627\n",
      "epoch: 1, batch: 821, loss: 2.2030210494995117\n",
      "epoch: 1, batch: 822, loss: 2.165269613265991\n",
      "epoch: 1, batch: 823, loss: 2.2088239192962646\n",
      "epoch: 1, batch: 824, loss: 2.1951751708984375\n",
      "epoch: 1, batch: 825, loss: 2.1603729724884033\n",
      "epoch: 1, batch: 826, loss: 2.1643593311309814\n",
      "epoch: 1, batch: 827, loss: 2.217478036880493\n",
      "epoch: 1, batch: 828, loss: 2.213585615158081\n",
      "epoch: 1, batch: 829, loss: 2.1870546340942383\n",
      "epoch: 1, batch: 830, loss: 2.1909213066101074\n",
      "epoch: 1, batch: 831, loss: 2.183297872543335\n",
      "epoch: 1, batch: 832, loss: 2.153578042984009\n",
      "epoch: 1, batch: 833, loss: 2.1518027782440186\n",
      "epoch: 1, batch: 834, loss: 2.224047899246216\n",
      "epoch: 1, batch: 835, loss: 2.1593894958496094\n",
      "epoch: 1, batch: 836, loss: 2.1518990993499756\n",
      "epoch: 1, batch: 837, loss: 2.162202835083008\n",
      "epoch: 1, batch: 838, loss: 2.1527106761932373\n",
      "epoch: 1, batch: 839, loss: 2.143620491027832\n",
      "epoch: 1, batch: 840, loss: 2.177905321121216\n",
      "epoch: 1, batch: 841, loss: 2.164825916290283\n",
      "epoch: 1, batch: 842, loss: 2.178905725479126\n",
      "epoch: 1, batch: 843, loss: 2.1588222980499268\n",
      "epoch: 1, batch: 844, loss: 2.153149127960205\n",
      "epoch: 1, batch: 845, loss: 2.1674211025238037\n",
      "epoch: 1, batch: 846, loss: 2.186021089553833\n",
      "epoch: 1, batch: 847, loss: 2.198389768600464\n",
      "epoch: 1, batch: 848, loss: 2.174121379852295\n",
      "epoch: 1, batch: 849, loss: 2.2039270401000977\n",
      "epoch: 1, batch: 850, loss: 2.192279815673828\n",
      "epoch: 1, batch: 851, loss: 2.1622297763824463\n",
      "epoch: 1, batch: 852, loss: 2.1922948360443115\n",
      "epoch: 1, batch: 853, loss: 2.1479616165161133\n",
      "epoch: 1, batch: 854, loss: 2.1591334342956543\n",
      "epoch: 1, batch: 855, loss: 2.160275459289551\n",
      "epoch: 1, batch: 856, loss: 2.188667058944702\n",
      "epoch: 1, batch: 857, loss: 2.172283172607422\n",
      "epoch: 1, batch: 858, loss: 2.1814868450164795\n",
      "epoch: 1, batch: 859, loss: 2.195726156234741\n",
      "epoch: 1, batch: 860, loss: 2.184189558029175\n",
      "epoch: 1, batch: 861, loss: 2.14339542388916\n",
      "epoch: 1, batch: 862, loss: 2.1931817531585693\n",
      "epoch: 1, batch: 863, loss: 2.1914167404174805\n",
      "epoch: 1, batch: 864, loss: 2.172149896621704\n",
      "epoch: 1, batch: 865, loss: 2.1858811378479004\n",
      "epoch: 1, batch: 866, loss: 2.135531425476074\n",
      "epoch: 1, batch: 867, loss: 2.1772375106811523\n",
      "epoch: 1, batch: 868, loss: 2.1902976036071777\n",
      "epoch: 1, batch: 869, loss: 2.184577465057373\n",
      "epoch: 1, batch: 870, loss: 2.1712801456451416\n",
      "epoch: 1, batch: 871, loss: 2.2169814109802246\n",
      "epoch: 1, batch: 872, loss: 2.1512720584869385\n",
      "epoch: 1, batch: 873, loss: 2.1748101711273193\n",
      "epoch: 1, batch: 874, loss: 2.1988987922668457\n",
      "epoch: 1, batch: 875, loss: 2.1364943981170654\n",
      "epoch: 1, batch: 876, loss: 2.194002151489258\n",
      "epoch: 1, batch: 877, loss: 2.1741204261779785\n",
      "epoch: 1, batch: 878, loss: 2.1948328018188477\n",
      "epoch: 1, batch: 879, loss: 2.126148223876953\n",
      "epoch: 1, batch: 880, loss: 2.1732218265533447\n",
      "epoch: 1, batch: 881, loss: 2.1804566383361816\n",
      "epoch: 1, batch: 882, loss: 2.1846835613250732\n",
      "epoch: 1, batch: 883, loss: 2.212838649749756\n",
      "epoch: 1, batch: 884, loss: 2.130635976791382\n",
      "epoch: 1, batch: 885, loss: 2.156708002090454\n",
      "epoch: 1, batch: 886, loss: 2.1414082050323486\n",
      "epoch: 1, batch: 887, loss: 2.2120871543884277\n",
      "epoch: 1, batch: 888, loss: 2.1548891067504883\n",
      "epoch: 1, batch: 889, loss: 2.1889336109161377\n",
      "epoch: 1, batch: 890, loss: 2.201392412185669\n",
      "epoch: 1, batch: 891, loss: 2.2140543460845947\n",
      "epoch: 1, batch: 892, loss: 2.158864974975586\n",
      "epoch: 1, batch: 893, loss: 2.1729555130004883\n",
      "epoch: 1, batch: 894, loss: 2.1840314865112305\n",
      "epoch: 1, batch: 895, loss: 2.1285033226013184\n",
      "epoch: 1, batch: 896, loss: 2.1740057468414307\n",
      "epoch: 1, batch: 897, loss: 2.1510324478149414\n",
      "epoch: 1, batch: 898, loss: 2.1231143474578857\n",
      "epoch: 1, batch: 899, loss: 2.2153451442718506\n",
      "epoch: 1, batch: 900, loss: 2.1745431423187256\n",
      "epoch: 1, batch: 901, loss: 2.177018880844116\n",
      "epoch: 1, batch: 902, loss: 2.1676836013793945\n",
      "epoch: 1, batch: 903, loss: 2.177476644515991\n",
      "epoch: 1, batch: 904, loss: 2.199963092803955\n",
      "epoch: 1, batch: 905, loss: 2.171339988708496\n",
      "epoch: 1, batch: 906, loss: 2.177880048751831\n",
      "epoch: 1, batch: 907, loss: 2.138420343399048\n",
      "epoch: 1, batch: 908, loss: 2.1839206218719482\n",
      "epoch: 1, batch: 909, loss: 2.157865285873413\n",
      "epoch: 1, batch: 910, loss: 2.2034542560577393\n",
      "epoch: 1, batch: 911, loss: 2.1812915802001953\n",
      "epoch: 1, batch: 912, loss: 2.1522302627563477\n",
      "epoch: 1, batch: 913, loss: 2.136094808578491\n",
      "epoch: 1, batch: 914, loss: 2.175201654434204\n",
      "epoch: 1, batch: 915, loss: 2.2093348503112793\n",
      "epoch: 1, batch: 916, loss: 2.173945426940918\n",
      "epoch: 1, batch: 917, loss: 2.147348403930664\n",
      "epoch: 1, batch: 918, loss: 2.190197706222534\n",
      "epoch: 1, batch: 919, loss: 2.1964056491851807\n",
      "epoch: 1, batch: 920, loss: 2.168520212173462\n",
      "epoch: 1, batch: 921, loss: 2.174283504486084\n",
      "epoch: 1, batch: 922, loss: 2.144033670425415\n",
      "epoch: 1, batch: 923, loss: 2.206510066986084\n",
      "epoch: 1, batch: 924, loss: 2.156310796737671\n",
      "epoch: 1, batch: 925, loss: 2.203120708465576\n",
      "epoch: 1, batch: 926, loss: 2.1525559425354004\n",
      "epoch: 1, batch: 927, loss: 2.1621522903442383\n",
      "epoch: 1, batch: 928, loss: 2.1564104557037354\n",
      "epoch: 1, batch: 929, loss: 2.2039008140563965\n",
      "epoch: 1, batch: 930, loss: 2.135303497314453\n",
      "epoch: 1, batch: 931, loss: 2.197476863861084\n",
      "epoch: 1, batch: 932, loss: 2.1727521419525146\n",
      "epoch: 1, batch: 933, loss: 2.165684700012207\n",
      "epoch: 1, batch: 934, loss: 2.22479248046875\n",
      "epoch: 1, batch: 935, loss: 2.1787943840026855\n",
      "epoch: 1, batch: 936, loss: 2.18404483795166\n",
      "epoch: 1, batch: 937, loss: 2.2095866203308105\n",
      "epoch: 1, batch: 938, loss: 2.1608054637908936\n",
      "epoch: 1, batch: 939, loss: 2.170132875442505\n",
      "epoch: 1, batch: 940, loss: 2.1829328536987305\n",
      "epoch: 1, batch: 941, loss: 2.2017009258270264\n",
      "epoch: 1, batch: 942, loss: 2.1852452754974365\n",
      "epoch: 1, batch: 943, loss: 2.1493871212005615\n",
      "epoch: 1, batch: 944, loss: 2.132891893386841\n",
      "epoch: 1, batch: 945, loss: 2.179532051086426\n",
      "epoch: 1, batch: 946, loss: 2.111110210418701\n",
      "epoch: 1, batch: 947, loss: 2.185490369796753\n",
      "epoch: 1, batch: 948, loss: 2.1626269817352295\n",
      "epoch: 1, batch: 949, loss: 2.165358066558838\n",
      "epoch: 1, batch: 950, loss: 2.1936216354370117\n",
      "epoch: 1, batch: 951, loss: 2.1716420650482178\n",
      "epoch: 1, batch: 952, loss: 2.1512837409973145\n",
      "epoch: 1, batch: 953, loss: 2.1202268600463867\n",
      "epoch: 1, batch: 954, loss: 2.1513075828552246\n",
      "epoch: 1, batch: 955, loss: 2.165771007537842\n",
      "epoch: 1, batch: 956, loss: 2.1916708946228027\n",
      "epoch: 1, batch: 957, loss: 2.1953015327453613\n",
      "epoch: 1, batch: 958, loss: 2.148083448410034\n",
      "epoch: 1, batch: 959, loss: 2.155452013015747\n",
      "epoch: 1, batch: 960, loss: 2.1897788047790527\n",
      "epoch: 1, batch: 961, loss: 2.1381640434265137\n",
      "epoch: 1, batch: 962, loss: 2.177755832672119\n",
      "epoch: 1, batch: 963, loss: 2.1877336502075195\n",
      "epoch: 1, batch: 964, loss: 2.1773359775543213\n",
      "epoch: 1, batch: 965, loss: 2.1708810329437256\n",
      "epoch: 1, batch: 966, loss: 2.1565003395080566\n",
      "epoch: 1, batch: 967, loss: 2.151268243789673\n",
      "epoch: 1, batch: 968, loss: 2.1546883583068848\n",
      "epoch: 1, batch: 969, loss: 2.1329102516174316\n",
      "epoch: 1, batch: 970, loss: 2.1733736991882324\n",
      "epoch: 1, batch: 971, loss: 2.1678786277770996\n",
      "epoch: 1, batch: 972, loss: 2.1531624794006348\n",
      "epoch: 1, batch: 973, loss: 2.215090036392212\n",
      "epoch: 1, batch: 974, loss: 2.145531415939331\n",
      "epoch: 1, batch: 975, loss: 2.151247024536133\n",
      "epoch: 1, batch: 976, loss: 2.227368116378784\n",
      "epoch: 1, batch: 977, loss: 2.111175298690796\n",
      "epoch: 1, batch: 978, loss: 2.1968958377838135\n",
      "epoch: 1, batch: 979, loss: 2.192625045776367\n",
      "epoch: 1, batch: 980, loss: 2.187601327896118\n",
      "epoch: 1, batch: 981, loss: 2.161036968231201\n",
      "epoch: 1, batch: 982, loss: 2.1814682483673096\n",
      "epoch: 1, batch: 983, loss: 2.178799867630005\n",
      "epoch: 1, batch: 984, loss: 2.178699016571045\n",
      "epoch: 1, batch: 985, loss: 2.1905627250671387\n",
      "epoch: 1, batch: 986, loss: 2.1830649375915527\n",
      "epoch: 1, batch: 987, loss: 2.133474111557007\n",
      "epoch: 1, batch: 988, loss: 2.1899492740631104\n",
      "epoch: 1, batch: 989, loss: 2.147289514541626\n",
      "epoch: 1, batch: 990, loss: 2.151014566421509\n",
      "epoch: 1, batch: 991, loss: 2.1691181659698486\n",
      "epoch: 1, batch: 992, loss: 2.1542885303497314\n",
      "epoch: 1, batch: 993, loss: 2.1481003761291504\n",
      "epoch: 1, batch: 994, loss: 2.152170419692993\n",
      "epoch: 1, batch: 995, loss: 2.2012922763824463\n",
      "epoch: 1, batch: 996, loss: 2.191117525100708\n",
      "epoch: 1, batch: 997, loss: 2.1826391220092773\n",
      "epoch: 1, batch: 998, loss: 2.1459951400756836\n",
      "epoch: 1, batch: 999, loss: 2.184757709503174\n",
      "epoch: 1, batch: 1000, loss: 2.1828577518463135\n",
      "epoch: 1, batch: 1001, loss: 2.135183334350586\n",
      "epoch: 1, batch: 1002, loss: 2.163428783416748\n",
      "epoch: 1, batch: 1003, loss: 2.205554962158203\n",
      "epoch: 1, batch: 1004, loss: 2.145583152770996\n",
      "epoch: 1, batch: 1005, loss: 2.171679973602295\n",
      "epoch: 1, batch: 1006, loss: 2.187626600265503\n",
      "epoch: 1, batch: 1007, loss: 2.1190710067749023\n",
      "epoch: 1, batch: 1008, loss: 2.137129068374634\n",
      "epoch: 1, batch: 1009, loss: 2.146195650100708\n",
      "epoch: 1, batch: 1010, loss: 2.1641757488250732\n",
      "epoch: 1, batch: 1011, loss: 2.1786375045776367\n",
      "epoch: 1, batch: 1012, loss: 2.175977945327759\n",
      "epoch: 1, batch: 1013, loss: 2.1689260005950928\n",
      "epoch: 1, batch: 1014, loss: 2.1662096977233887\n",
      "epoch: 1, batch: 1015, loss: 2.1457695960998535\n",
      "epoch: 1, batch: 1016, loss: 2.1954798698425293\n",
      "epoch: 1, batch: 1017, loss: 2.1005218029022217\n",
      "epoch: 1, batch: 1018, loss: 2.1464757919311523\n",
      "epoch: 1, batch: 1019, loss: 2.1352121829986572\n",
      "epoch: 1, batch: 1020, loss: 2.1900951862335205\n",
      "epoch: 1, batch: 1021, loss: 2.1333277225494385\n",
      "epoch: 1, batch: 1022, loss: 2.184790849685669\n",
      "epoch: 1, batch: 1023, loss: 2.184293508529663\n",
      "epoch: 1, batch: 1024, loss: 2.1637682914733887\n",
      "epoch: 1, batch: 1025, loss: 2.1490652561187744\n",
      "epoch: 1, batch: 1026, loss: 2.1139791011810303\n",
      "epoch: 1, batch: 1027, loss: 2.117464780807495\n",
      "epoch: 1, batch: 1028, loss: 2.1835622787475586\n",
      "epoch: 1, batch: 1029, loss: 2.1722147464752197\n",
      "epoch: 1, batch: 1030, loss: 2.1695191860198975\n",
      "epoch: 1, batch: 1031, loss: 2.1709747314453125\n",
      "epoch: 1, batch: 1032, loss: 2.163147211074829\n",
      "epoch: 1, batch: 1033, loss: 2.144014358520508\n",
      "epoch: 1, batch: 1034, loss: 2.163346290588379\n",
      "epoch: 1, batch: 1035, loss: 2.154292106628418\n",
      "epoch: 1, batch: 1036, loss: 2.1858489513397217\n",
      "epoch: 1, batch: 1037, loss: 2.1951849460601807\n",
      "epoch: 1, batch: 1038, loss: 2.134174346923828\n",
      "epoch: 1, batch: 1039, loss: 2.1592295169830322\n",
      "epoch: 1, batch: 1040, loss: 2.162909507751465\n",
      "epoch: 1, batch: 1041, loss: 2.1935129165649414\n",
      "epoch: 1, batch: 1042, loss: 2.131645679473877\n",
      "epoch: 1, batch: 1043, loss: 2.1681385040283203\n",
      "epoch: 1, batch: 1044, loss: 2.14713716506958\n",
      "epoch: 1, batch: 1045, loss: 2.1610519886016846\n",
      "epoch: 1, batch: 1046, loss: 2.207881212234497\n",
      "epoch: 1, batch: 1047, loss: 2.1690316200256348\n",
      "epoch: 1, batch: 1048, loss: 2.2142975330352783\n",
      "epoch: 1, batch: 1049, loss: 2.11918306350708\n",
      "epoch: 1, batch: 1050, loss: 2.165440797805786\n",
      "epoch: 1, batch: 1051, loss: 2.1919045448303223\n",
      "epoch: 1, batch: 1052, loss: 2.18155574798584\n",
      "epoch: 1, batch: 1053, loss: 2.1323070526123047\n",
      "epoch: 1, batch: 1054, loss: 2.145812511444092\n",
      "epoch: 1, batch: 1055, loss: 2.1364994049072266\n",
      "epoch: 1, batch: 1056, loss: 2.1728172302246094\n",
      "epoch: 1, batch: 1057, loss: 2.1239864826202393\n",
      "epoch: 1, batch: 1058, loss: 2.098214864730835\n",
      "epoch: 1, batch: 1059, loss: 2.1861119270324707\n",
      "epoch: 1, batch: 1060, loss: 2.142334461212158\n",
      "epoch: 1, batch: 1061, loss: 2.1389598846435547\n",
      "epoch: 1, batch: 1062, loss: 2.167656183242798\n",
      "epoch: 1, batch: 1063, loss: 2.169973850250244\n",
      "epoch: 1, batch: 1064, loss: 2.1633410453796387\n",
      "epoch: 1, batch: 1065, loss: 2.151024341583252\n",
      "epoch: 1, batch: 1066, loss: 2.1785757541656494\n",
      "epoch: 1, batch: 1067, loss: 2.1575751304626465\n",
      "epoch: 1, batch: 1068, loss: 2.139914035797119\n",
      "epoch: 1, batch: 1069, loss: 2.1301465034484863\n",
      "epoch: 1, batch: 1070, loss: 2.1496598720550537\n",
      "epoch: 1, batch: 1071, loss: 2.1205108165740967\n",
      "epoch: 1, batch: 1072, loss: 2.1301441192626953\n",
      "epoch: 1, batch: 1073, loss: 2.1291213035583496\n",
      "epoch: 1, batch: 1074, loss: 2.1628379821777344\n",
      "epoch: 1, batch: 1075, loss: 2.2114508152008057\n",
      "epoch: 1, batch: 1076, loss: 2.167194366455078\n",
      "epoch: 1, batch: 1077, loss: 2.1482250690460205\n",
      "epoch: 1, batch: 1078, loss: 2.1384124755859375\n",
      "epoch: 1, batch: 1079, loss: 2.1368017196655273\n",
      "epoch: 1, batch: 1080, loss: 2.195554494857788\n",
      "epoch: 1, batch: 1081, loss: 2.1353259086608887\n",
      "epoch: 1, batch: 1082, loss: 2.1406378746032715\n",
      "epoch: 1, batch: 1083, loss: 2.1461570262908936\n",
      "epoch: 1, batch: 1084, loss: 2.2195751667022705\n",
      "epoch: 1, batch: 1085, loss: 2.1408703327178955\n",
      "epoch: 1, batch: 1086, loss: 2.1309969425201416\n",
      "epoch: 1, batch: 1087, loss: 2.190718412399292\n",
      "epoch: 1, batch: 1088, loss: 2.1541378498077393\n",
      "epoch: 1, batch: 1089, loss: 2.1281204223632812\n",
      "epoch: 1, batch: 1090, loss: 2.123302936553955\n",
      "epoch: 1, batch: 1091, loss: 2.1425743103027344\n",
      "epoch: 1, batch: 1092, loss: 2.223646640777588\n",
      "epoch: 1, batch: 1093, loss: 2.2003140449523926\n",
      "epoch: 1, batch: 1094, loss: 2.127502202987671\n",
      "epoch: 1, batch: 1095, loss: 2.191164970397949\n",
      "epoch: 1, batch: 1096, loss: 2.1536648273468018\n",
      "epoch: 1, batch: 1097, loss: 2.1591451168060303\n",
      "epoch: 1, batch: 1098, loss: 2.1158018112182617\n",
      "epoch: 1, batch: 1099, loss: 2.148130416870117\n",
      "epoch: 1, batch: 1100, loss: 2.2094552516937256\n",
      "epoch: 1, batch: 1101, loss: 2.1514735221862793\n",
      "epoch: 1, batch: 1102, loss: 2.131098508834839\n",
      "epoch: 1, batch: 1103, loss: 2.1693735122680664\n",
      "epoch: 1, batch: 1104, loss: 2.144970417022705\n",
      "epoch: 1, batch: 1105, loss: 2.1378588676452637\n",
      "epoch: 1, batch: 1106, loss: 2.1884515285491943\n",
      "epoch: 1, batch: 1107, loss: 2.137934684753418\n",
      "epoch: 1, batch: 1108, loss: 2.1178476810455322\n",
      "epoch: 1, batch: 1109, loss: 2.193135976791382\n",
      "epoch: 1, batch: 1110, loss: 2.169574022293091\n",
      "epoch: 1, batch: 1111, loss: 2.1590235233306885\n",
      "epoch: 1, batch: 1112, loss: 2.2148594856262207\n",
      "epoch: 1, batch: 1113, loss: 2.1309967041015625\n",
      "epoch: 1, batch: 1114, loss: 2.198453664779663\n",
      "epoch: 1, batch: 1115, loss: 2.1478593349456787\n",
      "epoch: 1, batch: 1116, loss: 2.2031655311584473\n",
      "epoch: 1, batch: 1117, loss: 2.1382906436920166\n",
      "epoch: 1, batch: 1118, loss: 2.176964044570923\n",
      "epoch: 1, batch: 1119, loss: 2.158871650695801\n",
      "epoch: 1, batch: 1120, loss: 2.165095567703247\n",
      "epoch: 1, batch: 1121, loss: 2.1443634033203125\n",
      "epoch: 1, batch: 1122, loss: 2.1277804374694824\n",
      "epoch: 1, batch: 1123, loss: 2.172544240951538\n",
      "epoch: 1, batch: 1124, loss: 2.1961846351623535\n",
      "epoch: 1, batch: 1125, loss: 2.1722915172576904\n",
      "epoch: 1, batch: 1126, loss: 2.137484550476074\n",
      "epoch: 1, batch: 1127, loss: 2.136057138442993\n",
      "epoch: 1, batch: 1128, loss: 2.1670026779174805\n",
      "epoch: 1, batch: 1129, loss: 2.160187005996704\n",
      "epoch: 1, batch: 1130, loss: 2.1065561771392822\n",
      "epoch: 1, batch: 1131, loss: 2.1224923133850098\n",
      "epoch: 1, batch: 1132, loss: 2.1878137588500977\n",
      "epoch: 1, batch: 1133, loss: 2.170985460281372\n",
      "epoch: 1, batch: 1134, loss: 2.0925796031951904\n",
      "epoch: 1, batch: 1135, loss: 2.16152286529541\n",
      "epoch: 1, batch: 1136, loss: 2.150620937347412\n",
      "epoch: 1, batch: 1137, loss: 2.163912534713745\n",
      "epoch: 1, batch: 1138, loss: 2.103347063064575\n",
      "epoch: 1, batch: 1139, loss: 2.1591882705688477\n",
      "epoch: 1, batch: 1140, loss: 2.134758710861206\n",
      "epoch: 1, batch: 1141, loss: 2.1007943153381348\n",
      "epoch: 1, batch: 1142, loss: 2.1133852005004883\n",
      "epoch: 1, batch: 1143, loss: 2.1079933643341064\n",
      "epoch: 1, batch: 1144, loss: 2.158761978149414\n",
      "epoch: 1, batch: 1145, loss: 2.138300657272339\n",
      "epoch: 1, batch: 1146, loss: 2.1855344772338867\n",
      "epoch: 1, batch: 1147, loss: 2.1957290172576904\n",
      "epoch: 1, batch: 1148, loss: 2.1764400005340576\n",
      "epoch: 1, batch: 1149, loss: 2.1654255390167236\n",
      "epoch: 1, batch: 1150, loss: 2.1803340911865234\n",
      "epoch: 1, batch: 1151, loss: 2.150456428527832\n",
      "epoch: 1, batch: 1152, loss: 2.1556615829467773\n",
      "epoch: 1, batch: 1153, loss: 2.114867687225342\n",
      "epoch: 1, batch: 1154, loss: 2.19565749168396\n",
      "epoch: 1, batch: 1155, loss: 2.1406779289245605\n",
      "epoch: 1, batch: 1156, loss: 2.1751272678375244\n",
      "epoch: 1, batch: 1157, loss: 2.180046319961548\n",
      "epoch: 1, batch: 1158, loss: 2.1503896713256836\n",
      "epoch: 1, batch: 1159, loss: 2.1569924354553223\n",
      "epoch: 1, batch: 1160, loss: 2.148078680038452\n",
      "epoch: 1, batch: 1161, loss: 2.1448988914489746\n",
      "epoch: 1, batch: 1162, loss: 2.1626601219177246\n",
      "epoch: 1, batch: 1163, loss: 2.203277587890625\n",
      "epoch: 1, batch: 1164, loss: 2.123769760131836\n",
      "epoch: 1, batch: 1165, loss: 2.1482698917388916\n",
      "epoch: 1, batch: 1166, loss: 2.1170871257781982\n",
      "epoch: 1, batch: 1167, loss: 2.1639480590820312\n",
      "epoch: 1, batch: 1168, loss: 2.1256442070007324\n",
      "epoch: 1, batch: 1169, loss: 2.1481642723083496\n",
      "epoch: 1, batch: 1170, loss: 2.124340772628784\n",
      "epoch: 1, batch: 1171, loss: 2.0969655513763428\n",
      "epoch: 1, batch: 1172, loss: 2.1577281951904297\n",
      "epoch: 1, batch: 1173, loss: 2.143162965774536\n",
      "epoch: 1, batch: 1174, loss: 2.0915298461914062\n",
      "epoch: 1, batch: 1175, loss: 2.1595265865325928\n",
      "epoch: 1, batch: 1176, loss: 2.1467812061309814\n",
      "epoch: 1, batch: 1177, loss: 2.141777276992798\n",
      "epoch: 1, batch: 1178, loss: 2.114454984664917\n",
      "epoch: 1, batch: 1179, loss: 2.1431703567504883\n",
      "epoch: 1, batch: 1180, loss: 2.14888858795166\n",
      "epoch: 1, batch: 1181, loss: 2.112314224243164\n",
      "epoch: 1, batch: 1182, loss: 2.1391348838806152\n",
      "epoch: 1, batch: 1183, loss: 2.101604461669922\n",
      "epoch: 1, batch: 1184, loss: 2.1676547527313232\n",
      "epoch: 1, batch: 1185, loss: 2.145829439163208\n",
      "epoch: 1, batch: 1186, loss: 2.1163365840911865\n",
      "epoch: 1, batch: 1187, loss: 2.13942813873291\n",
      "epoch: 1, batch: 1188, loss: 2.156886100769043\n",
      "epoch: 1, batch: 1189, loss: 2.1586523056030273\n",
      "epoch: 1, batch: 1190, loss: 2.1723484992980957\n",
      "epoch: 1, batch: 1191, loss: 2.1083946228027344\n",
      "epoch: 1, batch: 1192, loss: 2.0730836391448975\n",
      "epoch: 1, batch: 1193, loss: 2.164933443069458\n",
      "epoch: 1, batch: 1194, loss: 2.163527727127075\n",
      "epoch: 1, batch: 1195, loss: 2.13688588142395\n",
      "epoch: 1, batch: 1196, loss: 2.118665933609009\n",
      "epoch: 1, batch: 1197, loss: 2.0891880989074707\n",
      "epoch: 1, batch: 1198, loss: 2.1960349082946777\n",
      "epoch: 1, batch: 1199, loss: 2.133854866027832\n",
      "epoch: 1, batch: 1200, loss: 2.1344690322875977\n",
      "epoch: 1, batch: 1201, loss: 2.183234930038452\n",
      "epoch: 1, batch: 1202, loss: 2.146200656890869\n",
      "epoch: 1, batch: 1203, loss: 2.1735599040985107\n",
      "epoch: 1, batch: 1204, loss: 2.1025185585021973\n",
      "epoch: 1, batch: 1205, loss: 2.1282780170440674\n",
      "epoch: 1, batch: 1206, loss: 2.164358377456665\n",
      "epoch: 1, batch: 1207, loss: 2.144243001937866\n",
      "epoch: 1, batch: 1208, loss: 2.153142213821411\n",
      "epoch: 1, batch: 1209, loss: 2.134077548980713\n",
      "epoch: 1, batch: 1210, loss: 2.070164442062378\n",
      "epoch: 1, batch: 1211, loss: 2.133531093597412\n",
      "epoch: 1, batch: 1212, loss: 2.132751703262329\n",
      "epoch: 1, batch: 1213, loss: 2.173976421356201\n",
      "epoch: 1, batch: 1214, loss: 2.2106897830963135\n",
      "epoch: 1, batch: 1215, loss: 2.1176376342773438\n",
      "epoch: 1, batch: 1216, loss: 2.1461310386657715\n",
      "epoch: 1, batch: 1217, loss: 2.084153652191162\n",
      "epoch: 1, batch: 1218, loss: 2.1190011501312256\n",
      "epoch: 1, batch: 1219, loss: 2.0997960567474365\n",
      "epoch: 1, batch: 1220, loss: 2.1822290420532227\n",
      "epoch: 1, batch: 1221, loss: 2.15791916847229\n",
      "epoch: 1, batch: 1222, loss: 2.093818187713623\n",
      "epoch: 1, batch: 1223, loss: 2.1301302909851074\n",
      "epoch: 1, batch: 1224, loss: 2.128917932510376\n",
      "epoch: 1, batch: 1225, loss: 2.133042573928833\n",
      "epoch: 1, batch: 1226, loss: 2.192430019378662\n",
      "epoch: 1, batch: 1227, loss: 2.1392388343811035\n",
      "epoch: 1, batch: 1228, loss: 2.162614345550537\n",
      "epoch: 1, batch: 1229, loss: 2.191210985183716\n",
      "epoch: 1, batch: 1230, loss: 2.1735217571258545\n",
      "epoch: 1, batch: 1231, loss: 2.081850290298462\n",
      "epoch: 1, batch: 1232, loss: 2.172927141189575\n",
      "epoch: 1, batch: 1233, loss: 2.2165911197662354\n",
      "epoch: 1, batch: 1234, loss: 2.169403553009033\n",
      "epoch: 1, batch: 1235, loss: 2.1621694564819336\n",
      "epoch: 1, batch: 1236, loss: 2.1025023460388184\n",
      "epoch: 1, batch: 1237, loss: 2.14455509185791\n",
      "epoch: 1, batch: 1238, loss: 2.1170153617858887\n",
      "epoch: 1, batch: 1239, loss: 2.132692813873291\n",
      "epoch: 1, batch: 1240, loss: 2.1356592178344727\n",
      "epoch: 1, batch: 1241, loss: 2.1079256534576416\n",
      "epoch: 1, batch: 1242, loss: 2.132462978363037\n",
      "epoch: 1, batch: 1243, loss: 2.1369194984436035\n",
      "epoch: 1, batch: 1244, loss: 2.1424784660339355\n",
      "epoch: 1, batch: 1245, loss: 2.129140615463257\n",
      "epoch: 1, batch: 1246, loss: 2.0939712524414062\n",
      "epoch: 1, batch: 1247, loss: 2.149406909942627\n",
      "epoch: 1, batch: 1248, loss: 2.161216974258423\n",
      "epoch: 1, batch: 1249, loss: 2.101835250854492\n",
      "epoch: 1, batch: 1250, loss: 2.1405527591705322\n",
      "epoch: 1, batch: 1251, loss: 2.17972731590271\n",
      "epoch: 1, batch: 1252, loss: 2.1191563606262207\n",
      "epoch: 1, batch: 1253, loss: 2.145516872406006\n",
      "epoch: 1, batch: 1254, loss: 2.1237056255340576\n",
      "epoch: 1, batch: 1255, loss: 2.194298028945923\n",
      "epoch: 1, batch: 1256, loss: 2.16237735748291\n",
      "epoch: 1, batch: 1257, loss: 2.1298580169677734\n",
      "epoch: 1, batch: 1258, loss: 2.1582679748535156\n",
      "epoch: 1, batch: 1259, loss: 2.1499414443969727\n",
      "epoch: 1, batch: 1260, loss: 2.138267993927002\n",
      "epoch: 1, batch: 1261, loss: 2.0852341651916504\n",
      "epoch: 1, batch: 1262, loss: 2.1220877170562744\n",
      "epoch: 1, batch: 1263, loss: 2.0941052436828613\n",
      "epoch: 1, batch: 1264, loss: 2.104724884033203\n",
      "epoch: 1, batch: 1265, loss: 2.113738775253296\n",
      "epoch: 1, batch: 1266, loss: 2.086103916168213\n",
      "epoch: 1, batch: 1267, loss: 2.1919784545898438\n",
      "epoch: 1, batch: 1268, loss: 2.16017746925354\n",
      "epoch: 1, batch: 1269, loss: 2.1560723781585693\n",
      "epoch: 1, batch: 1270, loss: 2.1370625495910645\n",
      "epoch: 1, batch: 1271, loss: 2.1257357597351074\n",
      "epoch: 1, batch: 1272, loss: 2.092310667037964\n",
      "epoch: 1, batch: 1273, loss: 2.153066635131836\n",
      "epoch: 1, batch: 1274, loss: 2.126680850982666\n",
      "epoch: 1, batch: 1275, loss: 2.1407947540283203\n",
      "epoch: 1, batch: 1276, loss: 2.1077260971069336\n",
      "epoch: 1, batch: 1277, loss: 2.1298282146453857\n",
      "epoch: 1, batch: 1278, loss: 2.144761562347412\n",
      "epoch: 1, batch: 1279, loss: 2.132411003112793\n",
      "epoch: 1, batch: 1280, loss: 2.102435350418091\n",
      "epoch: 1, batch: 1281, loss: 2.105546712875366\n",
      "epoch: 1, batch: 1282, loss: 2.1391968727111816\n",
      "epoch: 1, batch: 1283, loss: 2.096200942993164\n",
      "epoch: 1, batch: 1284, loss: 2.145888328552246\n",
      "epoch: 1, batch: 1285, loss: 2.1883702278137207\n",
      "epoch: 1, batch: 1286, loss: 2.1365745067596436\n",
      "epoch: 1, batch: 1287, loss: 2.120600461959839\n",
      "epoch: 1, batch: 1288, loss: 2.1654887199401855\n",
      "epoch: 1, batch: 1289, loss: 2.134320020675659\n",
      "epoch: 1, batch: 1290, loss: 2.1501693725585938\n",
      "epoch: 1, batch: 1291, loss: 2.1460118293762207\n",
      "epoch: 1, batch: 1292, loss: 2.1464755535125732\n",
      "epoch: 1, batch: 1293, loss: 2.1330199241638184\n",
      "epoch: 1, batch: 1294, loss: 2.1630666255950928\n",
      "epoch: 1, batch: 1295, loss: 2.1537485122680664\n",
      "epoch: 1, batch: 1296, loss: 2.1550679206848145\n",
      "epoch: 1, batch: 1297, loss: 2.0714991092681885\n",
      "epoch: 1, batch: 1298, loss: 2.1297125816345215\n",
      "epoch: 1, batch: 1299, loss: 2.1070165634155273\n",
      "epoch: 1, batch: 1300, loss: 2.1344549655914307\n",
      "epoch: 1, batch: 1301, loss: 2.080120801925659\n",
      "epoch: 1, batch: 1302, loss: 2.1147983074188232\n",
      "epoch: 1, batch: 1303, loss: 2.1451308727264404\n",
      "epoch: 1, batch: 1304, loss: 2.132200002670288\n",
      "epoch: 1, batch: 1305, loss: 2.1190004348754883\n",
      "epoch: 1, batch: 1306, loss: 2.14522647857666\n",
      "epoch: 1, batch: 1307, loss: 2.1283740997314453\n",
      "epoch: 1, batch: 1308, loss: 2.118943691253662\n",
      "epoch: 1, batch: 1309, loss: 2.1141891479492188\n",
      "epoch: 1, batch: 1310, loss: 2.0795905590057373\n",
      "epoch: 1, batch: 1311, loss: 2.1010186672210693\n",
      "epoch: 1, batch: 1312, loss: 2.156409740447998\n",
      "epoch: 1, batch: 1313, loss: 2.145875930786133\n",
      "epoch: 1, batch: 1314, loss: 2.11950421333313\n",
      "epoch: 1, batch: 1315, loss: 2.1098954677581787\n",
      "epoch: 1, batch: 1316, loss: 2.1147372722625732\n",
      "epoch: 1, batch: 1317, loss: 2.104886293411255\n",
      "epoch: 1, batch: 1318, loss: 2.1208608150482178\n",
      "epoch: 1, batch: 1319, loss: 2.139139413833618\n",
      "epoch: 1, batch: 1320, loss: 2.1681759357452393\n",
      "epoch: 1, batch: 1321, loss: 2.1581857204437256\n",
      "epoch: 1, batch: 1322, loss: 2.11995005607605\n",
      "epoch: 1, batch: 1323, loss: 2.132150173187256\n",
      "epoch: 1, batch: 1324, loss: 2.128291606903076\n",
      "epoch: 1, batch: 1325, loss: 2.128370523452759\n",
      "epoch: 1, batch: 1326, loss: 2.125556707382202\n",
      "epoch: 1, batch: 1327, loss: 2.1004960536956787\n",
      "epoch: 1, batch: 1328, loss: 2.1212868690490723\n",
      "epoch: 1, batch: 1329, loss: 2.084902048110962\n",
      "epoch: 1, batch: 1330, loss: 2.0952367782592773\n",
      "epoch: 1, batch: 1331, loss: 2.10745906829834\n",
      "epoch: 1, batch: 1332, loss: 2.1660335063934326\n",
      "epoch: 1, batch: 1333, loss: 2.121495485305786\n",
      "epoch: 1, batch: 1334, loss: 2.1070735454559326\n",
      "epoch: 1, batch: 1335, loss: 2.133659601211548\n",
      "epoch: 1, batch: 1336, loss: 2.1419029235839844\n",
      "epoch: 1, batch: 1337, loss: 2.14180850982666\n",
      "epoch: 1, batch: 1338, loss: 2.1587705612182617\n",
      "epoch: 1, batch: 1339, loss: 2.1241908073425293\n",
      "epoch: 1, batch: 1340, loss: 2.1500539779663086\n",
      "epoch: 1, batch: 1341, loss: 2.1248512268066406\n",
      "epoch: 1, batch: 1342, loss: 2.145336389541626\n",
      "epoch: 1, batch: 1343, loss: 2.115231990814209\n",
      "epoch: 1, batch: 1344, loss: 2.1283047199249268\n",
      "epoch: 1, batch: 1345, loss: 2.1644678115844727\n",
      "epoch: 1, batch: 1346, loss: 2.152813196182251\n",
      "epoch: 1, batch: 1347, loss: 2.07234263420105\n",
      "epoch: 1, batch: 1348, loss: 2.1551222801208496\n",
      "epoch: 1, batch: 1349, loss: 2.0944013595581055\n",
      "epoch: 1, batch: 1350, loss: 2.1259262561798096\n",
      "epoch: 1, batch: 1351, loss: 2.0691566467285156\n",
      "epoch: 1, batch: 1352, loss: 2.1076998710632324\n",
      "epoch: 1, batch: 1353, loss: 2.1411023139953613\n",
      "epoch: 1, batch: 1354, loss: 2.111485719680786\n",
      "epoch: 1, batch: 1355, loss: 2.1040666103363037\n",
      "epoch: 1, batch: 1356, loss: 2.0909976959228516\n",
      "epoch: 1, batch: 1357, loss: 2.140681505203247\n",
      "epoch: 1, batch: 1358, loss: 2.0536727905273438\n",
      "epoch: 1, batch: 1359, loss: 2.1415154933929443\n",
      "epoch: 1, batch: 1360, loss: 2.1686601638793945\n",
      "epoch: 1, batch: 1361, loss: 2.1003670692443848\n",
      "epoch: 1, batch: 1362, loss: 2.1061811447143555\n",
      "epoch: 1, batch: 1363, loss: 2.1159040927886963\n",
      "epoch: 1, batch: 1364, loss: 2.132209062576294\n",
      "epoch: 1, batch: 1365, loss: 2.1270179748535156\n",
      "epoch: 1, batch: 1366, loss: 2.1488170623779297\n",
      "epoch: 1, batch: 1367, loss: 2.127159357070923\n",
      "epoch: 1, batch: 1368, loss: 2.1339917182922363\n",
      "epoch: 1, batch: 1369, loss: 2.1322760581970215\n",
      "epoch: 1, batch: 1370, loss: 2.1624341011047363\n",
      "epoch: 1, batch: 1371, loss: 2.0998103618621826\n",
      "epoch: 1, batch: 1372, loss: 2.121093273162842\n",
      "epoch: 1, batch: 1373, loss: 2.1324775218963623\n",
      "epoch: 1, batch: 1374, loss: 2.1013646125793457\n",
      "epoch: 1, batch: 1375, loss: 2.1320571899414062\n",
      "epoch: 1, batch: 1376, loss: 2.102877140045166\n",
      "epoch: 1, batch: 1377, loss: 2.1748926639556885\n",
      "epoch: 1, batch: 1378, loss: 2.1425583362579346\n",
      "epoch: 1, batch: 1379, loss: 2.0738611221313477\n",
      "epoch: 1, batch: 1380, loss: 2.0843310356140137\n",
      "epoch: 1, batch: 1381, loss: 2.0750277042388916\n",
      "epoch: 1, batch: 1382, loss: 2.1238181591033936\n",
      "epoch: 1, batch: 1383, loss: 2.122020721435547\n",
      "epoch: 1, batch: 1384, loss: 2.1271281242370605\n",
      "epoch: 1, batch: 1385, loss: 2.103482484817505\n",
      "epoch: 1, batch: 1386, loss: 2.142655611038208\n",
      "epoch: 1, batch: 1387, loss: 2.07900333404541\n",
      "epoch: 1, batch: 1388, loss: 2.1310343742370605\n",
      "epoch: 1, batch: 1389, loss: 2.1209280490875244\n",
      "epoch: 1, batch: 1390, loss: 2.106351613998413\n",
      "epoch: 1, batch: 1391, loss: 2.111881732940674\n",
      "epoch: 1, batch: 1392, loss: 2.109626531600952\n",
      "epoch: 1, batch: 1393, loss: 2.1071505546569824\n",
      "epoch: 1, batch: 1394, loss: 2.0493013858795166\n",
      "epoch: 1, batch: 1395, loss: 2.0993409156799316\n",
      "epoch: 1, batch: 1396, loss: 2.1206698417663574\n",
      "epoch: 1, batch: 1397, loss: 2.1104543209075928\n",
      "epoch: 1, batch: 1398, loss: 2.1049163341522217\n",
      "epoch: 1, batch: 1399, loss: 2.108173370361328\n",
      "epoch: 1, batch: 1400, loss: 2.0887835025787354\n",
      "epoch: 1, batch: 1401, loss: 2.0769779682159424\n",
      "epoch: 1, batch: 1402, loss: 2.0665082931518555\n",
      "epoch: 1, batch: 1403, loss: 2.093345880508423\n",
      "epoch: 1, batch: 1404, loss: 2.138021945953369\n",
      "epoch: 1, batch: 1405, loss: 2.136389970779419\n",
      "epoch: 1, batch: 1406, loss: 2.1673126220703125\n",
      "epoch: 1, batch: 1407, loss: 2.1674413681030273\n",
      "epoch: 1, batch: 1408, loss: 2.1537015438079834\n",
      "epoch: 1, batch: 1409, loss: 2.1575586795806885\n",
      "epoch: 1, batch: 1410, loss: 2.13293194770813\n",
      "epoch: 1, batch: 1411, loss: 2.138770580291748\n",
      "epoch: 1, batch: 1412, loss: 2.1619150638580322\n",
      "epoch: 1, batch: 1413, loss: 2.0765998363494873\n",
      "epoch: 1, batch: 1414, loss: 2.124361991882324\n",
      "epoch: 1, batch: 1415, loss: 2.0751795768737793\n",
      "epoch: 1, batch: 1416, loss: 2.107714891433716\n",
      "epoch: 1, batch: 1417, loss: 2.1173794269561768\n",
      "epoch: 1, batch: 1418, loss: 2.0785961151123047\n",
      "epoch: 1, batch: 1419, loss: 2.089318037033081\n",
      "epoch: 1, batch: 1420, loss: 2.1197478771209717\n",
      "epoch: 1, batch: 1421, loss: 2.1013565063476562\n",
      "epoch: 1, batch: 1422, loss: 2.1853015422821045\n",
      "epoch: 1, batch: 1423, loss: 2.1126887798309326\n",
      "epoch: 1, batch: 1424, loss: 2.0849599838256836\n",
      "epoch: 1, batch: 1425, loss: 2.14677357673645\n",
      "epoch: 1, batch: 1426, loss: 2.1750597953796387\n",
      "epoch: 1, batch: 1427, loss: 2.1405792236328125\n",
      "epoch: 1, batch: 1428, loss: 2.077192783355713\n",
      "epoch: 1, batch: 1429, loss: 2.1220431327819824\n",
      "epoch: 1, batch: 1430, loss: 2.1403653621673584\n",
      "epoch: 1, batch: 1431, loss: 2.1215384006500244\n",
      "epoch: 1, batch: 1432, loss: 2.1054039001464844\n",
      "epoch: 1, batch: 1433, loss: 2.1065807342529297\n",
      "epoch: 1, batch: 1434, loss: 2.124939203262329\n",
      "epoch: 1, batch: 1435, loss: 2.145925283432007\n",
      "epoch: 1, batch: 1436, loss: 2.075230598449707\n",
      "epoch: 1, batch: 1437, loss: 2.1265146732330322\n",
      "epoch: 1, batch: 1438, loss: 2.0641868114471436\n",
      "epoch: 1, batch: 1439, loss: 2.1204512119293213\n",
      "epoch: 1, batch: 1440, loss: 2.1324751377105713\n",
      "epoch: 1, batch: 1441, loss: 2.14945387840271\n",
      "epoch: 1, batch: 1442, loss: 2.068415641784668\n",
      "epoch: 1, batch: 1443, loss: 2.074192523956299\n",
      "epoch: 1, batch: 1444, loss: 2.1121857166290283\n",
      "epoch: 1, batch: 1445, loss: 2.1389901638031006\n",
      "epoch: 1, batch: 1446, loss: 2.070875644683838\n",
      "epoch: 1, batch: 1447, loss: 2.0399012565612793\n",
      "epoch: 1, batch: 1448, loss: 2.084519386291504\n",
      "epoch: 1, batch: 1449, loss: 2.177103281021118\n",
      "epoch: 1, batch: 1450, loss: 2.1253957748413086\n",
      "epoch: 1, batch: 1451, loss: 2.119978427886963\n",
      "epoch: 1, batch: 1452, loss: 2.1115212440490723\n",
      "epoch: 1, batch: 1453, loss: 2.1642191410064697\n",
      "epoch: 1, batch: 1454, loss: 2.167574167251587\n",
      "epoch: 1, batch: 1455, loss: 2.1458609104156494\n",
      "epoch: 1, batch: 1456, loss: 2.153102159500122\n",
      "epoch: 1, batch: 1457, loss: 2.1352076530456543\n",
      "epoch: 1, batch: 1458, loss: 2.1495304107666016\n",
      "epoch: 1, batch: 1459, loss: 2.0619003772735596\n",
      "epoch: 1, batch: 1460, loss: 2.1667635440826416\n",
      "epoch: 1, batch: 1461, loss: 2.103822708129883\n",
      "epoch: 1, batch: 1462, loss: 2.1450977325439453\n",
      "epoch: 1, batch: 1463, loss: 2.1290860176086426\n",
      "epoch: 1, batch: 1464, loss: 2.1029069423675537\n",
      "epoch: 1, batch: 1465, loss: 2.0876379013061523\n",
      "epoch: 1, batch: 1466, loss: 2.1270790100097656\n",
      "epoch: 1, batch: 1467, loss: 2.1198995113372803\n",
      "epoch: 1, batch: 1468, loss: 2.0972230434417725\n",
      "epoch: 1, batch: 1469, loss: 2.1250996589660645\n",
      "epoch: 1, batch: 1470, loss: 2.0839109420776367\n",
      "epoch: 1, batch: 1471, loss: 2.1160593032836914\n",
      "epoch: 1, batch: 1472, loss: 2.134915590286255\n",
      "epoch: 1, batch: 1473, loss: 2.09334397315979\n",
      "epoch: 1, batch: 1474, loss: 2.111433267593384\n",
      "epoch: 1, batch: 1475, loss: 2.0364925861358643\n",
      "epoch: 1, batch: 1476, loss: 2.1289970874786377\n",
      "epoch: 1, batch: 1477, loss: 2.0609700679779053\n",
      "epoch: 1, batch: 1478, loss: 2.0915400981903076\n",
      "epoch: 1, batch: 1479, loss: 2.121816396713257\n",
      "epoch: 1, batch: 1480, loss: 2.055724859237671\n",
      "epoch: 1, batch: 1481, loss: 2.0424623489379883\n",
      "epoch: 1, batch: 1482, loss: 2.145007848739624\n",
      "epoch: 1, batch: 1483, loss: 2.0818519592285156\n",
      "epoch: 1, batch: 1484, loss: 2.0633649826049805\n",
      "epoch: 1, batch: 1485, loss: 2.1507997512817383\n",
      "epoch: 1, batch: 1486, loss: 2.146655797958374\n",
      "epoch: 1, batch: 1487, loss: 2.121713876724243\n",
      "epoch: 1, batch: 1488, loss: 2.1257426738739014\n",
      "epoch: 1, batch: 1489, loss: 2.0998287200927734\n",
      "epoch: 1, batch: 1490, loss: 2.1209475994110107\n",
      "epoch: 1, batch: 1491, loss: 2.144444465637207\n",
      "epoch: 1, batch: 1492, loss: 2.0964736938476562\n",
      "epoch: 1, batch: 1493, loss: 2.0562350749969482\n",
      "epoch: 1, batch: 1494, loss: 2.0748677253723145\n",
      "epoch: 1, batch: 1495, loss: 2.0627553462982178\n",
      "epoch: 1, batch: 1496, loss: 2.091764450073242\n",
      "epoch: 1, batch: 1497, loss: 2.123011827468872\n",
      "epoch: 1, batch: 1498, loss: 2.0810673236846924\n",
      "epoch: 1, batch: 1499, loss: 2.1198275089263916\n",
      "epoch: 1, batch: 1500, loss: 2.049426794052124\n",
      "epoch: 1, batch: 1501, loss: 2.125699758529663\n",
      "epoch: 1, batch: 1502, loss: 2.081265926361084\n",
      "epoch: 1, batch: 1503, loss: 2.0442867279052734\n",
      "epoch: 1, batch: 1504, loss: 2.064171552658081\n",
      "epoch: 1, batch: 1505, loss: 2.1081430912017822\n",
      "epoch: 1, batch: 1506, loss: 2.081570625305176\n",
      "epoch: 1, batch: 1507, loss: 2.0604166984558105\n",
      "epoch: 1, batch: 1508, loss: 2.1162045001983643\n",
      "epoch: 1, batch: 1509, loss: 2.107205390930176\n",
      "epoch: 1, batch: 1510, loss: 2.12753963470459\n",
      "epoch: 1, batch: 1511, loss: 2.1753997802734375\n",
      "epoch: 1, batch: 1512, loss: 2.1987433433532715\n",
      "epoch: 1, batch: 1513, loss: 2.159139633178711\n",
      "epoch: 1, batch: 1514, loss: 2.086223840713501\n",
      "epoch: 1, batch: 1515, loss: 2.098723888397217\n",
      "epoch: 1, batch: 1516, loss: 2.152036428451538\n",
      "epoch: 1, batch: 1517, loss: 2.1153130531311035\n",
      "epoch: 1, batch: 1518, loss: 2.089805841445923\n",
      "epoch: 1, batch: 1519, loss: 2.084341049194336\n",
      "epoch: 1, batch: 1520, loss: 2.0989158153533936\n",
      "epoch: 1, batch: 1521, loss: 2.107555627822876\n",
      "epoch: 1, batch: 1522, loss: 2.150571584701538\n",
      "epoch: 1, batch: 1523, loss: 2.06965970993042\n",
      "epoch: 1, batch: 1524, loss: 2.1296229362487793\n",
      "epoch: 1, batch: 1525, loss: 2.0774648189544678\n",
      "epoch: 1, batch: 1526, loss: 2.1043970584869385\n",
      "epoch: 1, batch: 1527, loss: 2.121718406677246\n",
      "epoch: 1, batch: 1528, loss: 2.135507583618164\n",
      "epoch: 1, batch: 1529, loss: 2.063777446746826\n",
      "epoch: 1, batch: 1530, loss: 2.05122447013855\n",
      "epoch: 1, batch: 1531, loss: 2.0643954277038574\n",
      "epoch: 1, batch: 1532, loss: 2.0651321411132812\n",
      "epoch: 1, batch: 1533, loss: 2.0728938579559326\n",
      "epoch: 1, batch: 1534, loss: 2.1117284297943115\n",
      "epoch: 1, batch: 1535, loss: 2.1342763900756836\n",
      "epoch: 1, batch: 1536, loss: 2.1080055236816406\n",
      "epoch: 1, batch: 1537, loss: 2.087555408477783\n",
      "epoch: 1, batch: 1538, loss: 2.0203793048858643\n",
      "epoch: 1, batch: 1539, loss: 2.1025638580322266\n",
      "epoch: 1, batch: 1540, loss: 2.0702931880950928\n",
      "epoch: 1, batch: 1541, loss: 2.119826555252075\n",
      "epoch: 1, batch: 1542, loss: 2.0733370780944824\n",
      "epoch: 1, batch: 1543, loss: 2.1287221908569336\n",
      "epoch: 1, batch: 1544, loss: 2.106593370437622\n",
      "epoch: 1, batch: 1545, loss: 2.077232599258423\n",
      "epoch: 1, batch: 1546, loss: 2.113436222076416\n",
      "epoch: 1, batch: 1547, loss: 2.117767572402954\n",
      "epoch: 1, batch: 1548, loss: 2.115694284439087\n",
      "epoch: 1, batch: 1549, loss: 2.1170549392700195\n",
      "epoch: 1, batch: 1550, loss: 2.1622817516326904\n",
      "epoch: 1, batch: 1551, loss: 2.1070778369903564\n",
      "epoch: 1, batch: 1552, loss: 2.119595766067505\n",
      "epoch: 1, batch: 1553, loss: 2.069188117980957\n",
      "epoch: 1, batch: 1554, loss: 2.118537187576294\n",
      "epoch: 1, batch: 1555, loss: 2.089477300643921\n",
      "epoch: 1, batch: 1556, loss: 2.0384600162506104\n",
      "epoch: 1, batch: 1557, loss: 2.0808591842651367\n",
      "epoch: 1, batch: 1558, loss: 2.176555871963501\n",
      "epoch: 1, batch: 1559, loss: 2.0916011333465576\n",
      "epoch: 1, batch: 1560, loss: 2.1175971031188965\n",
      "epoch: 1, batch: 1561, loss: 2.062878131866455\n",
      "epoch: 1, batch: 1562, loss: 2.175807476043701\n",
      "epoch: 1, batch: 1563, loss: 2.1208062171936035\n",
      "epoch: 1, batch: 1564, loss: 2.03448748588562\n",
      "epoch: 1, batch: 1565, loss: 2.1163032054901123\n",
      "epoch: 1, batch: 1566, loss: 2.092024803161621\n",
      "epoch: 1, batch: 1567, loss: 2.13022780418396\n",
      "epoch: 1, batch: 1568, loss: 2.1074233055114746\n",
      "epoch: 1, batch: 1569, loss: 2.0910191535949707\n",
      "epoch: 1, batch: 1570, loss: 2.1488306522369385\n",
      "epoch: 1, batch: 1571, loss: 2.109318733215332\n",
      "epoch: 1, batch: 1572, loss: 2.109898090362549\n",
      "epoch: 1, batch: 1573, loss: 2.070002794265747\n",
      "epoch: 1, batch: 1574, loss: 2.1567471027374268\n",
      "epoch: 1, batch: 1575, loss: 2.064927339553833\n",
      "epoch: 1, batch: 1576, loss: 2.093540668487549\n",
      "epoch: 1, batch: 1577, loss: 2.0290489196777344\n",
      "epoch: 1, batch: 1578, loss: 2.0840604305267334\n",
      "epoch: 1, batch: 1579, loss: 2.0391292572021484\n",
      "epoch: 1, batch: 1580, loss: 2.1091058254241943\n",
      "epoch: 1, batch: 1581, loss: 2.1265616416931152\n",
      "epoch: 1, batch: 1582, loss: 2.0509579181671143\n",
      "epoch: 1, batch: 1583, loss: 2.1350841522216797\n",
      "epoch: 1, batch: 1584, loss: 2.0886528491973877\n",
      "epoch: 1, batch: 1585, loss: 2.0952844619750977\n",
      "epoch: 1, batch: 1586, loss: 2.031378984451294\n",
      "epoch: 1, batch: 1587, loss: 2.0620663166046143\n",
      "epoch: 1, batch: 1588, loss: 2.0976974964141846\n",
      "epoch: 1, batch: 1589, loss: 2.0448272228240967\n",
      "epoch: 1, batch: 1590, loss: 2.0802767276763916\n",
      "epoch: 1, batch: 1591, loss: 2.054067850112915\n",
      "epoch: 1, batch: 1592, loss: 2.0461347103118896\n",
      "epoch: 1, batch: 1593, loss: 2.07977557182312\n",
      "epoch: 1, batch: 1594, loss: 2.136554718017578\n",
      "epoch: 1, batch: 1595, loss: 2.0324020385742188\n",
      "epoch: 1, batch: 1596, loss: 2.133148193359375\n",
      "epoch: 1, batch: 1597, loss: 2.0511908531188965\n",
      "epoch: 1, batch: 1598, loss: 2.0554089546203613\n",
      "epoch: 1, batch: 1599, loss: 2.1310625076293945\n",
      "epoch: 1, batch: 1600, loss: 2.062483072280884\n",
      "epoch: 1, batch: 1601, loss: 2.0958938598632812\n",
      "epoch: 1, batch: 1602, loss: 2.0967137813568115\n",
      "epoch: 1, batch: 1603, loss: 2.0639326572418213\n",
      "epoch: 1, batch: 1604, loss: 2.125354051589966\n",
      "epoch: 1, batch: 1605, loss: 2.142638683319092\n",
      "epoch: 1, batch: 1606, loss: 2.023555040359497\n",
      "epoch: 1, batch: 1607, loss: 2.0477147102355957\n",
      "epoch: 1, batch: 1608, loss: 2.1208887100219727\n",
      "epoch: 1, batch: 1609, loss: 2.0758635997772217\n",
      "epoch: 1, batch: 1610, loss: 2.1282289028167725\n",
      "epoch: 1, batch: 1611, loss: 2.0930182933807373\n",
      "epoch: 1, batch: 1612, loss: 2.0721046924591064\n",
      "epoch: 1, batch: 1613, loss: 2.138669729232788\n",
      "epoch: 1, batch: 1614, loss: 2.1033694744110107\n",
      "epoch: 1, batch: 1615, loss: 2.041154384613037\n",
      "epoch: 1, batch: 1616, loss: 2.125131845474243\n",
      "epoch: 1, batch: 1617, loss: 2.1156630516052246\n",
      "epoch: 1, batch: 1618, loss: 2.1165435314178467\n",
      "epoch: 1, batch: 1619, loss: 2.0333282947540283\n",
      "epoch: 1, batch: 1620, loss: 2.1360347270965576\n",
      "epoch: 1, batch: 1621, loss: 2.077280282974243\n",
      "epoch: 1, batch: 1622, loss: 2.033872127532959\n",
      "epoch: 1, batch: 1623, loss: 2.020582675933838\n",
      "epoch: 1, batch: 1624, loss: 2.0805840492248535\n",
      "epoch: 1, batch: 1625, loss: 2.10445499420166\n",
      "epoch: 1, batch: 1626, loss: 2.084944009780884\n",
      "epoch: 1, batch: 1627, loss: 2.0395004749298096\n",
      "epoch: 1, batch: 1628, loss: 2.057943820953369\n",
      "epoch: 1, batch: 1629, loss: 2.143765449523926\n",
      "epoch: 1, batch: 1630, loss: 2.043850898742676\n",
      "epoch: 1, batch: 1631, loss: 2.0477378368377686\n",
      "epoch: 1, batch: 1632, loss: 2.1072535514831543\n",
      "epoch: 1, batch: 1633, loss: 2.0768637657165527\n",
      "epoch: 1, batch: 1634, loss: 2.0890727043151855\n",
      "epoch: 1, batch: 1635, loss: 2.0736701488494873\n",
      "epoch: 1, batch: 1636, loss: 2.035444498062134\n",
      "epoch: 1, batch: 1637, loss: 1.9842565059661865\n",
      "epoch: 1, batch: 1638, loss: 2.13687801361084\n",
      "epoch: 1, batch: 1639, loss: 2.0911033153533936\n",
      "epoch: 1, batch: 1640, loss: 2.0928125381469727\n",
      "epoch: 1, batch: 1641, loss: 2.083174705505371\n",
      "epoch: 1, batch: 1642, loss: 2.0299484729766846\n",
      "epoch: 1, batch: 1643, loss: 2.08980131149292\n",
      "epoch: 1, batch: 1644, loss: 2.072956085205078\n",
      "epoch: 1, batch: 1645, loss: 2.123549699783325\n",
      "epoch: 1, batch: 1646, loss: 2.084459066390991\n",
      "epoch: 1, batch: 1647, loss: 2.0703229904174805\n",
      "epoch: 1, batch: 1648, loss: 2.0632052421569824\n",
      "epoch: 1, batch: 1649, loss: 2.0510973930358887\n",
      "epoch: 1, batch: 1650, loss: 2.1121304035186768\n",
      "epoch: 1, batch: 1651, loss: 2.0614755153656006\n",
      "epoch: 1, batch: 1652, loss: 2.0424370765686035\n",
      "epoch: 1, batch: 1653, loss: 2.092860460281372\n",
      "epoch: 1, batch: 1654, loss: 2.0430705547332764\n",
      "epoch: 1, batch: 1655, loss: 2.0816149711608887\n",
      "epoch: 1, batch: 1656, loss: 2.0325522422790527\n",
      "epoch: 1, batch: 1657, loss: 1.9820466041564941\n",
      "epoch: 1, batch: 1658, loss: 2.0817878246307373\n",
      "epoch: 1, batch: 1659, loss: 2.166398763656616\n",
      "epoch: 1, batch: 1660, loss: 2.0873115062713623\n",
      "epoch: 1, batch: 1661, loss: 2.107682943344116\n",
      "epoch: 1, batch: 1662, loss: 2.0564067363739014\n",
      "epoch: 1, batch: 1663, loss: 2.0537731647491455\n",
      "epoch: 1, batch: 1664, loss: 2.066800117492676\n",
      "epoch: 1, batch: 1665, loss: 2.084928274154663\n",
      "epoch: 1, batch: 1666, loss: 2.158834934234619\n",
      "epoch: 1, batch: 1667, loss: 2.0730996131896973\n",
      "epoch: 1, batch: 1668, loss: 2.0832278728485107\n",
      "epoch: 1, batch: 1669, loss: 2.1078615188598633\n",
      "epoch: 1, batch: 1670, loss: 2.0573441982269287\n",
      "epoch: 1, batch: 1671, loss: 2.0568249225616455\n",
      "epoch: 1, batch: 1672, loss: 2.0522632598876953\n",
      "epoch: 1, batch: 1673, loss: 2.09580397605896\n",
      "epoch: 1, batch: 1674, loss: 2.0849716663360596\n",
      "epoch: 1, batch: 1675, loss: 2.0719075202941895\n",
      "epoch: 1, batch: 1676, loss: 2.0307559967041016\n",
      "epoch: 1, batch: 1677, loss: 2.079698085784912\n",
      "epoch: 1, batch: 1678, loss: 2.027367353439331\n",
      "epoch: 1, batch: 1679, loss: 2.0670957565307617\n",
      "epoch: 1, batch: 1680, loss: 2.080080270767212\n",
      "epoch: 1, batch: 1681, loss: 2.052922487258911\n",
      "epoch: 1, batch: 1682, loss: 2.0638506412506104\n",
      "epoch: 1, batch: 1683, loss: 2.1453216075897217\n",
      "epoch: 1, batch: 1684, loss: 2.1118342876434326\n",
      "epoch: 1, batch: 1685, loss: 2.046029806137085\n",
      "epoch: 1, batch: 1686, loss: 2.0884387493133545\n",
      "epoch: 1, batch: 1687, loss: 2.0728399753570557\n",
      "epoch: 1, batch: 1688, loss: 2.12225079536438\n",
      "epoch: 1, batch: 1689, loss: 2.079072952270508\n",
      "epoch: 1, batch: 1690, loss: 2.110189437866211\n",
      "epoch: 1, batch: 1691, loss: 2.0759918689727783\n",
      "epoch: 1, batch: 1692, loss: 2.0863754749298096\n",
      "epoch: 1, batch: 1693, loss: 2.0179073810577393\n",
      "epoch: 1, batch: 1694, loss: 2.085904121398926\n",
      "epoch: 1, batch: 1695, loss: 2.0280022621154785\n",
      "epoch: 1, batch: 1696, loss: 2.0820095539093018\n",
      "epoch: 1, batch: 1697, loss: 2.115964651107788\n",
      "epoch: 1, batch: 1698, loss: 2.015629768371582\n",
      "epoch: 1, batch: 1699, loss: 2.084482431411743\n",
      "epoch: 1, batch: 1700, loss: 2.1097798347473145\n",
      "epoch: 1, batch: 1701, loss: 2.0883967876434326\n",
      "epoch: 1, batch: 1702, loss: 2.042278289794922\n",
      "epoch: 1, batch: 1703, loss: 2.133495807647705\n",
      "epoch: 1, batch: 1704, loss: 2.0819625854492188\n",
      "epoch: 1, batch: 1705, loss: 2.0959482192993164\n",
      "epoch: 1, batch: 1706, loss: 2.065776824951172\n",
      "epoch: 1, batch: 1707, loss: 2.0678696632385254\n",
      "epoch: 1, batch: 1708, loss: 2.07031512260437\n",
      "epoch: 1, batch: 1709, loss: 2.1231346130371094\n",
      "epoch: 1, batch: 1710, loss: 2.055850028991699\n",
      "epoch: 1, batch: 1711, loss: 2.070859670639038\n",
      "epoch: 1, batch: 1712, loss: 2.1132559776306152\n",
      "epoch: 1, batch: 1713, loss: 2.0743019580841064\n",
      "epoch: 1, batch: 1714, loss: 2.099050283432007\n",
      "epoch: 1, batch: 1715, loss: 2.1021132469177246\n",
      "epoch: 1, batch: 1716, loss: 2.101388692855835\n",
      "epoch: 1, batch: 1717, loss: 2.0593385696411133\n",
      "epoch: 1, batch: 1718, loss: 2.1102042198181152\n",
      "epoch: 1, batch: 1719, loss: 2.078732490539551\n",
      "epoch: 1, batch: 1720, loss: 2.059382677078247\n",
      "epoch: 1, batch: 1721, loss: 2.0471088886260986\n",
      "epoch: 1, batch: 1722, loss: 2.061980962753296\n",
      "epoch: 1, batch: 1723, loss: 2.0130529403686523\n",
      "epoch: 1, batch: 1724, loss: 2.105618953704834\n",
      "epoch: 1, batch: 1725, loss: 2.060457706451416\n",
      "epoch: 1, batch: 1726, loss: 2.003105640411377\n",
      "epoch: 1, batch: 1727, loss: 2.083731174468994\n",
      "epoch: 1, batch: 1728, loss: 2.054884195327759\n",
      "epoch: 1, batch: 1729, loss: 2.0040533542633057\n",
      "epoch: 1, batch: 1730, loss: 1.9937467575073242\n",
      "epoch: 1, batch: 1731, loss: 2.06469464302063\n",
      "epoch: 1, batch: 1732, loss: 1.9706107378005981\n",
      "epoch: 1, batch: 1733, loss: 2.080214262008667\n",
      "epoch: 1, batch: 1734, loss: 2.0451595783233643\n",
      "epoch: 1, batch: 1735, loss: 2.1136717796325684\n",
      "epoch: 1, batch: 1736, loss: 2.0681650638580322\n",
      "epoch: 1, batch: 1737, loss: 2.0233819484710693\n",
      "epoch: 1, batch: 1738, loss: 2.036466598510742\n",
      "epoch: 1, batch: 1739, loss: 2.055108070373535\n",
      "epoch: 1, batch: 1740, loss: 2.060781955718994\n",
      "epoch: 1, batch: 1741, loss: 2.126828193664551\n",
      "epoch: 1, batch: 1742, loss: 2.0909855365753174\n",
      "epoch: 1, batch: 1743, loss: 2.0179519653320312\n",
      "epoch: 1, batch: 1744, loss: 2.129744291305542\n",
      "epoch: 1, batch: 1745, loss: 2.058565616607666\n",
      "epoch: 1, batch: 1746, loss: 2.067063570022583\n",
      "epoch: 1, batch: 1747, loss: 2.1140356063842773\n",
      "epoch: 1, batch: 1748, loss: 2.049546241760254\n",
      "epoch: 1, batch: 1749, loss: 2.06949520111084\n",
      "epoch: 1, batch: 1750, loss: 2.125589609146118\n",
      "epoch: 1, batch: 1751, loss: 2.0676565170288086\n",
      "epoch: 1, batch: 1752, loss: 2.0663490295410156\n",
      "epoch: 1, batch: 1753, loss: 2.0679867267608643\n",
      "epoch: 1, batch: 1754, loss: 2.0478248596191406\n",
      "epoch: 1, batch: 1755, loss: 2.0486128330230713\n",
      "epoch: 1, batch: 1756, loss: 2.126979351043701\n",
      "epoch: 1, batch: 1757, loss: 2.0698795318603516\n",
      "epoch: 1, batch: 1758, loss: 2.0841598510742188\n",
      "epoch: 1, batch: 1759, loss: 2.0414845943450928\n",
      "epoch: 1, batch: 1760, loss: 2.048896551132202\n",
      "epoch: 1, batch: 1761, loss: 2.0592763423919678\n",
      "epoch: 1, batch: 1762, loss: 2.104857921600342\n",
      "epoch: 1, batch: 1763, loss: 1.9162627458572388\n",
      "epoch: 1, batch: 1764, loss: 2.056880474090576\n",
      "epoch: 1, batch: 1765, loss: 2.055971145629883\n",
      "epoch: 1, batch: 1766, loss: 2.0370709896087646\n",
      "epoch: 1, batch: 1767, loss: 2.072474479675293\n",
      "epoch: 1, batch: 1768, loss: 2.0170657634735107\n",
      "epoch: 1, batch: 1769, loss: 2.0909767150878906\n",
      "epoch: 1, batch: 1770, loss: 2.0303211212158203\n",
      "epoch: 1, batch: 1771, loss: 2.0620946884155273\n",
      "epoch: 1, batch: 1772, loss: 2.066042423248291\n",
      "epoch: 1, batch: 1773, loss: 2.0975308418273926\n",
      "epoch: 1, batch: 1774, loss: 2.025970458984375\n",
      "epoch: 1, batch: 1775, loss: 2.0894663333892822\n",
      "epoch: 1, batch: 1776, loss: 2.1022274494171143\n",
      "epoch: 1, batch: 1777, loss: 2.0090436935424805\n",
      "epoch: 1, batch: 1778, loss: 2.098985195159912\n",
      "epoch: 1, batch: 1779, loss: 2.103756904602051\n",
      "epoch: 1, batch: 1780, loss: 2.0813546180725098\n",
      "epoch: 1, batch: 1781, loss: 2.0480051040649414\n",
      "epoch: 1, batch: 1782, loss: 2.1237237453460693\n",
      "epoch: 1, batch: 1783, loss: 2.0295021533966064\n",
      "epoch: 1, batch: 1784, loss: 2.150254726409912\n",
      "epoch: 1, batch: 1785, loss: 2.0176453590393066\n",
      "epoch: 1, batch: 1786, loss: 2.109891891479492\n",
      "epoch: 1, batch: 1787, loss: 2.023142099380493\n",
      "epoch: 1, batch: 1788, loss: 2.0608246326446533\n",
      "epoch: 1, batch: 1789, loss: 2.0603668689727783\n",
      "epoch: 1, batch: 1790, loss: 2.009960651397705\n",
      "epoch: 1, batch: 1791, loss: 1.9955753087997437\n",
      "epoch: 1, batch: 1792, loss: 2.060537099838257\n",
      "epoch: 1, batch: 1793, loss: 2.067335605621338\n",
      "epoch: 1, batch: 1794, loss: 2.073289155960083\n",
      "epoch: 1, batch: 1795, loss: 2.0464770793914795\n",
      "epoch: 1, batch: 1796, loss: 2.046349048614502\n",
      "epoch: 1, batch: 1797, loss: 2.014462471008301\n",
      "epoch: 1, batch: 1798, loss: 2.078679084777832\n",
      "epoch: 1, batch: 1799, loss: 2.0198941230773926\n",
      "epoch: 1, batch: 1800, loss: 2.0490405559539795\n",
      "epoch: 1, batch: 1801, loss: 2.088367462158203\n",
      "epoch: 1, batch: 1802, loss: 2.070904493331909\n",
      "epoch: 1, batch: 1803, loss: 2.0874671936035156\n",
      "epoch: 1, batch: 1804, loss: 2.0686569213867188\n",
      "epoch: 1, batch: 1805, loss: 2.0070533752441406\n",
      "epoch: 1, batch: 1806, loss: 2.067171096801758\n",
      "epoch: 1, batch: 1807, loss: 2.0390288829803467\n",
      "epoch: 1, batch: 1808, loss: 1.9503154754638672\n",
      "epoch: 1, batch: 1809, loss: 2.046389102935791\n",
      "epoch: 1, batch: 1810, loss: 2.058283567428589\n",
      "epoch: 1, batch: 1811, loss: 2.1092689037323\n",
      "epoch: 1, batch: 1812, loss: 2.035247325897217\n",
      "epoch: 1, batch: 1813, loss: 2.0803589820861816\n",
      "epoch: 1, batch: 1814, loss: 2.080641508102417\n",
      "epoch: 1, batch: 1815, loss: 2.022343397140503\n",
      "epoch: 1, batch: 1816, loss: 2.0153865814208984\n",
      "epoch: 1, batch: 1817, loss: 2.0802993774414062\n",
      "epoch: 1, batch: 1818, loss: 2.0777411460876465\n",
      "epoch: 1, batch: 1819, loss: 2.1167242527008057\n",
      "epoch: 1, batch: 1820, loss: 2.1138226985931396\n",
      "epoch: 1, batch: 1821, loss: 2.0388495922088623\n",
      "epoch: 1, batch: 1822, loss: 2.0714075565338135\n",
      "epoch: 1, batch: 1823, loss: 2.067295551300049\n",
      "epoch: 1, batch: 1824, loss: 2.0448615550994873\n",
      "epoch: 1, batch: 1825, loss: 2.051563024520874\n",
      "epoch: 1, batch: 1826, loss: 2.009925603866577\n",
      "epoch: 1, batch: 1827, loss: 2.074819326400757\n",
      "epoch: 1, batch: 1828, loss: 2.1043267250061035\n",
      "epoch: 1, batch: 1829, loss: 2.029304265975952\n",
      "epoch: 1, batch: 1830, loss: 2.0426697731018066\n",
      "epoch: 1, batch: 1831, loss: 2.0340585708618164\n",
      "epoch: 1, batch: 1832, loss: 2.020228147506714\n",
      "epoch: 1, batch: 1833, loss: 2.075216054916382\n",
      "epoch: 1, batch: 1834, loss: 2.017580986022949\n",
      "epoch: 1, batch: 1835, loss: 2.071478843688965\n",
      "epoch: 1, batch: 1836, loss: 2.122760772705078\n",
      "epoch: 1, batch: 1837, loss: 2.0176749229431152\n",
      "epoch: 1, batch: 1838, loss: 2.037191152572632\n",
      "epoch: 1, batch: 1839, loss: 2.0806784629821777\n",
      "epoch: 1, batch: 1840, loss: 2.043199300765991\n",
      "epoch: 1, batch: 1841, loss: 2.0588340759277344\n",
      "epoch: 1, batch: 1842, loss: 2.0255799293518066\n",
      "epoch: 1, batch: 1843, loss: 2.079479455947876\n",
      "epoch: 1, batch: 1844, loss: 2.0129287242889404\n",
      "epoch: 1, batch: 1845, loss: 2.077153205871582\n",
      "epoch: 1, batch: 1846, loss: 2.0089268684387207\n",
      "epoch: 1, batch: 1847, loss: 2.0311551094055176\n",
      "epoch: 1, batch: 1848, loss: 2.021308422088623\n",
      "epoch: 1, batch: 1849, loss: 2.0534160137176514\n",
      "epoch: 1, batch: 1850, loss: 2.0946967601776123\n",
      "epoch: 1, batch: 1851, loss: 2.071141004562378\n",
      "epoch: 1, batch: 1852, loss: 2.068190336227417\n",
      "epoch: 1, batch: 1853, loss: 2.0864298343658447\n",
      "epoch: 1, batch: 1854, loss: 2.115159273147583\n",
      "epoch: 1, batch: 1855, loss: 2.0534260272979736\n",
      "epoch: 1, batch: 1856, loss: 2.067077398300171\n",
      "epoch: 1, batch: 1857, loss: 2.1145708560943604\n",
      "epoch: 1, batch: 1858, loss: 2.0050504207611084\n",
      "epoch: 1, batch: 1859, loss: 2.0626535415649414\n",
      "epoch: 1, batch: 1860, loss: 2.0960981845855713\n",
      "epoch: 1, batch: 1861, loss: 2.043893814086914\n",
      "epoch: 1, batch: 1862, loss: 2.025054454803467\n",
      "epoch: 1, batch: 1863, loss: 2.0520267486572266\n",
      "epoch: 1, batch: 1864, loss: 2.066819190979004\n",
      "epoch: 1, batch: 1865, loss: 2.1546995639801025\n",
      "epoch: 1, batch: 1866, loss: 2.024282693862915\n",
      "epoch: 1, batch: 1867, loss: 2.0177130699157715\n",
      "epoch: 1, batch: 1868, loss: 2.0149426460266113\n",
      "epoch: 1, batch: 1869, loss: 2.1067821979522705\n",
      "epoch: 1, batch: 1870, loss: 2.0922493934631348\n",
      "epoch: 1, batch: 1871, loss: 2.000056266784668\n",
      "epoch: 1, batch: 1872, loss: 2.1167659759521484\n",
      "epoch: 1, batch: 1873, loss: 1.9810824394226074\n",
      "epoch: 1, batch: 1874, loss: 2.0757088661193848\n",
      "epoch: 2, batch: 0, loss: 2.107670783996582\n",
      "epoch: 2, batch: 1, loss: 2.0090208053588867\n",
      "epoch: 2, batch: 2, loss: 1.9897981882095337\n",
      "epoch: 2, batch: 3, loss: 2.0654659271240234\n",
      "epoch: 2, batch: 4, loss: 2.082287311553955\n",
      "epoch: 2, batch: 5, loss: 2.043153762817383\n",
      "epoch: 2, batch: 6, loss: 2.0472934246063232\n",
      "epoch: 2, batch: 7, loss: 2.0262532234191895\n",
      "epoch: 2, batch: 8, loss: 2.0087475776672363\n",
      "epoch: 2, batch: 9, loss: 2.062495470046997\n",
      "epoch: 2, batch: 10, loss: 2.1032285690307617\n",
      "epoch: 2, batch: 11, loss: 2.0647976398468018\n",
      "epoch: 2, batch: 12, loss: 2.0720720291137695\n",
      "epoch: 2, batch: 13, loss: 2.0784757137298584\n",
      "epoch: 2, batch: 14, loss: 2.0367085933685303\n",
      "epoch: 2, batch: 15, loss: 1.995092511177063\n",
      "epoch: 2, batch: 16, loss: 2.0262954235076904\n",
      "epoch: 2, batch: 17, loss: 1.999401569366455\n",
      "epoch: 2, batch: 18, loss: 2.03813099861145\n",
      "epoch: 2, batch: 19, loss: 2.0130298137664795\n",
      "epoch: 2, batch: 20, loss: 1.970691442489624\n",
      "epoch: 2, batch: 21, loss: 2.026197910308838\n",
      "epoch: 2, batch: 22, loss: 2.0668630599975586\n",
      "epoch: 2, batch: 23, loss: 2.102663278579712\n",
      "epoch: 2, batch: 24, loss: 2.0647482872009277\n",
      "epoch: 2, batch: 25, loss: 2.0139613151550293\n",
      "epoch: 2, batch: 26, loss: 2.046938180923462\n",
      "epoch: 2, batch: 27, loss: 2.1216537952423096\n",
      "epoch: 2, batch: 28, loss: 2.041139602661133\n",
      "epoch: 2, batch: 29, loss: 2.052133798599243\n",
      "epoch: 2, batch: 30, loss: 2.123387336730957\n",
      "epoch: 2, batch: 31, loss: 2.079435110092163\n",
      "epoch: 2, batch: 32, loss: 1.991957187652588\n",
      "epoch: 2, batch: 33, loss: 2.039783000946045\n",
      "epoch: 2, batch: 34, loss: 2.0254218578338623\n",
      "epoch: 2, batch: 35, loss: 2.0561635494232178\n",
      "epoch: 2, batch: 36, loss: 2.0241968631744385\n",
      "epoch: 2, batch: 37, loss: 1.9791873693466187\n",
      "epoch: 2, batch: 38, loss: 1.9839186668395996\n",
      "epoch: 2, batch: 39, loss: 2.0268096923828125\n",
      "epoch: 2, batch: 40, loss: 2.0193731784820557\n",
      "epoch: 2, batch: 41, loss: 2.0150411128997803\n",
      "epoch: 2, batch: 42, loss: 1.9686797857284546\n",
      "epoch: 2, batch: 43, loss: 2.0628738403320312\n",
      "epoch: 2, batch: 44, loss: 2.0504424571990967\n",
      "epoch: 2, batch: 45, loss: 2.0983641147613525\n",
      "epoch: 2, batch: 46, loss: 2.0743961334228516\n",
      "epoch: 2, batch: 47, loss: 2.0538394451141357\n",
      "epoch: 2, batch: 48, loss: 2.0220203399658203\n",
      "epoch: 2, batch: 49, loss: 2.099167585372925\n",
      "epoch: 2, batch: 50, loss: 2.0899124145507812\n",
      "epoch: 2, batch: 51, loss: 2.0592358112335205\n",
      "epoch: 2, batch: 52, loss: 2.02286958694458\n",
      "epoch: 2, batch: 53, loss: 2.052121877670288\n",
      "epoch: 2, batch: 54, loss: 2.0279996395111084\n",
      "epoch: 2, batch: 55, loss: 2.0255281925201416\n",
      "epoch: 2, batch: 56, loss: 2.1127161979675293\n",
      "epoch: 2, batch: 57, loss: 2.0906319618225098\n",
      "epoch: 2, batch: 58, loss: 2.0023272037506104\n",
      "epoch: 2, batch: 59, loss: 2.0166726112365723\n",
      "epoch: 2, batch: 60, loss: 2.038362979888916\n",
      "epoch: 2, batch: 61, loss: 1.9797592163085938\n",
      "epoch: 2, batch: 62, loss: 2.0286591053009033\n",
      "epoch: 2, batch: 63, loss: 2.094750165939331\n",
      "epoch: 2, batch: 64, loss: 1.9566776752471924\n",
      "epoch: 2, batch: 65, loss: 2.0152721405029297\n",
      "epoch: 2, batch: 66, loss: 2.0194153785705566\n",
      "epoch: 2, batch: 67, loss: 2.0990965366363525\n",
      "epoch: 2, batch: 68, loss: 2.0249061584472656\n",
      "epoch: 2, batch: 69, loss: 2.0229437351226807\n",
      "epoch: 2, batch: 70, loss: 2.0209858417510986\n",
      "epoch: 2, batch: 71, loss: 1.9834873676300049\n",
      "epoch: 2, batch: 72, loss: 2.037163496017456\n",
      "epoch: 2, batch: 73, loss: 1.9962741136550903\n",
      "epoch: 2, batch: 74, loss: 2.1177611351013184\n",
      "epoch: 2, batch: 75, loss: 2.000930070877075\n",
      "epoch: 2, batch: 76, loss: 1.9961153268814087\n",
      "epoch: 2, batch: 77, loss: 2.007253408432007\n",
      "epoch: 2, batch: 78, loss: 1.9575575590133667\n",
      "epoch: 2, batch: 79, loss: 2.074899911880493\n",
      "epoch: 2, batch: 80, loss: 2.107923746109009\n",
      "epoch: 2, batch: 81, loss: 2.066828489303589\n",
      "epoch: 2, batch: 82, loss: 2.088827133178711\n",
      "epoch: 2, batch: 83, loss: 1.9978300333023071\n",
      "epoch: 2, batch: 84, loss: 2.0053412914276123\n",
      "epoch: 2, batch: 85, loss: 2.0021002292633057\n",
      "epoch: 2, batch: 86, loss: 2.0540833473205566\n",
      "epoch: 2, batch: 87, loss: 2.0089149475097656\n",
      "epoch: 2, batch: 88, loss: 1.9738229513168335\n",
      "epoch: 2, batch: 89, loss: 2.0688445568084717\n",
      "epoch: 2, batch: 90, loss: 2.0258147716522217\n",
      "epoch: 2, batch: 91, loss: 2.015090227127075\n",
      "epoch: 2, batch: 92, loss: 2.0556552410125732\n",
      "epoch: 2, batch: 93, loss: 2.0352375507354736\n",
      "epoch: 2, batch: 94, loss: 2.015885591506958\n",
      "epoch: 2, batch: 95, loss: 1.9557971954345703\n",
      "epoch: 2, batch: 96, loss: 2.000013828277588\n",
      "epoch: 2, batch: 97, loss: 2.0442543029785156\n",
      "epoch: 2, batch: 98, loss: 1.9979145526885986\n",
      "epoch: 2, batch: 99, loss: 1.9868792295455933\n",
      "epoch: 2, batch: 100, loss: 2.064685821533203\n",
      "epoch: 2, batch: 101, loss: 2.0736372470855713\n",
      "epoch: 2, batch: 102, loss: 2.0238232612609863\n",
      "epoch: 2, batch: 103, loss: 2.013868570327759\n",
      "epoch: 2, batch: 104, loss: 2.030052661895752\n",
      "epoch: 2, batch: 105, loss: 2.0665745735168457\n",
      "epoch: 2, batch: 106, loss: 2.0036826133728027\n",
      "epoch: 2, batch: 107, loss: 2.030778408050537\n",
      "epoch: 2, batch: 108, loss: 2.016683340072632\n",
      "epoch: 2, batch: 109, loss: 2.0412285327911377\n",
      "epoch: 2, batch: 110, loss: 2.083890438079834\n",
      "epoch: 2, batch: 111, loss: 2.082172155380249\n",
      "epoch: 2, batch: 112, loss: 2.054454803466797\n",
      "epoch: 2, batch: 113, loss: 2.0270049571990967\n",
      "epoch: 2, batch: 114, loss: 2.073986053466797\n",
      "epoch: 2, batch: 115, loss: 2.044813632965088\n",
      "epoch: 2, batch: 116, loss: 2.065521001815796\n",
      "epoch: 2, batch: 117, loss: 2.006347894668579\n",
      "epoch: 2, batch: 118, loss: 2.0034940242767334\n",
      "epoch: 2, batch: 119, loss: 2.087850332260132\n",
      "epoch: 2, batch: 120, loss: 2.069056272506714\n",
      "epoch: 2, batch: 121, loss: 2.0435900688171387\n",
      "epoch: 2, batch: 122, loss: 2.049727439880371\n",
      "epoch: 2, batch: 123, loss: 2.0785751342773438\n",
      "epoch: 2, batch: 124, loss: 1.9702068567276\n",
      "epoch: 2, batch: 125, loss: 2.025071144104004\n",
      "epoch: 2, batch: 126, loss: 2.061269760131836\n",
      "epoch: 2, batch: 127, loss: 2.082606792449951\n",
      "epoch: 2, batch: 128, loss: 2.0033185482025146\n",
      "epoch: 2, batch: 129, loss: 2.015778064727783\n",
      "epoch: 2, batch: 130, loss: 2.0538547039031982\n",
      "epoch: 2, batch: 131, loss: 2.0589003562927246\n",
      "epoch: 2, batch: 132, loss: 2.0127599239349365\n",
      "epoch: 2, batch: 133, loss: 2.029085636138916\n",
      "epoch: 2, batch: 134, loss: 2.0019538402557373\n",
      "epoch: 2, batch: 135, loss: 2.0376391410827637\n",
      "epoch: 2, batch: 136, loss: 2.0501863956451416\n",
      "epoch: 2, batch: 137, loss: 2.0380966663360596\n",
      "epoch: 2, batch: 138, loss: 1.9540009498596191\n",
      "epoch: 2, batch: 139, loss: 2.0269670486450195\n",
      "epoch: 2, batch: 140, loss: 2.0338683128356934\n",
      "epoch: 2, batch: 141, loss: 2.046980381011963\n",
      "epoch: 2, batch: 142, loss: 1.9352551698684692\n",
      "epoch: 2, batch: 143, loss: 2.1140902042388916\n",
      "epoch: 2, batch: 144, loss: 1.9780915975570679\n",
      "epoch: 2, batch: 145, loss: 2.0002682209014893\n",
      "epoch: 2, batch: 146, loss: 1.9893736839294434\n",
      "epoch: 2, batch: 147, loss: 1.9664936065673828\n",
      "epoch: 2, batch: 148, loss: 2.084512710571289\n",
      "epoch: 2, batch: 149, loss: 2.006418228149414\n",
      "epoch: 2, batch: 150, loss: 2.0787158012390137\n",
      "epoch: 2, batch: 151, loss: 2.014902353286743\n",
      "epoch: 2, batch: 152, loss: 2.0020384788513184\n",
      "epoch: 2, batch: 153, loss: 2.020432710647583\n",
      "epoch: 2, batch: 154, loss: 2.0180599689483643\n",
      "epoch: 2, batch: 155, loss: 2.1035592555999756\n",
      "epoch: 2, batch: 156, loss: 2.0329670906066895\n",
      "epoch: 2, batch: 157, loss: 1.9405686855316162\n",
      "epoch: 2, batch: 158, loss: 2.0710251331329346\n",
      "epoch: 2, batch: 159, loss: 2.050931215286255\n",
      "epoch: 2, batch: 160, loss: 1.9738203287124634\n",
      "epoch: 2, batch: 161, loss: 2.0982630252838135\n",
      "epoch: 2, batch: 162, loss: 1.9747499227523804\n",
      "epoch: 2, batch: 163, loss: 1.9484065771102905\n",
      "epoch: 2, batch: 164, loss: 1.968806266784668\n",
      "epoch: 2, batch: 165, loss: 1.9365479946136475\n",
      "epoch: 2, batch: 166, loss: 2.0986156463623047\n",
      "epoch: 2, batch: 167, loss: 2.0247509479522705\n",
      "epoch: 2, batch: 168, loss: 1.967070460319519\n",
      "epoch: 2, batch: 169, loss: 2.0191168785095215\n",
      "epoch: 2, batch: 170, loss: 2.0289928913116455\n",
      "epoch: 2, batch: 171, loss: 2.0276453495025635\n",
      "epoch: 2, batch: 172, loss: 2.0498247146606445\n",
      "epoch: 2, batch: 173, loss: 2.0669045448303223\n",
      "epoch: 2, batch: 174, loss: 1.9766559600830078\n",
      "epoch: 2, batch: 175, loss: 2.089024782180786\n",
      "epoch: 2, batch: 176, loss: 2.0332624912261963\n",
      "epoch: 2, batch: 177, loss: 2.056180953979492\n",
      "epoch: 2, batch: 178, loss: 2.0233378410339355\n",
      "epoch: 2, batch: 179, loss: 1.9495896100997925\n",
      "epoch: 2, batch: 180, loss: 1.920649766921997\n",
      "epoch: 2, batch: 181, loss: 2.110719680786133\n",
      "epoch: 2, batch: 182, loss: 2.0714027881622314\n",
      "epoch: 2, batch: 183, loss: 1.9789717197418213\n",
      "epoch: 2, batch: 184, loss: 2.014198064804077\n",
      "epoch: 2, batch: 185, loss: 1.9964802265167236\n",
      "epoch: 2, batch: 186, loss: 2.0057623386383057\n",
      "epoch: 2, batch: 187, loss: 1.9940515756607056\n",
      "epoch: 2, batch: 188, loss: 1.9568798542022705\n",
      "epoch: 2, batch: 189, loss: 1.9479950666427612\n",
      "epoch: 2, batch: 190, loss: 2.068965196609497\n",
      "epoch: 2, batch: 191, loss: 1.9514522552490234\n",
      "epoch: 2, batch: 192, loss: 1.9792367219924927\n",
      "epoch: 2, batch: 193, loss: 1.9934701919555664\n",
      "epoch: 2, batch: 194, loss: 2.0688560009002686\n",
      "epoch: 2, batch: 195, loss: 1.9958422183990479\n",
      "epoch: 2, batch: 196, loss: 2.065842390060425\n",
      "epoch: 2, batch: 197, loss: 1.9965988397598267\n",
      "epoch: 2, batch: 198, loss: 2.017582893371582\n",
      "epoch: 2, batch: 199, loss: 1.974908709526062\n",
      "epoch: 2, batch: 200, loss: 2.050149917602539\n",
      "epoch: 2, batch: 201, loss: 1.9957098960876465\n",
      "epoch: 2, batch: 202, loss: 2.026451826095581\n",
      "epoch: 2, batch: 203, loss: 2.0562243461608887\n",
      "epoch: 2, batch: 204, loss: 2.02972149848938\n",
      "epoch: 2, batch: 205, loss: 1.9550011157989502\n",
      "epoch: 2, batch: 206, loss: 2.0197250843048096\n",
      "epoch: 2, batch: 207, loss: 1.9612367153167725\n",
      "epoch: 2, batch: 208, loss: 2.03252911567688\n",
      "epoch: 2, batch: 209, loss: 1.910309076309204\n",
      "epoch: 2, batch: 210, loss: 2.0606467723846436\n",
      "epoch: 2, batch: 211, loss: 2.0092105865478516\n",
      "epoch: 2, batch: 212, loss: 1.9853155612945557\n",
      "epoch: 2, batch: 213, loss: 2.034679889678955\n",
      "epoch: 2, batch: 214, loss: 1.9400557279586792\n",
      "epoch: 2, batch: 215, loss: 1.9799163341522217\n",
      "epoch: 2, batch: 216, loss: 2.0397095680236816\n",
      "epoch: 2, batch: 217, loss: 2.050710916519165\n",
      "epoch: 2, batch: 218, loss: 1.985412359237671\n",
      "epoch: 2, batch: 219, loss: 2.1198596954345703\n",
      "epoch: 2, batch: 220, loss: 1.9438024759292603\n",
      "epoch: 2, batch: 221, loss: 1.975945234298706\n",
      "epoch: 2, batch: 222, loss: 2.0629773139953613\n",
      "epoch: 2, batch: 223, loss: 2.0818562507629395\n",
      "epoch: 2, batch: 224, loss: 1.9226254224777222\n",
      "epoch: 2, batch: 225, loss: 1.9695758819580078\n",
      "epoch: 2, batch: 226, loss: 2.053896427154541\n",
      "epoch: 2, batch: 227, loss: 2.0259644985198975\n",
      "epoch: 2, batch: 228, loss: 1.9916125535964966\n",
      "epoch: 2, batch: 229, loss: 1.9951554536819458\n",
      "epoch: 2, batch: 230, loss: 1.9395158290863037\n",
      "epoch: 2, batch: 231, loss: 1.980920672416687\n",
      "epoch: 2, batch: 232, loss: 1.9405304193496704\n",
      "epoch: 2, batch: 233, loss: 1.975566029548645\n",
      "epoch: 2, batch: 234, loss: 2.0121042728424072\n",
      "epoch: 2, batch: 235, loss: 1.9985203742980957\n",
      "epoch: 2, batch: 236, loss: 2.060110569000244\n",
      "epoch: 2, batch: 237, loss: 1.9622868299484253\n",
      "epoch: 2, batch: 238, loss: 1.9828146696090698\n",
      "epoch: 2, batch: 239, loss: 2.016659736633301\n",
      "epoch: 2, batch: 240, loss: 2.0905728340148926\n",
      "epoch: 2, batch: 241, loss: 2.0045013427734375\n",
      "epoch: 2, batch: 242, loss: 1.9953783750534058\n",
      "epoch: 2, batch: 243, loss: 1.9928150177001953\n",
      "epoch: 2, batch: 244, loss: 2.0419745445251465\n",
      "epoch: 2, batch: 245, loss: 2.0233876705169678\n",
      "epoch: 2, batch: 246, loss: 1.9333734512329102\n",
      "epoch: 2, batch: 247, loss: 2.002246618270874\n",
      "epoch: 2, batch: 248, loss: 1.9854285717010498\n",
      "epoch: 2, batch: 249, loss: 2.040921926498413\n",
      "epoch: 2, batch: 250, loss: 1.9432657957077026\n",
      "epoch: 2, batch: 251, loss: 2.0509047508239746\n",
      "epoch: 2, batch: 252, loss: 1.9622774124145508\n",
      "epoch: 2, batch: 253, loss: 1.9905129671096802\n",
      "epoch: 2, batch: 254, loss: 1.9570512771606445\n",
      "epoch: 2, batch: 255, loss: 1.922489047050476\n",
      "epoch: 2, batch: 256, loss: 2.006944417953491\n",
      "epoch: 2, batch: 257, loss: 1.9813076257705688\n",
      "epoch: 2, batch: 258, loss: 1.9465590715408325\n",
      "epoch: 2, batch: 259, loss: 1.995358943939209\n",
      "epoch: 2, batch: 260, loss: 1.967464804649353\n",
      "epoch: 2, batch: 261, loss: 2.0181331634521484\n",
      "epoch: 2, batch: 262, loss: 1.9721872806549072\n",
      "epoch: 2, batch: 263, loss: 2.028517246246338\n",
      "epoch: 2, batch: 264, loss: 2.0474064350128174\n",
      "epoch: 2, batch: 265, loss: 2.0019428730010986\n",
      "epoch: 2, batch: 266, loss: 1.9778131246566772\n",
      "epoch: 2, batch: 267, loss: 1.9583415985107422\n",
      "epoch: 2, batch: 268, loss: 1.9251377582550049\n",
      "epoch: 2, batch: 269, loss: 2.047389268875122\n",
      "epoch: 2, batch: 270, loss: 1.9779984951019287\n",
      "epoch: 2, batch: 271, loss: 2.0821950435638428\n",
      "epoch: 2, batch: 272, loss: 2.007089138031006\n",
      "epoch: 2, batch: 273, loss: 1.9888805150985718\n",
      "epoch: 2, batch: 274, loss: 1.969266414642334\n",
      "epoch: 2, batch: 275, loss: 1.9693771600723267\n",
      "epoch: 2, batch: 276, loss: 1.9401825666427612\n",
      "epoch: 2, batch: 277, loss: 1.9176851511001587\n",
      "epoch: 2, batch: 278, loss: 1.9674267768859863\n",
      "epoch: 2, batch: 279, loss: 1.9133026599884033\n",
      "epoch: 2, batch: 280, loss: 2.03568696975708\n",
      "epoch: 2, batch: 281, loss: 2.0428545475006104\n",
      "epoch: 2, batch: 282, loss: 1.9237076044082642\n",
      "epoch: 2, batch: 283, loss: 2.004686117172241\n",
      "epoch: 2, batch: 284, loss: 2.0268354415893555\n",
      "epoch: 2, batch: 285, loss: 2.0316250324249268\n",
      "epoch: 2, batch: 286, loss: 1.9804576635360718\n",
      "epoch: 2, batch: 287, loss: 1.950836420059204\n",
      "epoch: 2, batch: 288, loss: 1.9803951978683472\n",
      "epoch: 2, batch: 289, loss: 2.0208559036254883\n",
      "epoch: 2, batch: 290, loss: 2.043433904647827\n",
      "epoch: 2, batch: 291, loss: 2.0608632564544678\n",
      "epoch: 2, batch: 292, loss: 1.9990590810775757\n",
      "epoch: 2, batch: 293, loss: 2.0396955013275146\n",
      "epoch: 2, batch: 294, loss: 1.9959568977355957\n",
      "epoch: 2, batch: 295, loss: 1.9640141725540161\n",
      "epoch: 2, batch: 296, loss: 1.904107689857483\n",
      "epoch: 2, batch: 297, loss: 2.065436363220215\n",
      "epoch: 2, batch: 298, loss: 1.980463981628418\n",
      "epoch: 2, batch: 299, loss: 1.986997365951538\n",
      "epoch: 2, batch: 300, loss: 2.051413059234619\n",
      "epoch: 2, batch: 301, loss: 2.035280227661133\n",
      "epoch: 2, batch: 302, loss: 1.9198203086853027\n",
      "epoch: 2, batch: 303, loss: 2.000563383102417\n",
      "epoch: 2, batch: 304, loss: 2.0463647842407227\n",
      "epoch: 2, batch: 305, loss: 2.0439698696136475\n",
      "epoch: 2, batch: 306, loss: 1.9971566200256348\n",
      "epoch: 2, batch: 307, loss: 2.051546335220337\n",
      "epoch: 2, batch: 308, loss: 1.9713835716247559\n",
      "epoch: 2, batch: 309, loss: 1.9296846389770508\n",
      "epoch: 2, batch: 310, loss: 2.0033810138702393\n",
      "epoch: 2, batch: 311, loss: 2.035081386566162\n",
      "epoch: 2, batch: 312, loss: 1.994324803352356\n",
      "epoch: 2, batch: 313, loss: 1.9444899559020996\n",
      "epoch: 2, batch: 314, loss: 1.9928224086761475\n",
      "epoch: 2, batch: 315, loss: 1.9902182817459106\n",
      "epoch: 2, batch: 316, loss: 1.9725273847579956\n",
      "epoch: 2, batch: 317, loss: 2.0457682609558105\n",
      "epoch: 2, batch: 318, loss: 1.9746277332305908\n",
      "epoch: 2, batch: 319, loss: 1.9375851154327393\n",
      "epoch: 2, batch: 320, loss: 1.9771621227264404\n",
      "epoch: 2, batch: 321, loss: 1.9747263193130493\n",
      "epoch: 2, batch: 322, loss: 2.0108585357666016\n",
      "epoch: 2, batch: 323, loss: 1.9726426601409912\n",
      "epoch: 2, batch: 324, loss: 1.9795387983322144\n",
      "epoch: 2, batch: 325, loss: 2.0361154079437256\n",
      "epoch: 2, batch: 326, loss: 1.984521508216858\n",
      "epoch: 2, batch: 327, loss: 2.064166307449341\n",
      "epoch: 2, batch: 328, loss: 1.9359486103057861\n",
      "epoch: 2, batch: 329, loss: 1.8514025211334229\n",
      "epoch: 2, batch: 330, loss: 1.9631048440933228\n",
      "epoch: 2, batch: 331, loss: 2.0304064750671387\n",
      "epoch: 2, batch: 332, loss: 1.9036377668380737\n",
      "epoch: 2, batch: 333, loss: 2.0272841453552246\n",
      "epoch: 2, batch: 334, loss: 1.9371349811553955\n",
      "epoch: 2, batch: 335, loss: 1.982394814491272\n",
      "epoch: 2, batch: 336, loss: 2.0245118141174316\n",
      "epoch: 2, batch: 337, loss: 1.9523117542266846\n",
      "epoch: 2, batch: 338, loss: 1.9916272163391113\n",
      "epoch: 2, batch: 339, loss: 1.9693975448608398\n",
      "epoch: 2, batch: 340, loss: 2.0055153369903564\n",
      "epoch: 2, batch: 341, loss: 2.0177247524261475\n",
      "epoch: 2, batch: 342, loss: 2.0463552474975586\n",
      "epoch: 2, batch: 343, loss: 1.9220588207244873\n",
      "epoch: 2, batch: 344, loss: 1.9646745920181274\n",
      "epoch: 2, batch: 345, loss: 2.001906394958496\n",
      "epoch: 2, batch: 346, loss: 2.0533530712127686\n",
      "epoch: 2, batch: 347, loss: 2.0521349906921387\n",
      "epoch: 2, batch: 348, loss: 2.0181262493133545\n",
      "epoch: 2, batch: 349, loss: 1.9402867555618286\n",
      "epoch: 2, batch: 350, loss: 2.0016415119171143\n",
      "epoch: 2, batch: 351, loss: 1.917514443397522\n",
      "epoch: 2, batch: 352, loss: 1.9535475969314575\n",
      "epoch: 2, batch: 353, loss: 1.9698193073272705\n",
      "epoch: 2, batch: 354, loss: 2.0035881996154785\n",
      "epoch: 2, batch: 355, loss: 1.9282376766204834\n",
      "epoch: 2, batch: 356, loss: 1.958470344543457\n",
      "epoch: 2, batch: 357, loss: 1.9328628778457642\n",
      "epoch: 2, batch: 358, loss: 1.9706307649612427\n",
      "epoch: 2, batch: 359, loss: 1.946730136871338\n",
      "epoch: 2, batch: 360, loss: 1.948683261871338\n",
      "epoch: 2, batch: 361, loss: 2.0146141052246094\n",
      "epoch: 2, batch: 362, loss: 2.0237555503845215\n",
      "epoch: 2, batch: 363, loss: 1.9749785661697388\n",
      "epoch: 2, batch: 364, loss: 2.007979393005371\n",
      "epoch: 2, batch: 365, loss: 2.040010929107666\n",
      "epoch: 2, batch: 366, loss: 1.9709687232971191\n",
      "epoch: 2, batch: 367, loss: 1.8886511325836182\n",
      "epoch: 2, batch: 368, loss: 1.9910814762115479\n",
      "epoch: 2, batch: 369, loss: 2.078925609588623\n",
      "epoch: 2, batch: 370, loss: 2.0037271976470947\n",
      "epoch: 2, batch: 371, loss: 1.9562348127365112\n",
      "epoch: 2, batch: 372, loss: 1.9483745098114014\n",
      "epoch: 2, batch: 373, loss: 2.0593109130859375\n",
      "epoch: 2, batch: 374, loss: 1.9014227390289307\n",
      "epoch: 2, batch: 375, loss: 1.9348807334899902\n",
      "epoch: 2, batch: 376, loss: 1.9092278480529785\n",
      "epoch: 2, batch: 377, loss: 2.0160422325134277\n",
      "epoch: 2, batch: 378, loss: 1.9061853885650635\n",
      "epoch: 2, batch: 379, loss: 1.937589168548584\n",
      "epoch: 2, batch: 380, loss: 1.9003896713256836\n",
      "epoch: 2, batch: 381, loss: 2.09187912940979\n",
      "epoch: 2, batch: 382, loss: 1.9791464805603027\n",
      "epoch: 2, batch: 383, loss: 2.071507453918457\n",
      "epoch: 2, batch: 384, loss: 1.9192559719085693\n",
      "epoch: 2, batch: 385, loss: 1.938618540763855\n",
      "epoch: 2, batch: 386, loss: 1.8820703029632568\n",
      "epoch: 2, batch: 387, loss: 1.9776655435562134\n",
      "epoch: 2, batch: 388, loss: 2.0409996509552\n",
      "epoch: 2, batch: 389, loss: 1.9831255674362183\n",
      "epoch: 2, batch: 390, loss: 1.8823282718658447\n",
      "epoch: 2, batch: 391, loss: 1.9362447261810303\n",
      "epoch: 2, batch: 392, loss: 1.9905520677566528\n",
      "epoch: 2, batch: 393, loss: 2.0199968814849854\n",
      "epoch: 2, batch: 394, loss: 2.035114049911499\n",
      "epoch: 2, batch: 395, loss: 1.9945961236953735\n",
      "epoch: 2, batch: 396, loss: 2.027552366256714\n",
      "epoch: 2, batch: 397, loss: 2.003235101699829\n",
      "epoch: 2, batch: 398, loss: 1.9712982177734375\n",
      "epoch: 2, batch: 399, loss: 1.9599870443344116\n",
      "epoch: 2, batch: 400, loss: 1.9418481588363647\n",
      "epoch: 2, batch: 401, loss: 1.9557156562805176\n",
      "epoch: 2, batch: 402, loss: 1.9144303798675537\n",
      "epoch: 2, batch: 403, loss: 1.9059373140335083\n",
      "epoch: 2, batch: 404, loss: 2.0053815841674805\n",
      "epoch: 2, batch: 405, loss: 1.9882259368896484\n",
      "epoch: 2, batch: 406, loss: 1.9745489358901978\n",
      "epoch: 2, batch: 407, loss: 2.01824688911438\n",
      "epoch: 2, batch: 408, loss: 1.9591805934906006\n",
      "epoch: 2, batch: 409, loss: 1.960897445678711\n",
      "epoch: 2, batch: 410, loss: 1.95662260055542\n",
      "epoch: 2, batch: 411, loss: 1.9570716619491577\n",
      "epoch: 2, batch: 412, loss: 1.913583517074585\n",
      "epoch: 2, batch: 413, loss: 1.9713385105133057\n",
      "epoch: 2, batch: 414, loss: 1.9887999296188354\n",
      "epoch: 2, batch: 415, loss: 1.9753880500793457\n",
      "epoch: 2, batch: 416, loss: 1.92307710647583\n",
      "epoch: 2, batch: 417, loss: 2.0248970985412598\n",
      "epoch: 2, batch: 418, loss: 2.0211877822875977\n",
      "epoch: 2, batch: 419, loss: 1.9683854579925537\n",
      "epoch: 2, batch: 420, loss: 1.9369755983352661\n",
      "epoch: 2, batch: 421, loss: 1.9986249208450317\n",
      "epoch: 2, batch: 422, loss: 1.9676411151885986\n",
      "epoch: 2, batch: 423, loss: 1.9909430742263794\n",
      "epoch: 2, batch: 424, loss: 1.9504657983779907\n",
      "epoch: 2, batch: 425, loss: 1.9580185413360596\n",
      "epoch: 2, batch: 426, loss: 1.9371464252471924\n",
      "epoch: 2, batch: 427, loss: 1.9412622451782227\n",
      "epoch: 2, batch: 428, loss: 1.9234973192214966\n",
      "epoch: 2, batch: 429, loss: 1.8630197048187256\n",
      "epoch: 2, batch: 430, loss: 1.9312939643859863\n",
      "epoch: 2, batch: 431, loss: 1.933211326599121\n",
      "epoch: 2, batch: 432, loss: 1.9695098400115967\n",
      "epoch: 2, batch: 433, loss: 1.8825933933258057\n",
      "epoch: 2, batch: 434, loss: 1.9062690734863281\n",
      "epoch: 2, batch: 435, loss: 2.0012543201446533\n",
      "epoch: 2, batch: 436, loss: 1.94172203540802\n",
      "epoch: 2, batch: 437, loss: 1.9497411251068115\n",
      "epoch: 2, batch: 438, loss: 2.0518369674682617\n",
      "epoch: 2, batch: 439, loss: 2.047320604324341\n",
      "epoch: 2, batch: 440, loss: 1.9550817012786865\n",
      "epoch: 2, batch: 441, loss: 1.937814712524414\n",
      "epoch: 2, batch: 442, loss: 2.0355467796325684\n",
      "epoch: 2, batch: 443, loss: 1.9544110298156738\n",
      "epoch: 2, batch: 444, loss: 1.949144959449768\n",
      "epoch: 2, batch: 445, loss: 1.9889427423477173\n",
      "epoch: 2, batch: 446, loss: 1.8818130493164062\n",
      "epoch: 2, batch: 447, loss: 1.973760962486267\n",
      "epoch: 2, batch: 448, loss: 1.8644216060638428\n",
      "epoch: 2, batch: 449, loss: 2.0123653411865234\n",
      "epoch: 2, batch: 450, loss: 2.0365169048309326\n",
      "epoch: 2, batch: 451, loss: 1.9418604373931885\n",
      "epoch: 2, batch: 452, loss: 1.8962205648422241\n",
      "epoch: 2, batch: 453, loss: 1.849960446357727\n",
      "epoch: 2, batch: 454, loss: 1.9656903743743896\n",
      "epoch: 2, batch: 455, loss: 1.9726722240447998\n",
      "epoch: 2, batch: 456, loss: 1.9135417938232422\n",
      "epoch: 2, batch: 457, loss: 2.033399820327759\n",
      "epoch: 2, batch: 458, loss: 1.902818202972412\n",
      "epoch: 2, batch: 459, loss: 1.9319710731506348\n",
      "epoch: 2, batch: 460, loss: 2.0404553413391113\n",
      "epoch: 2, batch: 461, loss: 1.9790822267532349\n",
      "epoch: 2, batch: 462, loss: 1.9723670482635498\n",
      "epoch: 2, batch: 463, loss: 1.8933547735214233\n",
      "epoch: 2, batch: 464, loss: 1.9192798137664795\n",
      "epoch: 2, batch: 465, loss: 1.9725415706634521\n",
      "epoch: 2, batch: 466, loss: 1.9365521669387817\n",
      "epoch: 2, batch: 467, loss: 2.0000290870666504\n",
      "epoch: 2, batch: 468, loss: 1.9285467863082886\n",
      "epoch: 2, batch: 469, loss: 1.8688172101974487\n",
      "epoch: 2, batch: 470, loss: 1.9215470552444458\n",
      "epoch: 2, batch: 471, loss: 1.9480262994766235\n",
      "epoch: 2, batch: 472, loss: 1.9464483261108398\n",
      "epoch: 2, batch: 473, loss: 1.8886709213256836\n",
      "epoch: 2, batch: 474, loss: 1.9833911657333374\n",
      "epoch: 2, batch: 475, loss: 2.0158908367156982\n",
      "epoch: 2, batch: 476, loss: 1.895958423614502\n",
      "epoch: 2, batch: 477, loss: 1.9563583135604858\n",
      "epoch: 2, batch: 478, loss: 1.9694067239761353\n",
      "epoch: 2, batch: 479, loss: 1.9345762729644775\n",
      "epoch: 2, batch: 480, loss: 1.9522349834442139\n",
      "epoch: 2, batch: 481, loss: 1.9228390455245972\n",
      "epoch: 2, batch: 482, loss: 1.981933832168579\n",
      "epoch: 2, batch: 483, loss: 2.006999969482422\n",
      "epoch: 2, batch: 484, loss: 2.028837203979492\n",
      "epoch: 2, batch: 485, loss: 1.9099887609481812\n",
      "epoch: 2, batch: 486, loss: 1.9537028074264526\n",
      "epoch: 2, batch: 487, loss: 1.9550844430923462\n",
      "epoch: 2, batch: 488, loss: 1.8684526681900024\n",
      "epoch: 2, batch: 489, loss: 1.837819218635559\n",
      "epoch: 2, batch: 490, loss: 2.0137627124786377\n",
      "epoch: 2, batch: 491, loss: 1.9314109086990356\n",
      "epoch: 2, batch: 492, loss: 1.993396520614624\n",
      "epoch: 2, batch: 493, loss: 1.9463095664978027\n",
      "epoch: 2, batch: 494, loss: 1.9157719612121582\n",
      "epoch: 2, batch: 495, loss: 1.9559879302978516\n",
      "epoch: 2, batch: 496, loss: 1.9730665683746338\n",
      "epoch: 2, batch: 497, loss: 1.8955503702163696\n",
      "epoch: 2, batch: 498, loss: 1.8799617290496826\n",
      "epoch: 2, batch: 499, loss: 1.9500377178192139\n",
      "epoch: 2, batch: 500, loss: 1.987339735031128\n",
      "epoch: 2, batch: 501, loss: 1.940100908279419\n",
      "epoch: 2, batch: 502, loss: 1.8253639936447144\n",
      "epoch: 2, batch: 503, loss: 1.9673781394958496\n",
      "epoch: 2, batch: 504, loss: 1.9165992736816406\n",
      "epoch: 2, batch: 505, loss: 2.0239551067352295\n",
      "epoch: 2, batch: 506, loss: 1.9210195541381836\n",
      "epoch: 2, batch: 507, loss: 1.8777121305465698\n",
      "epoch: 2, batch: 508, loss: 1.9151387214660645\n",
      "epoch: 2, batch: 509, loss: 1.97453773021698\n",
      "epoch: 2, batch: 510, loss: 1.9261157512664795\n",
      "epoch: 2, batch: 511, loss: 1.96002995967865\n",
      "epoch: 2, batch: 512, loss: 1.991983413696289\n",
      "epoch: 2, batch: 513, loss: 1.9509286880493164\n",
      "epoch: 2, batch: 514, loss: 2.0309581756591797\n",
      "epoch: 2, batch: 515, loss: 1.8889065980911255\n",
      "epoch: 2, batch: 516, loss: 1.8892979621887207\n",
      "epoch: 2, batch: 517, loss: 1.9579626321792603\n",
      "epoch: 2, batch: 518, loss: 1.9398829936981201\n",
      "epoch: 2, batch: 519, loss: 1.9467743635177612\n",
      "epoch: 2, batch: 520, loss: 1.9557853937149048\n",
      "epoch: 2, batch: 521, loss: 1.9980007410049438\n",
      "epoch: 2, batch: 522, loss: 1.9745057821273804\n",
      "epoch: 2, batch: 523, loss: 1.8134198188781738\n",
      "epoch: 2, batch: 524, loss: 1.9826405048370361\n",
      "epoch: 2, batch: 525, loss: 1.9686979055404663\n",
      "epoch: 2, batch: 526, loss: 1.9919443130493164\n",
      "epoch: 2, batch: 527, loss: 1.8324098587036133\n",
      "epoch: 2, batch: 528, loss: 1.9442819356918335\n",
      "epoch: 2, batch: 529, loss: 1.9744088649749756\n",
      "epoch: 2, batch: 530, loss: 1.9729222059249878\n",
      "epoch: 2, batch: 531, loss: 1.9439080953598022\n",
      "epoch: 2, batch: 532, loss: 1.9022127389907837\n",
      "epoch: 2, batch: 533, loss: 1.8573857545852661\n",
      "epoch: 2, batch: 534, loss: 1.8943756818771362\n",
      "epoch: 2, batch: 535, loss: 1.8645045757293701\n",
      "epoch: 2, batch: 536, loss: 1.898222804069519\n",
      "epoch: 2, batch: 537, loss: 1.946256160736084\n",
      "epoch: 2, batch: 538, loss: 2.0237276554107666\n",
      "epoch: 2, batch: 539, loss: 1.9802910089492798\n",
      "epoch: 2, batch: 540, loss: 1.894565463066101\n",
      "epoch: 2, batch: 541, loss: 1.872624158859253\n",
      "epoch: 2, batch: 542, loss: 1.9514641761779785\n",
      "epoch: 2, batch: 543, loss: 1.9623875617980957\n",
      "epoch: 2, batch: 544, loss: 1.9257272481918335\n",
      "epoch: 2, batch: 545, loss: 2.0138113498687744\n",
      "epoch: 2, batch: 546, loss: 1.9029057025909424\n",
      "epoch: 2, batch: 547, loss: 1.959092378616333\n",
      "epoch: 2, batch: 548, loss: 1.902175784111023\n",
      "epoch: 2, batch: 549, loss: 1.9177895784378052\n",
      "epoch: 2, batch: 550, loss: 1.9536880254745483\n",
      "epoch: 2, batch: 551, loss: 2.068091630935669\n",
      "epoch: 2, batch: 552, loss: 1.9886201620101929\n",
      "epoch: 2, batch: 553, loss: 1.927773118019104\n",
      "epoch: 2, batch: 554, loss: 1.8509334325790405\n",
      "epoch: 2, batch: 555, loss: 1.9101139307022095\n",
      "epoch: 2, batch: 556, loss: 1.983230471611023\n",
      "epoch: 2, batch: 557, loss: 1.8590705394744873\n",
      "epoch: 2, batch: 558, loss: 1.8840889930725098\n",
      "epoch: 2, batch: 559, loss: 1.9074636697769165\n",
      "epoch: 2, batch: 560, loss: 1.9030169248580933\n",
      "epoch: 2, batch: 561, loss: 1.9118452072143555\n",
      "epoch: 2, batch: 562, loss: 1.967677116394043\n",
      "epoch: 2, batch: 563, loss: 1.9217455387115479\n",
      "epoch: 2, batch: 564, loss: 1.9497581720352173\n",
      "epoch: 2, batch: 565, loss: 1.8776023387908936\n",
      "epoch: 2, batch: 566, loss: 1.9675469398498535\n",
      "epoch: 2, batch: 567, loss: 1.93686842918396\n",
      "epoch: 2, batch: 568, loss: 1.8443512916564941\n",
      "epoch: 2, batch: 569, loss: 1.8759645223617554\n",
      "epoch: 2, batch: 570, loss: 1.986994981765747\n",
      "epoch: 2, batch: 571, loss: 1.9774036407470703\n",
      "epoch: 2, batch: 572, loss: 1.9379854202270508\n",
      "epoch: 2, batch: 573, loss: 1.8702149391174316\n",
      "epoch: 2, batch: 574, loss: 1.9101876020431519\n",
      "epoch: 2, batch: 575, loss: 1.9740996360778809\n",
      "epoch: 2, batch: 576, loss: 1.979308843612671\n",
      "epoch: 2, batch: 577, loss: 1.9859825372695923\n",
      "epoch: 2, batch: 578, loss: 1.950116515159607\n",
      "epoch: 2, batch: 579, loss: 1.8102840185165405\n",
      "epoch: 2, batch: 580, loss: 1.9520765542984009\n",
      "epoch: 2, batch: 581, loss: 1.9440364837646484\n",
      "epoch: 2, batch: 582, loss: 1.8382668495178223\n",
      "epoch: 2, batch: 583, loss: 1.965550422668457\n",
      "epoch: 2, batch: 584, loss: 1.9097877740859985\n",
      "epoch: 2, batch: 585, loss: 1.8813278675079346\n",
      "epoch: 2, batch: 586, loss: 1.8891634941101074\n",
      "epoch: 2, batch: 587, loss: 1.9646196365356445\n",
      "epoch: 2, batch: 588, loss: 1.8783937692642212\n",
      "epoch: 2, batch: 589, loss: 1.9157830476760864\n",
      "epoch: 2, batch: 590, loss: 1.9140273332595825\n",
      "epoch: 2, batch: 591, loss: 1.85762357711792\n",
      "epoch: 2, batch: 592, loss: 1.9460057020187378\n",
      "epoch: 2, batch: 593, loss: 1.936912178993225\n",
      "epoch: 2, batch: 594, loss: 1.966176986694336\n",
      "epoch: 2, batch: 595, loss: 1.8958951234817505\n",
      "epoch: 2, batch: 596, loss: 1.9749236106872559\n",
      "epoch: 2, batch: 597, loss: 1.896270513534546\n",
      "epoch: 2, batch: 598, loss: 2.0452985763549805\n",
      "epoch: 2, batch: 599, loss: 1.90994393825531\n",
      "epoch: 2, batch: 600, loss: 2.0246405601501465\n",
      "epoch: 2, batch: 601, loss: 1.9279921054840088\n",
      "epoch: 2, batch: 602, loss: 1.838890552520752\n",
      "epoch: 2, batch: 603, loss: 1.931136965751648\n",
      "epoch: 2, batch: 604, loss: 1.9252201318740845\n",
      "epoch: 2, batch: 605, loss: 1.925441861152649\n",
      "epoch: 2, batch: 606, loss: 1.9845902919769287\n",
      "epoch: 2, batch: 607, loss: 1.881636142730713\n",
      "epoch: 2, batch: 608, loss: 1.8935222625732422\n",
      "epoch: 2, batch: 609, loss: 1.967258334159851\n",
      "epoch: 2, batch: 610, loss: 1.9528433084487915\n",
      "epoch: 2, batch: 611, loss: 1.8845432996749878\n",
      "epoch: 2, batch: 612, loss: 1.9161871671676636\n",
      "epoch: 2, batch: 613, loss: 1.8772237300872803\n",
      "epoch: 2, batch: 614, loss: 1.9086147546768188\n",
      "epoch: 2, batch: 615, loss: 1.9393296241760254\n",
      "epoch: 2, batch: 616, loss: 2.0450148582458496\n",
      "epoch: 2, batch: 617, loss: 1.8678332567214966\n",
      "epoch: 2, batch: 618, loss: 1.992360234260559\n",
      "epoch: 2, batch: 619, loss: 1.9194458723068237\n",
      "epoch: 2, batch: 620, loss: 1.9274758100509644\n",
      "epoch: 2, batch: 621, loss: 1.9682568311691284\n",
      "epoch: 2, batch: 622, loss: 1.9434458017349243\n",
      "epoch: 2, batch: 623, loss: 1.888415813446045\n",
      "epoch: 2, batch: 624, loss: 1.8484976291656494\n",
      "epoch: 2, batch: 625, loss: 1.9273312091827393\n",
      "epoch: 2, batch: 626, loss: 1.960336446762085\n",
      "epoch: 2, batch: 627, loss: 1.8044222593307495\n",
      "epoch: 2, batch: 628, loss: 2.0055296421051025\n",
      "epoch: 2, batch: 629, loss: 1.8864655494689941\n",
      "epoch: 2, batch: 630, loss: 1.908249020576477\n",
      "epoch: 2, batch: 631, loss: 1.9092940092086792\n",
      "epoch: 2, batch: 632, loss: 1.8511626720428467\n",
      "epoch: 2, batch: 633, loss: 1.9096039533615112\n",
      "epoch: 2, batch: 634, loss: 1.9231961965560913\n",
      "epoch: 2, batch: 635, loss: 1.8980746269226074\n",
      "epoch: 2, batch: 636, loss: 1.906430721282959\n",
      "epoch: 2, batch: 637, loss: 1.9254357814788818\n",
      "epoch: 2, batch: 638, loss: 1.9474252462387085\n",
      "epoch: 2, batch: 639, loss: 2.034191131591797\n",
      "epoch: 2, batch: 640, loss: 1.8908318281173706\n",
      "epoch: 2, batch: 641, loss: 1.9921836853027344\n",
      "epoch: 2, batch: 642, loss: 1.9695913791656494\n",
      "epoch: 2, batch: 643, loss: 2.0491719245910645\n",
      "epoch: 2, batch: 644, loss: 1.945817232131958\n",
      "epoch: 2, batch: 645, loss: 1.8544061183929443\n",
      "epoch: 2, batch: 646, loss: 1.9290509223937988\n",
      "epoch: 2, batch: 647, loss: 1.8648542165756226\n",
      "epoch: 2, batch: 648, loss: 1.9351983070373535\n",
      "epoch: 2, batch: 649, loss: 1.9974216222763062\n",
      "epoch: 2, batch: 650, loss: 1.962809681892395\n",
      "epoch: 2, batch: 651, loss: 1.9174412488937378\n",
      "epoch: 2, batch: 652, loss: 1.863415241241455\n",
      "epoch: 2, batch: 653, loss: 1.9705396890640259\n",
      "epoch: 2, batch: 654, loss: 1.9089142084121704\n",
      "epoch: 2, batch: 655, loss: 1.8119115829467773\n",
      "epoch: 2, batch: 656, loss: 1.8862767219543457\n",
      "epoch: 2, batch: 657, loss: 1.9756666421890259\n",
      "epoch: 2, batch: 658, loss: 1.915661096572876\n",
      "epoch: 2, batch: 659, loss: 1.9478929042816162\n",
      "epoch: 2, batch: 660, loss: 1.9102705717086792\n",
      "epoch: 2, batch: 661, loss: 1.9611225128173828\n",
      "epoch: 2, batch: 662, loss: 1.8757362365722656\n",
      "epoch: 2, batch: 663, loss: 1.9439725875854492\n",
      "epoch: 2, batch: 664, loss: 1.8266284465789795\n",
      "epoch: 2, batch: 665, loss: 1.9186780452728271\n",
      "epoch: 2, batch: 666, loss: 1.8161381483078003\n",
      "epoch: 2, batch: 667, loss: 1.9722291231155396\n",
      "epoch: 2, batch: 668, loss: 1.8841478824615479\n",
      "epoch: 2, batch: 669, loss: 1.8989087343215942\n",
      "epoch: 2, batch: 670, loss: 1.91261887550354\n",
      "epoch: 2, batch: 671, loss: 1.8671081066131592\n",
      "epoch: 2, batch: 672, loss: 1.9572511911392212\n",
      "epoch: 2, batch: 673, loss: 1.8920410871505737\n",
      "epoch: 2, batch: 674, loss: 1.9418832063674927\n",
      "epoch: 2, batch: 675, loss: 1.8978606462478638\n",
      "epoch: 2, batch: 676, loss: 1.7896424531936646\n",
      "epoch: 2, batch: 677, loss: 1.9300353527069092\n",
      "epoch: 2, batch: 678, loss: 1.9539985656738281\n",
      "epoch: 2, batch: 679, loss: 1.8125253915786743\n",
      "epoch: 2, batch: 680, loss: 1.8774088621139526\n",
      "epoch: 2, batch: 681, loss: 1.909669041633606\n",
      "epoch: 2, batch: 682, loss: 1.795006275177002\n",
      "epoch: 2, batch: 683, loss: 1.9025198221206665\n",
      "epoch: 2, batch: 684, loss: 1.8935993909835815\n",
      "epoch: 2, batch: 685, loss: 2.021893262863159\n",
      "epoch: 2, batch: 686, loss: 1.8493629693984985\n",
      "epoch: 2, batch: 687, loss: 1.8525044918060303\n",
      "epoch: 2, batch: 688, loss: 1.9015793800354004\n",
      "epoch: 2, batch: 689, loss: 1.9336525201797485\n",
      "epoch: 2, batch: 690, loss: 1.8683627843856812\n",
      "epoch: 2, batch: 691, loss: 1.9135764837265015\n",
      "epoch: 2, batch: 692, loss: 1.9311670064926147\n",
      "epoch: 2, batch: 693, loss: 1.9464174509048462\n",
      "epoch: 2, batch: 694, loss: 1.9329133033752441\n",
      "epoch: 2, batch: 695, loss: 1.7961018085479736\n",
      "epoch: 2, batch: 696, loss: 1.8578741550445557\n",
      "epoch: 2, batch: 697, loss: 1.9431650638580322\n",
      "epoch: 2, batch: 698, loss: 1.9143726825714111\n",
      "epoch: 2, batch: 699, loss: 1.917052984237671\n",
      "epoch: 2, batch: 700, loss: 1.8326003551483154\n",
      "epoch: 2, batch: 701, loss: 1.9066044092178345\n",
      "epoch: 2, batch: 702, loss: 1.9052318334579468\n",
      "epoch: 2, batch: 703, loss: 1.8906457424163818\n",
      "epoch: 2, batch: 704, loss: 2.0070080757141113\n",
      "epoch: 2, batch: 705, loss: 1.9187403917312622\n",
      "epoch: 2, batch: 706, loss: 1.8441606760025024\n",
      "epoch: 2, batch: 707, loss: 1.9000428915023804\n",
      "epoch: 2, batch: 708, loss: 1.8169506788253784\n",
      "epoch: 2, batch: 709, loss: 1.9009418487548828\n",
      "epoch: 2, batch: 710, loss: 1.9249142408370972\n",
      "epoch: 2, batch: 711, loss: 1.8785693645477295\n",
      "epoch: 2, batch: 712, loss: 1.957871913909912\n",
      "epoch: 2, batch: 713, loss: 1.8766306638717651\n",
      "epoch: 2, batch: 714, loss: 1.945239782333374\n",
      "epoch: 2, batch: 715, loss: 1.8811283111572266\n",
      "epoch: 2, batch: 716, loss: 1.9055989980697632\n",
      "epoch: 2, batch: 717, loss: 1.880409598350525\n",
      "epoch: 2, batch: 718, loss: 1.8117262125015259\n",
      "epoch: 2, batch: 719, loss: 1.841186285018921\n",
      "epoch: 2, batch: 720, loss: 1.8527450561523438\n",
      "epoch: 2, batch: 721, loss: 1.9277247190475464\n",
      "epoch: 2, batch: 722, loss: 2.0180580615997314\n",
      "epoch: 2, batch: 723, loss: 1.9454039335250854\n",
      "epoch: 2, batch: 724, loss: 1.8960222005844116\n",
      "epoch: 2, batch: 725, loss: 1.923508882522583\n",
      "epoch: 2, batch: 726, loss: 1.9227656126022339\n",
      "epoch: 2, batch: 727, loss: 1.8731796741485596\n",
      "epoch: 2, batch: 728, loss: 1.898818850517273\n",
      "epoch: 2, batch: 729, loss: 1.9158121347427368\n",
      "epoch: 2, batch: 730, loss: 1.9258365631103516\n",
      "epoch: 2, batch: 731, loss: 1.8681749105453491\n",
      "epoch: 2, batch: 732, loss: 1.8192007541656494\n",
      "epoch: 2, batch: 733, loss: 1.9239938259124756\n",
      "epoch: 2, batch: 734, loss: 1.8552881479263306\n",
      "epoch: 2, batch: 735, loss: 1.879953384399414\n",
      "epoch: 2, batch: 736, loss: 1.9071743488311768\n",
      "epoch: 2, batch: 737, loss: 1.8786296844482422\n",
      "epoch: 2, batch: 738, loss: 1.8798240423202515\n",
      "epoch: 2, batch: 739, loss: 1.8553813695907593\n",
      "epoch: 2, batch: 740, loss: 1.9180129766464233\n",
      "epoch: 2, batch: 741, loss: 1.867824912071228\n",
      "epoch: 2, batch: 742, loss: 1.8526794910430908\n",
      "epoch: 2, batch: 743, loss: 1.8465802669525146\n",
      "epoch: 2, batch: 744, loss: 1.9268558025360107\n",
      "epoch: 2, batch: 745, loss: 1.9333746433258057\n",
      "epoch: 2, batch: 746, loss: 1.9445911645889282\n",
      "epoch: 2, batch: 747, loss: 1.8463783264160156\n",
      "epoch: 2, batch: 748, loss: 1.89583158493042\n",
      "epoch: 2, batch: 749, loss: 1.99448823928833\n",
      "epoch: 2, batch: 750, loss: 1.8593530654907227\n",
      "epoch: 2, batch: 751, loss: 2.005777597427368\n",
      "epoch: 2, batch: 752, loss: 1.8110798597335815\n",
      "epoch: 2, batch: 753, loss: 1.9129289388656616\n",
      "epoch: 2, batch: 754, loss: 1.959104299545288\n",
      "epoch: 2, batch: 755, loss: 1.815460443496704\n",
      "epoch: 2, batch: 756, loss: 1.859614372253418\n",
      "epoch: 2, batch: 757, loss: 1.9302245378494263\n",
      "epoch: 2, batch: 758, loss: 1.8276647329330444\n",
      "epoch: 2, batch: 759, loss: 1.8680367469787598\n",
      "epoch: 2, batch: 760, loss: 1.869794487953186\n",
      "epoch: 2, batch: 761, loss: 1.9351376295089722\n",
      "epoch: 2, batch: 762, loss: 1.8999383449554443\n",
      "epoch: 2, batch: 763, loss: 1.9397141933441162\n",
      "epoch: 2, batch: 764, loss: 1.8459432125091553\n",
      "epoch: 2, batch: 765, loss: 1.8323193788528442\n",
      "epoch: 2, batch: 766, loss: 1.8429926633834839\n",
      "epoch: 2, batch: 767, loss: 1.8477972745895386\n",
      "epoch: 2, batch: 768, loss: 1.9028958082199097\n",
      "epoch: 2, batch: 769, loss: 1.8758518695831299\n",
      "epoch: 2, batch: 770, loss: 1.9232414960861206\n",
      "epoch: 2, batch: 771, loss: 1.8171638250350952\n",
      "epoch: 2, batch: 772, loss: 1.8619643449783325\n",
      "epoch: 2, batch: 773, loss: 1.8964264392852783\n",
      "epoch: 2, batch: 774, loss: 1.967533826828003\n",
      "epoch: 2, batch: 775, loss: 1.9186655282974243\n",
      "epoch: 2, batch: 776, loss: 1.9139599800109863\n",
      "epoch: 2, batch: 777, loss: 1.9699151515960693\n",
      "epoch: 2, batch: 778, loss: 1.9241458177566528\n",
      "epoch: 2, batch: 779, loss: 1.8384778499603271\n",
      "epoch: 2, batch: 780, loss: 1.810150384902954\n",
      "epoch: 2, batch: 781, loss: 1.8217449188232422\n",
      "epoch: 2, batch: 782, loss: 1.8669191598892212\n",
      "epoch: 2, batch: 783, loss: 1.8869742155075073\n",
      "epoch: 2, batch: 784, loss: 1.8732820749282837\n",
      "epoch: 2, batch: 785, loss: 1.8581883907318115\n",
      "epoch: 2, batch: 786, loss: 1.9379454851150513\n",
      "epoch: 2, batch: 787, loss: 1.940450668334961\n",
      "epoch: 2, batch: 788, loss: 1.8895310163497925\n",
      "epoch: 2, batch: 789, loss: 1.809862494468689\n",
      "epoch: 2, batch: 790, loss: 1.857336401939392\n",
      "epoch: 2, batch: 791, loss: 1.8398573398590088\n",
      "epoch: 2, batch: 792, loss: 1.8321874141693115\n",
      "epoch: 2, batch: 793, loss: 1.9183688163757324\n",
      "epoch: 2, batch: 794, loss: 1.8749253749847412\n",
      "epoch: 2, batch: 795, loss: 1.820870280265808\n",
      "epoch: 2, batch: 796, loss: 1.8560519218444824\n",
      "epoch: 2, batch: 797, loss: 1.9161772727966309\n",
      "epoch: 2, batch: 798, loss: 1.914689064025879\n",
      "epoch: 2, batch: 799, loss: 1.8201210498809814\n",
      "epoch: 2, batch: 800, loss: 1.769214153289795\n",
      "epoch: 2, batch: 801, loss: 1.9059208631515503\n",
      "epoch: 2, batch: 802, loss: 1.8201810121536255\n",
      "epoch: 2, batch: 803, loss: 1.7967826128005981\n",
      "epoch: 2, batch: 804, loss: 1.8111929893493652\n",
      "epoch: 2, batch: 805, loss: 1.8080167770385742\n",
      "epoch: 2, batch: 806, loss: 1.7958920001983643\n",
      "epoch: 2, batch: 807, loss: 1.8308939933776855\n",
      "epoch: 2, batch: 808, loss: 1.8449187278747559\n",
      "epoch: 2, batch: 809, loss: 1.8942644596099854\n",
      "epoch: 2, batch: 810, loss: 1.8695729970932007\n",
      "epoch: 2, batch: 811, loss: 1.8681126832962036\n",
      "epoch: 2, batch: 812, loss: 1.8492724895477295\n",
      "epoch: 2, batch: 813, loss: 1.8652746677398682\n",
      "epoch: 2, batch: 814, loss: 1.896798849105835\n",
      "epoch: 2, batch: 815, loss: 1.9178510904312134\n",
      "epoch: 2, batch: 816, loss: 1.9184820652008057\n",
      "epoch: 2, batch: 817, loss: 1.8191248178482056\n",
      "epoch: 2, batch: 818, loss: 1.9003316164016724\n",
      "epoch: 2, batch: 819, loss: 1.9065167903900146\n",
      "epoch: 2, batch: 820, loss: 1.836864709854126\n",
      "epoch: 2, batch: 821, loss: 1.862187385559082\n",
      "epoch: 2, batch: 822, loss: 1.8677234649658203\n",
      "epoch: 2, batch: 823, loss: 1.8301903009414673\n",
      "epoch: 2, batch: 824, loss: 1.8309725522994995\n",
      "epoch: 2, batch: 825, loss: 1.8873482942581177\n",
      "epoch: 2, batch: 826, loss: 1.9118322134017944\n",
      "epoch: 2, batch: 827, loss: 1.8600983619689941\n",
      "epoch: 2, batch: 828, loss: 1.8544425964355469\n",
      "epoch: 2, batch: 829, loss: 1.8995956182479858\n",
      "epoch: 2, batch: 830, loss: 1.8831504583358765\n",
      "epoch: 2, batch: 831, loss: 1.8962132930755615\n",
      "epoch: 2, batch: 832, loss: 1.7232085466384888\n",
      "epoch: 2, batch: 833, loss: 1.8910704851150513\n",
      "epoch: 2, batch: 834, loss: 1.9381564855575562\n",
      "epoch: 2, batch: 835, loss: 1.9223878383636475\n",
      "epoch: 2, batch: 836, loss: 1.8663742542266846\n",
      "epoch: 2, batch: 837, loss: 1.8097639083862305\n",
      "epoch: 2, batch: 838, loss: 1.8722224235534668\n",
      "epoch: 2, batch: 839, loss: 1.8924199342727661\n",
      "epoch: 2, batch: 840, loss: 1.7744140625\n",
      "epoch: 2, batch: 841, loss: 1.8806300163269043\n",
      "epoch: 2, batch: 842, loss: 1.8694170713424683\n",
      "epoch: 2, batch: 843, loss: 1.9644272327423096\n",
      "epoch: 2, batch: 844, loss: 1.9003711938858032\n",
      "epoch: 2, batch: 845, loss: 1.92880117893219\n",
      "epoch: 2, batch: 846, loss: 1.918443202972412\n",
      "epoch: 2, batch: 847, loss: 1.9373692274093628\n",
      "epoch: 2, batch: 848, loss: 1.9400357007980347\n",
      "epoch: 2, batch: 849, loss: 1.762082815170288\n",
      "epoch: 2, batch: 850, loss: 1.9279245138168335\n",
      "epoch: 2, batch: 851, loss: 1.9001039266586304\n",
      "epoch: 2, batch: 852, loss: 1.948962688446045\n",
      "epoch: 2, batch: 853, loss: 1.984289526939392\n",
      "epoch: 2, batch: 854, loss: 1.803419589996338\n",
      "epoch: 2, batch: 855, loss: 1.8030579090118408\n",
      "epoch: 2, batch: 856, loss: 1.9011359214782715\n",
      "epoch: 2, batch: 857, loss: 1.768317461013794\n",
      "epoch: 2, batch: 858, loss: 1.827243447303772\n",
      "epoch: 2, batch: 859, loss: 1.8591002225875854\n",
      "epoch: 2, batch: 860, loss: 1.8026728630065918\n",
      "epoch: 2, batch: 861, loss: 1.8727308511734009\n",
      "epoch: 2, batch: 862, loss: 1.8274872303009033\n",
      "epoch: 2, batch: 863, loss: 1.8316080570220947\n",
      "epoch: 2, batch: 864, loss: 1.8641990423202515\n",
      "epoch: 2, batch: 865, loss: 1.8419229984283447\n",
      "epoch: 2, batch: 866, loss: 1.8809548616409302\n",
      "epoch: 2, batch: 867, loss: 1.9265804290771484\n",
      "epoch: 2, batch: 868, loss: 1.852249026298523\n",
      "epoch: 2, batch: 869, loss: 1.9660508632659912\n",
      "epoch: 2, batch: 870, loss: 1.8186970949172974\n",
      "epoch: 2, batch: 871, loss: 1.9475029706954956\n",
      "epoch: 2, batch: 872, loss: 1.8205143213272095\n",
      "epoch: 2, batch: 873, loss: 1.8007034063339233\n",
      "epoch: 2, batch: 874, loss: 1.9101027250289917\n",
      "epoch: 2, batch: 875, loss: 1.7986645698547363\n",
      "epoch: 2, batch: 876, loss: 1.883589744567871\n",
      "epoch: 2, batch: 877, loss: 1.7904058694839478\n",
      "epoch: 2, batch: 878, loss: 1.9462782144546509\n",
      "epoch: 2, batch: 879, loss: 1.8906673192977905\n",
      "epoch: 2, batch: 880, loss: 1.8354699611663818\n",
      "epoch: 2, batch: 881, loss: 1.8636753559112549\n",
      "epoch: 2, batch: 882, loss: 1.8214352130889893\n",
      "epoch: 2, batch: 883, loss: 1.8727505207061768\n",
      "epoch: 2, batch: 884, loss: 1.9263110160827637\n",
      "epoch: 2, batch: 885, loss: 1.812501311302185\n",
      "epoch: 2, batch: 886, loss: 1.8948477506637573\n",
      "epoch: 2, batch: 887, loss: 1.8919589519500732\n",
      "epoch: 2, batch: 888, loss: 1.8929650783538818\n",
      "epoch: 2, batch: 889, loss: 1.8365864753723145\n",
      "epoch: 2, batch: 890, loss: 1.934443712234497\n",
      "epoch: 2, batch: 891, loss: 1.8043367862701416\n",
      "epoch: 2, batch: 892, loss: 1.8870869874954224\n",
      "epoch: 2, batch: 893, loss: 1.8742314577102661\n",
      "epoch: 2, batch: 894, loss: 1.93878173828125\n",
      "epoch: 2, batch: 895, loss: 1.8629474639892578\n",
      "epoch: 2, batch: 896, loss: 1.8782440423965454\n",
      "epoch: 2, batch: 897, loss: 1.9178999662399292\n",
      "epoch: 2, batch: 898, loss: 1.7952425479888916\n",
      "epoch: 2, batch: 899, loss: 1.8036242723464966\n",
      "epoch: 2, batch: 900, loss: 1.8138145208358765\n",
      "epoch: 2, batch: 901, loss: 1.7943699359893799\n",
      "epoch: 2, batch: 902, loss: 1.7651617527008057\n",
      "epoch: 2, batch: 903, loss: 1.819104552268982\n",
      "epoch: 2, batch: 904, loss: 1.8360540866851807\n",
      "epoch: 2, batch: 905, loss: 1.9562900066375732\n",
      "epoch: 2, batch: 906, loss: 1.7498036623001099\n",
      "epoch: 2, batch: 907, loss: 1.8787627220153809\n",
      "epoch: 2, batch: 908, loss: 1.9099371433258057\n",
      "epoch: 2, batch: 909, loss: 1.840271234512329\n",
      "epoch: 2, batch: 910, loss: 1.8570207357406616\n",
      "epoch: 2, batch: 911, loss: 1.7893058061599731\n",
      "epoch: 2, batch: 912, loss: 1.8067348003387451\n",
      "epoch: 2, batch: 913, loss: 1.8045189380645752\n",
      "epoch: 2, batch: 914, loss: 1.8301817178726196\n",
      "epoch: 2, batch: 915, loss: 1.7852588891983032\n",
      "epoch: 2, batch: 916, loss: 1.857488989830017\n",
      "epoch: 2, batch: 917, loss: 1.7804688215255737\n",
      "epoch: 2, batch: 918, loss: 1.8154736757278442\n",
      "epoch: 2, batch: 919, loss: 1.8584736585617065\n",
      "epoch: 2, batch: 920, loss: 1.8168907165527344\n",
      "epoch: 2, batch: 921, loss: 1.9146571159362793\n",
      "epoch: 2, batch: 922, loss: 1.8469061851501465\n",
      "epoch: 2, batch: 923, loss: 1.9073346853256226\n",
      "epoch: 2, batch: 924, loss: 1.8342889547348022\n",
      "epoch: 2, batch: 925, loss: 1.6729347705841064\n",
      "epoch: 2, batch: 926, loss: 1.8771790266036987\n",
      "epoch: 2, batch: 927, loss: 1.8092774152755737\n",
      "epoch: 2, batch: 928, loss: 1.7829012870788574\n",
      "epoch: 2, batch: 929, loss: 1.8547441959381104\n",
      "epoch: 2, batch: 930, loss: 1.7772687673568726\n",
      "epoch: 2, batch: 931, loss: 1.9014930725097656\n",
      "epoch: 2, batch: 932, loss: 1.8195743560791016\n",
      "epoch: 2, batch: 933, loss: 1.8974275588989258\n",
      "epoch: 2, batch: 934, loss: 1.9659936428070068\n",
      "epoch: 2, batch: 935, loss: 1.7889416217803955\n",
      "epoch: 2, batch: 936, loss: 1.8728594779968262\n",
      "epoch: 2, batch: 937, loss: 1.929688572883606\n",
      "epoch: 2, batch: 938, loss: 1.7970556020736694\n",
      "epoch: 2, batch: 939, loss: 1.864751935005188\n",
      "epoch: 2, batch: 940, loss: 1.843853235244751\n",
      "epoch: 2, batch: 941, loss: 1.7917637825012207\n",
      "epoch: 2, batch: 942, loss: 1.7826018333435059\n",
      "epoch: 2, batch: 943, loss: 1.853839635848999\n",
      "epoch: 2, batch: 944, loss: 1.8818421363830566\n",
      "epoch: 2, batch: 945, loss: 1.8346660137176514\n",
      "epoch: 2, batch: 946, loss: 1.8600568771362305\n",
      "epoch: 2, batch: 947, loss: 1.7946491241455078\n",
      "epoch: 2, batch: 948, loss: 1.9731664657592773\n",
      "epoch: 2, batch: 949, loss: 1.8402036428451538\n",
      "epoch: 2, batch: 950, loss: 1.6846307516098022\n",
      "epoch: 2, batch: 951, loss: 1.8754962682724\n",
      "epoch: 2, batch: 952, loss: 1.7351561784744263\n",
      "epoch: 2, batch: 953, loss: 1.8650126457214355\n",
      "epoch: 2, batch: 954, loss: 1.8798151016235352\n",
      "epoch: 2, batch: 955, loss: 1.873177409172058\n",
      "epoch: 2, batch: 956, loss: 1.925289273262024\n",
      "epoch: 2, batch: 957, loss: 1.8207497596740723\n",
      "epoch: 2, batch: 958, loss: 1.767535924911499\n",
      "epoch: 2, batch: 959, loss: 1.8564212322235107\n",
      "epoch: 2, batch: 960, loss: 1.8116875886917114\n",
      "epoch: 2, batch: 961, loss: 1.8465917110443115\n",
      "epoch: 2, batch: 962, loss: 1.9287644624710083\n",
      "epoch: 2, batch: 963, loss: 1.7780115604400635\n",
      "epoch: 2, batch: 964, loss: 1.7622884511947632\n",
      "epoch: 2, batch: 965, loss: 1.76595139503479\n",
      "epoch: 2, batch: 966, loss: 1.843552589416504\n",
      "epoch: 2, batch: 967, loss: 1.8706530332565308\n",
      "epoch: 2, batch: 968, loss: 1.8587337732315063\n",
      "epoch: 2, batch: 969, loss: 1.9208894968032837\n",
      "epoch: 2, batch: 970, loss: 1.7862273454666138\n",
      "epoch: 2, batch: 971, loss: 1.8172760009765625\n",
      "epoch: 2, batch: 972, loss: 1.8331637382507324\n",
      "epoch: 2, batch: 973, loss: 1.8068386316299438\n",
      "epoch: 2, batch: 974, loss: 1.7576221227645874\n",
      "epoch: 2, batch: 975, loss: 1.872678518295288\n",
      "epoch: 2, batch: 976, loss: 1.834999680519104\n",
      "epoch: 2, batch: 977, loss: 1.7987923622131348\n",
      "epoch: 2, batch: 978, loss: 1.7748124599456787\n",
      "epoch: 2, batch: 979, loss: 1.8825045824050903\n",
      "epoch: 2, batch: 980, loss: 1.7776507139205933\n",
      "epoch: 2, batch: 981, loss: 1.7482465505599976\n",
      "epoch: 2, batch: 982, loss: 1.8389216661453247\n",
      "epoch: 2, batch: 983, loss: 1.8782927989959717\n",
      "epoch: 2, batch: 984, loss: 1.7586058378219604\n",
      "epoch: 2, batch: 985, loss: 1.716476321220398\n",
      "epoch: 2, batch: 986, loss: 1.8288780450820923\n",
      "epoch: 2, batch: 987, loss: 1.8628836870193481\n",
      "epoch: 2, batch: 988, loss: 1.6932005882263184\n",
      "epoch: 2, batch: 989, loss: 1.8060296773910522\n",
      "epoch: 2, batch: 990, loss: 1.8627876043319702\n",
      "epoch: 2, batch: 991, loss: 1.7528387308120728\n",
      "epoch: 2, batch: 992, loss: 1.8889333009719849\n",
      "epoch: 2, batch: 993, loss: 1.8509677648544312\n",
      "epoch: 2, batch: 994, loss: 1.8574974536895752\n",
      "epoch: 2, batch: 995, loss: 1.7963558435440063\n",
      "epoch: 2, batch: 996, loss: 1.8820366859436035\n",
      "epoch: 2, batch: 997, loss: 1.782074213027954\n",
      "epoch: 2, batch: 998, loss: 1.8418697118759155\n",
      "epoch: 2, batch: 999, loss: 1.9360817670822144\n",
      "epoch: 2, batch: 1000, loss: 1.885728120803833\n",
      "epoch: 2, batch: 1001, loss: 1.8178976774215698\n",
      "epoch: 2, batch: 1002, loss: 1.9070003032684326\n",
      "epoch: 2, batch: 1003, loss: 1.7939023971557617\n",
      "epoch: 2, batch: 1004, loss: 1.825242280960083\n",
      "epoch: 2, batch: 1005, loss: 1.804355263710022\n",
      "epoch: 2, batch: 1006, loss: 1.7469162940979004\n",
      "epoch: 2, batch: 1007, loss: 1.909043788909912\n",
      "epoch: 2, batch: 1008, loss: 1.7627952098846436\n",
      "epoch: 2, batch: 1009, loss: 1.846784234046936\n",
      "epoch: 2, batch: 1010, loss: 1.8579163551330566\n",
      "epoch: 2, batch: 1011, loss: 1.8179893493652344\n",
      "epoch: 2, batch: 1012, loss: 1.7228233814239502\n",
      "epoch: 2, batch: 1013, loss: 1.859446406364441\n",
      "epoch: 2, batch: 1014, loss: 1.7594554424285889\n",
      "epoch: 2, batch: 1015, loss: 1.799096703529358\n",
      "epoch: 2, batch: 1016, loss: 1.8210607767105103\n",
      "epoch: 2, batch: 1017, loss: 1.8417580127716064\n",
      "epoch: 2, batch: 1018, loss: 1.848697304725647\n",
      "epoch: 2, batch: 1019, loss: 1.8709887266159058\n",
      "epoch: 2, batch: 1020, loss: 1.878714919090271\n",
      "epoch: 2, batch: 1021, loss: 1.847608208656311\n",
      "epoch: 2, batch: 1022, loss: 1.8459317684173584\n",
      "epoch: 2, batch: 1023, loss: 1.7148555517196655\n",
      "epoch: 2, batch: 1024, loss: 1.8407924175262451\n",
      "epoch: 2, batch: 1025, loss: 1.8327733278274536\n",
      "epoch: 2, batch: 1026, loss: 1.8694589138031006\n",
      "epoch: 2, batch: 1027, loss: 1.8679686784744263\n",
      "epoch: 2, batch: 1028, loss: 1.7765768766403198\n",
      "epoch: 2, batch: 1029, loss: 1.7333409786224365\n",
      "epoch: 2, batch: 1030, loss: 1.874850869178772\n",
      "epoch: 2, batch: 1031, loss: 1.7726716995239258\n",
      "epoch: 2, batch: 1032, loss: 1.7303142547607422\n",
      "epoch: 2, batch: 1033, loss: 1.8198039531707764\n",
      "epoch: 2, batch: 1034, loss: 1.7589651346206665\n",
      "epoch: 2, batch: 1035, loss: 1.8054654598236084\n",
      "epoch: 2, batch: 1036, loss: 1.8979767560958862\n",
      "epoch: 2, batch: 1037, loss: 1.7951977252960205\n",
      "epoch: 2, batch: 1038, loss: 1.58022141456604\n",
      "epoch: 2, batch: 1039, loss: 1.8945871591567993\n",
      "epoch: 2, batch: 1040, loss: 1.6234948635101318\n",
      "epoch: 2, batch: 1041, loss: 1.9083067178726196\n",
      "epoch: 2, batch: 1042, loss: 1.829938530921936\n",
      "epoch: 2, batch: 1043, loss: 1.8377842903137207\n",
      "epoch: 2, batch: 1044, loss: 1.813853144645691\n",
      "epoch: 2, batch: 1045, loss: 1.8240517377853394\n",
      "epoch: 2, batch: 1046, loss: 1.7145886421203613\n",
      "epoch: 2, batch: 1047, loss: 1.8688384294509888\n",
      "epoch: 2, batch: 1048, loss: 1.8332053422927856\n",
      "epoch: 2, batch: 1049, loss: 1.78212571144104\n",
      "epoch: 2, batch: 1050, loss: 1.6994088888168335\n",
      "epoch: 2, batch: 1051, loss: 1.798385739326477\n",
      "epoch: 2, batch: 1052, loss: 1.7739040851593018\n",
      "epoch: 2, batch: 1053, loss: 1.8459985256195068\n",
      "epoch: 2, batch: 1054, loss: 1.8298585414886475\n",
      "epoch: 2, batch: 1055, loss: 1.7052152156829834\n",
      "epoch: 2, batch: 1056, loss: 1.8169142007827759\n",
      "epoch: 2, batch: 1057, loss: 1.8647199869155884\n",
      "epoch: 2, batch: 1058, loss: 1.7723546028137207\n",
      "epoch: 2, batch: 1059, loss: 1.8496809005737305\n",
      "epoch: 2, batch: 1060, loss: 1.7590200901031494\n",
      "epoch: 2, batch: 1061, loss: 1.8311147689819336\n",
      "epoch: 2, batch: 1062, loss: 1.7653125524520874\n",
      "epoch: 2, batch: 1063, loss: 1.8290410041809082\n",
      "epoch: 2, batch: 1064, loss: 1.80656099319458\n",
      "epoch: 2, batch: 1065, loss: 1.8995842933654785\n",
      "epoch: 2, batch: 1066, loss: 1.8478268384933472\n",
      "epoch: 2, batch: 1067, loss: 1.8309801816940308\n",
      "epoch: 2, batch: 1068, loss: 1.7497737407684326\n",
      "epoch: 2, batch: 1069, loss: 1.917162299156189\n",
      "epoch: 2, batch: 1070, loss: 1.9068820476531982\n",
      "epoch: 2, batch: 1071, loss: 1.6020678281784058\n",
      "epoch: 2, batch: 1072, loss: 1.7334699630737305\n",
      "epoch: 2, batch: 1073, loss: 1.7804594039916992\n",
      "epoch: 2, batch: 1074, loss: 1.853238821029663\n",
      "epoch: 2, batch: 1075, loss: 1.7661017179489136\n",
      "epoch: 2, batch: 1076, loss: 1.9913091659545898\n",
      "epoch: 2, batch: 1077, loss: 1.8319871425628662\n",
      "epoch: 2, batch: 1078, loss: 1.8656895160675049\n",
      "epoch: 2, batch: 1079, loss: 1.765613079071045\n",
      "epoch: 2, batch: 1080, loss: 1.8020703792572021\n",
      "epoch: 2, batch: 1081, loss: 1.814713716506958\n",
      "epoch: 2, batch: 1082, loss: 1.8554069995880127\n",
      "epoch: 2, batch: 1083, loss: 1.8286747932434082\n",
      "epoch: 2, batch: 1084, loss: 1.7443861961364746\n",
      "epoch: 2, batch: 1085, loss: 1.7591954469680786\n",
      "epoch: 2, batch: 1086, loss: 1.8353022336959839\n",
      "epoch: 2, batch: 1087, loss: 1.6667581796646118\n",
      "epoch: 2, batch: 1088, loss: 1.76143217086792\n",
      "epoch: 2, batch: 1089, loss: 1.7971688508987427\n",
      "epoch: 2, batch: 1090, loss: 1.823215365409851\n",
      "epoch: 2, batch: 1091, loss: 1.805153727531433\n",
      "epoch: 2, batch: 1092, loss: 1.815714955329895\n",
      "epoch: 2, batch: 1093, loss: 1.8042337894439697\n",
      "epoch: 2, batch: 1094, loss: 1.8054299354553223\n",
      "epoch: 2, batch: 1095, loss: 1.761193037033081\n",
      "epoch: 2, batch: 1096, loss: 1.7320170402526855\n",
      "epoch: 2, batch: 1097, loss: 1.7718374729156494\n",
      "epoch: 2, batch: 1098, loss: 1.7463082075119019\n",
      "epoch: 2, batch: 1099, loss: 1.7999539375305176\n",
      "epoch: 2, batch: 1100, loss: 1.7483724355697632\n",
      "epoch: 2, batch: 1101, loss: 1.7551548480987549\n",
      "epoch: 2, batch: 1102, loss: 1.8567334413528442\n",
      "epoch: 2, batch: 1103, loss: 1.855035424232483\n",
      "epoch: 2, batch: 1104, loss: 1.8560235500335693\n",
      "epoch: 2, batch: 1105, loss: 1.8157134056091309\n",
      "epoch: 2, batch: 1106, loss: 1.7998485565185547\n",
      "epoch: 2, batch: 1107, loss: 1.9330428838729858\n",
      "epoch: 2, batch: 1108, loss: 1.659334659576416\n",
      "epoch: 2, batch: 1109, loss: 1.8032737970352173\n",
      "epoch: 2, batch: 1110, loss: 1.8809027671813965\n",
      "epoch: 2, batch: 1111, loss: 1.7443578243255615\n",
      "epoch: 2, batch: 1112, loss: 1.772455096244812\n",
      "epoch: 2, batch: 1113, loss: 1.7902064323425293\n",
      "epoch: 2, batch: 1114, loss: 1.735283374786377\n",
      "epoch: 2, batch: 1115, loss: 1.8670830726623535\n",
      "epoch: 2, batch: 1116, loss: 1.766589641571045\n",
      "epoch: 2, batch: 1117, loss: 1.851441502571106\n",
      "epoch: 2, batch: 1118, loss: 1.7768577337265015\n",
      "epoch: 2, batch: 1119, loss: 1.775795340538025\n",
      "epoch: 2, batch: 1120, loss: 1.8615959882736206\n",
      "epoch: 2, batch: 1121, loss: 1.7422116994857788\n",
      "epoch: 2, batch: 1122, loss: 1.7343076467514038\n",
      "epoch: 2, batch: 1123, loss: 1.7448222637176514\n",
      "epoch: 2, batch: 1124, loss: 1.8465415239334106\n",
      "epoch: 2, batch: 1125, loss: 1.7664140462875366\n",
      "epoch: 2, batch: 1126, loss: 1.7092698812484741\n",
      "epoch: 2, batch: 1127, loss: 1.7455390691757202\n",
      "epoch: 2, batch: 1128, loss: 1.7369565963745117\n",
      "epoch: 2, batch: 1129, loss: 1.7693030834197998\n",
      "epoch: 2, batch: 1130, loss: 1.8281891345977783\n",
      "epoch: 2, batch: 1131, loss: 1.7781835794448853\n",
      "epoch: 2, batch: 1132, loss: 1.756150722503662\n",
      "epoch: 2, batch: 1133, loss: 1.7139394283294678\n",
      "epoch: 2, batch: 1134, loss: 1.8432124853134155\n",
      "epoch: 2, batch: 1135, loss: 1.840301275253296\n",
      "epoch: 2, batch: 1136, loss: 1.887470006942749\n",
      "epoch: 2, batch: 1137, loss: 1.7655231952667236\n",
      "epoch: 2, batch: 1138, loss: 1.8520522117614746\n",
      "epoch: 2, batch: 1139, loss: 1.740182876586914\n",
      "epoch: 2, batch: 1140, loss: 1.6997082233428955\n",
      "epoch: 2, batch: 1141, loss: 1.7624034881591797\n",
      "epoch: 2, batch: 1142, loss: 1.7914968729019165\n",
      "epoch: 2, batch: 1143, loss: 1.8655043840408325\n",
      "epoch: 2, batch: 1144, loss: 1.700677752494812\n",
      "epoch: 2, batch: 1145, loss: 1.7988145351409912\n",
      "epoch: 2, batch: 1146, loss: 1.8259083032608032\n",
      "epoch: 2, batch: 1147, loss: 1.7155978679656982\n",
      "epoch: 2, batch: 1148, loss: 1.7840590476989746\n",
      "epoch: 2, batch: 1149, loss: 1.778487205505371\n",
      "epoch: 2, batch: 1150, loss: 1.7335668802261353\n",
      "epoch: 2, batch: 1151, loss: 1.6764148473739624\n",
      "epoch: 2, batch: 1152, loss: 1.729249119758606\n",
      "epoch: 2, batch: 1153, loss: 1.7171629667282104\n",
      "epoch: 2, batch: 1154, loss: 1.849211573600769\n",
      "epoch: 2, batch: 1155, loss: 1.8144891262054443\n",
      "epoch: 2, batch: 1156, loss: 1.7429906129837036\n",
      "epoch: 2, batch: 1157, loss: 1.7317824363708496\n",
      "epoch: 2, batch: 1158, loss: 1.7892900705337524\n",
      "epoch: 2, batch: 1159, loss: 1.7796916961669922\n",
      "epoch: 2, batch: 1160, loss: 1.7530568838119507\n",
      "epoch: 2, batch: 1161, loss: 1.8178577423095703\n",
      "epoch: 2, batch: 1162, loss: 1.8890146017074585\n",
      "epoch: 2, batch: 1163, loss: 1.8017315864562988\n",
      "epoch: 2, batch: 1164, loss: 1.723376750946045\n",
      "epoch: 2, batch: 1165, loss: 1.8365051746368408\n",
      "epoch: 2, batch: 1166, loss: 1.7448927164077759\n",
      "epoch: 2, batch: 1167, loss: 1.6513890027999878\n",
      "epoch: 2, batch: 1168, loss: 1.6784473657608032\n",
      "epoch: 2, batch: 1169, loss: 1.8184722661972046\n",
      "epoch: 2, batch: 1170, loss: 1.8077837228775024\n",
      "epoch: 2, batch: 1171, loss: 1.6978340148925781\n",
      "epoch: 2, batch: 1172, loss: 1.8056540489196777\n",
      "epoch: 2, batch: 1173, loss: 1.7225286960601807\n",
      "epoch: 2, batch: 1174, loss: 1.9001572132110596\n",
      "epoch: 2, batch: 1175, loss: 1.8739663362503052\n",
      "epoch: 2, batch: 1176, loss: 1.7926883697509766\n",
      "epoch: 2, batch: 1177, loss: 1.7846875190734863\n",
      "epoch: 2, batch: 1178, loss: 1.726765513420105\n",
      "epoch: 2, batch: 1179, loss: 1.7060075998306274\n",
      "epoch: 2, batch: 1180, loss: 1.7362209558486938\n",
      "epoch: 2, batch: 1181, loss: 1.8306077718734741\n",
      "epoch: 2, batch: 1182, loss: 1.7709280252456665\n",
      "epoch: 2, batch: 1183, loss: 1.7755444049835205\n",
      "epoch: 2, batch: 1184, loss: 1.760676622390747\n",
      "epoch: 2, batch: 1185, loss: 1.71415114402771\n",
      "epoch: 2, batch: 1186, loss: 1.7746334075927734\n",
      "epoch: 2, batch: 1187, loss: 1.9266762733459473\n",
      "epoch: 2, batch: 1188, loss: 1.8154053688049316\n",
      "epoch: 2, batch: 1189, loss: 1.722276210784912\n",
      "epoch: 2, batch: 1190, loss: 1.7718815803527832\n",
      "epoch: 2, batch: 1191, loss: 1.8383212089538574\n",
      "epoch: 2, batch: 1192, loss: 1.813051700592041\n",
      "epoch: 2, batch: 1193, loss: 1.7438617944717407\n",
      "epoch: 2, batch: 1194, loss: 1.7505868673324585\n",
      "epoch: 2, batch: 1195, loss: 1.7472509145736694\n",
      "epoch: 2, batch: 1196, loss: 1.858380913734436\n",
      "epoch: 2, batch: 1197, loss: 1.819999098777771\n",
      "epoch: 2, batch: 1198, loss: 1.7984238862991333\n",
      "epoch: 2, batch: 1199, loss: 1.6876534223556519\n",
      "epoch: 2, batch: 1200, loss: 1.683732032775879\n",
      "epoch: 2, batch: 1201, loss: 1.8170287609100342\n",
      "epoch: 2, batch: 1202, loss: 1.771020770072937\n",
      "epoch: 2, batch: 1203, loss: 1.7506330013275146\n",
      "epoch: 2, batch: 1204, loss: 1.704032063484192\n",
      "epoch: 2, batch: 1205, loss: 1.6506952047348022\n",
      "epoch: 2, batch: 1206, loss: 1.7453874349594116\n",
      "epoch: 2, batch: 1207, loss: 1.820652961730957\n",
      "epoch: 2, batch: 1208, loss: 1.8033298254013062\n",
      "epoch: 2, batch: 1209, loss: 1.8084741830825806\n",
      "epoch: 2, batch: 1210, loss: 1.748271107673645\n",
      "epoch: 2, batch: 1211, loss: 1.773598551750183\n",
      "epoch: 2, batch: 1212, loss: 1.8163989782333374\n",
      "epoch: 2, batch: 1213, loss: 1.700222134590149\n",
      "epoch: 2, batch: 1214, loss: 1.7234339714050293\n",
      "epoch: 2, batch: 1215, loss: 1.7249946594238281\n",
      "epoch: 2, batch: 1216, loss: 1.712267279624939\n",
      "epoch: 2, batch: 1217, loss: 1.8040024042129517\n",
      "epoch: 2, batch: 1218, loss: 1.6645159721374512\n",
      "epoch: 2, batch: 1219, loss: 1.7613779306411743\n",
      "epoch: 2, batch: 1220, loss: 1.8552244901657104\n",
      "epoch: 2, batch: 1221, loss: 1.7985385656356812\n",
      "epoch: 2, batch: 1222, loss: 1.760491967201233\n",
      "epoch: 2, batch: 1223, loss: 1.8171008825302124\n",
      "epoch: 2, batch: 1224, loss: 1.752659797668457\n",
      "epoch: 2, batch: 1225, loss: 1.6604169607162476\n",
      "epoch: 2, batch: 1226, loss: 1.7849583625793457\n",
      "epoch: 2, batch: 1227, loss: 1.7047450542449951\n",
      "epoch: 2, batch: 1228, loss: 1.7764792442321777\n",
      "epoch: 2, batch: 1229, loss: 1.7584246397018433\n",
      "epoch: 2, batch: 1230, loss: 1.7868934869766235\n",
      "epoch: 2, batch: 1231, loss: 1.7330741882324219\n",
      "epoch: 2, batch: 1232, loss: 1.7215110063552856\n",
      "epoch: 2, batch: 1233, loss: 1.690225601196289\n",
      "epoch: 2, batch: 1234, loss: 1.5959688425064087\n",
      "epoch: 2, batch: 1235, loss: 1.6614867448806763\n",
      "epoch: 2, batch: 1236, loss: 1.7215036153793335\n",
      "epoch: 2, batch: 1237, loss: 1.7634779214859009\n",
      "epoch: 2, batch: 1238, loss: 1.8653552532196045\n",
      "epoch: 2, batch: 1239, loss: 1.7849706411361694\n",
      "epoch: 2, batch: 1240, loss: 1.6491745710372925\n",
      "epoch: 2, batch: 1241, loss: 1.6545578241348267\n",
      "epoch: 2, batch: 1242, loss: 1.6739474534988403\n",
      "epoch: 2, batch: 1243, loss: 1.8918954133987427\n",
      "epoch: 2, batch: 1244, loss: 1.7129329442977905\n",
      "epoch: 2, batch: 1245, loss: 1.6997349262237549\n",
      "epoch: 2, batch: 1246, loss: 1.7735133171081543\n",
      "epoch: 2, batch: 1247, loss: 1.7475175857543945\n",
      "epoch: 2, batch: 1248, loss: 1.8618600368499756\n",
      "epoch: 2, batch: 1249, loss: 1.7321326732635498\n",
      "epoch: 2, batch: 1250, loss: 1.6478111743927002\n",
      "epoch: 2, batch: 1251, loss: 1.8527659177780151\n",
      "epoch: 2, batch: 1252, loss: 1.72700035572052\n",
      "epoch: 2, batch: 1253, loss: 1.5851197242736816\n",
      "epoch: 2, batch: 1254, loss: 1.7501506805419922\n",
      "epoch: 2, batch: 1255, loss: 1.8213906288146973\n",
      "epoch: 2, batch: 1256, loss: 1.6547341346740723\n",
      "epoch: 2, batch: 1257, loss: 1.7494099140167236\n",
      "epoch: 2, batch: 1258, loss: 1.7687557935714722\n",
      "epoch: 2, batch: 1259, loss: 1.7529287338256836\n",
      "epoch: 2, batch: 1260, loss: 1.6588393449783325\n",
      "epoch: 2, batch: 1261, loss: 1.7542186975479126\n",
      "epoch: 2, batch: 1262, loss: 1.6749616861343384\n",
      "epoch: 2, batch: 1263, loss: 1.7433693408966064\n",
      "epoch: 2, batch: 1264, loss: 1.8503724336624146\n",
      "epoch: 2, batch: 1265, loss: 1.7505784034729004\n",
      "epoch: 2, batch: 1266, loss: 1.6459547281265259\n",
      "epoch: 2, batch: 1267, loss: 1.8392947912216187\n",
      "epoch: 2, batch: 1268, loss: 1.7985494136810303\n",
      "epoch: 2, batch: 1269, loss: 1.742976427078247\n",
      "epoch: 2, batch: 1270, loss: 1.7225866317749023\n",
      "epoch: 2, batch: 1271, loss: 1.71356201171875\n",
      "epoch: 2, batch: 1272, loss: 1.750189185142517\n",
      "epoch: 2, batch: 1273, loss: 1.8182004690170288\n",
      "epoch: 2, batch: 1274, loss: 1.6321266889572144\n",
      "epoch: 2, batch: 1275, loss: 1.889610767364502\n",
      "epoch: 2, batch: 1276, loss: 1.6801546812057495\n",
      "epoch: 2, batch: 1277, loss: 1.5962278842926025\n",
      "epoch: 2, batch: 1278, loss: 1.7572635412216187\n",
      "epoch: 2, batch: 1279, loss: 1.7493680715560913\n",
      "epoch: 2, batch: 1280, loss: 1.7839939594268799\n",
      "epoch: 2, batch: 1281, loss: 1.6388967037200928\n",
      "epoch: 2, batch: 1282, loss: 1.7559056282043457\n",
      "epoch: 2, batch: 1283, loss: 1.7262572050094604\n",
      "epoch: 2, batch: 1284, loss: 1.6412725448608398\n",
      "epoch: 2, batch: 1285, loss: 1.729391098022461\n",
      "epoch: 2, batch: 1286, loss: 1.7266875505447388\n",
      "epoch: 2, batch: 1287, loss: 1.7997311353683472\n",
      "epoch: 2, batch: 1288, loss: 1.688169002532959\n",
      "epoch: 2, batch: 1289, loss: 1.9349679946899414\n",
      "epoch: 2, batch: 1290, loss: 1.8617420196533203\n",
      "epoch: 2, batch: 1291, loss: 1.6803048849105835\n",
      "epoch: 2, batch: 1292, loss: 1.7948392629623413\n",
      "epoch: 2, batch: 1293, loss: 1.8257328271865845\n",
      "epoch: 2, batch: 1294, loss: 1.689703106880188\n",
      "epoch: 2, batch: 1295, loss: 1.7527004480361938\n",
      "epoch: 2, batch: 1296, loss: 1.826277256011963\n",
      "epoch: 2, batch: 1297, loss: 1.650449514389038\n",
      "epoch: 2, batch: 1298, loss: 1.7343316078186035\n",
      "epoch: 2, batch: 1299, loss: 1.6761404275894165\n",
      "epoch: 2, batch: 1300, loss: 1.6839885711669922\n",
      "epoch: 2, batch: 1301, loss: 1.6156344413757324\n",
      "epoch: 2, batch: 1302, loss: 1.7302590608596802\n",
      "epoch: 2, batch: 1303, loss: 1.6541504859924316\n",
      "epoch: 2, batch: 1304, loss: 1.6878721714019775\n",
      "epoch: 2, batch: 1305, loss: 1.770408272743225\n",
      "epoch: 2, batch: 1306, loss: 1.9370999336242676\n",
      "epoch: 2, batch: 1307, loss: 1.718337059020996\n",
      "epoch: 2, batch: 1308, loss: 1.7178632020950317\n",
      "epoch: 2, batch: 1309, loss: 1.747837781906128\n",
      "epoch: 2, batch: 1310, loss: 1.7233253717422485\n",
      "epoch: 2, batch: 1311, loss: 1.7499163150787354\n",
      "epoch: 2, batch: 1312, loss: 1.7494980096817017\n",
      "epoch: 2, batch: 1313, loss: 1.7344341278076172\n",
      "epoch: 2, batch: 1314, loss: 1.7452013492584229\n",
      "epoch: 2, batch: 1315, loss: 1.7043625116348267\n",
      "epoch: 2, batch: 1316, loss: 1.709565281867981\n",
      "epoch: 2, batch: 1317, loss: 1.6839964389801025\n",
      "epoch: 2, batch: 1318, loss: 1.7165225744247437\n",
      "epoch: 2, batch: 1319, loss: 1.8464009761810303\n",
      "epoch: 2, batch: 1320, loss: 1.727076768875122\n",
      "epoch: 2, batch: 1321, loss: 1.6636985540390015\n",
      "epoch: 2, batch: 1322, loss: 1.646389126777649\n",
      "epoch: 2, batch: 1323, loss: 1.6396037340164185\n",
      "epoch: 2, batch: 1324, loss: 1.7039916515350342\n",
      "epoch: 2, batch: 1325, loss: 1.7527532577514648\n",
      "epoch: 2, batch: 1326, loss: 1.7375543117523193\n",
      "epoch: 2, batch: 1327, loss: 1.8618508577346802\n",
      "epoch: 2, batch: 1328, loss: 1.7826051712036133\n",
      "epoch: 2, batch: 1329, loss: 1.741278886795044\n",
      "epoch: 2, batch: 1330, loss: 1.7540128231048584\n",
      "epoch: 2, batch: 1331, loss: 1.7840059995651245\n",
      "epoch: 2, batch: 1332, loss: 1.7036380767822266\n",
      "epoch: 2, batch: 1333, loss: 1.710935354232788\n",
      "epoch: 2, batch: 1334, loss: 1.833540678024292\n",
      "epoch: 2, batch: 1335, loss: 1.825160264968872\n",
      "epoch: 2, batch: 1336, loss: 1.731041669845581\n",
      "epoch: 2, batch: 1337, loss: 1.537398099899292\n",
      "epoch: 2, batch: 1338, loss: 1.7777292728424072\n",
      "epoch: 2, batch: 1339, loss: 1.6828380823135376\n",
      "epoch: 2, batch: 1340, loss: 1.751144528388977\n",
      "epoch: 2, batch: 1341, loss: 1.6704272031784058\n",
      "epoch: 2, batch: 1342, loss: 1.7715331315994263\n",
      "epoch: 2, batch: 1343, loss: 1.7586957216262817\n",
      "epoch: 2, batch: 1344, loss: 1.6325124502182007\n",
      "epoch: 2, batch: 1345, loss: 1.8060652017593384\n",
      "epoch: 2, batch: 1346, loss: 1.698006510734558\n",
      "epoch: 2, batch: 1347, loss: 1.6343797445297241\n",
      "epoch: 2, batch: 1348, loss: 1.6467077732086182\n",
      "epoch: 2, batch: 1349, loss: 1.7596391439437866\n",
      "epoch: 2, batch: 1350, loss: 1.7700937986373901\n",
      "epoch: 2, batch: 1351, loss: 1.7499340772628784\n",
      "epoch: 2, batch: 1352, loss: 1.840264081954956\n",
      "epoch: 2, batch: 1353, loss: 1.781376600265503\n",
      "epoch: 2, batch: 1354, loss: 1.6907392740249634\n",
      "epoch: 2, batch: 1355, loss: 1.7051736116409302\n",
      "epoch: 2, batch: 1356, loss: 1.7224841117858887\n",
      "epoch: 2, batch: 1357, loss: 1.652668833732605\n",
      "epoch: 2, batch: 1358, loss: 1.7798017263412476\n",
      "epoch: 2, batch: 1359, loss: 1.8326716423034668\n",
      "epoch: 2, batch: 1360, loss: 1.7640777826309204\n",
      "epoch: 2, batch: 1361, loss: 1.671329379081726\n",
      "epoch: 2, batch: 1362, loss: 1.614189863204956\n",
      "epoch: 2, batch: 1363, loss: 1.7473589181900024\n",
      "epoch: 2, batch: 1364, loss: 1.7370684146881104\n",
      "epoch: 2, batch: 1365, loss: 1.8591545820236206\n",
      "epoch: 2, batch: 1366, loss: 1.7920078039169312\n",
      "epoch: 2, batch: 1367, loss: 1.698367714881897\n",
      "epoch: 2, batch: 1368, loss: 1.7431920766830444\n",
      "epoch: 2, batch: 1369, loss: 1.6055450439453125\n",
      "epoch: 2, batch: 1370, loss: 1.637760043144226\n",
      "epoch: 2, batch: 1371, loss: 1.5690160989761353\n",
      "epoch: 2, batch: 1372, loss: 1.6278018951416016\n",
      "epoch: 2, batch: 1373, loss: 1.7374622821807861\n",
      "epoch: 2, batch: 1374, loss: 1.7840644121170044\n",
      "epoch: 2, batch: 1375, loss: 1.8117936849594116\n",
      "epoch: 2, batch: 1376, loss: 1.7733577489852905\n",
      "epoch: 2, batch: 1377, loss: 1.6068670749664307\n",
      "epoch: 2, batch: 1378, loss: 1.748189091682434\n",
      "epoch: 2, batch: 1379, loss: 1.6261472702026367\n",
      "epoch: 2, batch: 1380, loss: 1.7462146282196045\n",
      "epoch: 2, batch: 1381, loss: 1.6925957202911377\n",
      "epoch: 2, batch: 1382, loss: 1.7397780418395996\n",
      "epoch: 2, batch: 1383, loss: 1.7697149515151978\n",
      "epoch: 2, batch: 1384, loss: 1.6617213487625122\n",
      "epoch: 2, batch: 1385, loss: 1.632757544517517\n",
      "epoch: 2, batch: 1386, loss: 1.7536221742630005\n",
      "epoch: 2, batch: 1387, loss: 1.793173909187317\n",
      "epoch: 2, batch: 1388, loss: 1.804587721824646\n",
      "epoch: 2, batch: 1389, loss: 1.6831176280975342\n",
      "epoch: 2, batch: 1390, loss: 1.7786179780960083\n",
      "epoch: 2, batch: 1391, loss: 1.7112972736358643\n",
      "epoch: 2, batch: 1392, loss: 1.7107422351837158\n",
      "epoch: 2, batch: 1393, loss: 1.6437901258468628\n",
      "epoch: 2, batch: 1394, loss: 1.6268768310546875\n",
      "epoch: 2, batch: 1395, loss: 1.7184271812438965\n",
      "epoch: 2, batch: 1396, loss: 1.8463371992111206\n",
      "epoch: 2, batch: 1397, loss: 1.6597087383270264\n",
      "epoch: 2, batch: 1398, loss: 1.732417345046997\n",
      "epoch: 2, batch: 1399, loss: 1.6170345544815063\n",
      "epoch: 2, batch: 1400, loss: 1.6658382415771484\n",
      "epoch: 2, batch: 1401, loss: 1.7191082239151\n",
      "epoch: 2, batch: 1402, loss: 1.6531823873519897\n",
      "epoch: 2, batch: 1403, loss: 1.6250697374343872\n",
      "epoch: 2, batch: 1404, loss: 1.827530026435852\n",
      "epoch: 2, batch: 1405, loss: 1.5787715911865234\n",
      "epoch: 2, batch: 1406, loss: 1.635711669921875\n",
      "epoch: 2, batch: 1407, loss: 1.6779578924179077\n",
      "epoch: 2, batch: 1408, loss: 1.7193678617477417\n",
      "epoch: 2, batch: 1409, loss: 1.7447850704193115\n",
      "epoch: 2, batch: 1410, loss: 1.7496892213821411\n",
      "epoch: 2, batch: 1411, loss: 1.669446587562561\n",
      "epoch: 2, batch: 1412, loss: 1.8496036529541016\n",
      "epoch: 2, batch: 1413, loss: 1.552916407585144\n",
      "epoch: 2, batch: 1414, loss: 1.7958848476409912\n",
      "epoch: 2, batch: 1415, loss: 1.6583057641983032\n",
      "epoch: 2, batch: 1416, loss: 1.7675464153289795\n",
      "epoch: 2, batch: 1417, loss: 1.7285321950912476\n",
      "epoch: 2, batch: 1418, loss: 1.6707055568695068\n",
      "epoch: 2, batch: 1419, loss: 1.746477484703064\n",
      "epoch: 2, batch: 1420, loss: 1.7229984998703003\n",
      "epoch: 2, batch: 1421, loss: 1.7202138900756836\n",
      "epoch: 2, batch: 1422, loss: 1.7092288732528687\n",
      "epoch: 2, batch: 1423, loss: 1.7403043508529663\n",
      "epoch: 2, batch: 1424, loss: 1.7108683586120605\n",
      "epoch: 2, batch: 1425, loss: 1.7241547107696533\n",
      "epoch: 2, batch: 1426, loss: 1.6662909984588623\n",
      "epoch: 2, batch: 1427, loss: 1.6040233373641968\n",
      "epoch: 2, batch: 1428, loss: 1.7768372297286987\n",
      "epoch: 2, batch: 1429, loss: 1.7059968709945679\n",
      "epoch: 2, batch: 1430, loss: 1.6224486827850342\n",
      "epoch: 2, batch: 1431, loss: 1.8166732788085938\n",
      "epoch: 2, batch: 1432, loss: 1.7285878658294678\n",
      "epoch: 2, batch: 1433, loss: 1.662163496017456\n",
      "epoch: 2, batch: 1434, loss: 1.723699688911438\n",
      "epoch: 2, batch: 1435, loss: 1.7767035961151123\n",
      "epoch: 2, batch: 1436, loss: 1.6867105960845947\n",
      "epoch: 2, batch: 1437, loss: 1.6945070028305054\n",
      "epoch: 2, batch: 1438, loss: 1.672235369682312\n",
      "epoch: 2, batch: 1439, loss: 1.6036878824234009\n",
      "epoch: 2, batch: 1440, loss: 1.728001594543457\n",
      "epoch: 2, batch: 1441, loss: 1.5368794202804565\n",
      "epoch: 2, batch: 1442, loss: 1.6830220222473145\n",
      "epoch: 2, batch: 1443, loss: 1.710489273071289\n",
      "epoch: 2, batch: 1444, loss: 1.603502631187439\n",
      "epoch: 2, batch: 1445, loss: 1.7450861930847168\n",
      "epoch: 2, batch: 1446, loss: 1.7571370601654053\n",
      "epoch: 2, batch: 1447, loss: 1.655308485031128\n",
      "epoch: 2, batch: 1448, loss: 1.644539713859558\n",
      "epoch: 2, batch: 1449, loss: 1.6797391176223755\n",
      "epoch: 2, batch: 1450, loss: 1.6672855615615845\n",
      "epoch: 2, batch: 1451, loss: 1.675986647605896\n",
      "epoch: 2, batch: 1452, loss: 1.6723625659942627\n",
      "epoch: 2, batch: 1453, loss: 1.6651893854141235\n",
      "epoch: 2, batch: 1454, loss: 1.7439953088760376\n",
      "epoch: 2, batch: 1455, loss: 1.8786181211471558\n",
      "epoch: 2, batch: 1456, loss: 1.7655372619628906\n",
      "epoch: 2, batch: 1457, loss: 1.6665050983428955\n",
      "epoch: 2, batch: 1458, loss: 1.8043484687805176\n",
      "epoch: 2, batch: 1459, loss: 1.724109411239624\n",
      "epoch: 2, batch: 1460, loss: 1.7606955766677856\n",
      "epoch: 2, batch: 1461, loss: 1.4918274879455566\n",
      "epoch: 2, batch: 1462, loss: 1.7303744554519653\n",
      "epoch: 2, batch: 1463, loss: 1.7554806470870972\n",
      "epoch: 2, batch: 1464, loss: 1.6588351726531982\n",
      "epoch: 2, batch: 1465, loss: 1.7625386714935303\n",
      "epoch: 2, batch: 1466, loss: 1.7386208772659302\n",
      "epoch: 2, batch: 1467, loss: 1.6961899995803833\n",
      "epoch: 2, batch: 1468, loss: 1.6345748901367188\n",
      "epoch: 2, batch: 1469, loss: 1.5268545150756836\n",
      "epoch: 2, batch: 1470, loss: 1.667995810508728\n",
      "epoch: 2, batch: 1471, loss: 1.6493685245513916\n",
      "epoch: 2, batch: 1472, loss: 1.8610994815826416\n",
      "epoch: 2, batch: 1473, loss: 1.7485166788101196\n",
      "epoch: 2, batch: 1474, loss: 1.6595120429992676\n",
      "epoch: 2, batch: 1475, loss: 1.7157357931137085\n",
      "epoch: 2, batch: 1476, loss: 1.6624462604522705\n",
      "epoch: 2, batch: 1477, loss: 1.5567989349365234\n",
      "epoch: 2, batch: 1478, loss: 1.7315444946289062\n",
      "epoch: 2, batch: 1479, loss: 1.8018760681152344\n",
      "epoch: 2, batch: 1480, loss: 1.6204441785812378\n",
      "epoch: 2, batch: 1481, loss: 1.6546673774719238\n",
      "epoch: 2, batch: 1482, loss: 1.571589708328247\n",
      "epoch: 2, batch: 1483, loss: 1.5662424564361572\n",
      "epoch: 2, batch: 1484, loss: 1.6222376823425293\n",
      "epoch: 2, batch: 1485, loss: 1.7306997776031494\n",
      "epoch: 2, batch: 1486, loss: 1.7543009519577026\n",
      "epoch: 2, batch: 1487, loss: 1.6668083667755127\n",
      "epoch: 2, batch: 1488, loss: 1.6553475856781006\n",
      "epoch: 2, batch: 1489, loss: 1.6884608268737793\n",
      "epoch: 2, batch: 1490, loss: 1.703916311264038\n",
      "epoch: 2, batch: 1491, loss: 1.7895245552062988\n",
      "epoch: 2, batch: 1492, loss: 1.6893444061279297\n",
      "epoch: 2, batch: 1493, loss: 1.6343591213226318\n",
      "epoch: 2, batch: 1494, loss: 1.643669843673706\n",
      "epoch: 2, batch: 1495, loss: 1.7082163095474243\n",
      "epoch: 2, batch: 1496, loss: 1.5243630409240723\n",
      "epoch: 2, batch: 1497, loss: 1.7659283876419067\n",
      "epoch: 2, batch: 1498, loss: 1.5282915830612183\n",
      "epoch: 2, batch: 1499, loss: 1.5603162050247192\n",
      "epoch: 2, batch: 1500, loss: 1.7161098718643188\n",
      "epoch: 2, batch: 1501, loss: 1.5473897457122803\n",
      "epoch: 2, batch: 1502, loss: 1.7038977146148682\n",
      "epoch: 2, batch: 1503, loss: 1.668199062347412\n",
      "epoch: 2, batch: 1504, loss: 1.597396969795227\n",
      "epoch: 2, batch: 1505, loss: 1.7257755994796753\n",
      "epoch: 2, batch: 1506, loss: 1.6247780323028564\n",
      "epoch: 2, batch: 1507, loss: 1.7837026119232178\n",
      "epoch: 2, batch: 1508, loss: 1.545813798904419\n",
      "epoch: 2, batch: 1509, loss: 1.6888039112091064\n",
      "epoch: 2, batch: 1510, loss: 1.7175453901290894\n",
      "epoch: 2, batch: 1511, loss: 1.7533880472183228\n",
      "epoch: 2, batch: 1512, loss: 1.5390042066574097\n",
      "epoch: 2, batch: 1513, loss: 1.7343027591705322\n",
      "epoch: 2, batch: 1514, loss: 1.6880693435668945\n",
      "epoch: 2, batch: 1515, loss: 1.7627630233764648\n",
      "epoch: 2, batch: 1516, loss: 1.8503433465957642\n",
      "epoch: 2, batch: 1517, loss: 1.5283210277557373\n",
      "epoch: 2, batch: 1518, loss: 1.7643235921859741\n",
      "epoch: 2, batch: 1519, loss: 1.6081185340881348\n",
      "epoch: 2, batch: 1520, loss: 1.7764030694961548\n",
      "epoch: 2, batch: 1521, loss: 1.5475174188613892\n",
      "epoch: 2, batch: 1522, loss: 1.5895166397094727\n",
      "epoch: 2, batch: 1523, loss: 1.7880350351333618\n",
      "epoch: 2, batch: 1524, loss: 1.5059148073196411\n",
      "epoch: 2, batch: 1525, loss: 1.5699514150619507\n",
      "epoch: 2, batch: 1526, loss: 1.7072879076004028\n",
      "epoch: 2, batch: 1527, loss: 1.6430211067199707\n",
      "epoch: 2, batch: 1528, loss: 1.6454230546951294\n",
      "epoch: 2, batch: 1529, loss: 1.679420828819275\n",
      "epoch: 2, batch: 1530, loss: 1.5655896663665771\n",
      "epoch: 2, batch: 1531, loss: 1.5678497552871704\n",
      "epoch: 2, batch: 1532, loss: 1.6594449281692505\n",
      "epoch: 2, batch: 1533, loss: 1.6087405681610107\n",
      "epoch: 2, batch: 1534, loss: 1.580223798751831\n",
      "epoch: 2, batch: 1535, loss: 1.608127474784851\n",
      "epoch: 2, batch: 1536, loss: 1.7595466375350952\n",
      "epoch: 2, batch: 1537, loss: 1.6856564283370972\n",
      "epoch: 2, batch: 1538, loss: 1.6672418117523193\n",
      "epoch: 2, batch: 1539, loss: 1.5970628261566162\n",
      "epoch: 2, batch: 1540, loss: 1.6080238819122314\n",
      "epoch: 2, batch: 1541, loss: 1.776817798614502\n",
      "epoch: 2, batch: 1542, loss: 1.5562196969985962\n",
      "epoch: 2, batch: 1543, loss: 1.7206957340240479\n",
      "epoch: 2, batch: 1544, loss: 1.6840331554412842\n",
      "epoch: 2, batch: 1545, loss: 1.6284568309783936\n",
      "epoch: 2, batch: 1546, loss: 1.599092960357666\n",
      "epoch: 2, batch: 1547, loss: 1.6028014421463013\n",
      "epoch: 2, batch: 1548, loss: 1.5782891511917114\n",
      "epoch: 2, batch: 1549, loss: 1.6654746532440186\n",
      "epoch: 2, batch: 1550, loss: 1.5131150484085083\n",
      "epoch: 2, batch: 1551, loss: 1.6507381200790405\n",
      "epoch: 2, batch: 1552, loss: 1.7161060571670532\n",
      "epoch: 2, batch: 1553, loss: 1.7314900159835815\n",
      "epoch: 2, batch: 1554, loss: 1.5802282094955444\n",
      "epoch: 2, batch: 1555, loss: 1.6298092603683472\n",
      "epoch: 2, batch: 1556, loss: 1.6494488716125488\n",
      "epoch: 2, batch: 1557, loss: 1.6288509368896484\n",
      "epoch: 2, batch: 1558, loss: 1.6693676710128784\n",
      "epoch: 2, batch: 1559, loss: 1.6601735353469849\n",
      "epoch: 2, batch: 1560, loss: 1.667145013809204\n",
      "epoch: 2, batch: 1561, loss: 1.66791570186615\n",
      "epoch: 2, batch: 1562, loss: 1.5960421562194824\n",
      "epoch: 2, batch: 1563, loss: 1.6768431663513184\n",
      "epoch: 2, batch: 1564, loss: 1.6375778913497925\n",
      "epoch: 2, batch: 1565, loss: 1.6180362701416016\n",
      "epoch: 2, batch: 1566, loss: 1.6350761651992798\n",
      "epoch: 2, batch: 1567, loss: 1.8013044595718384\n",
      "epoch: 2, batch: 1568, loss: 1.5946890115737915\n",
      "epoch: 2, batch: 1569, loss: 1.607092022895813\n",
      "epoch: 2, batch: 1570, loss: 1.596240520477295\n",
      "epoch: 2, batch: 1571, loss: 1.586351752281189\n",
      "epoch: 2, batch: 1572, loss: 1.6070233583450317\n",
      "epoch: 2, batch: 1573, loss: 1.6463457345962524\n",
      "epoch: 2, batch: 1574, loss: 1.6653668880462646\n",
      "epoch: 2, batch: 1575, loss: 1.747473955154419\n",
      "epoch: 2, batch: 1576, loss: 1.558198094367981\n",
      "epoch: 2, batch: 1577, loss: 1.5625215768814087\n",
      "epoch: 2, batch: 1578, loss: 1.5095114707946777\n",
      "epoch: 2, batch: 1579, loss: 1.7358064651489258\n",
      "epoch: 2, batch: 1580, loss: 1.654914140701294\n",
      "epoch: 2, batch: 1581, loss: 1.5982437133789062\n",
      "epoch: 2, batch: 1582, loss: 1.5613932609558105\n",
      "epoch: 2, batch: 1583, loss: 1.6011732816696167\n",
      "epoch: 2, batch: 1584, loss: 1.52969229221344\n",
      "epoch: 2, batch: 1585, loss: 1.7002644538879395\n",
      "epoch: 2, batch: 1586, loss: 1.6511716842651367\n",
      "epoch: 2, batch: 1587, loss: 1.5269042253494263\n",
      "epoch: 2, batch: 1588, loss: 1.6316015720367432\n",
      "epoch: 2, batch: 1589, loss: 1.7157254219055176\n",
      "epoch: 2, batch: 1590, loss: 1.570927619934082\n",
      "epoch: 2, batch: 1591, loss: 1.6074837446212769\n",
      "epoch: 2, batch: 1592, loss: 1.5629644393920898\n",
      "epoch: 2, batch: 1593, loss: 1.5973783731460571\n",
      "epoch: 2, batch: 1594, loss: 1.6032979488372803\n",
      "epoch: 2, batch: 1595, loss: 1.685302495956421\n",
      "epoch: 2, batch: 1596, loss: 1.673568844795227\n",
      "epoch: 2, batch: 1597, loss: 1.536574363708496\n",
      "epoch: 2, batch: 1598, loss: 1.6376595497131348\n",
      "epoch: 2, batch: 1599, loss: 1.732163429260254\n",
      "epoch: 2, batch: 1600, loss: 1.7154909372329712\n",
      "epoch: 2, batch: 1601, loss: 1.634554147720337\n",
      "epoch: 2, batch: 1602, loss: 1.596501350402832\n",
      "epoch: 2, batch: 1603, loss: 1.7347062826156616\n",
      "epoch: 2, batch: 1604, loss: 1.6921554803848267\n",
      "epoch: 2, batch: 1605, loss: 1.5721051692962646\n",
      "epoch: 2, batch: 1606, loss: 1.5948607921600342\n",
      "epoch: 2, batch: 1607, loss: 1.5969672203063965\n",
      "epoch: 2, batch: 1608, loss: 1.5931061506271362\n",
      "epoch: 2, batch: 1609, loss: 1.614991545677185\n",
      "epoch: 2, batch: 1610, loss: 1.664581060409546\n",
      "epoch: 2, batch: 1611, loss: 1.6309486627578735\n",
      "epoch: 2, batch: 1612, loss: 1.6843024492263794\n",
      "epoch: 2, batch: 1613, loss: 1.6412556171417236\n",
      "epoch: 2, batch: 1614, loss: 1.7116726636886597\n",
      "epoch: 2, batch: 1615, loss: 1.6921308040618896\n",
      "epoch: 2, batch: 1616, loss: 1.6001771688461304\n",
      "epoch: 2, batch: 1617, loss: 1.5996601581573486\n",
      "epoch: 2, batch: 1618, loss: 1.617112636566162\n",
      "epoch: 2, batch: 1619, loss: 1.6606146097183228\n",
      "epoch: 2, batch: 1620, loss: 1.753868818283081\n",
      "epoch: 2, batch: 1621, loss: 1.5984392166137695\n",
      "epoch: 2, batch: 1622, loss: 1.5789923667907715\n",
      "epoch: 2, batch: 1623, loss: 1.5869933366775513\n",
      "epoch: 2, batch: 1624, loss: 1.5587786436080933\n",
      "epoch: 2, batch: 1625, loss: 1.551347255706787\n",
      "epoch: 2, batch: 1626, loss: 1.76310396194458\n",
      "epoch: 2, batch: 1627, loss: 1.7088419198989868\n",
      "epoch: 2, batch: 1628, loss: 1.6404964923858643\n",
      "epoch: 2, batch: 1629, loss: 1.521111249923706\n",
      "epoch: 2, batch: 1630, loss: 1.6383390426635742\n",
      "epoch: 2, batch: 1631, loss: 1.532233476638794\n",
      "epoch: 2, batch: 1632, loss: 1.646791696548462\n",
      "epoch: 2, batch: 1633, loss: 1.6074113845825195\n",
      "epoch: 2, batch: 1634, loss: 1.5762369632720947\n",
      "epoch: 2, batch: 1635, loss: 1.7642351388931274\n",
      "epoch: 2, batch: 1636, loss: 1.7685158252716064\n",
      "epoch: 2, batch: 1637, loss: 1.6878188848495483\n",
      "epoch: 2, batch: 1638, loss: 1.6860699653625488\n",
      "epoch: 2, batch: 1639, loss: 1.607820987701416\n",
      "epoch: 2, batch: 1640, loss: 1.7565817832946777\n",
      "epoch: 2, batch: 1641, loss: 1.6551741361618042\n",
      "epoch: 2, batch: 1642, loss: 1.7182551622390747\n",
      "epoch: 2, batch: 1643, loss: 1.7177903652191162\n",
      "epoch: 2, batch: 1644, loss: 1.5371636152267456\n",
      "epoch: 2, batch: 1645, loss: 1.6843923330307007\n",
      "epoch: 2, batch: 1646, loss: 1.5924365520477295\n",
      "epoch: 2, batch: 1647, loss: 1.6239421367645264\n",
      "epoch: 2, batch: 1648, loss: 1.4872721433639526\n",
      "epoch: 2, batch: 1649, loss: 1.6788440942764282\n",
      "epoch: 2, batch: 1650, loss: 1.596258521080017\n",
      "epoch: 2, batch: 1651, loss: 1.6536436080932617\n",
      "epoch: 2, batch: 1652, loss: 1.5853962898254395\n",
      "epoch: 2, batch: 1653, loss: 1.5944336652755737\n",
      "epoch: 2, batch: 1654, loss: 1.6416542530059814\n",
      "epoch: 2, batch: 1655, loss: 1.643171787261963\n",
      "epoch: 2, batch: 1656, loss: 1.6912200450897217\n",
      "epoch: 2, batch: 1657, loss: 1.6383249759674072\n",
      "epoch: 2, batch: 1658, loss: 1.4879655838012695\n",
      "epoch: 2, batch: 1659, loss: 1.5610876083374023\n",
      "epoch: 2, batch: 1660, loss: 1.5233428478240967\n",
      "epoch: 2, batch: 1661, loss: 1.6721638441085815\n",
      "epoch: 2, batch: 1662, loss: 1.7314447164535522\n",
      "epoch: 2, batch: 1663, loss: 1.685301661491394\n",
      "epoch: 2, batch: 1664, loss: 1.7224582433700562\n",
      "epoch: 2, batch: 1665, loss: 1.4951529502868652\n",
      "epoch: 2, batch: 1666, loss: 1.6238179206848145\n",
      "epoch: 2, batch: 1667, loss: 1.7102327346801758\n",
      "epoch: 2, batch: 1668, loss: 1.529907464981079\n",
      "epoch: 2, batch: 1669, loss: 1.520420789718628\n",
      "epoch: 2, batch: 1670, loss: 1.5853583812713623\n",
      "epoch: 2, batch: 1671, loss: 1.5879749059677124\n",
      "epoch: 2, batch: 1672, loss: 1.6247797012329102\n",
      "epoch: 2, batch: 1673, loss: 1.627730131149292\n",
      "epoch: 2, batch: 1674, loss: 1.476715326309204\n",
      "epoch: 2, batch: 1675, loss: 1.6021921634674072\n",
      "epoch: 2, batch: 1676, loss: 1.4956212043762207\n",
      "epoch: 2, batch: 1677, loss: 1.5005770921707153\n",
      "epoch: 2, batch: 1678, loss: 1.6018939018249512\n",
      "epoch: 2, batch: 1679, loss: 1.6443250179290771\n",
      "epoch: 2, batch: 1680, loss: 1.6073391437530518\n",
      "epoch: 2, batch: 1681, loss: 1.6325106620788574\n",
      "epoch: 2, batch: 1682, loss: 1.5636160373687744\n",
      "epoch: 2, batch: 1683, loss: 1.688091516494751\n",
      "epoch: 2, batch: 1684, loss: 1.502049446105957\n",
      "epoch: 2, batch: 1685, loss: 1.587033987045288\n",
      "epoch: 2, batch: 1686, loss: 1.533094882965088\n",
      "epoch: 2, batch: 1687, loss: 1.5624234676361084\n",
      "epoch: 2, batch: 1688, loss: 1.7232210636138916\n",
      "epoch: 2, batch: 1689, loss: 1.5194733142852783\n",
      "epoch: 2, batch: 1690, loss: 1.6201186180114746\n",
      "epoch: 2, batch: 1691, loss: 1.6056132316589355\n",
      "epoch: 2, batch: 1692, loss: 1.4995805025100708\n",
      "epoch: 2, batch: 1693, loss: 1.580384612083435\n",
      "epoch: 2, batch: 1694, loss: 1.6680325269699097\n",
      "epoch: 2, batch: 1695, loss: 1.73930823802948\n",
      "epoch: 2, batch: 1696, loss: 1.6058590412139893\n",
      "epoch: 2, batch: 1697, loss: 1.5555026531219482\n",
      "epoch: 2, batch: 1698, loss: 1.6233900785446167\n",
      "epoch: 2, batch: 1699, loss: 1.5385911464691162\n",
      "epoch: 2, batch: 1700, loss: 1.4950807094573975\n",
      "epoch: 2, batch: 1701, loss: 1.6201919317245483\n",
      "epoch: 2, batch: 1702, loss: 1.5449355840682983\n",
      "epoch: 2, batch: 1703, loss: 1.4923772811889648\n",
      "epoch: 2, batch: 1704, loss: 1.6105185747146606\n",
      "epoch: 2, batch: 1705, loss: 1.4580714702606201\n",
      "epoch: 2, batch: 1706, loss: 1.6550540924072266\n",
      "epoch: 2, batch: 1707, loss: 1.6281392574310303\n",
      "epoch: 2, batch: 1708, loss: 1.6060566902160645\n",
      "epoch: 2, batch: 1709, loss: 1.6475528478622437\n",
      "epoch: 2, batch: 1710, loss: 1.5884073972702026\n",
      "epoch: 2, batch: 1711, loss: 1.6065466403961182\n",
      "epoch: 2, batch: 1712, loss: 1.5888382196426392\n",
      "epoch: 2, batch: 1713, loss: 1.7391985654830933\n",
      "epoch: 2, batch: 1714, loss: 1.7236655950546265\n",
      "epoch: 2, batch: 1715, loss: 1.6721051931381226\n",
      "epoch: 2, batch: 1716, loss: 1.5172615051269531\n",
      "epoch: 2, batch: 1717, loss: 1.511181116104126\n",
      "epoch: 2, batch: 1718, loss: 1.4911203384399414\n",
      "epoch: 2, batch: 1719, loss: 1.6322178840637207\n",
      "epoch: 2, batch: 1720, loss: 1.6601958274841309\n",
      "epoch: 2, batch: 1721, loss: 1.6981017589569092\n",
      "epoch: 2, batch: 1722, loss: 1.68149995803833\n",
      "epoch: 2, batch: 1723, loss: 1.6880005598068237\n",
      "epoch: 2, batch: 1724, loss: 1.6568090915679932\n",
      "epoch: 2, batch: 1725, loss: 1.5779286623001099\n",
      "epoch: 2, batch: 1726, loss: 1.7051352262496948\n",
      "epoch: 2, batch: 1727, loss: 1.6003611087799072\n",
      "epoch: 2, batch: 1728, loss: 1.6960307359695435\n",
      "epoch: 2, batch: 1729, loss: 1.5619969367980957\n",
      "epoch: 2, batch: 1730, loss: 1.5844192504882812\n",
      "epoch: 2, batch: 1731, loss: 1.5301324129104614\n",
      "epoch: 2, batch: 1732, loss: 1.6806869506835938\n",
      "epoch: 2, batch: 1733, loss: 1.6549746990203857\n",
      "epoch: 2, batch: 1734, loss: 1.7021666765213013\n",
      "epoch: 2, batch: 1735, loss: 1.603621244430542\n",
      "epoch: 2, batch: 1736, loss: 1.5385159254074097\n",
      "epoch: 2, batch: 1737, loss: 1.5641242265701294\n",
      "epoch: 2, batch: 1738, loss: 1.5847078561782837\n",
      "epoch: 2, batch: 1739, loss: 1.5617951154708862\n",
      "epoch: 2, batch: 1740, loss: 1.6799615621566772\n",
      "epoch: 2, batch: 1741, loss: 1.7551630735397339\n",
      "epoch: 2, batch: 1742, loss: 1.7238330841064453\n",
      "epoch: 2, batch: 1743, loss: 1.5816401243209839\n",
      "epoch: 2, batch: 1744, loss: 1.5511043071746826\n",
      "epoch: 2, batch: 1745, loss: 1.486301302909851\n",
      "epoch: 2, batch: 1746, loss: 1.5647082328796387\n",
      "epoch: 2, batch: 1747, loss: 1.507311224937439\n",
      "epoch: 2, batch: 1748, loss: 1.6039026975631714\n",
      "epoch: 2, batch: 1749, loss: 1.6585725545883179\n",
      "epoch: 2, batch: 1750, loss: 1.7482664585113525\n",
      "epoch: 2, batch: 1751, loss: 1.5251613855361938\n",
      "epoch: 2, batch: 1752, loss: 1.6307954788208008\n",
      "epoch: 2, batch: 1753, loss: 1.5232300758361816\n",
      "epoch: 2, batch: 1754, loss: 1.473090410232544\n",
      "epoch: 2, batch: 1755, loss: 1.644108772277832\n",
      "epoch: 2, batch: 1756, loss: 1.6541188955307007\n",
      "epoch: 2, batch: 1757, loss: 1.6135649681091309\n",
      "epoch: 2, batch: 1758, loss: 1.5205687284469604\n",
      "epoch: 2, batch: 1759, loss: 1.61982262134552\n",
      "epoch: 2, batch: 1760, loss: 1.5473147630691528\n",
      "epoch: 2, batch: 1761, loss: 1.569643259048462\n",
      "epoch: 2, batch: 1762, loss: 1.6985092163085938\n",
      "epoch: 2, batch: 1763, loss: 1.6107858419418335\n",
      "epoch: 2, batch: 1764, loss: 1.545201301574707\n",
      "epoch: 2, batch: 1765, loss: 1.4994760751724243\n",
      "epoch: 2, batch: 1766, loss: 1.5874227285385132\n",
      "epoch: 2, batch: 1767, loss: 1.55580735206604\n",
      "epoch: 2, batch: 1768, loss: 1.413577675819397\n",
      "epoch: 2, batch: 1769, loss: 1.5615246295928955\n",
      "epoch: 2, batch: 1770, loss: 1.6513473987579346\n",
      "epoch: 2, batch: 1771, loss: 1.6437909603118896\n",
      "epoch: 2, batch: 1772, loss: 1.4983445405960083\n",
      "epoch: 2, batch: 1773, loss: 1.5490357875823975\n",
      "epoch: 2, batch: 1774, loss: 1.4378360509872437\n",
      "epoch: 2, batch: 1775, loss: 1.5705190896987915\n",
      "epoch: 2, batch: 1776, loss: 1.5119099617004395\n",
      "epoch: 2, batch: 1777, loss: 1.6965491771697998\n",
      "epoch: 2, batch: 1778, loss: 1.5701013803482056\n",
      "epoch: 2, batch: 1779, loss: 1.6032710075378418\n",
      "epoch: 2, batch: 1780, loss: 1.4812465906143188\n",
      "epoch: 2, batch: 1781, loss: 1.5054724216461182\n",
      "epoch: 2, batch: 1782, loss: 1.626819372177124\n",
      "epoch: 2, batch: 1783, loss: 1.6527103185653687\n",
      "epoch: 2, batch: 1784, loss: 1.6288007497787476\n",
      "epoch: 2, batch: 1785, loss: 1.629015564918518\n",
      "epoch: 2, batch: 1786, loss: 1.7129392623901367\n",
      "epoch: 2, batch: 1787, loss: 1.676807165145874\n",
      "epoch: 2, batch: 1788, loss: 1.8092408180236816\n",
      "epoch: 2, batch: 1789, loss: 1.600121021270752\n",
      "epoch: 2, batch: 1790, loss: 1.6580877304077148\n",
      "epoch: 2, batch: 1791, loss: 1.6567858457565308\n",
      "epoch: 2, batch: 1792, loss: 1.529566764831543\n",
      "epoch: 2, batch: 1793, loss: 1.6607602834701538\n",
      "epoch: 2, batch: 1794, loss: 1.542470932006836\n",
      "epoch: 2, batch: 1795, loss: 1.5820151567459106\n",
      "epoch: 2, batch: 1796, loss: 1.5767568349838257\n",
      "epoch: 2, batch: 1797, loss: 1.5528355836868286\n",
      "epoch: 2, batch: 1798, loss: 1.6920489072799683\n",
      "epoch: 2, batch: 1799, loss: 1.651351809501648\n",
      "epoch: 2, batch: 1800, loss: 1.5988456010818481\n",
      "epoch: 2, batch: 1801, loss: 1.5847346782684326\n",
      "epoch: 2, batch: 1802, loss: 1.534764289855957\n",
      "epoch: 2, batch: 1803, loss: 1.5236151218414307\n",
      "epoch: 2, batch: 1804, loss: 1.6624727249145508\n",
      "epoch: 2, batch: 1805, loss: 1.5419920682907104\n",
      "epoch: 2, batch: 1806, loss: 1.582483172416687\n",
      "epoch: 2, batch: 1807, loss: 1.523154377937317\n",
      "epoch: 2, batch: 1808, loss: 1.4981733560562134\n",
      "epoch: 2, batch: 1809, loss: 1.5693695545196533\n",
      "epoch: 2, batch: 1810, loss: 1.6047143936157227\n",
      "epoch: 2, batch: 1811, loss: 1.5276281833648682\n",
      "epoch: 2, batch: 1812, loss: 1.663352370262146\n",
      "epoch: 2, batch: 1813, loss: 1.5658996105194092\n",
      "epoch: 2, batch: 1814, loss: 1.611979365348816\n",
      "epoch: 2, batch: 1815, loss: 1.552566409111023\n",
      "epoch: 2, batch: 1816, loss: 1.555059552192688\n",
      "epoch: 2, batch: 1817, loss: 1.5226092338562012\n",
      "epoch: 2, batch: 1818, loss: 1.6664024591445923\n",
      "epoch: 2, batch: 1819, loss: 1.59402334690094\n",
      "epoch: 2, batch: 1820, loss: 1.6055614948272705\n",
      "epoch: 2, batch: 1821, loss: 1.5621631145477295\n",
      "epoch: 2, batch: 1822, loss: 1.5417921543121338\n",
      "epoch: 2, batch: 1823, loss: 1.5920852422714233\n",
      "epoch: 2, batch: 1824, loss: 1.569728136062622\n",
      "epoch: 2, batch: 1825, loss: 1.548183560371399\n",
      "epoch: 2, batch: 1826, loss: 1.538490891456604\n",
      "epoch: 2, batch: 1827, loss: 1.6402400732040405\n",
      "epoch: 2, batch: 1828, loss: 1.4762755632400513\n",
      "epoch: 2, batch: 1829, loss: 1.650600790977478\n",
      "epoch: 2, batch: 1830, loss: 1.4529359340667725\n",
      "epoch: 2, batch: 1831, loss: 1.6091715097427368\n",
      "epoch: 2, batch: 1832, loss: 1.4269115924835205\n",
      "epoch: 2, batch: 1833, loss: 1.517582893371582\n",
      "epoch: 2, batch: 1834, loss: 1.4695621728897095\n",
      "epoch: 2, batch: 1835, loss: 1.443548321723938\n",
      "epoch: 2, batch: 1836, loss: 1.5147055387496948\n",
      "epoch: 2, batch: 1837, loss: 1.5245816707611084\n",
      "epoch: 2, batch: 1838, loss: 1.4726343154907227\n",
      "epoch: 2, batch: 1839, loss: 1.6206934452056885\n",
      "epoch: 2, batch: 1840, loss: 1.6155943870544434\n",
      "epoch: 2, batch: 1841, loss: 1.5100550651550293\n",
      "epoch: 2, batch: 1842, loss: 1.5090980529785156\n",
      "epoch: 2, batch: 1843, loss: 1.5308316946029663\n",
      "epoch: 2, batch: 1844, loss: 1.655678153038025\n",
      "epoch: 2, batch: 1845, loss: 1.6631301641464233\n",
      "epoch: 2, batch: 1846, loss: 1.4653173685073853\n",
      "epoch: 2, batch: 1847, loss: 1.3509610891342163\n",
      "epoch: 2, batch: 1848, loss: 1.653469443321228\n",
      "epoch: 2, batch: 1849, loss: 1.5720618963241577\n",
      "epoch: 2, batch: 1850, loss: 1.5384656190872192\n",
      "epoch: 2, batch: 1851, loss: 1.4936343431472778\n",
      "epoch: 2, batch: 1852, loss: 1.6017627716064453\n",
      "epoch: 2, batch: 1853, loss: 1.4416165351867676\n",
      "epoch: 2, batch: 1854, loss: 1.5327280759811401\n",
      "epoch: 2, batch: 1855, loss: 1.577510952949524\n",
      "epoch: 2, batch: 1856, loss: 1.6299608945846558\n",
      "epoch: 2, batch: 1857, loss: 1.5465296506881714\n",
      "epoch: 2, batch: 1858, loss: 1.5563256740570068\n",
      "epoch: 2, batch: 1859, loss: 1.6125922203063965\n",
      "epoch: 2, batch: 1860, loss: 1.5555484294891357\n",
      "epoch: 2, batch: 1861, loss: 1.439748764038086\n",
      "epoch: 2, batch: 1862, loss: 1.5597279071807861\n",
      "epoch: 2, batch: 1863, loss: 1.4467620849609375\n",
      "epoch: 2, batch: 1864, loss: 1.5171500444412231\n",
      "epoch: 2, batch: 1865, loss: 1.5545850992202759\n",
      "epoch: 2, batch: 1866, loss: 1.4065619707107544\n",
      "epoch: 2, batch: 1867, loss: 1.672041893005371\n",
      "epoch: 2, batch: 1868, loss: 1.532152533531189\n",
      "epoch: 2, batch: 1869, loss: 1.6352430582046509\n",
      "epoch: 2, batch: 1870, loss: 1.4239838123321533\n",
      "epoch: 2, batch: 1871, loss: 1.5640144348144531\n",
      "epoch: 2, batch: 1872, loss: 1.4985663890838623\n",
      "epoch: 2, batch: 1873, loss: 1.584800124168396\n",
      "epoch: 2, batch: 1874, loss: 1.4838228225708008\n",
      "epoch: 3, batch: 0, loss: 1.5756230354309082\n",
      "epoch: 3, batch: 1, loss: 1.576581597328186\n",
      "epoch: 3, batch: 2, loss: 1.6862280368804932\n",
      "epoch: 3, batch: 3, loss: 1.6071875095367432\n",
      "epoch: 3, batch: 4, loss: 1.49772310256958\n",
      "epoch: 3, batch: 5, loss: 1.5105080604553223\n",
      "epoch: 3, batch: 6, loss: 1.4371278285980225\n",
      "epoch: 3, batch: 7, loss: 1.4985806941986084\n",
      "epoch: 3, batch: 8, loss: 1.5241450071334839\n",
      "epoch: 3, batch: 9, loss: 1.642832636833191\n",
      "epoch: 3, batch: 10, loss: 1.4447561502456665\n",
      "epoch: 3, batch: 11, loss: 1.6498472690582275\n",
      "epoch: 3, batch: 12, loss: 1.5052350759506226\n",
      "epoch: 3, batch: 13, loss: 1.5405522584915161\n",
      "epoch: 3, batch: 14, loss: 1.5040866136550903\n",
      "epoch: 3, batch: 15, loss: 1.4026809930801392\n",
      "epoch: 3, batch: 16, loss: 1.3880863189697266\n",
      "epoch: 3, batch: 17, loss: 1.5274560451507568\n",
      "epoch: 3, batch: 18, loss: 1.7665858268737793\n",
      "epoch: 3, batch: 19, loss: 1.6702460050582886\n",
      "epoch: 3, batch: 20, loss: 1.530428171157837\n",
      "epoch: 3, batch: 21, loss: 1.4854562282562256\n",
      "epoch: 3, batch: 22, loss: 1.5256372690200806\n",
      "epoch: 3, batch: 23, loss: 1.5663414001464844\n",
      "epoch: 3, batch: 24, loss: 1.4600900411605835\n",
      "epoch: 3, batch: 25, loss: 1.540588617324829\n",
      "epoch: 3, batch: 26, loss: 1.5789930820465088\n",
      "epoch: 3, batch: 27, loss: 1.479779601097107\n",
      "epoch: 3, batch: 28, loss: 1.5909790992736816\n",
      "epoch: 3, batch: 29, loss: 1.7100324630737305\n",
      "epoch: 3, batch: 30, loss: 1.6177884340286255\n",
      "epoch: 3, batch: 31, loss: 1.5820270776748657\n",
      "epoch: 3, batch: 32, loss: 1.4082227945327759\n",
      "epoch: 3, batch: 33, loss: 1.5521293878555298\n",
      "epoch: 3, batch: 34, loss: 1.5058587789535522\n",
      "epoch: 3, batch: 35, loss: 1.5363045930862427\n",
      "epoch: 3, batch: 36, loss: 1.5481290817260742\n",
      "epoch: 3, batch: 37, loss: 1.5780872106552124\n",
      "epoch: 3, batch: 38, loss: 1.485619068145752\n",
      "epoch: 3, batch: 39, loss: 1.4310466051101685\n",
      "epoch: 3, batch: 40, loss: 1.5958635807037354\n",
      "epoch: 3, batch: 41, loss: 1.4856120347976685\n",
      "epoch: 3, batch: 42, loss: 1.5144569873809814\n",
      "epoch: 3, batch: 43, loss: 1.6701023578643799\n",
      "epoch: 3, batch: 44, loss: 1.3821306228637695\n",
      "epoch: 3, batch: 45, loss: 1.5402435064315796\n",
      "epoch: 3, batch: 46, loss: 1.5034942626953125\n",
      "epoch: 3, batch: 47, loss: 1.4770857095718384\n",
      "epoch: 3, batch: 48, loss: 1.5640430450439453\n",
      "epoch: 3, batch: 49, loss: 1.585709810256958\n",
      "epoch: 3, batch: 50, loss: 1.470035433769226\n",
      "epoch: 3, batch: 51, loss: 1.6367194652557373\n",
      "epoch: 3, batch: 52, loss: 1.6478756666183472\n",
      "epoch: 3, batch: 53, loss: 1.5360674858093262\n",
      "epoch: 3, batch: 54, loss: 1.510457158088684\n",
      "epoch: 3, batch: 55, loss: 1.6303703784942627\n",
      "epoch: 3, batch: 56, loss: 1.6262321472167969\n",
      "epoch: 3, batch: 57, loss: 1.393479347229004\n",
      "epoch: 3, batch: 58, loss: 1.5340733528137207\n",
      "epoch: 3, batch: 59, loss: 1.54989492893219\n",
      "epoch: 3, batch: 60, loss: 1.5976498126983643\n",
      "epoch: 3, batch: 61, loss: 1.6960532665252686\n",
      "epoch: 3, batch: 62, loss: 1.519963026046753\n",
      "epoch: 3, batch: 63, loss: 1.5545092821121216\n",
      "epoch: 3, batch: 64, loss: 1.420179843902588\n",
      "epoch: 3, batch: 65, loss: 1.5135951042175293\n",
      "epoch: 3, batch: 66, loss: 1.5002027750015259\n",
      "epoch: 3, batch: 67, loss: 1.3579951524734497\n",
      "epoch: 3, batch: 68, loss: 1.666279673576355\n",
      "epoch: 3, batch: 69, loss: 1.613566279411316\n",
      "epoch: 3, batch: 70, loss: 1.6021283864974976\n",
      "epoch: 3, batch: 71, loss: 1.4726934432983398\n",
      "epoch: 3, batch: 72, loss: 1.4628911018371582\n",
      "epoch: 3, batch: 73, loss: 1.6033093929290771\n",
      "epoch: 3, batch: 74, loss: 1.4995204210281372\n",
      "epoch: 3, batch: 75, loss: 1.6215864419937134\n",
      "epoch: 3, batch: 76, loss: 1.673303484916687\n",
      "epoch: 3, batch: 77, loss: 1.428776502609253\n",
      "epoch: 3, batch: 78, loss: 1.5790019035339355\n",
      "epoch: 3, batch: 79, loss: 1.4701749086380005\n",
      "epoch: 3, batch: 80, loss: 1.4928942918777466\n",
      "epoch: 3, batch: 81, loss: 1.4654158353805542\n",
      "epoch: 3, batch: 82, loss: 1.4564077854156494\n",
      "epoch: 3, batch: 83, loss: 1.409597635269165\n",
      "epoch: 3, batch: 84, loss: 1.5563794374465942\n",
      "epoch: 3, batch: 85, loss: 1.5496999025344849\n",
      "epoch: 3, batch: 86, loss: 1.391111969947815\n",
      "epoch: 3, batch: 87, loss: 1.3559134006500244\n",
      "epoch: 3, batch: 88, loss: 1.4062987565994263\n",
      "epoch: 3, batch: 89, loss: 1.458965539932251\n",
      "epoch: 3, batch: 90, loss: 1.5857361555099487\n",
      "epoch: 3, batch: 91, loss: 1.4274139404296875\n",
      "epoch: 3, batch: 92, loss: 1.6080057621002197\n",
      "epoch: 3, batch: 93, loss: 1.431907057762146\n",
      "epoch: 3, batch: 94, loss: 1.4969388246536255\n",
      "epoch: 3, batch: 95, loss: 1.4392995834350586\n",
      "epoch: 3, batch: 96, loss: 1.4371953010559082\n",
      "epoch: 3, batch: 97, loss: 1.6136417388916016\n",
      "epoch: 3, batch: 98, loss: 1.5026824474334717\n",
      "epoch: 3, batch: 99, loss: 1.5162023305892944\n",
      "epoch: 3, batch: 100, loss: 1.634611964225769\n",
      "epoch: 3, batch: 101, loss: 1.6115913391113281\n",
      "epoch: 3, batch: 102, loss: 1.445863962173462\n",
      "epoch: 3, batch: 103, loss: 1.6276036500930786\n",
      "epoch: 3, batch: 104, loss: 1.4617230892181396\n",
      "epoch: 3, batch: 105, loss: 1.4214495420455933\n",
      "epoch: 3, batch: 106, loss: 1.6574305295944214\n",
      "epoch: 3, batch: 107, loss: 1.511188268661499\n",
      "epoch: 3, batch: 108, loss: 1.366869568824768\n",
      "epoch: 3, batch: 109, loss: 1.5917350053787231\n",
      "epoch: 3, batch: 110, loss: 1.5413588285446167\n",
      "epoch: 3, batch: 111, loss: 1.5320274829864502\n",
      "epoch: 3, batch: 112, loss: 1.4423925876617432\n",
      "epoch: 3, batch: 113, loss: 1.447161078453064\n",
      "epoch: 3, batch: 114, loss: 1.497534155845642\n",
      "epoch: 3, batch: 115, loss: 1.4582633972167969\n",
      "epoch: 3, batch: 116, loss: 1.5115859508514404\n",
      "epoch: 3, batch: 117, loss: 1.4311234951019287\n",
      "epoch: 3, batch: 118, loss: 1.7499580383300781\n",
      "epoch: 3, batch: 119, loss: 1.5584721565246582\n",
      "epoch: 3, batch: 120, loss: 1.5127981901168823\n",
      "epoch: 3, batch: 121, loss: 1.6243765354156494\n",
      "epoch: 3, batch: 122, loss: 1.6809277534484863\n",
      "epoch: 3, batch: 123, loss: 1.3852053880691528\n",
      "epoch: 3, batch: 124, loss: 1.5630534887313843\n",
      "epoch: 3, batch: 125, loss: 1.6296827793121338\n",
      "epoch: 3, batch: 126, loss: 1.4864461421966553\n",
      "epoch: 3, batch: 127, loss: 1.5015039443969727\n",
      "epoch: 3, batch: 128, loss: 1.4836989641189575\n",
      "epoch: 3, batch: 129, loss: 1.4665695428848267\n",
      "epoch: 3, batch: 130, loss: 1.6676750183105469\n",
      "epoch: 3, batch: 131, loss: 1.376367211341858\n",
      "epoch: 3, batch: 132, loss: 1.3919631242752075\n",
      "epoch: 3, batch: 133, loss: 1.3061301708221436\n",
      "epoch: 3, batch: 134, loss: 1.4374284744262695\n",
      "epoch: 3, batch: 135, loss: 1.393975019454956\n",
      "epoch: 3, batch: 136, loss: 1.4947081804275513\n",
      "epoch: 3, batch: 137, loss: 1.333514928817749\n",
      "epoch: 3, batch: 138, loss: 1.5864781141281128\n",
      "epoch: 3, batch: 139, loss: 1.3692339658737183\n",
      "epoch: 3, batch: 140, loss: 1.3964347839355469\n",
      "epoch: 3, batch: 141, loss: 1.3370232582092285\n",
      "epoch: 3, batch: 142, loss: 1.4648953676223755\n",
      "epoch: 3, batch: 143, loss: 1.6007943153381348\n",
      "epoch: 3, batch: 144, loss: 1.3695870637893677\n",
      "epoch: 3, batch: 145, loss: 1.4354861974716187\n",
      "epoch: 3, batch: 146, loss: 1.3703804016113281\n",
      "epoch: 3, batch: 147, loss: 1.3937056064605713\n",
      "epoch: 3, batch: 148, loss: 1.3819888830184937\n",
      "epoch: 3, batch: 149, loss: 1.5324774980545044\n",
      "epoch: 3, batch: 150, loss: 1.481396198272705\n",
      "epoch: 3, batch: 151, loss: 1.436159372329712\n",
      "epoch: 3, batch: 152, loss: 1.61629319190979\n",
      "epoch: 3, batch: 153, loss: 1.5317323207855225\n",
      "epoch: 3, batch: 154, loss: 1.4124892950057983\n",
      "epoch: 3, batch: 155, loss: 1.5719496011734009\n",
      "epoch: 3, batch: 156, loss: 1.457880973815918\n",
      "epoch: 3, batch: 157, loss: 1.3292096853256226\n",
      "epoch: 3, batch: 158, loss: 1.320906639099121\n",
      "epoch: 3, batch: 159, loss: 1.4273418188095093\n",
      "epoch: 3, batch: 160, loss: 1.4208014011383057\n",
      "epoch: 3, batch: 161, loss: 1.4705359935760498\n",
      "epoch: 3, batch: 162, loss: 1.5543229579925537\n",
      "epoch: 3, batch: 163, loss: 1.3571103811264038\n",
      "epoch: 3, batch: 164, loss: 1.451062798500061\n",
      "epoch: 3, batch: 165, loss: 1.4735580682754517\n",
      "epoch: 3, batch: 166, loss: 1.4663535356521606\n",
      "epoch: 3, batch: 167, loss: 1.5203670263290405\n",
      "epoch: 3, batch: 168, loss: 1.4103707075119019\n",
      "epoch: 3, batch: 169, loss: 1.3695430755615234\n",
      "epoch: 3, batch: 170, loss: 1.559061050415039\n",
      "epoch: 3, batch: 171, loss: 1.458985447883606\n",
      "epoch: 3, batch: 172, loss: 1.397413730621338\n",
      "epoch: 3, batch: 173, loss: 1.4716527462005615\n",
      "epoch: 3, batch: 174, loss: 1.407920241355896\n",
      "epoch: 3, batch: 175, loss: 1.34514582157135\n",
      "epoch: 3, batch: 176, loss: 1.3622517585754395\n",
      "epoch: 3, batch: 177, loss: 1.462398648262024\n",
      "epoch: 3, batch: 178, loss: 1.50575852394104\n",
      "epoch: 3, batch: 179, loss: 1.5593417882919312\n",
      "epoch: 3, batch: 180, loss: 1.4272946119308472\n",
      "epoch: 3, batch: 181, loss: 1.4842867851257324\n",
      "epoch: 3, batch: 182, loss: 1.320586919784546\n",
      "epoch: 3, batch: 183, loss: 1.3305079936981201\n",
      "epoch: 3, batch: 184, loss: 1.4684427976608276\n",
      "epoch: 3, batch: 185, loss: 1.51052725315094\n",
      "epoch: 3, batch: 186, loss: 1.5344539880752563\n",
      "epoch: 3, batch: 187, loss: 1.5980523824691772\n",
      "epoch: 3, batch: 188, loss: 1.3293458223342896\n",
      "epoch: 3, batch: 189, loss: 1.5675818920135498\n",
      "epoch: 3, batch: 190, loss: 1.5604498386383057\n",
      "epoch: 3, batch: 191, loss: 1.4350966215133667\n",
      "epoch: 3, batch: 192, loss: 1.4172592163085938\n",
      "epoch: 3, batch: 193, loss: 1.542673110961914\n",
      "epoch: 3, batch: 194, loss: 1.5247803926467896\n",
      "epoch: 3, batch: 195, loss: 1.5695040225982666\n",
      "epoch: 3, batch: 196, loss: 1.3789219856262207\n",
      "epoch: 3, batch: 197, loss: 1.3998222351074219\n",
      "epoch: 3, batch: 198, loss: 1.3669137954711914\n",
      "epoch: 3, batch: 199, loss: 1.4410532712936401\n",
      "epoch: 3, batch: 200, loss: 1.5009132623672485\n",
      "epoch: 3, batch: 201, loss: 1.5252476930618286\n",
      "epoch: 3, batch: 202, loss: 1.4723689556121826\n",
      "epoch: 3, batch: 203, loss: 1.496986985206604\n",
      "epoch: 3, batch: 204, loss: 1.5494662523269653\n",
      "epoch: 3, batch: 205, loss: 1.4181715250015259\n",
      "epoch: 3, batch: 206, loss: 1.459973692893982\n",
      "epoch: 3, batch: 207, loss: 1.3624531030654907\n",
      "epoch: 3, batch: 208, loss: 1.5223454236984253\n",
      "epoch: 3, batch: 209, loss: 1.4489037990570068\n",
      "epoch: 3, batch: 210, loss: 1.395951509475708\n",
      "epoch: 3, batch: 211, loss: 1.5719938278198242\n",
      "epoch: 3, batch: 212, loss: 1.5114444494247437\n",
      "epoch: 3, batch: 213, loss: 1.5469390153884888\n",
      "epoch: 3, batch: 214, loss: 1.4025211334228516\n",
      "epoch: 3, batch: 215, loss: 1.5251356363296509\n",
      "epoch: 3, batch: 216, loss: 1.4523108005523682\n",
      "epoch: 3, batch: 217, loss: 1.3098279237747192\n",
      "epoch: 3, batch: 218, loss: 1.5263161659240723\n",
      "epoch: 3, batch: 219, loss: 1.3788975477218628\n",
      "epoch: 3, batch: 220, loss: 1.5329129695892334\n",
      "epoch: 3, batch: 221, loss: 1.3007116317749023\n",
      "epoch: 3, batch: 222, loss: 1.430065631866455\n",
      "epoch: 3, batch: 223, loss: 1.4684929847717285\n",
      "epoch: 3, batch: 224, loss: 1.484879493713379\n",
      "epoch: 3, batch: 225, loss: 1.3779659271240234\n",
      "epoch: 3, batch: 226, loss: 1.5046709775924683\n",
      "epoch: 3, batch: 227, loss: 1.5079786777496338\n",
      "epoch: 3, batch: 228, loss: 1.390805959701538\n",
      "epoch: 3, batch: 229, loss: 1.4432610273361206\n",
      "epoch: 3, batch: 230, loss: 1.5395207405090332\n",
      "epoch: 3, batch: 231, loss: 1.372004508972168\n",
      "epoch: 3, batch: 232, loss: 1.471590518951416\n",
      "epoch: 3, batch: 233, loss: 1.499197006225586\n",
      "epoch: 3, batch: 234, loss: 1.3866411447525024\n",
      "epoch: 3, batch: 235, loss: 1.3920916318893433\n",
      "epoch: 3, batch: 236, loss: 1.392432689666748\n",
      "epoch: 3, batch: 237, loss: 1.4955451488494873\n",
      "epoch: 3, batch: 238, loss: 1.4324170351028442\n",
      "epoch: 3, batch: 239, loss: 1.6557992696762085\n",
      "epoch: 3, batch: 240, loss: 1.398622751235962\n",
      "epoch: 3, batch: 241, loss: 1.470884919166565\n",
      "epoch: 3, batch: 242, loss: 1.4289010763168335\n",
      "epoch: 3, batch: 243, loss: 1.331856608390808\n",
      "epoch: 3, batch: 244, loss: 1.3597584962844849\n",
      "epoch: 3, batch: 245, loss: 1.473824143409729\n",
      "epoch: 3, batch: 246, loss: 1.5651403665542603\n",
      "epoch: 3, batch: 247, loss: 1.619939923286438\n",
      "epoch: 3, batch: 248, loss: 1.3116554021835327\n",
      "epoch: 3, batch: 249, loss: 1.480268955230713\n",
      "epoch: 3, batch: 250, loss: 1.4197666645050049\n",
      "epoch: 3, batch: 251, loss: 1.5048058032989502\n",
      "epoch: 3, batch: 252, loss: 1.6026889085769653\n",
      "epoch: 3, batch: 253, loss: 1.4922511577606201\n",
      "epoch: 3, batch: 254, loss: 1.4791871309280396\n",
      "epoch: 3, batch: 255, loss: 1.387121319770813\n",
      "epoch: 3, batch: 256, loss: 1.4485405683517456\n",
      "epoch: 3, batch: 257, loss: 1.4814753532409668\n",
      "epoch: 3, batch: 258, loss: 1.426889419555664\n",
      "epoch: 3, batch: 259, loss: 1.3294353485107422\n",
      "epoch: 3, batch: 260, loss: 1.412475347518921\n",
      "epoch: 3, batch: 261, loss: 1.4140210151672363\n",
      "epoch: 3, batch: 262, loss: 1.6269055604934692\n",
      "epoch: 3, batch: 263, loss: 1.3626682758331299\n",
      "epoch: 3, batch: 264, loss: 1.42538321018219\n",
      "epoch: 3, batch: 265, loss: 1.5111647844314575\n",
      "epoch: 3, batch: 266, loss: 1.4442470073699951\n",
      "epoch: 3, batch: 267, loss: 1.501003384590149\n",
      "epoch: 3, batch: 268, loss: 1.4689124822616577\n",
      "epoch: 3, batch: 269, loss: 1.3352439403533936\n",
      "epoch: 3, batch: 270, loss: 1.366206169128418\n",
      "epoch: 3, batch: 271, loss: 1.3082125186920166\n",
      "epoch: 3, batch: 272, loss: 1.598347544670105\n",
      "epoch: 3, batch: 273, loss: 1.3228464126586914\n",
      "epoch: 3, batch: 274, loss: 1.4399592876434326\n",
      "epoch: 3, batch: 275, loss: 1.3567512035369873\n",
      "epoch: 3, batch: 276, loss: 1.3818143606185913\n",
      "epoch: 3, batch: 277, loss: 1.5650986433029175\n",
      "epoch: 3, batch: 278, loss: 1.488102674484253\n",
      "epoch: 3, batch: 279, loss: 1.253060221672058\n",
      "epoch: 3, batch: 280, loss: 1.4877763986587524\n",
      "epoch: 3, batch: 281, loss: 1.4343900680541992\n",
      "epoch: 3, batch: 282, loss: 1.3644981384277344\n",
      "epoch: 3, batch: 283, loss: 1.3928217887878418\n",
      "epoch: 3, batch: 284, loss: 1.4010701179504395\n",
      "epoch: 3, batch: 285, loss: 1.4584569931030273\n",
      "epoch: 3, batch: 286, loss: 1.6659173965454102\n",
      "epoch: 3, batch: 287, loss: 1.5285450220108032\n",
      "epoch: 3, batch: 288, loss: 1.4176069498062134\n",
      "epoch: 3, batch: 289, loss: 1.4646847248077393\n",
      "epoch: 3, batch: 290, loss: 1.4771702289581299\n",
      "epoch: 3, batch: 291, loss: 1.2793924808502197\n",
      "epoch: 3, batch: 292, loss: 1.6012922525405884\n",
      "epoch: 3, batch: 293, loss: 1.4045965671539307\n",
      "epoch: 3, batch: 294, loss: 1.4730757474899292\n",
      "epoch: 3, batch: 295, loss: 1.2808966636657715\n",
      "epoch: 3, batch: 296, loss: 1.449222207069397\n",
      "epoch: 3, batch: 297, loss: 1.4306488037109375\n",
      "epoch: 3, batch: 298, loss: 1.5163192749023438\n",
      "epoch: 3, batch: 299, loss: 1.5710757970809937\n",
      "epoch: 3, batch: 300, loss: 1.5620639324188232\n",
      "epoch: 3, batch: 301, loss: 1.4640361070632935\n",
      "epoch: 3, batch: 302, loss: 1.5463165044784546\n",
      "epoch: 3, batch: 303, loss: 1.4543789625167847\n",
      "epoch: 3, batch: 304, loss: 1.5099354982376099\n",
      "epoch: 3, batch: 305, loss: 1.4178893566131592\n",
      "epoch: 3, batch: 306, loss: 1.4705084562301636\n",
      "epoch: 3, batch: 307, loss: 1.4986164569854736\n",
      "epoch: 3, batch: 308, loss: 1.538644790649414\n",
      "epoch: 3, batch: 309, loss: 1.3789830207824707\n",
      "epoch: 3, batch: 310, loss: 1.499325156211853\n",
      "epoch: 3, batch: 311, loss: 1.504393219947815\n",
      "epoch: 3, batch: 312, loss: 1.3569990396499634\n",
      "epoch: 3, batch: 313, loss: 1.3994295597076416\n",
      "epoch: 3, batch: 314, loss: 1.4604517221450806\n",
      "epoch: 3, batch: 315, loss: 1.4863189458847046\n",
      "epoch: 3, batch: 316, loss: 1.4492297172546387\n",
      "epoch: 3, batch: 317, loss: 1.4751553535461426\n",
      "epoch: 3, batch: 318, loss: 1.4346132278442383\n",
      "epoch: 3, batch: 319, loss: 1.6345605850219727\n",
      "epoch: 3, batch: 320, loss: 1.308410882949829\n",
      "epoch: 3, batch: 321, loss: 1.4455987215042114\n",
      "epoch: 3, batch: 322, loss: 1.2590630054473877\n",
      "epoch: 3, batch: 323, loss: 1.4794150590896606\n",
      "epoch: 3, batch: 324, loss: 1.4934650659561157\n",
      "epoch: 3, batch: 325, loss: 1.455673336982727\n",
      "epoch: 3, batch: 326, loss: 1.4098092317581177\n",
      "epoch: 3, batch: 327, loss: 1.4201596975326538\n",
      "epoch: 3, batch: 328, loss: 1.4541417360305786\n",
      "epoch: 3, batch: 329, loss: 1.3138015270233154\n",
      "epoch: 3, batch: 330, loss: 1.4147783517837524\n",
      "epoch: 3, batch: 331, loss: 1.6069294214248657\n",
      "epoch: 3, batch: 332, loss: 1.4596149921417236\n",
      "epoch: 3, batch: 333, loss: 1.408808946609497\n",
      "epoch: 3, batch: 334, loss: 1.3688548803329468\n",
      "epoch: 3, batch: 335, loss: 1.4784159660339355\n",
      "epoch: 3, batch: 336, loss: 1.45840585231781\n",
      "epoch: 3, batch: 337, loss: 1.4312729835510254\n",
      "epoch: 3, batch: 338, loss: 1.389001488685608\n",
      "epoch: 3, batch: 339, loss: 1.4951852560043335\n",
      "epoch: 3, batch: 340, loss: 1.3387378454208374\n",
      "epoch: 3, batch: 341, loss: 1.3811683654785156\n",
      "epoch: 3, batch: 342, loss: 1.3868732452392578\n",
      "epoch: 3, batch: 343, loss: 1.386006236076355\n",
      "epoch: 3, batch: 344, loss: 1.547353744506836\n",
      "epoch: 3, batch: 345, loss: 1.5029394626617432\n",
      "epoch: 3, batch: 346, loss: 1.2878164052963257\n",
      "epoch: 3, batch: 347, loss: 1.4502124786376953\n",
      "epoch: 3, batch: 348, loss: 1.5313434600830078\n",
      "epoch: 3, batch: 349, loss: 1.4564498662948608\n",
      "epoch: 3, batch: 350, loss: 1.4696749448776245\n",
      "epoch: 3, batch: 351, loss: 1.3682807683944702\n",
      "epoch: 3, batch: 352, loss: 1.465844750404358\n",
      "epoch: 3, batch: 353, loss: 1.3787466287612915\n",
      "epoch: 3, batch: 354, loss: 1.318701982498169\n",
      "epoch: 3, batch: 355, loss: 1.5179800987243652\n",
      "epoch: 3, batch: 356, loss: 1.419495940208435\n",
      "epoch: 3, batch: 357, loss: 1.482933521270752\n",
      "epoch: 3, batch: 358, loss: 1.382591962814331\n",
      "epoch: 3, batch: 359, loss: 1.4092504978179932\n",
      "epoch: 3, batch: 360, loss: 1.2526075839996338\n",
      "epoch: 3, batch: 361, loss: 1.5381532907485962\n",
      "epoch: 3, batch: 362, loss: 1.4405239820480347\n",
      "epoch: 3, batch: 363, loss: 1.520843505859375\n",
      "epoch: 3, batch: 364, loss: 1.311201810836792\n",
      "epoch: 3, batch: 365, loss: 1.375523328781128\n",
      "epoch: 3, batch: 366, loss: 1.3694865703582764\n",
      "epoch: 3, batch: 367, loss: 1.2942911386489868\n",
      "epoch: 3, batch: 368, loss: 1.5022757053375244\n",
      "epoch: 3, batch: 369, loss: 1.4373984336853027\n",
      "epoch: 3, batch: 370, loss: 1.507246494293213\n",
      "epoch: 3, batch: 371, loss: 1.5130877494812012\n",
      "epoch: 3, batch: 372, loss: 1.480433702468872\n",
      "epoch: 3, batch: 373, loss: 1.3466646671295166\n",
      "epoch: 3, batch: 374, loss: 1.4091764688491821\n",
      "epoch: 3, batch: 375, loss: 1.4250863790512085\n",
      "epoch: 3, batch: 376, loss: 1.2647700309753418\n",
      "epoch: 3, batch: 377, loss: 1.468854308128357\n",
      "epoch: 3, batch: 378, loss: 1.4673082828521729\n",
      "epoch: 3, batch: 379, loss: 1.3478630781173706\n",
      "epoch: 3, batch: 380, loss: 1.3452672958374023\n",
      "epoch: 3, batch: 381, loss: 1.3661977052688599\n",
      "epoch: 3, batch: 382, loss: 1.4090297222137451\n",
      "epoch: 3, batch: 383, loss: 1.427361249923706\n",
      "epoch: 3, batch: 384, loss: 1.315722942352295\n",
      "epoch: 3, batch: 385, loss: 1.416290283203125\n",
      "epoch: 3, batch: 386, loss: 1.315161108970642\n",
      "epoch: 3, batch: 387, loss: 1.3390724658966064\n",
      "epoch: 3, batch: 388, loss: 1.3728238344192505\n",
      "epoch: 3, batch: 389, loss: 1.4646000862121582\n",
      "epoch: 3, batch: 390, loss: 1.3042283058166504\n",
      "epoch: 3, batch: 391, loss: 1.4702731370925903\n",
      "epoch: 3, batch: 392, loss: 1.451279878616333\n",
      "epoch: 3, batch: 393, loss: 1.4122716188430786\n",
      "epoch: 3, batch: 394, loss: 1.3045520782470703\n",
      "epoch: 3, batch: 395, loss: 1.2606133222579956\n",
      "epoch: 3, batch: 396, loss: 1.2081841230392456\n",
      "epoch: 3, batch: 397, loss: 1.4759923219680786\n",
      "epoch: 3, batch: 398, loss: 1.4564189910888672\n",
      "epoch: 3, batch: 399, loss: 1.4489253759384155\n",
      "epoch: 3, batch: 400, loss: 1.3460427522659302\n",
      "epoch: 3, batch: 401, loss: 1.5291465520858765\n",
      "epoch: 3, batch: 402, loss: 1.5406746864318848\n",
      "epoch: 3, batch: 403, loss: 1.4462380409240723\n",
      "epoch: 3, batch: 404, loss: 1.4426501989364624\n",
      "epoch: 3, batch: 405, loss: 1.47122323513031\n",
      "epoch: 3, batch: 406, loss: 1.4239771366119385\n",
      "epoch: 3, batch: 407, loss: 1.4485182762145996\n",
      "epoch: 3, batch: 408, loss: 1.2678422927856445\n",
      "epoch: 3, batch: 409, loss: 1.456653118133545\n",
      "epoch: 3, batch: 410, loss: 1.475951910018921\n",
      "epoch: 3, batch: 411, loss: 1.403387188911438\n",
      "epoch: 3, batch: 412, loss: 1.4505910873413086\n",
      "epoch: 3, batch: 413, loss: 1.5047492980957031\n",
      "epoch: 3, batch: 414, loss: 1.4452455043792725\n",
      "epoch: 3, batch: 415, loss: 1.2825731039047241\n",
      "epoch: 3, batch: 416, loss: 1.4267480373382568\n",
      "epoch: 3, batch: 417, loss: 1.1903897523880005\n",
      "epoch: 3, batch: 418, loss: 1.5476341247558594\n",
      "epoch: 3, batch: 419, loss: 1.5632050037384033\n",
      "epoch: 3, batch: 420, loss: 1.4874098300933838\n",
      "epoch: 3, batch: 421, loss: 1.4556251764297485\n",
      "epoch: 3, batch: 422, loss: 1.2272472381591797\n",
      "epoch: 3, batch: 423, loss: 1.3826779127120972\n",
      "epoch: 3, batch: 424, loss: 1.3651204109191895\n",
      "epoch: 3, batch: 425, loss: 1.2454088926315308\n",
      "epoch: 3, batch: 426, loss: 1.3683645725250244\n",
      "epoch: 3, batch: 427, loss: 1.349104881286621\n",
      "epoch: 3, batch: 428, loss: 1.4171061515808105\n",
      "epoch: 3, batch: 429, loss: 1.3703765869140625\n",
      "epoch: 3, batch: 430, loss: 1.363053560256958\n",
      "epoch: 3, batch: 431, loss: 1.3602616786956787\n",
      "epoch: 3, batch: 432, loss: 1.4871633052825928\n",
      "epoch: 3, batch: 433, loss: 1.5910446643829346\n",
      "epoch: 3, batch: 434, loss: 1.3457951545715332\n",
      "epoch: 3, batch: 435, loss: 1.4083913564682007\n",
      "epoch: 3, batch: 436, loss: 1.413848638534546\n",
      "epoch: 3, batch: 437, loss: 1.4676460027694702\n",
      "epoch: 3, batch: 438, loss: 1.3295228481292725\n",
      "epoch: 3, batch: 439, loss: 1.4769803285598755\n",
      "epoch: 3, batch: 440, loss: 1.392737627029419\n",
      "epoch: 3, batch: 441, loss: 1.3846863508224487\n",
      "epoch: 3, batch: 442, loss: 1.451055645942688\n",
      "epoch: 3, batch: 443, loss: 1.475852370262146\n",
      "epoch: 3, batch: 444, loss: 1.2920595407485962\n",
      "epoch: 3, batch: 445, loss: 1.3198800086975098\n",
      "epoch: 3, batch: 446, loss: 1.4296786785125732\n",
      "epoch: 3, batch: 447, loss: 1.3115497827529907\n",
      "epoch: 3, batch: 448, loss: 1.455973505973816\n",
      "epoch: 3, batch: 449, loss: 1.442543625831604\n",
      "epoch: 3, batch: 450, loss: 1.5899204015731812\n",
      "epoch: 3, batch: 451, loss: 1.4199000597000122\n",
      "epoch: 3, batch: 452, loss: 1.4393844604492188\n",
      "epoch: 3, batch: 453, loss: 1.253261685371399\n",
      "epoch: 3, batch: 454, loss: 1.3609435558319092\n",
      "epoch: 3, batch: 455, loss: 1.5527610778808594\n",
      "epoch: 3, batch: 456, loss: 1.3161516189575195\n",
      "epoch: 3, batch: 457, loss: 1.4325015544891357\n",
      "epoch: 3, batch: 458, loss: 1.493074655532837\n",
      "epoch: 3, batch: 459, loss: 1.4337016344070435\n",
      "epoch: 3, batch: 460, loss: 1.4060986042022705\n",
      "epoch: 3, batch: 461, loss: 1.4570096731185913\n",
      "epoch: 3, batch: 462, loss: 1.3296456336975098\n",
      "epoch: 3, batch: 463, loss: 1.2855956554412842\n",
      "epoch: 3, batch: 464, loss: 1.3413546085357666\n",
      "epoch: 3, batch: 465, loss: 1.3379716873168945\n",
      "epoch: 3, batch: 466, loss: 1.3748466968536377\n",
      "epoch: 3, batch: 467, loss: 1.387304425239563\n",
      "epoch: 3, batch: 468, loss: 1.507873773574829\n",
      "epoch: 3, batch: 469, loss: 1.3498867750167847\n",
      "epoch: 3, batch: 470, loss: 1.327194333076477\n",
      "epoch: 3, batch: 471, loss: 1.2947063446044922\n",
      "epoch: 3, batch: 472, loss: 1.4133046865463257\n",
      "epoch: 3, batch: 473, loss: 1.48390793800354\n",
      "epoch: 3, batch: 474, loss: 1.3703618049621582\n",
      "epoch: 3, batch: 475, loss: 1.3332499265670776\n",
      "epoch: 3, batch: 476, loss: 1.3882811069488525\n",
      "epoch: 3, batch: 477, loss: 1.293515920639038\n",
      "epoch: 3, batch: 478, loss: 1.268404483795166\n",
      "epoch: 3, batch: 479, loss: 1.4210973978042603\n",
      "epoch: 3, batch: 480, loss: 1.3983932733535767\n",
      "epoch: 3, batch: 481, loss: 1.3766255378723145\n",
      "epoch: 3, batch: 482, loss: 1.3611887693405151\n",
      "epoch: 3, batch: 483, loss: 1.3531724214553833\n",
      "epoch: 3, batch: 484, loss: 1.3742355108261108\n",
      "epoch: 3, batch: 485, loss: 1.3080987930297852\n",
      "epoch: 3, batch: 486, loss: 1.2444218397140503\n",
      "epoch: 3, batch: 487, loss: 1.4762523174285889\n",
      "epoch: 3, batch: 488, loss: 1.3594616651535034\n",
      "epoch: 3, batch: 489, loss: 1.4947232007980347\n",
      "epoch: 3, batch: 490, loss: 1.4105160236358643\n",
      "epoch: 3, batch: 491, loss: 1.188336730003357\n",
      "epoch: 3, batch: 492, loss: 1.3636785745620728\n",
      "epoch: 3, batch: 493, loss: 1.3142627477645874\n",
      "epoch: 3, batch: 494, loss: 1.4046939611434937\n",
      "epoch: 3, batch: 495, loss: 1.3830184936523438\n",
      "epoch: 3, batch: 496, loss: 1.296513557434082\n",
      "epoch: 3, batch: 497, loss: 1.2240458726882935\n",
      "epoch: 3, batch: 498, loss: 1.4212270975112915\n",
      "epoch: 3, batch: 499, loss: 1.4515219926834106\n",
      "epoch: 3, batch: 500, loss: 1.3786406517028809\n",
      "epoch: 3, batch: 501, loss: 1.3261287212371826\n",
      "epoch: 3, batch: 502, loss: 1.39822518825531\n",
      "epoch: 3, batch: 503, loss: 1.54975163936615\n",
      "epoch: 3, batch: 504, loss: 1.4531636238098145\n",
      "epoch: 3, batch: 505, loss: 1.415196418762207\n",
      "epoch: 3, batch: 506, loss: 1.313123345375061\n",
      "epoch: 3, batch: 507, loss: 1.5216885805130005\n",
      "epoch: 3, batch: 508, loss: 1.1951960325241089\n",
      "epoch: 3, batch: 509, loss: 1.4848616123199463\n",
      "epoch: 3, batch: 510, loss: 1.2714823484420776\n",
      "epoch: 3, batch: 511, loss: 1.5769301652908325\n",
      "epoch: 3, batch: 512, loss: 1.3104499578475952\n",
      "epoch: 3, batch: 513, loss: 1.422993540763855\n",
      "epoch: 3, batch: 514, loss: 1.3531687259674072\n",
      "epoch: 3, batch: 515, loss: 1.4259564876556396\n",
      "epoch: 3, batch: 516, loss: 1.3489247560501099\n",
      "epoch: 3, batch: 517, loss: 1.2990537881851196\n",
      "epoch: 3, batch: 518, loss: 1.41823148727417\n",
      "epoch: 3, batch: 519, loss: 1.348648190498352\n",
      "epoch: 3, batch: 520, loss: 1.588565707206726\n",
      "epoch: 3, batch: 521, loss: 1.4206184148788452\n",
      "epoch: 3, batch: 522, loss: 1.3226885795593262\n",
      "epoch: 3, batch: 523, loss: 1.410333275794983\n",
      "epoch: 3, batch: 524, loss: 1.3368546962738037\n",
      "epoch: 3, batch: 525, loss: 1.5521043539047241\n",
      "epoch: 3, batch: 526, loss: 1.4265835285186768\n",
      "epoch: 3, batch: 527, loss: 1.608978271484375\n",
      "epoch: 3, batch: 528, loss: 1.4026250839233398\n",
      "epoch: 3, batch: 529, loss: 1.448126196861267\n",
      "epoch: 3, batch: 530, loss: 1.4746161699295044\n",
      "epoch: 3, batch: 531, loss: 1.3445563316345215\n",
      "epoch: 3, batch: 532, loss: 1.266007423400879\n",
      "epoch: 3, batch: 533, loss: 1.2764484882354736\n",
      "epoch: 3, batch: 534, loss: 1.4683743715286255\n",
      "epoch: 3, batch: 535, loss: 1.412399172782898\n",
      "epoch: 3, batch: 536, loss: 1.2893093824386597\n",
      "epoch: 3, batch: 537, loss: 1.3714559078216553\n",
      "epoch: 3, batch: 538, loss: 1.2597121000289917\n",
      "epoch: 3, batch: 539, loss: 1.2958735227584839\n",
      "epoch: 3, batch: 540, loss: 1.3580242395401\n",
      "epoch: 3, batch: 541, loss: 1.3381725549697876\n",
      "epoch: 3, batch: 542, loss: 1.4117790460586548\n",
      "epoch: 3, batch: 543, loss: 1.4194042682647705\n",
      "epoch: 3, batch: 544, loss: 1.1830837726593018\n",
      "epoch: 3, batch: 545, loss: 1.3129043579101562\n",
      "epoch: 3, batch: 546, loss: 1.2813252210617065\n",
      "epoch: 3, batch: 547, loss: 1.3793325424194336\n",
      "epoch: 3, batch: 548, loss: 1.3194133043289185\n",
      "epoch: 3, batch: 549, loss: 1.4284862279891968\n",
      "epoch: 3, batch: 550, loss: 1.1065726280212402\n",
      "epoch: 3, batch: 551, loss: 1.2889587879180908\n",
      "epoch: 3, batch: 552, loss: 1.363681674003601\n",
      "epoch: 3, batch: 553, loss: 1.3985644578933716\n",
      "epoch: 3, batch: 554, loss: 1.2822167873382568\n",
      "epoch: 3, batch: 555, loss: 1.2928974628448486\n",
      "epoch: 3, batch: 556, loss: 1.4723236560821533\n",
      "epoch: 3, batch: 557, loss: 1.4425184726715088\n",
      "epoch: 3, batch: 558, loss: 1.4827061891555786\n",
      "epoch: 3, batch: 559, loss: 1.2358049154281616\n",
      "epoch: 3, batch: 560, loss: 1.30023992061615\n",
      "epoch: 3, batch: 561, loss: 1.5724234580993652\n",
      "epoch: 3, batch: 562, loss: 1.4247117042541504\n",
      "epoch: 3, batch: 563, loss: 1.3833290338516235\n",
      "epoch: 3, batch: 564, loss: 1.3823115825653076\n",
      "epoch: 3, batch: 565, loss: 1.232265591621399\n",
      "epoch: 3, batch: 566, loss: 1.4110891819000244\n",
      "epoch: 3, batch: 567, loss: 1.3156825304031372\n",
      "epoch: 3, batch: 568, loss: 1.4646812677383423\n",
      "epoch: 3, batch: 569, loss: 1.2668653726577759\n",
      "epoch: 3, batch: 570, loss: 1.385993242263794\n",
      "epoch: 3, batch: 571, loss: 1.4409879446029663\n",
      "epoch: 3, batch: 572, loss: 1.252691388130188\n",
      "epoch: 3, batch: 573, loss: 1.3396008014678955\n",
      "epoch: 3, batch: 574, loss: 1.4118808507919312\n",
      "epoch: 3, batch: 575, loss: 1.2741131782531738\n",
      "epoch: 3, batch: 576, loss: 1.2404611110687256\n",
      "epoch: 3, batch: 577, loss: 1.2805194854736328\n",
      "epoch: 3, batch: 578, loss: 1.3456116914749146\n",
      "epoch: 3, batch: 579, loss: 1.3103805780410767\n",
      "epoch: 3, batch: 580, loss: 1.341603398323059\n",
      "epoch: 3, batch: 581, loss: 1.293534755706787\n",
      "epoch: 3, batch: 582, loss: 1.4514635801315308\n",
      "epoch: 3, batch: 583, loss: 1.264233112335205\n",
      "epoch: 3, batch: 584, loss: 1.3082846403121948\n",
      "epoch: 3, batch: 585, loss: 1.4350504875183105\n",
      "epoch: 3, batch: 586, loss: 1.407555103302002\n",
      "epoch: 3, batch: 587, loss: 1.4056938886642456\n",
      "epoch: 3, batch: 588, loss: 1.4927496910095215\n",
      "epoch: 3, batch: 589, loss: 1.2609418630599976\n",
      "epoch: 3, batch: 590, loss: 1.3557488918304443\n",
      "epoch: 3, batch: 591, loss: 1.322960615158081\n",
      "epoch: 3, batch: 592, loss: 1.3725520372390747\n",
      "epoch: 3, batch: 593, loss: 1.2622153759002686\n",
      "epoch: 3, batch: 594, loss: 1.3159610033035278\n",
      "epoch: 3, batch: 595, loss: 1.3189101219177246\n",
      "epoch: 3, batch: 596, loss: 1.1896610260009766\n",
      "epoch: 3, batch: 597, loss: 1.2509979009628296\n",
      "epoch: 3, batch: 598, loss: 1.3436390161514282\n",
      "epoch: 3, batch: 599, loss: 1.3740707635879517\n",
      "epoch: 3, batch: 600, loss: 1.2649340629577637\n",
      "epoch: 3, batch: 601, loss: 1.3234390020370483\n",
      "epoch: 3, batch: 602, loss: 1.3099675178527832\n",
      "epoch: 3, batch: 603, loss: 1.2157189846038818\n",
      "epoch: 3, batch: 604, loss: 1.2127844095230103\n",
      "epoch: 3, batch: 605, loss: 1.2697685956954956\n",
      "epoch: 3, batch: 606, loss: 1.3981773853302002\n",
      "epoch: 3, batch: 607, loss: 1.2515937089920044\n",
      "epoch: 3, batch: 608, loss: 1.389711856842041\n",
      "epoch: 3, batch: 609, loss: 1.4112077951431274\n",
      "epoch: 3, batch: 610, loss: 1.294482946395874\n",
      "epoch: 3, batch: 611, loss: 1.2923524379730225\n",
      "epoch: 3, batch: 612, loss: 1.3485311269760132\n",
      "epoch: 3, batch: 613, loss: 1.3137494325637817\n",
      "epoch: 3, batch: 614, loss: 1.2932690382003784\n",
      "epoch: 3, batch: 615, loss: 1.1821142435073853\n",
      "epoch: 3, batch: 616, loss: 1.3918962478637695\n",
      "epoch: 3, batch: 617, loss: 1.3336150646209717\n",
      "epoch: 3, batch: 618, loss: 1.511206865310669\n",
      "epoch: 3, batch: 619, loss: 1.4184958934783936\n",
      "epoch: 3, batch: 620, loss: 1.3740240335464478\n",
      "epoch: 3, batch: 621, loss: 1.4116226434707642\n",
      "epoch: 3, batch: 622, loss: 1.1973509788513184\n",
      "epoch: 3, batch: 623, loss: 1.2197020053863525\n",
      "epoch: 3, batch: 624, loss: 1.35110342502594\n",
      "epoch: 3, batch: 625, loss: 1.3800907135009766\n",
      "epoch: 3, batch: 626, loss: 1.2725119590759277\n",
      "epoch: 3, batch: 627, loss: 1.2105568647384644\n",
      "epoch: 3, batch: 628, loss: 1.1896826028823853\n",
      "epoch: 3, batch: 629, loss: 1.2920321226119995\n",
      "epoch: 3, batch: 630, loss: 1.3995863199234009\n",
      "epoch: 3, batch: 631, loss: 1.3493727445602417\n",
      "epoch: 3, batch: 632, loss: 1.25066339969635\n",
      "epoch: 3, batch: 633, loss: 1.4403270483016968\n",
      "epoch: 3, batch: 634, loss: 1.180031657218933\n",
      "epoch: 3, batch: 635, loss: 1.3571830987930298\n",
      "epoch: 3, batch: 636, loss: 1.1994061470031738\n",
      "epoch: 3, batch: 637, loss: 1.291991114616394\n",
      "epoch: 3, batch: 638, loss: 1.3294527530670166\n",
      "epoch: 3, batch: 639, loss: 1.3618721961975098\n",
      "epoch: 3, batch: 640, loss: 1.3338706493377686\n",
      "epoch: 3, batch: 641, loss: 1.2821091413497925\n",
      "epoch: 3, batch: 642, loss: 1.301499366760254\n",
      "epoch: 3, batch: 643, loss: 1.2859693765640259\n",
      "epoch: 3, batch: 644, loss: 1.421360969543457\n",
      "epoch: 3, batch: 645, loss: 1.4424846172332764\n",
      "epoch: 3, batch: 646, loss: 1.3250961303710938\n",
      "epoch: 3, batch: 647, loss: 1.2556233406066895\n",
      "epoch: 3, batch: 648, loss: 1.2969295978546143\n",
      "epoch: 3, batch: 649, loss: 1.3326785564422607\n",
      "epoch: 3, batch: 650, loss: 1.1905543804168701\n",
      "epoch: 3, batch: 651, loss: 1.2198790311813354\n",
      "epoch: 3, batch: 652, loss: 1.4412373304367065\n",
      "epoch: 3, batch: 653, loss: 1.3962161540985107\n",
      "epoch: 3, batch: 654, loss: 1.412255048751831\n",
      "epoch: 3, batch: 655, loss: 1.1649112701416016\n",
      "epoch: 3, batch: 656, loss: 1.4604930877685547\n",
      "epoch: 3, batch: 657, loss: 1.3646700382232666\n",
      "epoch: 3, batch: 658, loss: 1.220940351486206\n",
      "epoch: 3, batch: 659, loss: 1.3522969484329224\n",
      "epoch: 3, batch: 660, loss: 1.35050368309021\n",
      "epoch: 3, batch: 661, loss: 1.4182250499725342\n",
      "epoch: 3, batch: 662, loss: 1.3058240413665771\n",
      "epoch: 3, batch: 663, loss: 1.4020353555679321\n",
      "epoch: 3, batch: 664, loss: 1.290794849395752\n",
      "epoch: 3, batch: 665, loss: 1.3019444942474365\n",
      "epoch: 3, batch: 666, loss: 1.320614218711853\n",
      "epoch: 3, batch: 667, loss: 1.237916350364685\n",
      "epoch: 3, batch: 668, loss: 1.3755435943603516\n",
      "epoch: 3, batch: 669, loss: 1.3859877586364746\n",
      "epoch: 3, batch: 670, loss: 1.462025761604309\n",
      "epoch: 3, batch: 671, loss: 1.2559289932250977\n",
      "epoch: 3, batch: 672, loss: 1.2449686527252197\n",
      "epoch: 3, batch: 673, loss: 1.4921903610229492\n",
      "epoch: 3, batch: 674, loss: 1.3464590311050415\n",
      "epoch: 3, batch: 675, loss: 1.3222873210906982\n",
      "epoch: 3, batch: 676, loss: 1.373227834701538\n",
      "epoch: 3, batch: 677, loss: 1.370579481124878\n",
      "epoch: 3, batch: 678, loss: 1.3055453300476074\n",
      "epoch: 3, batch: 679, loss: 1.2763025760650635\n",
      "epoch: 3, batch: 680, loss: 1.2487926483154297\n",
      "epoch: 3, batch: 681, loss: 1.43967866897583\n",
      "epoch: 3, batch: 682, loss: 1.446122407913208\n",
      "epoch: 3, batch: 683, loss: 1.2563148736953735\n",
      "epoch: 3, batch: 684, loss: 1.3555965423583984\n",
      "epoch: 3, batch: 685, loss: 1.4660587310791016\n",
      "epoch: 3, batch: 686, loss: 1.3221125602722168\n",
      "epoch: 3, batch: 687, loss: 1.308837890625\n",
      "epoch: 3, batch: 688, loss: 1.3106971979141235\n",
      "epoch: 3, batch: 689, loss: 1.431646466255188\n",
      "epoch: 3, batch: 690, loss: 1.2386255264282227\n",
      "epoch: 3, batch: 691, loss: 1.3363593816757202\n",
      "epoch: 3, batch: 692, loss: 1.391204833984375\n",
      "epoch: 3, batch: 693, loss: 1.317852258682251\n",
      "epoch: 3, batch: 694, loss: 1.1350868940353394\n",
      "epoch: 3, batch: 695, loss: 1.3052107095718384\n",
      "epoch: 3, batch: 696, loss: 1.234615445137024\n",
      "epoch: 3, batch: 697, loss: 1.160836100578308\n",
      "epoch: 3, batch: 698, loss: 1.423675298690796\n",
      "epoch: 3, batch: 699, loss: 1.355104923248291\n",
      "epoch: 3, batch: 700, loss: 1.2729955911636353\n",
      "epoch: 3, batch: 701, loss: 1.3852204084396362\n",
      "epoch: 3, batch: 702, loss: 1.3024389743804932\n",
      "epoch: 3, batch: 703, loss: 1.3508973121643066\n",
      "epoch: 3, batch: 704, loss: 1.2247042655944824\n",
      "epoch: 3, batch: 705, loss: 1.3898829221725464\n",
      "epoch: 3, batch: 706, loss: 1.1543703079223633\n",
      "epoch: 3, batch: 707, loss: 1.1122307777404785\n",
      "epoch: 3, batch: 708, loss: 1.280885934829712\n",
      "epoch: 3, batch: 709, loss: 1.3940718173980713\n",
      "epoch: 3, batch: 710, loss: 1.303637146949768\n",
      "epoch: 3, batch: 711, loss: 1.3041962385177612\n",
      "epoch: 3, batch: 712, loss: 1.2232911586761475\n",
      "epoch: 3, batch: 713, loss: 1.273463249206543\n",
      "epoch: 3, batch: 714, loss: 1.1758463382720947\n",
      "epoch: 3, batch: 715, loss: 1.243802547454834\n",
      "epoch: 3, batch: 716, loss: 1.1789616346359253\n",
      "epoch: 3, batch: 717, loss: 1.275477647781372\n",
      "epoch: 3, batch: 718, loss: 1.3177367448806763\n",
      "epoch: 3, batch: 719, loss: 1.1763979196548462\n",
      "epoch: 3, batch: 720, loss: 1.2324249744415283\n",
      "epoch: 3, batch: 721, loss: 1.3441001176834106\n",
      "epoch: 3, batch: 722, loss: 1.482043743133545\n",
      "epoch: 3, batch: 723, loss: 1.2021846771240234\n",
      "epoch: 3, batch: 724, loss: 1.3736858367919922\n",
      "epoch: 3, batch: 725, loss: 1.3175363540649414\n",
      "epoch: 3, batch: 726, loss: 1.3746033906936646\n",
      "epoch: 3, batch: 727, loss: 1.1734440326690674\n",
      "epoch: 3, batch: 728, loss: 1.286453366279602\n",
      "epoch: 3, batch: 729, loss: 1.2834059000015259\n",
      "epoch: 3, batch: 730, loss: 1.2701016664505005\n",
      "epoch: 3, batch: 731, loss: 1.5105795860290527\n",
      "epoch: 3, batch: 732, loss: 1.1904271841049194\n",
      "epoch: 3, batch: 733, loss: 1.3265137672424316\n",
      "epoch: 3, batch: 734, loss: 1.3948113918304443\n",
      "epoch: 3, batch: 735, loss: 1.3181504011154175\n",
      "epoch: 3, batch: 736, loss: 1.3278416395187378\n",
      "epoch: 3, batch: 737, loss: 1.2387531995773315\n",
      "epoch: 3, batch: 738, loss: 1.404991865158081\n",
      "epoch: 3, batch: 739, loss: 1.2743921279907227\n",
      "epoch: 3, batch: 740, loss: 1.37923264503479\n",
      "epoch: 3, batch: 741, loss: 1.3818018436431885\n",
      "epoch: 3, batch: 742, loss: 1.1387300491333008\n",
      "epoch: 3, batch: 743, loss: 1.28439462184906\n",
      "epoch: 3, batch: 744, loss: 1.3682576417922974\n",
      "epoch: 3, batch: 745, loss: 1.3298979997634888\n",
      "epoch: 3, batch: 746, loss: 1.2909106016159058\n",
      "epoch: 3, batch: 747, loss: 1.2716511487960815\n",
      "epoch: 3, batch: 748, loss: 1.2972948551177979\n",
      "epoch: 3, batch: 749, loss: 1.3021413087844849\n",
      "epoch: 3, batch: 750, loss: 1.3693106174468994\n",
      "epoch: 3, batch: 751, loss: 1.2976984977722168\n",
      "epoch: 3, batch: 752, loss: 1.3230578899383545\n",
      "epoch: 3, batch: 753, loss: 1.2848376035690308\n",
      "epoch: 3, batch: 754, loss: 1.386099100112915\n",
      "epoch: 3, batch: 755, loss: 1.3987923860549927\n",
      "epoch: 3, batch: 756, loss: 1.2878665924072266\n",
      "epoch: 3, batch: 757, loss: 1.232167363166809\n",
      "epoch: 3, batch: 758, loss: 1.283781886100769\n",
      "epoch: 3, batch: 759, loss: 1.2208439111709595\n",
      "epoch: 3, batch: 760, loss: 1.4111137390136719\n",
      "epoch: 3, batch: 761, loss: 1.1139603853225708\n",
      "epoch: 3, batch: 762, loss: 1.2258005142211914\n",
      "epoch: 3, batch: 763, loss: 1.4248595237731934\n",
      "epoch: 3, batch: 764, loss: 1.3242616653442383\n",
      "epoch: 3, batch: 765, loss: 1.319149136543274\n",
      "epoch: 3, batch: 766, loss: 1.296655297279358\n",
      "epoch: 3, batch: 767, loss: 1.512792944908142\n",
      "epoch: 3, batch: 768, loss: 1.265426516532898\n",
      "epoch: 3, batch: 769, loss: 1.2036043405532837\n",
      "epoch: 3, batch: 770, loss: 1.309412956237793\n",
      "epoch: 3, batch: 771, loss: 1.1639236211776733\n",
      "epoch: 3, batch: 772, loss: 1.4629411697387695\n",
      "epoch: 3, batch: 773, loss: 1.2946768999099731\n",
      "epoch: 3, batch: 774, loss: 1.2981288433074951\n",
      "epoch: 3, batch: 775, loss: 1.49159574508667\n",
      "epoch: 3, batch: 776, loss: 1.2188023328781128\n",
      "epoch: 3, batch: 777, loss: 1.3079230785369873\n",
      "epoch: 3, batch: 778, loss: 1.2914773225784302\n",
      "epoch: 3, batch: 779, loss: 1.2844865322113037\n",
      "epoch: 3, batch: 780, loss: 1.2822062969207764\n",
      "epoch: 3, batch: 781, loss: 1.3264073133468628\n",
      "epoch: 3, batch: 782, loss: 1.306167483329773\n",
      "epoch: 3, batch: 783, loss: 1.21360182762146\n",
      "epoch: 3, batch: 784, loss: 1.2055226564407349\n",
      "epoch: 3, batch: 785, loss: 1.3325828313827515\n",
      "epoch: 3, batch: 786, loss: 1.26398503780365\n",
      "epoch: 3, batch: 787, loss: 1.2868820428848267\n",
      "epoch: 3, batch: 788, loss: 1.247009515762329\n",
      "epoch: 3, batch: 789, loss: 1.3192551136016846\n",
      "epoch: 3, batch: 790, loss: 1.3752269744873047\n",
      "epoch: 3, batch: 791, loss: 1.2183302640914917\n",
      "epoch: 3, batch: 792, loss: 1.1119977235794067\n",
      "epoch: 3, batch: 793, loss: 1.2439146041870117\n",
      "epoch: 3, batch: 794, loss: 1.2192267179489136\n",
      "epoch: 3, batch: 795, loss: 1.351969599723816\n",
      "epoch: 3, batch: 796, loss: 1.3392571210861206\n",
      "epoch: 3, batch: 797, loss: 1.435623049736023\n",
      "epoch: 3, batch: 798, loss: 1.2338168621063232\n",
      "epoch: 3, batch: 799, loss: 1.3137753009796143\n",
      "epoch: 3, batch: 800, loss: 1.2338306903839111\n",
      "epoch: 3, batch: 801, loss: 1.2648992538452148\n",
      "epoch: 3, batch: 802, loss: 1.2551480531692505\n",
      "epoch: 3, batch: 803, loss: 1.2589058876037598\n",
      "epoch: 3, batch: 804, loss: 1.2630099058151245\n",
      "epoch: 3, batch: 805, loss: 1.1844877004623413\n",
      "epoch: 3, batch: 806, loss: 1.3018282651901245\n",
      "epoch: 3, batch: 807, loss: 1.18192720413208\n",
      "epoch: 3, batch: 808, loss: 1.3103352785110474\n",
      "epoch: 3, batch: 809, loss: 1.3603675365447998\n",
      "epoch: 3, batch: 810, loss: 1.3168361186981201\n",
      "epoch: 3, batch: 811, loss: 1.3046962022781372\n",
      "epoch: 3, batch: 812, loss: 1.334970235824585\n",
      "epoch: 3, batch: 813, loss: 1.1672048568725586\n",
      "epoch: 3, batch: 814, loss: 1.2694846391677856\n",
      "epoch: 3, batch: 815, loss: 1.2057552337646484\n",
      "epoch: 3, batch: 816, loss: 1.3771395683288574\n",
      "epoch: 3, batch: 817, loss: 1.2018204927444458\n",
      "epoch: 3, batch: 818, loss: 1.4426460266113281\n",
      "epoch: 3, batch: 819, loss: 1.3100121021270752\n",
      "epoch: 3, batch: 820, loss: 1.2416311502456665\n",
      "epoch: 3, batch: 821, loss: 1.3018840551376343\n",
      "epoch: 3, batch: 822, loss: 1.3381524085998535\n",
      "epoch: 3, batch: 823, loss: 1.282142162322998\n",
      "epoch: 3, batch: 824, loss: 1.351754069328308\n",
      "epoch: 3, batch: 825, loss: 1.2729064226150513\n",
      "epoch: 3, batch: 826, loss: 1.1552684307098389\n",
      "epoch: 3, batch: 827, loss: 1.1391762495040894\n",
      "epoch: 3, batch: 828, loss: 1.2171049118041992\n",
      "epoch: 3, batch: 829, loss: 1.3802173137664795\n",
      "epoch: 3, batch: 830, loss: 1.2095648050308228\n",
      "epoch: 3, batch: 831, loss: 1.3710527420043945\n",
      "epoch: 3, batch: 832, loss: 1.4264403581619263\n",
      "epoch: 3, batch: 833, loss: 1.2471508979797363\n",
      "epoch: 3, batch: 834, loss: 1.4706974029541016\n",
      "epoch: 3, batch: 835, loss: 1.1349279880523682\n",
      "epoch: 3, batch: 836, loss: 1.2095756530761719\n",
      "epoch: 3, batch: 837, loss: 1.344021201133728\n",
      "epoch: 3, batch: 838, loss: 1.457053542137146\n",
      "epoch: 3, batch: 839, loss: 1.2109994888305664\n",
      "epoch: 3, batch: 840, loss: 1.2935563325881958\n",
      "epoch: 3, batch: 841, loss: 1.161157488822937\n",
      "epoch: 3, batch: 842, loss: 1.423214077949524\n",
      "epoch: 3, batch: 843, loss: 1.1238489151000977\n",
      "epoch: 3, batch: 844, loss: 1.4238170385360718\n",
      "epoch: 3, batch: 845, loss: 1.2934801578521729\n",
      "epoch: 3, batch: 846, loss: 1.316098928451538\n",
      "epoch: 3, batch: 847, loss: 1.0987955331802368\n",
      "epoch: 3, batch: 848, loss: 1.216840386390686\n",
      "epoch: 3, batch: 849, loss: 1.3367524147033691\n",
      "epoch: 3, batch: 850, loss: 1.3064372539520264\n",
      "epoch: 3, batch: 851, loss: 1.101802110671997\n",
      "epoch: 3, batch: 852, loss: 1.311303973197937\n",
      "epoch: 3, batch: 853, loss: 1.1289663314819336\n",
      "epoch: 3, batch: 854, loss: 1.1050516366958618\n",
      "epoch: 3, batch: 855, loss: 1.5564833879470825\n",
      "epoch: 3, batch: 856, loss: 1.023868203163147\n",
      "epoch: 3, batch: 857, loss: 1.3619599342346191\n",
      "epoch: 3, batch: 858, loss: 1.1707929372787476\n",
      "epoch: 3, batch: 859, loss: 1.1291393041610718\n",
      "epoch: 3, batch: 860, loss: 1.1537280082702637\n",
      "epoch: 3, batch: 861, loss: 1.2042421102523804\n",
      "epoch: 3, batch: 862, loss: 1.3938584327697754\n",
      "epoch: 3, batch: 863, loss: 1.1685161590576172\n",
      "epoch: 3, batch: 864, loss: 1.2816805839538574\n",
      "epoch: 3, batch: 865, loss: 1.424883246421814\n",
      "epoch: 3, batch: 866, loss: 1.3050289154052734\n",
      "epoch: 3, batch: 867, loss: 1.1202086210250854\n",
      "epoch: 3, batch: 868, loss: 1.2543083429336548\n",
      "epoch: 3, batch: 869, loss: 1.2488062381744385\n",
      "epoch: 3, batch: 870, loss: 1.2985689640045166\n",
      "epoch: 3, batch: 871, loss: 1.2869433164596558\n",
      "epoch: 3, batch: 872, loss: 1.091580867767334\n",
      "epoch: 3, batch: 873, loss: 1.137238621711731\n",
      "epoch: 3, batch: 874, loss: 1.2766900062561035\n",
      "epoch: 3, batch: 875, loss: 1.1034764051437378\n",
      "epoch: 3, batch: 876, loss: 1.3031764030456543\n",
      "epoch: 3, batch: 877, loss: 1.1828521490097046\n",
      "epoch: 3, batch: 878, loss: 1.3597135543823242\n",
      "epoch: 3, batch: 879, loss: 1.1355646848678589\n",
      "epoch: 3, batch: 880, loss: 1.568610668182373\n",
      "epoch: 3, batch: 881, loss: 1.2401608228683472\n",
      "epoch: 3, batch: 882, loss: 1.216714859008789\n",
      "epoch: 3, batch: 883, loss: 1.4097504615783691\n",
      "epoch: 3, batch: 884, loss: 1.2759687900543213\n",
      "epoch: 3, batch: 885, loss: 1.4151861667633057\n",
      "epoch: 3, batch: 886, loss: 1.1789844036102295\n",
      "epoch: 3, batch: 887, loss: 1.3034700155258179\n",
      "epoch: 3, batch: 888, loss: 1.267469048500061\n",
      "epoch: 3, batch: 889, loss: 1.233521819114685\n",
      "epoch: 3, batch: 890, loss: 1.4614362716674805\n",
      "epoch: 3, batch: 891, loss: 1.3039259910583496\n",
      "epoch: 3, batch: 892, loss: 1.2999736070632935\n",
      "epoch: 3, batch: 893, loss: 1.2068121433258057\n",
      "epoch: 3, batch: 894, loss: 1.2616281509399414\n",
      "epoch: 3, batch: 895, loss: 1.1668331623077393\n",
      "epoch: 3, batch: 896, loss: 1.324258804321289\n",
      "epoch: 3, batch: 897, loss: 1.3308340311050415\n",
      "epoch: 3, batch: 898, loss: 1.1640790700912476\n",
      "epoch: 3, batch: 899, loss: 1.1697869300842285\n",
      "epoch: 3, batch: 900, loss: 1.3922080993652344\n",
      "epoch: 3, batch: 901, loss: 1.2042487859725952\n",
      "epoch: 3, batch: 902, loss: 1.1570124626159668\n",
      "epoch: 3, batch: 903, loss: 1.2552903890609741\n",
      "epoch: 3, batch: 904, loss: 1.1026500463485718\n",
      "epoch: 3, batch: 905, loss: 1.1048238277435303\n",
      "epoch: 3, batch: 906, loss: 1.1972784996032715\n",
      "epoch: 3, batch: 907, loss: 1.3311156034469604\n",
      "epoch: 3, batch: 908, loss: 1.27001953125\n",
      "epoch: 3, batch: 909, loss: 1.279815673828125\n",
      "epoch: 3, batch: 910, loss: 1.2421079874038696\n",
      "epoch: 3, batch: 911, loss: 1.2886173725128174\n",
      "epoch: 3, batch: 912, loss: 1.362783432006836\n",
      "epoch: 3, batch: 913, loss: 1.222765326499939\n",
      "epoch: 3, batch: 914, loss: 1.170930027961731\n",
      "epoch: 3, batch: 915, loss: 1.3003432750701904\n",
      "epoch: 3, batch: 916, loss: 1.2102904319763184\n",
      "epoch: 3, batch: 917, loss: 1.1558164358139038\n",
      "epoch: 3, batch: 918, loss: 1.2100690603256226\n",
      "epoch: 3, batch: 919, loss: 1.0904667377471924\n",
      "epoch: 3, batch: 920, loss: 1.2549927234649658\n",
      "epoch: 3, batch: 921, loss: 1.19707190990448\n",
      "epoch: 3, batch: 922, loss: 1.187440276145935\n",
      "epoch: 3, batch: 923, loss: 1.2065013647079468\n",
      "epoch: 3, batch: 924, loss: 1.2293437719345093\n",
      "epoch: 3, batch: 925, loss: 1.1154216527938843\n",
      "epoch: 3, batch: 926, loss: 1.31642484664917\n",
      "epoch: 3, batch: 927, loss: 1.3748207092285156\n",
      "epoch: 3, batch: 928, loss: 1.3923516273498535\n",
      "epoch: 3, batch: 929, loss: 1.0487868785858154\n",
      "epoch: 3, batch: 930, loss: 1.0221713781356812\n",
      "epoch: 3, batch: 931, loss: 1.2728204727172852\n",
      "epoch: 3, batch: 932, loss: 1.4938679933547974\n",
      "epoch: 3, batch: 933, loss: 1.2015916109085083\n",
      "epoch: 3, batch: 934, loss: 1.1748766899108887\n",
      "epoch: 3, batch: 935, loss: 1.2974458932876587\n",
      "epoch: 3, batch: 936, loss: 1.1653783321380615\n",
      "epoch: 3, batch: 937, loss: 1.3381352424621582\n",
      "epoch: 3, batch: 938, loss: 1.3533470630645752\n",
      "epoch: 3, batch: 939, loss: 1.1721482276916504\n",
      "epoch: 3, batch: 940, loss: 1.092427134513855\n",
      "epoch: 3, batch: 941, loss: 1.1792552471160889\n",
      "epoch: 3, batch: 942, loss: 1.2219892740249634\n",
      "epoch: 3, batch: 943, loss: 1.435831904411316\n",
      "epoch: 3, batch: 944, loss: 1.3178160190582275\n",
      "epoch: 3, batch: 945, loss: 1.3594378232955933\n",
      "epoch: 3, batch: 946, loss: 1.2136698961257935\n",
      "epoch: 3, batch: 947, loss: 1.2854732275009155\n",
      "epoch: 3, batch: 948, loss: 1.3434675931930542\n",
      "epoch: 3, batch: 949, loss: 1.33503258228302\n",
      "epoch: 3, batch: 950, loss: 1.244107961654663\n",
      "epoch: 3, batch: 951, loss: 1.244458556175232\n",
      "epoch: 3, batch: 952, loss: 1.3162126541137695\n",
      "epoch: 3, batch: 953, loss: 1.3186578750610352\n",
      "epoch: 3, batch: 954, loss: 1.0554978847503662\n",
      "epoch: 3, batch: 955, loss: 1.1191598176956177\n",
      "epoch: 3, batch: 956, loss: 1.1656699180603027\n",
      "epoch: 3, batch: 957, loss: 1.221496820449829\n",
      "epoch: 3, batch: 958, loss: 1.1370295286178589\n",
      "epoch: 3, batch: 959, loss: 1.1475681066513062\n",
      "epoch: 3, batch: 960, loss: 1.3122000694274902\n",
      "epoch: 3, batch: 961, loss: 1.2729495763778687\n",
      "epoch: 3, batch: 962, loss: 1.480879306793213\n",
      "epoch: 3, batch: 963, loss: 1.2544479370117188\n",
      "epoch: 3, batch: 964, loss: 1.3317402601242065\n",
      "epoch: 3, batch: 965, loss: 1.2529699802398682\n",
      "epoch: 3, batch: 966, loss: 1.2973015308380127\n",
      "epoch: 3, batch: 967, loss: 1.3053277730941772\n",
      "epoch: 3, batch: 968, loss: 1.3611927032470703\n",
      "epoch: 3, batch: 969, loss: 1.1616337299346924\n",
      "epoch: 3, batch: 970, loss: 1.387786626815796\n",
      "epoch: 3, batch: 971, loss: 1.4794938564300537\n",
      "epoch: 3, batch: 972, loss: 1.2704647779464722\n",
      "epoch: 3, batch: 973, loss: 1.5057860612869263\n",
      "epoch: 3, batch: 974, loss: 1.24883234500885\n",
      "epoch: 3, batch: 975, loss: 1.260993480682373\n",
      "epoch: 3, batch: 976, loss: 1.2800706624984741\n",
      "epoch: 3, batch: 977, loss: 1.3553423881530762\n",
      "epoch: 3, batch: 978, loss: 1.1372419595718384\n",
      "epoch: 3, batch: 979, loss: 1.1341028213500977\n",
      "epoch: 3, batch: 980, loss: 1.1403257846832275\n",
      "epoch: 3, batch: 981, loss: 1.168988823890686\n",
      "epoch: 3, batch: 982, loss: 1.2123985290527344\n",
      "epoch: 3, batch: 983, loss: 1.2319799661636353\n",
      "epoch: 3, batch: 984, loss: 0.9470319151878357\n",
      "epoch: 3, batch: 985, loss: 1.1507883071899414\n",
      "epoch: 3, batch: 986, loss: 1.1852633953094482\n",
      "epoch: 3, batch: 987, loss: 1.2240583896636963\n",
      "epoch: 3, batch: 988, loss: 1.197587251663208\n",
      "epoch: 3, batch: 989, loss: 1.2075729370117188\n",
      "epoch: 3, batch: 990, loss: 1.4063998460769653\n",
      "epoch: 3, batch: 991, loss: 1.206490397453308\n",
      "epoch: 3, batch: 992, loss: 1.3610373735427856\n",
      "epoch: 3, batch: 993, loss: 1.1014316082000732\n",
      "epoch: 3, batch: 994, loss: 1.119924545288086\n",
      "epoch: 3, batch: 995, loss: 1.1510624885559082\n",
      "epoch: 3, batch: 996, loss: 1.2487422227859497\n",
      "epoch: 3, batch: 997, loss: 1.3646360635757446\n",
      "epoch: 3, batch: 998, loss: 1.2890915870666504\n",
      "epoch: 3, batch: 999, loss: 1.265230417251587\n",
      "epoch: 3, batch: 1000, loss: 1.0956605672836304\n",
      "epoch: 3, batch: 1001, loss: 1.2038344144821167\n",
      "epoch: 3, batch: 1002, loss: 1.4086804389953613\n",
      "epoch: 3, batch: 1003, loss: 0.9645530581474304\n",
      "epoch: 3, batch: 1004, loss: 1.1211899518966675\n",
      "epoch: 3, batch: 1005, loss: 1.3177216053009033\n",
      "epoch: 3, batch: 1006, loss: 1.089348554611206\n",
      "epoch: 3, batch: 1007, loss: 1.479759693145752\n",
      "epoch: 3, batch: 1008, loss: 1.4061495065689087\n",
      "epoch: 3, batch: 1009, loss: 1.2629474401474\n",
      "epoch: 3, batch: 1010, loss: 1.2542128562927246\n",
      "epoch: 3, batch: 1011, loss: 1.233195185661316\n",
      "epoch: 3, batch: 1012, loss: 0.9922311902046204\n",
      "epoch: 3, batch: 1013, loss: 1.1899503469467163\n",
      "epoch: 3, batch: 1014, loss: 1.1394051313400269\n",
      "epoch: 3, batch: 1015, loss: 1.0392448902130127\n",
      "epoch: 3, batch: 1016, loss: 1.2981972694396973\n",
      "epoch: 3, batch: 1017, loss: 1.1999379396438599\n",
      "epoch: 3, batch: 1018, loss: 1.0350195169448853\n",
      "epoch: 3, batch: 1019, loss: 1.1494930982589722\n",
      "epoch: 3, batch: 1020, loss: 1.203696608543396\n",
      "epoch: 3, batch: 1021, loss: 1.1900540590286255\n",
      "epoch: 3, batch: 1022, loss: 1.3004504442214966\n",
      "epoch: 3, batch: 1023, loss: 1.1138018369674683\n",
      "epoch: 3, batch: 1024, loss: 1.1165403127670288\n",
      "epoch: 3, batch: 1025, loss: 1.149937391281128\n",
      "epoch: 3, batch: 1026, loss: 1.2465696334838867\n",
      "epoch: 3, batch: 1027, loss: 1.1745612621307373\n",
      "epoch: 3, batch: 1028, loss: 1.1276452541351318\n",
      "epoch: 3, batch: 1029, loss: 1.2810953855514526\n",
      "epoch: 3, batch: 1030, loss: 1.2686076164245605\n",
      "epoch: 3, batch: 1031, loss: 1.0210449695587158\n",
      "epoch: 3, batch: 1032, loss: 1.3492857217788696\n",
      "epoch: 3, batch: 1033, loss: 1.0600411891937256\n",
      "epoch: 3, batch: 1034, loss: 1.2362284660339355\n",
      "epoch: 3, batch: 1035, loss: 1.211938500404358\n",
      "epoch: 3, batch: 1036, loss: 1.2205898761749268\n",
      "epoch: 3, batch: 1037, loss: 1.2657142877578735\n",
      "epoch: 3, batch: 1038, loss: 1.2999893426895142\n",
      "epoch: 3, batch: 1039, loss: 1.1797869205474854\n",
      "epoch: 3, batch: 1040, loss: 1.07844877243042\n",
      "epoch: 3, batch: 1041, loss: 1.2110021114349365\n",
      "epoch: 3, batch: 1042, loss: 1.220935583114624\n",
      "epoch: 3, batch: 1043, loss: 1.1782110929489136\n",
      "epoch: 3, batch: 1044, loss: 1.412208914756775\n",
      "epoch: 3, batch: 1045, loss: 1.5047733783721924\n",
      "epoch: 3, batch: 1046, loss: 1.2387125492095947\n",
      "epoch: 3, batch: 1047, loss: 1.2767913341522217\n",
      "epoch: 3, batch: 1048, loss: 1.1611875295639038\n",
      "epoch: 3, batch: 1049, loss: 1.1380611658096313\n",
      "epoch: 3, batch: 1050, loss: 1.1379891633987427\n",
      "epoch: 3, batch: 1051, loss: 1.339231252670288\n",
      "epoch: 3, batch: 1052, loss: 1.1814823150634766\n",
      "epoch: 3, batch: 1053, loss: 1.1742877960205078\n",
      "epoch: 3, batch: 1054, loss: 1.246201992034912\n",
      "epoch: 3, batch: 1055, loss: 1.090958595275879\n",
      "epoch: 3, batch: 1056, loss: 1.2245742082595825\n",
      "epoch: 3, batch: 1057, loss: 1.3223857879638672\n",
      "epoch: 3, batch: 1058, loss: 1.2454396486282349\n",
      "epoch: 3, batch: 1059, loss: 1.2018287181854248\n",
      "epoch: 3, batch: 1060, loss: 1.2167855501174927\n",
      "epoch: 3, batch: 1061, loss: 1.212375283241272\n",
      "epoch: 3, batch: 1062, loss: 1.3095816373825073\n",
      "epoch: 3, batch: 1063, loss: 1.2717870473861694\n",
      "epoch: 3, batch: 1064, loss: 0.9757680892944336\n",
      "epoch: 3, batch: 1065, loss: 1.352428674697876\n",
      "epoch: 3, batch: 1066, loss: 1.111141562461853\n",
      "epoch: 3, batch: 1067, loss: 1.2945256233215332\n",
      "epoch: 3, batch: 1068, loss: 1.3343815803527832\n",
      "epoch: 3, batch: 1069, loss: 1.2524269819259644\n",
      "epoch: 3, batch: 1070, loss: 1.1041252613067627\n",
      "epoch: 3, batch: 1071, loss: 1.3395323753356934\n",
      "epoch: 3, batch: 1072, loss: 1.2532823085784912\n",
      "epoch: 3, batch: 1073, loss: 1.3854130506515503\n",
      "epoch: 3, batch: 1074, loss: 1.3681135177612305\n",
      "epoch: 3, batch: 1075, loss: 1.333128571510315\n",
      "epoch: 3, batch: 1076, loss: 1.2616337537765503\n",
      "epoch: 3, batch: 1077, loss: 1.3800654411315918\n",
      "epoch: 3, batch: 1078, loss: 1.336404800415039\n",
      "epoch: 3, batch: 1079, loss: 1.285622477531433\n",
      "epoch: 3, batch: 1080, loss: 1.2090703248977661\n",
      "epoch: 3, batch: 1081, loss: 1.1348936557769775\n",
      "epoch: 3, batch: 1082, loss: 1.2717649936676025\n",
      "epoch: 3, batch: 1083, loss: 1.0845166444778442\n",
      "epoch: 3, batch: 1084, loss: 0.9786058664321899\n",
      "epoch: 3, batch: 1085, loss: 1.1420773267745972\n",
      "epoch: 3, batch: 1086, loss: 1.0111515522003174\n",
      "epoch: 3, batch: 1087, loss: 1.2546000480651855\n",
      "epoch: 3, batch: 1088, loss: 0.9979692697525024\n",
      "epoch: 3, batch: 1089, loss: 1.328670620918274\n",
      "epoch: 3, batch: 1090, loss: 0.985381007194519\n",
      "epoch: 3, batch: 1091, loss: 1.195865273475647\n",
      "epoch: 3, batch: 1092, loss: 1.1867396831512451\n",
      "epoch: 3, batch: 1093, loss: 1.3387291431427002\n",
      "epoch: 3, batch: 1094, loss: 1.046156406402588\n",
      "epoch: 3, batch: 1095, loss: 1.1622384786605835\n",
      "epoch: 3, batch: 1096, loss: 1.1698615550994873\n",
      "epoch: 3, batch: 1097, loss: 1.1777217388153076\n",
      "epoch: 3, batch: 1098, loss: 1.1967737674713135\n",
      "epoch: 3, batch: 1099, loss: 1.6049703359603882\n",
      "epoch: 3, batch: 1100, loss: 1.2170989513397217\n",
      "epoch: 3, batch: 1101, loss: 1.1058244705200195\n",
      "epoch: 3, batch: 1102, loss: 1.2176282405853271\n",
      "epoch: 3, batch: 1103, loss: 1.2408217191696167\n",
      "epoch: 3, batch: 1104, loss: 1.2135348320007324\n",
      "epoch: 3, batch: 1105, loss: 1.2079066038131714\n",
      "epoch: 3, batch: 1106, loss: 1.2829066514968872\n",
      "epoch: 3, batch: 1107, loss: 1.3185659646987915\n",
      "epoch: 3, batch: 1108, loss: 1.1455775499343872\n",
      "epoch: 3, batch: 1109, loss: 1.3975805044174194\n",
      "epoch: 3, batch: 1110, loss: 1.2534748315811157\n",
      "epoch: 3, batch: 1111, loss: 1.2854799032211304\n",
      "epoch: 3, batch: 1112, loss: 1.1281126737594604\n",
      "epoch: 3, batch: 1113, loss: 1.3943544626235962\n",
      "epoch: 3, batch: 1114, loss: 1.1916217803955078\n",
      "epoch: 3, batch: 1115, loss: 1.1066138744354248\n",
      "epoch: 3, batch: 1116, loss: 1.2089602947235107\n",
      "epoch: 3, batch: 1117, loss: 1.1218944787979126\n",
      "epoch: 3, batch: 1118, loss: 1.0707576274871826\n",
      "epoch: 3, batch: 1119, loss: 1.1789531707763672\n",
      "epoch: 3, batch: 1120, loss: 1.2579878568649292\n",
      "epoch: 3, batch: 1121, loss: 1.147672414779663\n",
      "epoch: 3, batch: 1122, loss: 1.116722822189331\n",
      "epoch: 3, batch: 1123, loss: 1.1627141237258911\n",
      "epoch: 3, batch: 1124, loss: 1.2438501119613647\n",
      "epoch: 3, batch: 1125, loss: 1.2292972803115845\n",
      "epoch: 3, batch: 1126, loss: 1.0990509986877441\n",
      "epoch: 3, batch: 1127, loss: 1.378914713859558\n",
      "epoch: 3, batch: 1128, loss: 1.0423043966293335\n",
      "epoch: 3, batch: 1129, loss: 1.1804386377334595\n",
      "epoch: 3, batch: 1130, loss: 1.1278131008148193\n",
      "epoch: 3, batch: 1131, loss: 1.0193482637405396\n",
      "epoch: 3, batch: 1132, loss: 1.2783114910125732\n",
      "epoch: 3, batch: 1133, loss: 1.080902338027954\n",
      "epoch: 3, batch: 1134, loss: 1.0309169292449951\n",
      "epoch: 3, batch: 1135, loss: 1.126894235610962\n",
      "epoch: 3, batch: 1136, loss: 1.2008336782455444\n",
      "epoch: 3, batch: 1137, loss: 1.0046693086624146\n",
      "epoch: 3, batch: 1138, loss: 1.1784679889678955\n",
      "epoch: 3, batch: 1139, loss: 1.1135318279266357\n",
      "epoch: 3, batch: 1140, loss: 1.3335098028182983\n",
      "epoch: 3, batch: 1141, loss: 1.1805459260940552\n",
      "epoch: 3, batch: 1142, loss: 1.2402325868606567\n",
      "epoch: 3, batch: 1143, loss: 1.2535737752914429\n",
      "epoch: 3, batch: 1144, loss: 1.4301074743270874\n",
      "epoch: 3, batch: 1145, loss: 1.1955909729003906\n",
      "epoch: 3, batch: 1146, loss: 1.1053836345672607\n",
      "epoch: 3, batch: 1147, loss: 1.136466145515442\n",
      "epoch: 3, batch: 1148, loss: 1.1136130094528198\n",
      "epoch: 3, batch: 1149, loss: 1.3982661962509155\n",
      "epoch: 3, batch: 1150, loss: 1.2043135166168213\n",
      "epoch: 3, batch: 1151, loss: 0.9886031150817871\n",
      "epoch: 3, batch: 1152, loss: 1.2402536869049072\n",
      "epoch: 3, batch: 1153, loss: 1.1714869737625122\n",
      "epoch: 3, batch: 1154, loss: 1.1303703784942627\n",
      "epoch: 3, batch: 1155, loss: 1.2741624116897583\n",
      "epoch: 3, batch: 1156, loss: 1.107659101486206\n",
      "epoch: 3, batch: 1157, loss: 1.1836845874786377\n",
      "epoch: 3, batch: 1158, loss: 1.1686086654663086\n",
      "epoch: 3, batch: 1159, loss: 1.129265308380127\n",
      "epoch: 3, batch: 1160, loss: 1.142654538154602\n",
      "epoch: 3, batch: 1161, loss: 1.148017406463623\n",
      "epoch: 3, batch: 1162, loss: 1.1901265382766724\n",
      "epoch: 3, batch: 1163, loss: 1.0606998205184937\n",
      "epoch: 3, batch: 1164, loss: 1.1198945045471191\n",
      "epoch: 3, batch: 1165, loss: 1.0909148454666138\n",
      "epoch: 3, batch: 1166, loss: 1.4340183734893799\n",
      "epoch: 3, batch: 1167, loss: 1.266987681388855\n",
      "epoch: 3, batch: 1168, loss: 1.181654930114746\n",
      "epoch: 3, batch: 1169, loss: 1.218294620513916\n",
      "epoch: 3, batch: 1170, loss: 1.2190566062927246\n",
      "epoch: 3, batch: 1171, loss: 1.168861985206604\n",
      "epoch: 3, batch: 1172, loss: 1.4216861724853516\n",
      "epoch: 3, batch: 1173, loss: 1.2441322803497314\n",
      "epoch: 3, batch: 1174, loss: 1.247899055480957\n",
      "epoch: 3, batch: 1175, loss: 1.1445707082748413\n",
      "epoch: 3, batch: 1176, loss: 1.107177495956421\n",
      "epoch: 3, batch: 1177, loss: 1.0540937185287476\n",
      "epoch: 3, batch: 1178, loss: 1.1287287473678589\n",
      "epoch: 3, batch: 1179, loss: 1.2228254079818726\n",
      "epoch: 3, batch: 1180, loss: 1.2073869705200195\n",
      "epoch: 3, batch: 1181, loss: 1.3591203689575195\n",
      "epoch: 3, batch: 1182, loss: 1.3087570667266846\n",
      "epoch: 3, batch: 1183, loss: 1.2322202920913696\n",
      "epoch: 3, batch: 1184, loss: 1.1661376953125\n",
      "epoch: 3, batch: 1185, loss: 1.0573354959487915\n",
      "epoch: 3, batch: 1186, loss: 1.2888448238372803\n",
      "epoch: 3, batch: 1187, loss: 1.1778939962387085\n",
      "epoch: 3, batch: 1188, loss: 1.227283239364624\n",
      "epoch: 3, batch: 1189, loss: 1.2838932275772095\n",
      "epoch: 3, batch: 1190, loss: 1.198133111000061\n",
      "epoch: 3, batch: 1191, loss: 1.2052994966506958\n",
      "epoch: 3, batch: 1192, loss: 1.0877608060836792\n",
      "epoch: 3, batch: 1193, loss: 1.188848614692688\n",
      "epoch: 3, batch: 1194, loss: 1.1498397588729858\n",
      "epoch: 3, batch: 1195, loss: 1.0981401205062866\n",
      "epoch: 3, batch: 1196, loss: 1.200432300567627\n",
      "epoch: 3, batch: 1197, loss: 1.000700831413269\n",
      "epoch: 3, batch: 1198, loss: 0.9625053405761719\n",
      "epoch: 3, batch: 1199, loss: 1.3085319995880127\n",
      "epoch: 3, batch: 1200, loss: 1.2743557691574097\n",
      "epoch: 3, batch: 1201, loss: 1.1198123693466187\n",
      "epoch: 3, batch: 1202, loss: 1.0284528732299805\n",
      "epoch: 3, batch: 1203, loss: 1.179123044013977\n",
      "epoch: 3, batch: 1204, loss: 1.1577852964401245\n",
      "epoch: 3, batch: 1205, loss: 1.0800113677978516\n",
      "epoch: 3, batch: 1206, loss: 1.1879792213439941\n",
      "epoch: 3, batch: 1207, loss: 1.115594744682312\n",
      "epoch: 3, batch: 1208, loss: 1.2331840991973877\n",
      "epoch: 3, batch: 1209, loss: 1.350204586982727\n",
      "epoch: 3, batch: 1210, loss: 1.1920123100280762\n",
      "epoch: 3, batch: 1211, loss: 1.2930828332901\n",
      "epoch: 3, batch: 1212, loss: 1.2497315406799316\n",
      "epoch: 3, batch: 1213, loss: 1.112264633178711\n",
      "epoch: 3, batch: 1214, loss: 1.0945273637771606\n",
      "epoch: 3, batch: 1215, loss: 1.1579900979995728\n",
      "epoch: 3, batch: 1216, loss: 1.1781762838363647\n",
      "epoch: 3, batch: 1217, loss: 1.0277024507522583\n",
      "epoch: 3, batch: 1218, loss: 1.0977758169174194\n",
      "epoch: 3, batch: 1219, loss: 1.2401354312896729\n",
      "epoch: 3, batch: 1220, loss: 1.201509952545166\n",
      "epoch: 3, batch: 1221, loss: 1.2388375997543335\n",
      "epoch: 3, batch: 1222, loss: 1.093500018119812\n",
      "epoch: 3, batch: 1223, loss: 1.1469600200653076\n",
      "epoch: 3, batch: 1224, loss: 1.0913703441619873\n",
      "epoch: 3, batch: 1225, loss: 1.0749889612197876\n",
      "epoch: 3, batch: 1226, loss: 1.198758840560913\n",
      "epoch: 3, batch: 1227, loss: 1.1346368789672852\n",
      "epoch: 3, batch: 1228, loss: 1.1455190181732178\n",
      "epoch: 3, batch: 1229, loss: 1.2429479360580444\n",
      "epoch: 3, batch: 1230, loss: 1.3185979127883911\n",
      "epoch: 3, batch: 1231, loss: 1.2388830184936523\n",
      "epoch: 3, batch: 1232, loss: 1.3481345176696777\n",
      "epoch: 3, batch: 1233, loss: 1.2258409261703491\n",
      "epoch: 3, batch: 1234, loss: 1.0927623510360718\n",
      "epoch: 3, batch: 1235, loss: 1.0809000730514526\n",
      "epoch: 3, batch: 1236, loss: 1.0996745824813843\n",
      "epoch: 3, batch: 1237, loss: 1.2441668510437012\n",
      "epoch: 3, batch: 1238, loss: 1.098681092262268\n",
      "epoch: 3, batch: 1239, loss: 1.1621263027191162\n",
      "epoch: 3, batch: 1240, loss: 1.077962040901184\n",
      "epoch: 3, batch: 1241, loss: 1.2796367406845093\n",
      "epoch: 3, batch: 1242, loss: 1.1645513772964478\n",
      "epoch: 3, batch: 1243, loss: 1.1990370750427246\n",
      "epoch: 3, batch: 1244, loss: 1.2308404445648193\n",
      "epoch: 3, batch: 1245, loss: 1.2605165243148804\n",
      "epoch: 3, batch: 1246, loss: 1.1397768259048462\n",
      "epoch: 3, batch: 1247, loss: 1.4542262554168701\n",
      "epoch: 3, batch: 1248, loss: 1.0984199047088623\n",
      "epoch: 3, batch: 1249, loss: 1.1618738174438477\n",
      "epoch: 3, batch: 1250, loss: 1.1967909336090088\n",
      "epoch: 3, batch: 1251, loss: 1.2587220668792725\n",
      "epoch: 3, batch: 1252, loss: 1.3642627000808716\n",
      "epoch: 3, batch: 1253, loss: 0.970508873462677\n",
      "epoch: 3, batch: 1254, loss: 1.0993832349777222\n",
      "epoch: 3, batch: 1255, loss: 1.3093345165252686\n",
      "epoch: 3, batch: 1256, loss: 1.2532869577407837\n",
      "epoch: 3, batch: 1257, loss: 1.2479658126831055\n",
      "epoch: 3, batch: 1258, loss: 1.0688945055007935\n",
      "epoch: 3, batch: 1259, loss: 1.0996479988098145\n",
      "epoch: 3, batch: 1260, loss: 1.2140192985534668\n",
      "epoch: 3, batch: 1261, loss: 1.205383062362671\n",
      "epoch: 3, batch: 1262, loss: 1.2085120677947998\n",
      "epoch: 3, batch: 1263, loss: 1.1945669651031494\n",
      "epoch: 3, batch: 1264, loss: 1.074826955795288\n",
      "epoch: 3, batch: 1265, loss: 1.1691176891326904\n",
      "epoch: 3, batch: 1266, loss: 1.2443352937698364\n",
      "epoch: 3, batch: 1267, loss: 1.0259661674499512\n",
      "epoch: 3, batch: 1268, loss: 1.3563193082809448\n",
      "epoch: 3, batch: 1269, loss: 1.1240202188491821\n",
      "epoch: 3, batch: 1270, loss: 1.2469072341918945\n",
      "epoch: 3, batch: 1271, loss: 1.167818307876587\n",
      "epoch: 3, batch: 1272, loss: 1.2133262157440186\n",
      "epoch: 3, batch: 1273, loss: 1.1269686222076416\n",
      "epoch: 3, batch: 1274, loss: 1.1050819158554077\n",
      "epoch: 3, batch: 1275, loss: 0.9449796676635742\n",
      "epoch: 3, batch: 1276, loss: 1.367934226989746\n",
      "epoch: 3, batch: 1277, loss: 1.2482320070266724\n",
      "epoch: 3, batch: 1278, loss: 1.0778900384902954\n",
      "epoch: 3, batch: 1279, loss: 1.1734399795532227\n",
      "epoch: 3, batch: 1280, loss: 1.1875081062316895\n",
      "epoch: 3, batch: 1281, loss: 1.1553843021392822\n",
      "epoch: 3, batch: 1282, loss: 1.1574801206588745\n",
      "epoch: 3, batch: 1283, loss: 1.032364845275879\n",
      "epoch: 3, batch: 1284, loss: 1.1643482446670532\n",
      "epoch: 3, batch: 1285, loss: 1.2125582695007324\n",
      "epoch: 3, batch: 1286, loss: 1.0687835216522217\n",
      "epoch: 3, batch: 1287, loss: 1.1074409484863281\n",
      "epoch: 3, batch: 1288, loss: 1.1606489419937134\n",
      "epoch: 3, batch: 1289, loss: 1.116808295249939\n",
      "epoch: 3, batch: 1290, loss: 1.1702182292938232\n",
      "epoch: 3, batch: 1291, loss: 1.1560951471328735\n",
      "epoch: 3, batch: 1292, loss: 1.2821507453918457\n",
      "epoch: 3, batch: 1293, loss: 1.1209620237350464\n",
      "epoch: 3, batch: 1294, loss: 1.1544891595840454\n",
      "epoch: 3, batch: 1295, loss: 1.3986314535140991\n",
      "epoch: 3, batch: 1296, loss: 1.2379069328308105\n",
      "epoch: 3, batch: 1297, loss: 1.1976970434188843\n",
      "epoch: 3, batch: 1298, loss: 1.0659128427505493\n",
      "epoch: 3, batch: 1299, loss: 1.2158137559890747\n",
      "epoch: 3, batch: 1300, loss: 0.8861749768257141\n",
      "epoch: 3, batch: 1301, loss: 1.2115637063980103\n",
      "epoch: 3, batch: 1302, loss: 1.2484169006347656\n",
      "epoch: 3, batch: 1303, loss: 1.1534479856491089\n",
      "epoch: 3, batch: 1304, loss: 1.2653816938400269\n",
      "epoch: 3, batch: 1305, loss: 1.10610032081604\n",
      "epoch: 3, batch: 1306, loss: 0.9447454214096069\n",
      "epoch: 3, batch: 1307, loss: 1.1981587409973145\n",
      "epoch: 3, batch: 1308, loss: 0.9755120873451233\n",
      "epoch: 3, batch: 1309, loss: 1.115357756614685\n",
      "epoch: 3, batch: 1310, loss: 1.0557347536087036\n",
      "epoch: 3, batch: 1311, loss: 1.1930427551269531\n",
      "epoch: 3, batch: 1312, loss: 1.0610437393188477\n",
      "epoch: 3, batch: 1313, loss: 1.1388704776763916\n",
      "epoch: 3, batch: 1314, loss: 1.349660873413086\n",
      "epoch: 3, batch: 1315, loss: 1.2385658025741577\n",
      "epoch: 3, batch: 1316, loss: 0.9518073797225952\n",
      "epoch: 3, batch: 1317, loss: 1.111991047859192\n",
      "epoch: 3, batch: 1318, loss: 1.222415566444397\n",
      "epoch: 3, batch: 1319, loss: 1.3037335872650146\n",
      "epoch: 3, batch: 1320, loss: 1.3498750925064087\n",
      "epoch: 3, batch: 1321, loss: 0.8627585768699646\n",
      "epoch: 3, batch: 1322, loss: 1.019189715385437\n",
      "epoch: 3, batch: 1323, loss: 1.229745864868164\n",
      "epoch: 3, batch: 1324, loss: 1.1382817029953003\n",
      "epoch: 3, batch: 1325, loss: 1.2919938564300537\n",
      "epoch: 3, batch: 1326, loss: 1.0277974605560303\n",
      "epoch: 3, batch: 1327, loss: 1.1631969213485718\n",
      "epoch: 3, batch: 1328, loss: 1.1383514404296875\n",
      "epoch: 3, batch: 1329, loss: 1.087298035621643\n",
      "epoch: 3, batch: 1330, loss: 0.9920874238014221\n",
      "epoch: 3, batch: 1331, loss: 1.4297627210617065\n",
      "epoch: 3, batch: 1332, loss: 0.9909234046936035\n",
      "epoch: 3, batch: 1333, loss: 1.0471562147140503\n",
      "epoch: 3, batch: 1334, loss: 1.2084975242614746\n",
      "epoch: 3, batch: 1335, loss: 1.0527746677398682\n",
      "epoch: 3, batch: 1336, loss: 1.0751186609268188\n",
      "epoch: 3, batch: 1337, loss: 1.3975872993469238\n",
      "epoch: 3, batch: 1338, loss: 1.0157933235168457\n",
      "epoch: 3, batch: 1339, loss: 1.1415984630584717\n",
      "epoch: 3, batch: 1340, loss: 1.1011104583740234\n",
      "epoch: 3, batch: 1341, loss: 0.95018070936203\n",
      "epoch: 3, batch: 1342, loss: 1.2415401935577393\n",
      "epoch: 3, batch: 1343, loss: 1.0078520774841309\n",
      "epoch: 3, batch: 1344, loss: 1.2845580577850342\n",
      "epoch: 3, batch: 1345, loss: 1.0696698427200317\n",
      "epoch: 3, batch: 1346, loss: 0.9494975209236145\n",
      "epoch: 3, batch: 1347, loss: 1.1964197158813477\n",
      "epoch: 3, batch: 1348, loss: 1.0597243309020996\n",
      "epoch: 3, batch: 1349, loss: 0.9668483734130859\n",
      "epoch: 3, batch: 1350, loss: 1.121590256690979\n",
      "epoch: 3, batch: 1351, loss: 1.4088760614395142\n",
      "epoch: 3, batch: 1352, loss: 1.1602978706359863\n",
      "epoch: 3, batch: 1353, loss: 1.02578604221344\n",
      "epoch: 3, batch: 1354, loss: 1.0465327501296997\n",
      "epoch: 3, batch: 1355, loss: 1.0111839771270752\n",
      "epoch: 3, batch: 1356, loss: 1.047143578529358\n",
      "epoch: 3, batch: 1357, loss: 1.1994291543960571\n",
      "epoch: 3, batch: 1358, loss: 1.0061157941818237\n",
      "epoch: 3, batch: 1359, loss: 1.0493322610855103\n",
      "epoch: 3, batch: 1360, loss: 1.1074162721633911\n",
      "epoch: 3, batch: 1361, loss: 1.0877114534378052\n",
      "epoch: 3, batch: 1362, loss: 1.0990794897079468\n",
      "epoch: 3, batch: 1363, loss: 1.2442567348480225\n",
      "epoch: 3, batch: 1364, loss: 1.1564158201217651\n",
      "epoch: 3, batch: 1365, loss: 1.0207840204238892\n",
      "epoch: 3, batch: 1366, loss: 1.0338554382324219\n",
      "epoch: 3, batch: 1367, loss: 1.3601621389389038\n",
      "epoch: 3, batch: 1368, loss: 1.1268399953842163\n",
      "epoch: 3, batch: 1369, loss: 1.1920723915100098\n",
      "epoch: 3, batch: 1370, loss: 1.0035669803619385\n",
      "epoch: 3, batch: 1371, loss: 1.1400902271270752\n",
      "epoch: 3, batch: 1372, loss: 1.0173932313919067\n",
      "epoch: 3, batch: 1373, loss: 1.129819393157959\n",
      "epoch: 3, batch: 1374, loss: 1.1768308877944946\n",
      "epoch: 3, batch: 1375, loss: 1.1865074634552002\n",
      "epoch: 3, batch: 1376, loss: 1.3845164775848389\n",
      "epoch: 3, batch: 1377, loss: 1.0602643489837646\n",
      "epoch: 3, batch: 1378, loss: 1.0221835374832153\n",
      "epoch: 3, batch: 1379, loss: 1.1513596773147583\n",
      "epoch: 3, batch: 1380, loss: 0.9434462785720825\n",
      "epoch: 3, batch: 1381, loss: 1.0484787225723267\n",
      "epoch: 3, batch: 1382, loss: 1.1580750942230225\n",
      "epoch: 3, batch: 1383, loss: 0.842616081237793\n",
      "epoch: 3, batch: 1384, loss: 1.090347409248352\n",
      "epoch: 3, batch: 1385, loss: 1.0230717658996582\n",
      "epoch: 3, batch: 1386, loss: 1.032577633857727\n",
      "epoch: 3, batch: 1387, loss: 0.8886303305625916\n",
      "epoch: 3, batch: 1388, loss: 1.0924108028411865\n",
      "epoch: 3, batch: 1389, loss: 1.1584428548812866\n",
      "epoch: 3, batch: 1390, loss: 1.1444069147109985\n",
      "epoch: 3, batch: 1391, loss: 1.0719807147979736\n",
      "epoch: 3, batch: 1392, loss: 0.9982367157936096\n",
      "epoch: 3, batch: 1393, loss: 0.9850230813026428\n",
      "epoch: 3, batch: 1394, loss: 1.377534031867981\n",
      "epoch: 3, batch: 1395, loss: 1.049177885055542\n",
      "epoch: 3, batch: 1396, loss: 1.1127134561538696\n",
      "epoch: 3, batch: 1397, loss: 1.2372417449951172\n",
      "epoch: 3, batch: 1398, loss: 1.137791633605957\n",
      "epoch: 3, batch: 1399, loss: 1.1882356405258179\n",
      "epoch: 3, batch: 1400, loss: 1.0595523118972778\n",
      "epoch: 3, batch: 1401, loss: 1.0378230810165405\n",
      "epoch: 3, batch: 1402, loss: 1.1416559219360352\n",
      "epoch: 3, batch: 1403, loss: 1.0886127948760986\n",
      "epoch: 3, batch: 1404, loss: 1.1256155967712402\n",
      "epoch: 3, batch: 1405, loss: 1.2419594526290894\n",
      "epoch: 3, batch: 1406, loss: 1.1693061590194702\n",
      "epoch: 3, batch: 1407, loss: 1.265992283821106\n",
      "epoch: 3, batch: 1408, loss: 1.0129477977752686\n",
      "epoch: 3, batch: 1409, loss: 1.1695246696472168\n",
      "epoch: 3, batch: 1410, loss: 0.9687719345092773\n",
      "epoch: 3, batch: 1411, loss: 1.0006424188613892\n",
      "epoch: 3, batch: 1412, loss: 1.0282928943634033\n",
      "epoch: 3, batch: 1413, loss: 1.061687707901001\n",
      "epoch: 3, batch: 1414, loss: 1.3626693487167358\n",
      "epoch: 3, batch: 1415, loss: 1.1204496622085571\n",
      "epoch: 3, batch: 1416, loss: 1.0559719800949097\n",
      "epoch: 3, batch: 1417, loss: 1.1529511213302612\n",
      "epoch: 3, batch: 1418, loss: 1.0712416172027588\n",
      "epoch: 3, batch: 1419, loss: 1.0209479331970215\n",
      "epoch: 3, batch: 1420, loss: 1.0031721591949463\n",
      "epoch: 3, batch: 1421, loss: 1.0317301750183105\n",
      "epoch: 3, batch: 1422, loss: 1.0754992961883545\n",
      "epoch: 3, batch: 1423, loss: 1.2301017045974731\n",
      "epoch: 3, batch: 1424, loss: 1.0179104804992676\n",
      "epoch: 3, batch: 1425, loss: 1.115958333015442\n",
      "epoch: 3, batch: 1426, loss: 1.2263035774230957\n",
      "epoch: 3, batch: 1427, loss: 0.9556236863136292\n",
      "epoch: 3, batch: 1428, loss: 1.1894956827163696\n",
      "epoch: 3, batch: 1429, loss: 1.1745030879974365\n",
      "epoch: 3, batch: 1430, loss: 1.178646445274353\n",
      "epoch: 3, batch: 1431, loss: 1.0982270240783691\n",
      "epoch: 3, batch: 1432, loss: 1.0499476194381714\n",
      "epoch: 3, batch: 1433, loss: 1.0881775617599487\n",
      "epoch: 3, batch: 1434, loss: 0.9977565407752991\n",
      "epoch: 3, batch: 1435, loss: 1.063347339630127\n",
      "epoch: 3, batch: 1436, loss: 1.030875563621521\n",
      "epoch: 3, batch: 1437, loss: 0.990391731262207\n",
      "epoch: 3, batch: 1438, loss: 1.0214773416519165\n",
      "epoch: 3, batch: 1439, loss: 1.1118119955062866\n",
      "epoch: 3, batch: 1440, loss: 1.3589149713516235\n",
      "epoch: 3, batch: 1441, loss: 1.0990697145462036\n",
      "epoch: 3, batch: 1442, loss: 1.139582633972168\n",
      "epoch: 3, batch: 1443, loss: 1.2131006717681885\n",
      "epoch: 3, batch: 1444, loss: 1.1626099348068237\n",
      "epoch: 3, batch: 1445, loss: 0.8699159026145935\n",
      "epoch: 3, batch: 1446, loss: 1.1638712882995605\n",
      "epoch: 3, batch: 1447, loss: 1.1388201713562012\n",
      "epoch: 3, batch: 1448, loss: 1.2017226219177246\n",
      "epoch: 3, batch: 1449, loss: 1.1823561191558838\n",
      "epoch: 3, batch: 1450, loss: 1.1789525747299194\n",
      "epoch: 3, batch: 1451, loss: 1.0753828287124634\n",
      "epoch: 3, batch: 1452, loss: 1.1617149114608765\n",
      "epoch: 3, batch: 1453, loss: 1.2102439403533936\n",
      "epoch: 3, batch: 1454, loss: 1.0522443056106567\n",
      "epoch: 3, batch: 1455, loss: 1.0275359153747559\n",
      "epoch: 3, batch: 1456, loss: 1.0732966661453247\n",
      "epoch: 3, batch: 1457, loss: 1.0823110342025757\n",
      "epoch: 3, batch: 1458, loss: 0.9477973580360413\n",
      "epoch: 3, batch: 1459, loss: 0.9754374623298645\n",
      "epoch: 3, batch: 1460, loss: 1.2054932117462158\n",
      "epoch: 3, batch: 1461, loss: 1.2121950387954712\n",
      "epoch: 3, batch: 1462, loss: 1.0397366285324097\n",
      "epoch: 3, batch: 1463, loss: 1.2910819053649902\n",
      "epoch: 3, batch: 1464, loss: 1.2501178979873657\n",
      "epoch: 3, batch: 1465, loss: 1.2081596851348877\n",
      "epoch: 3, batch: 1466, loss: 1.0379407405853271\n",
      "epoch: 3, batch: 1467, loss: 1.0090904235839844\n",
      "epoch: 3, batch: 1468, loss: 1.0739095211029053\n",
      "epoch: 3, batch: 1469, loss: 1.2526583671569824\n",
      "epoch: 3, batch: 1470, loss: 1.0384961366653442\n",
      "epoch: 3, batch: 1471, loss: 1.1520460844039917\n",
      "epoch: 3, batch: 1472, loss: 0.8894757628440857\n",
      "epoch: 3, batch: 1473, loss: 1.3935219049453735\n",
      "epoch: 3, batch: 1474, loss: 1.1070762872695923\n",
      "epoch: 3, batch: 1475, loss: 1.285401463508606\n",
      "epoch: 3, batch: 1476, loss: 1.0322394371032715\n",
      "epoch: 3, batch: 1477, loss: 1.3296964168548584\n",
      "epoch: 3, batch: 1478, loss: 1.0333139896392822\n",
      "epoch: 3, batch: 1479, loss: 1.2078509330749512\n",
      "epoch: 3, batch: 1480, loss: 1.1130832433700562\n",
      "epoch: 3, batch: 1481, loss: 0.9570695757865906\n",
      "epoch: 3, batch: 1482, loss: 1.0908794403076172\n",
      "epoch: 3, batch: 1483, loss: 1.0903747081756592\n",
      "epoch: 3, batch: 1484, loss: 1.2154306173324585\n",
      "epoch: 3, batch: 1485, loss: 1.1357756853103638\n",
      "epoch: 3, batch: 1486, loss: 1.0925313234329224\n",
      "epoch: 3, batch: 1487, loss: 0.9619712233543396\n",
      "epoch: 3, batch: 1488, loss: 1.1834903955459595\n",
      "epoch: 3, batch: 1489, loss: 1.0275671482086182\n",
      "epoch: 3, batch: 1490, loss: 1.0140880346298218\n",
      "epoch: 3, batch: 1491, loss: 1.1993035078048706\n",
      "epoch: 3, batch: 1492, loss: 1.100806713104248\n",
      "epoch: 3, batch: 1493, loss: 1.1714317798614502\n",
      "epoch: 3, batch: 1494, loss: 1.0215996503829956\n",
      "epoch: 3, batch: 1495, loss: 1.156570315361023\n",
      "epoch: 3, batch: 1496, loss: 1.1587889194488525\n",
      "epoch: 3, batch: 1497, loss: 1.1507134437561035\n",
      "epoch: 3, batch: 1498, loss: 1.1052143573760986\n",
      "epoch: 3, batch: 1499, loss: 1.0293354988098145\n",
      "epoch: 3, batch: 1500, loss: 0.9221418499946594\n",
      "epoch: 3, batch: 1501, loss: 1.1073933839797974\n",
      "epoch: 3, batch: 1502, loss: 0.9632934927940369\n",
      "epoch: 3, batch: 1503, loss: 0.9668951630592346\n",
      "epoch: 3, batch: 1504, loss: 1.1598103046417236\n",
      "epoch: 3, batch: 1505, loss: 0.8756967782974243\n",
      "epoch: 3, batch: 1506, loss: 1.1397793292999268\n",
      "epoch: 3, batch: 1507, loss: 1.0950428247451782\n",
      "epoch: 3, batch: 1508, loss: 0.9971601963043213\n",
      "epoch: 3, batch: 1509, loss: 1.196802020072937\n",
      "epoch: 3, batch: 1510, loss: 1.2060216665267944\n",
      "epoch: 3, batch: 1511, loss: 1.123405933380127\n",
      "epoch: 3, batch: 1512, loss: 1.2275837659835815\n",
      "epoch: 3, batch: 1513, loss: 1.1429837942123413\n",
      "epoch: 3, batch: 1514, loss: 1.28800630569458\n",
      "epoch: 3, batch: 1515, loss: 1.1113250255584717\n",
      "epoch: 3, batch: 1516, loss: 1.2319532632827759\n",
      "epoch: 3, batch: 1517, loss: 1.0812664031982422\n",
      "epoch: 3, batch: 1518, loss: 1.081520915031433\n",
      "epoch: 3, batch: 1519, loss: 1.0593132972717285\n",
      "epoch: 3, batch: 1520, loss: 0.9892828464508057\n",
      "epoch: 3, batch: 1521, loss: 1.224952220916748\n",
      "epoch: 3, batch: 1522, loss: 1.1070066690444946\n",
      "epoch: 3, batch: 1523, loss: 1.1815378665924072\n",
      "epoch: 3, batch: 1524, loss: 1.0765773057937622\n",
      "epoch: 3, batch: 1525, loss: 1.1121147871017456\n",
      "epoch: 3, batch: 1526, loss: 1.0533652305603027\n",
      "epoch: 3, batch: 1527, loss: 1.047655701637268\n",
      "epoch: 3, batch: 1528, loss: 1.353496789932251\n",
      "epoch: 3, batch: 1529, loss: 0.9646567702293396\n",
      "epoch: 3, batch: 1530, loss: 1.115557074546814\n",
      "epoch: 3, batch: 1531, loss: 1.0552294254302979\n",
      "epoch: 3, batch: 1532, loss: 1.028548002243042\n",
      "epoch: 3, batch: 1533, loss: 1.173852801322937\n",
      "epoch: 3, batch: 1534, loss: 1.089409351348877\n",
      "epoch: 3, batch: 1535, loss: 1.0561827421188354\n",
      "epoch: 3, batch: 1536, loss: 1.0509867668151855\n",
      "epoch: 3, batch: 1537, loss: 1.1058309078216553\n",
      "epoch: 3, batch: 1538, loss: 0.9130650758743286\n",
      "epoch: 3, batch: 1539, loss: 1.1820045709609985\n",
      "epoch: 3, batch: 1540, loss: 1.1038637161254883\n",
      "epoch: 3, batch: 1541, loss: 1.3122421503067017\n",
      "epoch: 3, batch: 1542, loss: 1.1480149030685425\n",
      "epoch: 3, batch: 1543, loss: 1.0565364360809326\n",
      "epoch: 3, batch: 1544, loss: 1.0003974437713623\n",
      "epoch: 3, batch: 1545, loss: 1.0125528573989868\n",
      "epoch: 3, batch: 1546, loss: 1.0569952726364136\n",
      "epoch: 3, batch: 1547, loss: 1.077893853187561\n",
      "epoch: 3, batch: 1548, loss: 1.1161104440689087\n",
      "epoch: 3, batch: 1549, loss: 1.0291136503219604\n",
      "epoch: 3, batch: 1550, loss: 1.1454038619995117\n",
      "epoch: 3, batch: 1551, loss: 1.0729663372039795\n",
      "epoch: 3, batch: 1552, loss: 1.2063642740249634\n",
      "epoch: 3, batch: 1553, loss: 0.9364714622497559\n",
      "epoch: 3, batch: 1554, loss: 1.2442086935043335\n",
      "epoch: 3, batch: 1555, loss: 1.0447648763656616\n",
      "epoch: 3, batch: 1556, loss: 1.1427628993988037\n",
      "epoch: 3, batch: 1557, loss: 1.083927035331726\n",
      "epoch: 3, batch: 1558, loss: 0.9753838777542114\n",
      "epoch: 3, batch: 1559, loss: 1.1127195358276367\n",
      "epoch: 3, batch: 1560, loss: 1.0503753423690796\n",
      "epoch: 3, batch: 1561, loss: 1.157242774963379\n",
      "epoch: 3, batch: 1562, loss: 1.100541591644287\n",
      "epoch: 3, batch: 1563, loss: 1.1793832778930664\n",
      "epoch: 3, batch: 1564, loss: 0.953058123588562\n",
      "epoch: 3, batch: 1565, loss: 1.097872257232666\n",
      "epoch: 3, batch: 1566, loss: 1.0739314556121826\n",
      "epoch: 3, batch: 1567, loss: 1.123403549194336\n",
      "epoch: 3, batch: 1568, loss: 0.9411959648132324\n",
      "epoch: 3, batch: 1569, loss: 1.1218000650405884\n",
      "epoch: 3, batch: 1570, loss: 1.2274999618530273\n",
      "epoch: 3, batch: 1571, loss: 0.9954423904418945\n",
      "epoch: 3, batch: 1572, loss: 0.9634755253791809\n",
      "epoch: 3, batch: 1573, loss: 1.071155309677124\n",
      "epoch: 3, batch: 1574, loss: 1.0412615537643433\n",
      "epoch: 3, batch: 1575, loss: 1.1391199827194214\n",
      "epoch: 3, batch: 1576, loss: 1.1652888059616089\n",
      "epoch: 3, batch: 1577, loss: 1.1758413314819336\n",
      "epoch: 3, batch: 1578, loss: 1.157700777053833\n",
      "epoch: 3, batch: 1579, loss: 0.9819523096084595\n",
      "epoch: 3, batch: 1580, loss: 0.9864985942840576\n",
      "epoch: 3, batch: 1581, loss: 1.170133113861084\n",
      "epoch: 3, batch: 1582, loss: 1.0568640232086182\n",
      "epoch: 3, batch: 1583, loss: 1.0652735233306885\n",
      "epoch: 3, batch: 1584, loss: 1.0667767524719238\n",
      "epoch: 3, batch: 1585, loss: 1.2539401054382324\n",
      "epoch: 3, batch: 1586, loss: 0.9059188961982727\n",
      "epoch: 3, batch: 1587, loss: 1.0095508098602295\n",
      "epoch: 3, batch: 1588, loss: 1.0903406143188477\n",
      "epoch: 3, batch: 1589, loss: 0.9367097020149231\n",
      "epoch: 3, batch: 1590, loss: 1.1670093536376953\n",
      "epoch: 3, batch: 1591, loss: 0.8946682810783386\n",
      "epoch: 3, batch: 1592, loss: 1.0757179260253906\n",
      "epoch: 3, batch: 1593, loss: 1.0146563053131104\n",
      "epoch: 3, batch: 1594, loss: 1.0146574974060059\n",
      "epoch: 3, batch: 1595, loss: 1.0592741966247559\n",
      "epoch: 3, batch: 1596, loss: 1.1278458833694458\n",
      "epoch: 3, batch: 1597, loss: 0.9842009544372559\n",
      "epoch: 3, batch: 1598, loss: 1.1115756034851074\n",
      "epoch: 3, batch: 1599, loss: 1.2415456771850586\n",
      "epoch: 3, batch: 1600, loss: 1.064058780670166\n",
      "epoch: 3, batch: 1601, loss: 1.0682183504104614\n",
      "epoch: 3, batch: 1602, loss: 1.1090338230133057\n",
      "epoch: 3, batch: 1603, loss: 0.9224801659584045\n",
      "epoch: 3, batch: 1604, loss: 0.9889139533042908\n",
      "epoch: 3, batch: 1605, loss: 1.2807974815368652\n",
      "epoch: 3, batch: 1606, loss: 0.9999244809150696\n",
      "epoch: 3, batch: 1607, loss: 0.9487365484237671\n",
      "epoch: 3, batch: 1608, loss: 0.9820272922515869\n",
      "epoch: 3, batch: 1609, loss: 1.1398155689239502\n",
      "epoch: 3, batch: 1610, loss: 1.0494520664215088\n",
      "epoch: 3, batch: 1611, loss: 0.9188592433929443\n",
      "epoch: 3, batch: 1612, loss: 1.0593063831329346\n",
      "epoch: 3, batch: 1613, loss: 1.184359073638916\n",
      "epoch: 3, batch: 1614, loss: 0.9524798393249512\n",
      "epoch: 3, batch: 1615, loss: 0.8080449104309082\n",
      "epoch: 3, batch: 1616, loss: 1.0028882026672363\n",
      "epoch: 3, batch: 1617, loss: 1.0732545852661133\n",
      "epoch: 3, batch: 1618, loss: 1.1077921390533447\n",
      "epoch: 3, batch: 1619, loss: 1.197388768196106\n",
      "epoch: 3, batch: 1620, loss: 1.2548953294754028\n",
      "epoch: 3, batch: 1621, loss: 1.1205754280090332\n",
      "epoch: 3, batch: 1622, loss: 0.885037899017334\n",
      "epoch: 3, batch: 1623, loss: 1.0991833209991455\n",
      "epoch: 3, batch: 1624, loss: 1.148099422454834\n",
      "epoch: 3, batch: 1625, loss: 0.8540284633636475\n",
      "epoch: 3, batch: 1626, loss: 0.9281088709831238\n",
      "epoch: 3, batch: 1627, loss: 1.0951590538024902\n",
      "epoch: 3, batch: 1628, loss: 1.1136975288391113\n",
      "epoch: 3, batch: 1629, loss: 1.136801838874817\n",
      "epoch: 3, batch: 1630, loss: 1.0335110425949097\n",
      "epoch: 3, batch: 1631, loss: 1.207444190979004\n",
      "epoch: 3, batch: 1632, loss: 0.9807751774787903\n",
      "epoch: 3, batch: 1633, loss: 1.0452996492385864\n",
      "epoch: 3, batch: 1634, loss: 1.24881911277771\n",
      "epoch: 3, batch: 1635, loss: 0.9703041911125183\n",
      "epoch: 3, batch: 1636, loss: 1.0200010538101196\n",
      "epoch: 3, batch: 1637, loss: 1.2310152053833008\n",
      "epoch: 3, batch: 1638, loss: 1.028673768043518\n",
      "epoch: 3, batch: 1639, loss: 1.0632984638214111\n",
      "epoch: 3, batch: 1640, loss: 1.0286083221435547\n",
      "epoch: 3, batch: 1641, loss: 1.0977262258529663\n",
      "epoch: 3, batch: 1642, loss: 0.9748654365539551\n",
      "epoch: 3, batch: 1643, loss: 1.0633350610733032\n",
      "epoch: 3, batch: 1644, loss: 1.0582144260406494\n",
      "epoch: 3, batch: 1645, loss: 1.057498574256897\n",
      "epoch: 3, batch: 1646, loss: 0.9289618134498596\n",
      "epoch: 3, batch: 1647, loss: 0.9396292567253113\n",
      "epoch: 3, batch: 1648, loss: 0.7840676307678223\n",
      "epoch: 3, batch: 1649, loss: 1.0432188510894775\n",
      "epoch: 3, batch: 1650, loss: 1.0880390405654907\n",
      "epoch: 3, batch: 1651, loss: 1.0187509059906006\n",
      "epoch: 3, batch: 1652, loss: 1.0223989486694336\n",
      "epoch: 3, batch: 1653, loss: 1.1002566814422607\n",
      "epoch: 3, batch: 1654, loss: 1.0614968538284302\n",
      "epoch: 3, batch: 1655, loss: 0.970835268497467\n",
      "epoch: 3, batch: 1656, loss: 1.0331958532333374\n",
      "epoch: 3, batch: 1657, loss: 1.0685126781463623\n",
      "epoch: 3, batch: 1658, loss: 1.206505298614502\n",
      "epoch: 3, batch: 1659, loss: 1.0616536140441895\n",
      "epoch: 3, batch: 1660, loss: 1.189178466796875\n",
      "epoch: 3, batch: 1661, loss: 0.9783256649971008\n",
      "epoch: 3, batch: 1662, loss: 1.2800588607788086\n",
      "epoch: 3, batch: 1663, loss: 1.09352707862854\n",
      "epoch: 3, batch: 1664, loss: 1.119969129562378\n",
      "epoch: 3, batch: 1665, loss: 1.0829339027404785\n",
      "epoch: 3, batch: 1666, loss: 1.0358695983886719\n",
      "epoch: 3, batch: 1667, loss: 1.1521486043930054\n",
      "epoch: 3, batch: 1668, loss: 0.9258604645729065\n",
      "epoch: 3, batch: 1669, loss: 1.0759481191635132\n",
      "epoch: 3, batch: 1670, loss: 0.983101487159729\n",
      "epoch: 3, batch: 1671, loss: 1.1748439073562622\n",
      "epoch: 3, batch: 1672, loss: 1.2740739583969116\n",
      "epoch: 3, batch: 1673, loss: 0.9829787611961365\n",
      "epoch: 3, batch: 1674, loss: 1.1217360496520996\n",
      "epoch: 3, batch: 1675, loss: 1.0510950088500977\n",
      "epoch: 3, batch: 1676, loss: 1.031827688217163\n",
      "epoch: 3, batch: 1677, loss: 0.9893419742584229\n",
      "epoch: 3, batch: 1678, loss: 1.2061779499053955\n",
      "epoch: 3, batch: 1679, loss: 1.2670472860336304\n",
      "epoch: 3, batch: 1680, loss: 0.9243121147155762\n",
      "epoch: 3, batch: 1681, loss: 1.1450343132019043\n",
      "epoch: 3, batch: 1682, loss: 1.1845996379852295\n",
      "epoch: 3, batch: 1683, loss: 0.8980660438537598\n",
      "epoch: 3, batch: 1684, loss: 1.0010426044464111\n",
      "epoch: 3, batch: 1685, loss: 0.9851956963539124\n",
      "epoch: 3, batch: 1686, loss: 1.2145181894302368\n",
      "epoch: 3, batch: 1687, loss: 1.0270200967788696\n",
      "epoch: 3, batch: 1688, loss: 0.9659415483474731\n",
      "epoch: 3, batch: 1689, loss: 1.0004053115844727\n",
      "epoch: 3, batch: 1690, loss: 0.9962770938873291\n",
      "epoch: 3, batch: 1691, loss: 1.0604580640792847\n",
      "epoch: 3, batch: 1692, loss: 0.9889309406280518\n",
      "epoch: 3, batch: 1693, loss: 0.9699405431747437\n",
      "epoch: 3, batch: 1694, loss: 1.076819658279419\n",
      "epoch: 3, batch: 1695, loss: 1.0946189165115356\n",
      "epoch: 3, batch: 1696, loss: 1.0406121015548706\n",
      "epoch: 3, batch: 1697, loss: 0.9356133341789246\n",
      "epoch: 3, batch: 1698, loss: 0.9444278478622437\n",
      "epoch: 3, batch: 1699, loss: 0.9107717275619507\n",
      "epoch: 3, batch: 1700, loss: 0.9920552372932434\n",
      "epoch: 3, batch: 1701, loss: 1.037692904472351\n",
      "epoch: 3, batch: 1702, loss: 1.0568301677703857\n",
      "epoch: 3, batch: 1703, loss: 1.0797226428985596\n",
      "epoch: 3, batch: 1704, loss: 1.1832940578460693\n",
      "epoch: 3, batch: 1705, loss: 1.1483346223831177\n",
      "epoch: 3, batch: 1706, loss: 1.02509605884552\n",
      "epoch: 3, batch: 1707, loss: 1.0951035022735596\n",
      "epoch: 3, batch: 1708, loss: 0.8559860587120056\n",
      "epoch: 3, batch: 1709, loss: 0.9532000422477722\n",
      "epoch: 3, batch: 1710, loss: 0.9452937841415405\n",
      "epoch: 3, batch: 1711, loss: 0.9757816195487976\n",
      "epoch: 3, batch: 1712, loss: 0.9981929659843445\n",
      "epoch: 3, batch: 1713, loss: 1.1072379350662231\n",
      "epoch: 3, batch: 1714, loss: 1.167965054512024\n",
      "epoch: 3, batch: 1715, loss: 1.0017151832580566\n",
      "epoch: 3, batch: 1716, loss: 1.1026585102081299\n",
      "epoch: 3, batch: 1717, loss: 1.1521580219268799\n",
      "epoch: 3, batch: 1718, loss: 1.0826808214187622\n",
      "epoch: 3, batch: 1719, loss: 0.9875789284706116\n",
      "epoch: 3, batch: 1720, loss: 1.2342997789382935\n",
      "epoch: 3, batch: 1721, loss: 1.045377254486084\n",
      "epoch: 3, batch: 1722, loss: 1.0732314586639404\n",
      "epoch: 3, batch: 1723, loss: 0.9603049159049988\n",
      "epoch: 3, batch: 1724, loss: 1.0413788557052612\n",
      "epoch: 3, batch: 1725, loss: 0.9629930853843689\n",
      "epoch: 3, batch: 1726, loss: 1.069663166999817\n",
      "epoch: 3, batch: 1727, loss: 0.9711355566978455\n",
      "epoch: 3, batch: 1728, loss: 0.9777407050132751\n",
      "epoch: 3, batch: 1729, loss: 0.9540393352508545\n",
      "epoch: 3, batch: 1730, loss: 1.0625685453414917\n",
      "epoch: 3, batch: 1731, loss: 0.9748696684837341\n",
      "epoch: 3, batch: 1732, loss: 1.0266331434249878\n",
      "epoch: 3, batch: 1733, loss: 1.0789498090744019\n",
      "epoch: 3, batch: 1734, loss: 1.0423583984375\n",
      "epoch: 3, batch: 1735, loss: 1.1374253034591675\n",
      "epoch: 3, batch: 1736, loss: 1.0444166660308838\n",
      "epoch: 3, batch: 1737, loss: 1.139229416847229\n",
      "epoch: 3, batch: 1738, loss: 1.1385746002197266\n",
      "epoch: 3, batch: 1739, loss: 1.1176538467407227\n",
      "epoch: 3, batch: 1740, loss: 0.8862728476524353\n",
      "epoch: 3, batch: 1741, loss: 1.1883864402770996\n",
      "epoch: 3, batch: 1742, loss: 1.0658847093582153\n",
      "epoch: 3, batch: 1743, loss: 0.8859691619873047\n",
      "epoch: 3, batch: 1744, loss: 1.060915231704712\n",
      "epoch: 3, batch: 1745, loss: 1.0759057998657227\n",
      "epoch: 3, batch: 1746, loss: 0.9822304844856262\n",
      "epoch: 3, batch: 1747, loss: 1.0872622728347778\n",
      "epoch: 3, batch: 1748, loss: 1.0511283874511719\n",
      "epoch: 3, batch: 1749, loss: 0.7312017679214478\n",
      "epoch: 3, batch: 1750, loss: 0.9652013778686523\n",
      "epoch: 3, batch: 1751, loss: 1.1740258932113647\n",
      "epoch: 3, batch: 1752, loss: 1.1062240600585938\n",
      "epoch: 3, batch: 1753, loss: 1.151169776916504\n",
      "epoch: 3, batch: 1754, loss: 1.2075809240341187\n",
      "epoch: 3, batch: 1755, loss: 1.2076785564422607\n",
      "epoch: 3, batch: 1756, loss: 1.3704092502593994\n",
      "epoch: 3, batch: 1757, loss: 1.1776939630508423\n",
      "epoch: 3, batch: 1758, loss: 1.0252699851989746\n",
      "epoch: 3, batch: 1759, loss: 1.143564224243164\n",
      "epoch: 3, batch: 1760, loss: 0.8696346879005432\n",
      "epoch: 3, batch: 1761, loss: 0.9676949977874756\n",
      "epoch: 3, batch: 1762, loss: 0.9394375085830688\n",
      "epoch: 3, batch: 1763, loss: 1.1245461702346802\n",
      "epoch: 3, batch: 1764, loss: 1.0332372188568115\n",
      "epoch: 3, batch: 1765, loss: 1.1455403566360474\n",
      "epoch: 3, batch: 1766, loss: 0.9052013158798218\n",
      "epoch: 3, batch: 1767, loss: 1.0356028079986572\n",
      "epoch: 3, batch: 1768, loss: 1.0605489015579224\n",
      "epoch: 3, batch: 1769, loss: 1.0468231439590454\n",
      "epoch: 3, batch: 1770, loss: 0.950529158115387\n",
      "epoch: 3, batch: 1771, loss: 1.1922684907913208\n",
      "epoch: 3, batch: 1772, loss: 1.1485183238983154\n",
      "epoch: 3, batch: 1773, loss: 1.0313557386398315\n",
      "epoch: 3, batch: 1774, loss: 1.098264455795288\n",
      "epoch: 3, batch: 1775, loss: 1.0909985303878784\n",
      "epoch: 3, batch: 1776, loss: 1.1516724824905396\n",
      "epoch: 3, batch: 1777, loss: 1.116579294204712\n",
      "epoch: 3, batch: 1778, loss: 0.8674420118331909\n",
      "epoch: 3, batch: 1779, loss: 1.1575443744659424\n",
      "epoch: 3, batch: 1780, loss: 1.299747347831726\n",
      "epoch: 3, batch: 1781, loss: 1.2236336469650269\n",
      "epoch: 3, batch: 1782, loss: 0.9641209840774536\n",
      "epoch: 3, batch: 1783, loss: 1.007317066192627\n",
      "epoch: 3, batch: 1784, loss: 1.0019080638885498\n",
      "epoch: 3, batch: 1785, loss: 0.9946255683898926\n",
      "epoch: 3, batch: 1786, loss: 1.024931788444519\n",
      "epoch: 3, batch: 1787, loss: 1.0460700988769531\n",
      "epoch: 3, batch: 1788, loss: 1.1365224123001099\n",
      "epoch: 3, batch: 1789, loss: 0.9926624298095703\n",
      "epoch: 3, batch: 1790, loss: 0.8777486085891724\n",
      "epoch: 3, batch: 1791, loss: 0.9613977074623108\n",
      "epoch: 3, batch: 1792, loss: 0.9923146963119507\n",
      "epoch: 3, batch: 1793, loss: 0.8998659253120422\n",
      "epoch: 3, batch: 1794, loss: 0.977949321269989\n",
      "epoch: 3, batch: 1795, loss: 1.1787018775939941\n",
      "epoch: 3, batch: 1796, loss: 1.053114414215088\n",
      "epoch: 3, batch: 1797, loss: 1.2223998308181763\n",
      "epoch: 3, batch: 1798, loss: 0.912059485912323\n",
      "epoch: 3, batch: 1799, loss: 1.0171197652816772\n",
      "epoch: 3, batch: 1800, loss: 1.1318168640136719\n",
      "epoch: 3, batch: 1801, loss: 0.946223795413971\n",
      "epoch: 3, batch: 1802, loss: 1.1194616556167603\n",
      "epoch: 3, batch: 1803, loss: 0.8761422634124756\n",
      "epoch: 3, batch: 1804, loss: 1.0254943370819092\n",
      "epoch: 3, batch: 1805, loss: 1.0286134481430054\n",
      "epoch: 3, batch: 1806, loss: 1.183209776878357\n",
      "epoch: 3, batch: 1807, loss: 1.0786546468734741\n",
      "epoch: 3, batch: 1808, loss: 1.019285798072815\n",
      "epoch: 3, batch: 1809, loss: 1.0723876953125\n",
      "epoch: 3, batch: 1810, loss: 1.051789402961731\n",
      "epoch: 3, batch: 1811, loss: 0.8459169864654541\n",
      "epoch: 3, batch: 1812, loss: 1.0126867294311523\n",
      "epoch: 3, batch: 1813, loss: 1.0185502767562866\n",
      "epoch: 3, batch: 1814, loss: 1.027456283569336\n",
      "epoch: 3, batch: 1815, loss: 0.9153980612754822\n",
      "epoch: 3, batch: 1816, loss: 1.037793755531311\n",
      "epoch: 3, batch: 1817, loss: 0.970432460308075\n",
      "epoch: 3, batch: 1818, loss: 1.120261311531067\n",
      "epoch: 3, batch: 1819, loss: 1.0114153623580933\n",
      "epoch: 3, batch: 1820, loss: 1.1077338457107544\n",
      "epoch: 3, batch: 1821, loss: 1.0041675567626953\n",
      "epoch: 3, batch: 1822, loss: 0.9196942448616028\n",
      "epoch: 3, batch: 1823, loss: 1.0982826948165894\n",
      "epoch: 3, batch: 1824, loss: 1.1680874824523926\n",
      "epoch: 3, batch: 1825, loss: 0.8106791973114014\n",
      "epoch: 3, batch: 1826, loss: 0.9970037937164307\n",
      "epoch: 3, batch: 1827, loss: 1.111026406288147\n",
      "epoch: 3, batch: 1828, loss: 1.0965754985809326\n",
      "epoch: 3, batch: 1829, loss: 1.1842846870422363\n",
      "epoch: 3, batch: 1830, loss: 1.1869242191314697\n",
      "epoch: 3, batch: 1831, loss: 1.1084729433059692\n",
      "epoch: 3, batch: 1832, loss: 1.1721560955047607\n",
      "epoch: 3, batch: 1833, loss: 1.1740355491638184\n",
      "epoch: 3, batch: 1834, loss: 0.9796632528305054\n",
      "epoch: 3, batch: 1835, loss: 0.925083577632904\n",
      "epoch: 3, batch: 1836, loss: 0.9030377864837646\n",
      "epoch: 3, batch: 1837, loss: 1.1389679908752441\n",
      "epoch: 3, batch: 1838, loss: 1.1695598363876343\n",
      "epoch: 3, batch: 1839, loss: 0.9915624260902405\n",
      "epoch: 3, batch: 1840, loss: 1.0757579803466797\n",
      "epoch: 3, batch: 1841, loss: 0.8849721550941467\n",
      "epoch: 3, batch: 1842, loss: 0.894384503364563\n",
      "epoch: 3, batch: 1843, loss: 0.7765661478042603\n",
      "epoch: 3, batch: 1844, loss: 1.097237467765808\n",
      "epoch: 3, batch: 1845, loss: 0.9743703007698059\n",
      "epoch: 3, batch: 1846, loss: 0.9369465708732605\n",
      "epoch: 3, batch: 1847, loss: 1.1411142349243164\n",
      "epoch: 3, batch: 1848, loss: 0.9939278364181519\n",
      "epoch: 3, batch: 1849, loss: 1.0550999641418457\n",
      "epoch: 3, batch: 1850, loss: 1.045499324798584\n",
      "epoch: 3, batch: 1851, loss: 1.3227840662002563\n",
      "epoch: 3, batch: 1852, loss: 0.9185459613800049\n",
      "epoch: 3, batch: 1853, loss: 0.8039199709892273\n",
      "epoch: 3, batch: 1854, loss: 0.9388833045959473\n",
      "epoch: 3, batch: 1855, loss: 0.8337955474853516\n",
      "epoch: 3, batch: 1856, loss: 1.0730600357055664\n",
      "epoch: 3, batch: 1857, loss: 1.0709494352340698\n",
      "epoch: 3, batch: 1858, loss: 0.9875597357749939\n",
      "epoch: 3, batch: 1859, loss: 0.9639615416526794\n",
      "epoch: 3, batch: 1860, loss: 1.0760080814361572\n",
      "epoch: 3, batch: 1861, loss: 1.0193183422088623\n",
      "epoch: 3, batch: 1862, loss: 1.0775526762008667\n",
      "epoch: 3, batch: 1863, loss: 1.1747441291809082\n",
      "epoch: 3, batch: 1864, loss: 0.9035351276397705\n",
      "epoch: 3, batch: 1865, loss: 1.1950078010559082\n",
      "epoch: 3, batch: 1866, loss: 0.8764219880104065\n",
      "epoch: 3, batch: 1867, loss: 1.0249050855636597\n",
      "epoch: 3, batch: 1868, loss: 0.9587070941925049\n",
      "epoch: 3, batch: 1869, loss: 0.8182767033576965\n",
      "epoch: 3, batch: 1870, loss: 1.0847837924957275\n",
      "epoch: 3, batch: 1871, loss: 1.013857126235962\n",
      "epoch: 3, batch: 1872, loss: 1.0518085956573486\n",
      "epoch: 3, batch: 1873, loss: 1.037894606590271\n",
      "epoch: 3, batch: 1874, loss: 0.979273796081543\n",
      "epoch: 4, batch: 0, loss: 0.8576751947402954\n",
      "epoch: 4, batch: 1, loss: 0.8882334232330322\n",
      "epoch: 4, batch: 2, loss: 1.0376673936843872\n",
      "epoch: 4, batch: 3, loss: 0.9637411236763\n",
      "epoch: 4, batch: 4, loss: 1.0370049476623535\n",
      "epoch: 4, batch: 5, loss: 0.9832824468612671\n",
      "epoch: 4, batch: 6, loss: 1.0978397130966187\n",
      "epoch: 4, batch: 7, loss: 1.1212515830993652\n",
      "epoch: 4, batch: 8, loss: 0.9985911250114441\n",
      "epoch: 4, batch: 9, loss: 0.9739949107170105\n",
      "epoch: 4, batch: 10, loss: 1.0902018547058105\n",
      "epoch: 4, batch: 11, loss: 1.112302541732788\n",
      "epoch: 4, batch: 12, loss: 1.265549898147583\n",
      "epoch: 4, batch: 13, loss: 0.894400417804718\n",
      "epoch: 4, batch: 14, loss: 0.927166223526001\n",
      "epoch: 4, batch: 15, loss: 1.0207102298736572\n",
      "epoch: 4, batch: 16, loss: 0.8964650630950928\n",
      "epoch: 4, batch: 17, loss: 0.91428542137146\n",
      "epoch: 4, batch: 18, loss: 1.2338064908981323\n",
      "epoch: 4, batch: 19, loss: 0.908308207988739\n",
      "epoch: 4, batch: 20, loss: 1.1013920307159424\n",
      "epoch: 4, batch: 21, loss: 1.0307955741882324\n",
      "epoch: 4, batch: 22, loss: 1.0341625213623047\n",
      "epoch: 4, batch: 23, loss: 0.8726757764816284\n",
      "epoch: 4, batch: 24, loss: 0.9111176133155823\n",
      "epoch: 4, batch: 25, loss: 0.9289427995681763\n",
      "epoch: 4, batch: 26, loss: 0.854208767414093\n",
      "epoch: 4, batch: 27, loss: 0.9341710805892944\n",
      "epoch: 4, batch: 28, loss: 0.874799370765686\n",
      "epoch: 4, batch: 29, loss: 0.9200065732002258\n",
      "epoch: 4, batch: 30, loss: 1.285651683807373\n",
      "epoch: 4, batch: 31, loss: 1.1023015975952148\n",
      "epoch: 4, batch: 32, loss: 1.1570756435394287\n",
      "epoch: 4, batch: 33, loss: 1.026005506515503\n",
      "epoch: 4, batch: 34, loss: 0.9638755321502686\n",
      "epoch: 4, batch: 35, loss: 1.2056419849395752\n",
      "epoch: 4, batch: 36, loss: 1.0490696430206299\n",
      "epoch: 4, batch: 37, loss: 1.1174302101135254\n",
      "epoch: 4, batch: 38, loss: 0.883363664150238\n",
      "epoch: 4, batch: 39, loss: 1.0689035654067993\n",
      "epoch: 4, batch: 40, loss: 0.8277092576026917\n",
      "epoch: 4, batch: 41, loss: 1.3243542909622192\n",
      "epoch: 4, batch: 42, loss: 1.240107774734497\n",
      "epoch: 4, batch: 43, loss: 0.9582850933074951\n",
      "epoch: 4, batch: 44, loss: 1.1751004457473755\n",
      "epoch: 4, batch: 45, loss: 1.2098495960235596\n",
      "epoch: 4, batch: 46, loss: 0.7604365944862366\n",
      "epoch: 4, batch: 47, loss: 0.9769797921180725\n",
      "epoch: 4, batch: 48, loss: 1.0242645740509033\n",
      "epoch: 4, batch: 49, loss: 1.0348995923995972\n",
      "epoch: 4, batch: 50, loss: 0.948034942150116\n",
      "epoch: 4, batch: 51, loss: 1.0173310041427612\n",
      "epoch: 4, batch: 52, loss: 0.855670690536499\n",
      "epoch: 4, batch: 53, loss: 0.7523245811462402\n",
      "epoch: 4, batch: 54, loss: 0.9239532351493835\n",
      "epoch: 4, batch: 55, loss: 0.9575653076171875\n",
      "epoch: 4, batch: 56, loss: 1.1050106287002563\n",
      "epoch: 4, batch: 57, loss: 0.9977493286132812\n",
      "epoch: 4, batch: 58, loss: 1.0289934873580933\n",
      "epoch: 4, batch: 59, loss: 0.9991899728775024\n",
      "epoch: 4, batch: 60, loss: 1.0678081512451172\n",
      "epoch: 4, batch: 61, loss: 0.9547401666641235\n",
      "epoch: 4, batch: 62, loss: 0.8904847502708435\n",
      "epoch: 4, batch: 63, loss: 0.9597070813179016\n",
      "epoch: 4, batch: 64, loss: 1.1654857397079468\n",
      "epoch: 4, batch: 65, loss: 0.8938190937042236\n",
      "epoch: 4, batch: 66, loss: 0.9649522304534912\n",
      "epoch: 4, batch: 67, loss: 1.1579256057739258\n",
      "epoch: 4, batch: 68, loss: 0.9636322855949402\n",
      "epoch: 4, batch: 69, loss: 0.9060482978820801\n",
      "epoch: 4, batch: 70, loss: 0.8962814807891846\n",
      "epoch: 4, batch: 71, loss: 0.8841796517372131\n",
      "epoch: 4, batch: 72, loss: 1.1836833953857422\n",
      "epoch: 4, batch: 73, loss: 1.154462456703186\n",
      "epoch: 4, batch: 74, loss: 1.0614776611328125\n",
      "epoch: 4, batch: 75, loss: 1.0442776679992676\n",
      "epoch: 4, batch: 76, loss: 1.231817603111267\n",
      "epoch: 4, batch: 77, loss: 1.0629078149795532\n",
      "epoch: 4, batch: 78, loss: 1.1999729871749878\n",
      "epoch: 4, batch: 79, loss: 1.0225108861923218\n",
      "epoch: 4, batch: 80, loss: 1.1144077777862549\n",
      "epoch: 4, batch: 81, loss: 1.0376300811767578\n",
      "epoch: 4, batch: 82, loss: 0.9222476482391357\n",
      "epoch: 4, batch: 83, loss: 1.1939263343811035\n",
      "epoch: 4, batch: 84, loss: 1.0523052215576172\n",
      "epoch: 4, batch: 85, loss: 1.2286958694458008\n",
      "epoch: 4, batch: 86, loss: 1.0473198890686035\n",
      "epoch: 4, batch: 87, loss: 0.9550938606262207\n",
      "epoch: 4, batch: 88, loss: 0.8164738416671753\n",
      "epoch: 4, batch: 89, loss: 1.0352234840393066\n",
      "epoch: 4, batch: 90, loss: 0.9588649868965149\n",
      "epoch: 4, batch: 91, loss: 0.9153529405593872\n",
      "epoch: 4, batch: 92, loss: 1.064420223236084\n",
      "epoch: 4, batch: 93, loss: 0.9083979725837708\n",
      "epoch: 4, batch: 94, loss: 0.8980339169502258\n",
      "epoch: 4, batch: 95, loss: 0.9366782307624817\n",
      "epoch: 4, batch: 96, loss: 0.9896974563598633\n",
      "epoch: 4, batch: 97, loss: 0.9874290823936462\n",
      "epoch: 4, batch: 98, loss: 0.7852940559387207\n",
      "epoch: 4, batch: 99, loss: 1.0956323146820068\n",
      "epoch: 4, batch: 100, loss: 1.0445349216461182\n",
      "epoch: 4, batch: 101, loss: 1.4007304906845093\n",
      "epoch: 4, batch: 102, loss: 0.7328235507011414\n",
      "epoch: 4, batch: 103, loss: 1.1644878387451172\n",
      "epoch: 4, batch: 104, loss: 0.9665875434875488\n",
      "epoch: 4, batch: 105, loss: 1.0529872179031372\n",
      "epoch: 4, batch: 106, loss: 1.2538214921951294\n",
      "epoch: 4, batch: 107, loss: 0.975733757019043\n",
      "epoch: 4, batch: 108, loss: 0.854682445526123\n",
      "epoch: 4, batch: 109, loss: 0.9428374767303467\n",
      "epoch: 4, batch: 110, loss: 0.9757080674171448\n",
      "epoch: 4, batch: 111, loss: 0.8779338002204895\n",
      "epoch: 4, batch: 112, loss: 0.8900624513626099\n",
      "epoch: 4, batch: 113, loss: 0.9804739952087402\n",
      "epoch: 4, batch: 114, loss: 0.9912438988685608\n",
      "epoch: 4, batch: 115, loss: 0.9410688877105713\n",
      "epoch: 4, batch: 116, loss: 0.8859612941741943\n",
      "epoch: 4, batch: 117, loss: 1.0774184465408325\n",
      "epoch: 4, batch: 118, loss: 0.9319306015968323\n",
      "epoch: 4, batch: 119, loss: 0.9335567355155945\n",
      "epoch: 4, batch: 120, loss: 0.9328076243400574\n",
      "epoch: 4, batch: 121, loss: 0.989672839641571\n",
      "epoch: 4, batch: 122, loss: 1.106416940689087\n",
      "epoch: 4, batch: 123, loss: 1.0140103101730347\n",
      "epoch: 4, batch: 124, loss: 0.95383620262146\n",
      "epoch: 4, batch: 125, loss: 0.8216326236724854\n",
      "epoch: 4, batch: 126, loss: 0.7622424364089966\n",
      "epoch: 4, batch: 127, loss: 1.070020318031311\n",
      "epoch: 4, batch: 128, loss: 1.0044782161712646\n",
      "epoch: 4, batch: 129, loss: 1.037048101425171\n",
      "epoch: 4, batch: 130, loss: 0.933127224445343\n",
      "epoch: 4, batch: 131, loss: 1.0001789331436157\n",
      "epoch: 4, batch: 132, loss: 1.2067698240280151\n",
      "epoch: 4, batch: 133, loss: 1.1489231586456299\n",
      "epoch: 4, batch: 134, loss: 1.012033462524414\n",
      "epoch: 4, batch: 135, loss: 0.8883957266807556\n",
      "epoch: 4, batch: 136, loss: 1.0774816274642944\n",
      "epoch: 4, batch: 137, loss: 0.93117356300354\n",
      "epoch: 4, batch: 138, loss: 0.9732987284660339\n",
      "epoch: 4, batch: 139, loss: 0.9300400018692017\n",
      "epoch: 4, batch: 140, loss: 0.8301928043365479\n",
      "epoch: 4, batch: 141, loss: 1.0211766958236694\n",
      "epoch: 4, batch: 142, loss: 0.9148205518722534\n",
      "epoch: 4, batch: 143, loss: 0.775591254234314\n",
      "epoch: 4, batch: 144, loss: 0.902839183807373\n",
      "epoch: 4, batch: 145, loss: 1.0996379852294922\n",
      "epoch: 4, batch: 146, loss: 0.8734211921691895\n",
      "epoch: 4, batch: 147, loss: 1.0456457138061523\n",
      "epoch: 4, batch: 148, loss: 1.130183219909668\n",
      "epoch: 4, batch: 149, loss: 0.8714997172355652\n",
      "epoch: 4, batch: 150, loss: 1.0576560497283936\n",
      "epoch: 4, batch: 151, loss: 1.0906192064285278\n",
      "epoch: 4, batch: 152, loss: 0.9465874433517456\n",
      "epoch: 4, batch: 153, loss: 0.9318425059318542\n",
      "epoch: 4, batch: 154, loss: 0.7785794138908386\n",
      "epoch: 4, batch: 155, loss: 0.9625789523124695\n",
      "epoch: 4, batch: 156, loss: 1.0027378797531128\n",
      "epoch: 4, batch: 157, loss: 0.9816197752952576\n",
      "epoch: 4, batch: 158, loss: 0.9053401350975037\n",
      "epoch: 4, batch: 159, loss: 0.76991868019104\n",
      "epoch: 4, batch: 160, loss: 1.0667524337768555\n",
      "epoch: 4, batch: 161, loss: 0.7424231171607971\n",
      "epoch: 4, batch: 162, loss: 0.7836418151855469\n",
      "epoch: 4, batch: 163, loss: 0.8844273090362549\n",
      "epoch: 4, batch: 164, loss: 0.9305670261383057\n",
      "epoch: 4, batch: 165, loss: 0.9664182066917419\n",
      "epoch: 4, batch: 166, loss: 0.9342597723007202\n",
      "epoch: 4, batch: 167, loss: 0.8880977630615234\n",
      "epoch: 4, batch: 168, loss: 1.1353811025619507\n",
      "epoch: 4, batch: 169, loss: 0.8389948010444641\n",
      "epoch: 4, batch: 170, loss: 0.9132179021835327\n",
      "epoch: 4, batch: 171, loss: 1.02496337890625\n",
      "epoch: 4, batch: 172, loss: 1.067745327949524\n",
      "epoch: 4, batch: 173, loss: 0.8358345627784729\n",
      "epoch: 4, batch: 174, loss: 1.0109678506851196\n",
      "epoch: 4, batch: 175, loss: 0.9235727190971375\n",
      "epoch: 4, batch: 176, loss: 1.1056787967681885\n",
      "epoch: 4, batch: 177, loss: 1.0842092037200928\n",
      "epoch: 4, batch: 178, loss: 0.9485657215118408\n",
      "epoch: 4, batch: 179, loss: 0.9506829380989075\n",
      "epoch: 4, batch: 180, loss: 1.0701918601989746\n",
      "epoch: 4, batch: 181, loss: 1.1440048217773438\n",
      "epoch: 4, batch: 182, loss: 0.9112563729286194\n",
      "epoch: 4, batch: 183, loss: 0.8838014006614685\n",
      "epoch: 4, batch: 184, loss: 0.9380220174789429\n",
      "epoch: 4, batch: 185, loss: 1.025773286819458\n",
      "epoch: 4, batch: 186, loss: 1.0768189430236816\n",
      "epoch: 4, batch: 187, loss: 0.8091510534286499\n",
      "epoch: 4, batch: 188, loss: 1.1442451477050781\n",
      "epoch: 4, batch: 189, loss: 0.95671147108078\n",
      "epoch: 4, batch: 190, loss: 1.0552362203598022\n",
      "epoch: 4, batch: 191, loss: 1.0293868780136108\n",
      "epoch: 4, batch: 192, loss: 0.9280517101287842\n",
      "epoch: 4, batch: 193, loss: 0.9941161870956421\n",
      "epoch: 4, batch: 194, loss: 1.1625053882598877\n",
      "epoch: 4, batch: 195, loss: 0.9719918370246887\n",
      "epoch: 4, batch: 196, loss: 1.1604770421981812\n",
      "epoch: 4, batch: 197, loss: 0.9914701581001282\n",
      "epoch: 4, batch: 198, loss: 0.9854902029037476\n",
      "epoch: 4, batch: 199, loss: 0.8739736676216125\n",
      "epoch: 4, batch: 200, loss: 0.8182350993156433\n",
      "epoch: 4, batch: 201, loss: 1.1802952289581299\n",
      "epoch: 4, batch: 202, loss: 0.9980505704879761\n",
      "epoch: 4, batch: 203, loss: 0.9128161668777466\n",
      "epoch: 4, batch: 204, loss: 1.1680335998535156\n",
      "epoch: 4, batch: 205, loss: 0.9099396467208862\n",
      "epoch: 4, batch: 206, loss: 0.9578049778938293\n",
      "epoch: 4, batch: 207, loss: 0.881585955619812\n",
      "epoch: 4, batch: 208, loss: 1.0097659826278687\n",
      "epoch: 4, batch: 209, loss: 1.1190084218978882\n",
      "epoch: 4, batch: 210, loss: 0.8235023021697998\n",
      "epoch: 4, batch: 211, loss: 1.0394660234451294\n",
      "epoch: 4, batch: 212, loss: 0.7427385449409485\n",
      "epoch: 4, batch: 213, loss: 1.136732578277588\n",
      "epoch: 4, batch: 214, loss: 0.8665729761123657\n",
      "epoch: 4, batch: 215, loss: 1.0271024703979492\n",
      "epoch: 4, batch: 216, loss: 1.0254970788955688\n",
      "epoch: 4, batch: 217, loss: 1.0097072124481201\n",
      "epoch: 4, batch: 218, loss: 0.8367229700088501\n",
      "epoch: 4, batch: 219, loss: 1.0284428596496582\n",
      "epoch: 4, batch: 220, loss: 0.91599041223526\n",
      "epoch: 4, batch: 221, loss: 0.8887084722518921\n",
      "epoch: 4, batch: 222, loss: 0.7160689234733582\n",
      "epoch: 4, batch: 223, loss: 1.0814552307128906\n",
      "epoch: 4, batch: 224, loss: 0.838620662689209\n",
      "epoch: 4, batch: 225, loss: 0.9621814489364624\n",
      "epoch: 4, batch: 226, loss: 1.0600920915603638\n",
      "epoch: 4, batch: 227, loss: 0.9390782713890076\n",
      "epoch: 4, batch: 228, loss: 0.9087420701980591\n",
      "epoch: 4, batch: 229, loss: 1.2055460214614868\n",
      "epoch: 4, batch: 230, loss: 0.9274126291275024\n",
      "epoch: 4, batch: 231, loss: 0.9703585505485535\n",
      "epoch: 4, batch: 232, loss: 0.9109439253807068\n",
      "epoch: 4, batch: 233, loss: 0.9389541149139404\n",
      "epoch: 4, batch: 234, loss: 1.0297255516052246\n",
      "epoch: 4, batch: 235, loss: 1.0119454860687256\n",
      "epoch: 4, batch: 236, loss: 0.7416132092475891\n",
      "epoch: 4, batch: 237, loss: 0.9127602577209473\n",
      "epoch: 4, batch: 238, loss: 0.8827974796295166\n",
      "epoch: 4, batch: 239, loss: 0.9351904988288879\n",
      "epoch: 4, batch: 240, loss: 1.0491397380828857\n",
      "epoch: 4, batch: 241, loss: 1.0831001996994019\n",
      "epoch: 4, batch: 242, loss: 0.9831961393356323\n",
      "epoch: 4, batch: 243, loss: 1.0325075387954712\n",
      "epoch: 4, batch: 244, loss: 0.9369301795959473\n",
      "epoch: 4, batch: 245, loss: 1.1666120290756226\n",
      "epoch: 4, batch: 246, loss: 0.9997731447219849\n",
      "epoch: 4, batch: 247, loss: 0.9145910143852234\n",
      "epoch: 4, batch: 248, loss: 0.7776551246643066\n",
      "epoch: 4, batch: 249, loss: 1.235966444015503\n",
      "epoch: 4, batch: 250, loss: 0.9356033205986023\n",
      "epoch: 4, batch: 251, loss: 0.8946359157562256\n",
      "epoch: 4, batch: 252, loss: 0.8592901229858398\n",
      "epoch: 4, batch: 253, loss: 0.9523352980613708\n",
      "epoch: 4, batch: 254, loss: 0.9276952147483826\n",
      "epoch: 4, batch: 255, loss: 1.0554225444793701\n",
      "epoch: 4, batch: 256, loss: 0.8899185657501221\n",
      "epoch: 4, batch: 257, loss: 0.981092631816864\n",
      "epoch: 4, batch: 258, loss: 0.8333452939987183\n",
      "epoch: 4, batch: 259, loss: 0.9074183702468872\n",
      "epoch: 4, batch: 260, loss: 0.9120851755142212\n",
      "epoch: 4, batch: 261, loss: 1.0183296203613281\n",
      "epoch: 4, batch: 262, loss: 1.0755013227462769\n",
      "epoch: 4, batch: 263, loss: 1.0280135869979858\n",
      "epoch: 4, batch: 264, loss: 0.8040525913238525\n",
      "epoch: 4, batch: 265, loss: 1.1129083633422852\n",
      "epoch: 4, batch: 266, loss: 1.0326573848724365\n",
      "epoch: 4, batch: 267, loss: 0.9286657571792603\n",
      "epoch: 4, batch: 268, loss: 0.8524225354194641\n",
      "epoch: 4, batch: 269, loss: 0.939801812171936\n",
      "epoch: 4, batch: 270, loss: 0.9499808549880981\n",
      "epoch: 4, batch: 271, loss: 1.0402467250823975\n",
      "epoch: 4, batch: 272, loss: 0.9951568245887756\n",
      "epoch: 4, batch: 273, loss: 1.0217074155807495\n",
      "epoch: 4, batch: 274, loss: 0.8770474791526794\n",
      "epoch: 4, batch: 275, loss: 1.1092908382415771\n",
      "epoch: 4, batch: 276, loss: 0.8055345416069031\n",
      "epoch: 4, batch: 277, loss: 1.075993299484253\n",
      "epoch: 4, batch: 278, loss: 0.8583637475967407\n",
      "epoch: 4, batch: 279, loss: 0.9705231189727783\n",
      "epoch: 4, batch: 280, loss: 0.952960729598999\n",
      "epoch: 4, batch: 281, loss: 0.9034926891326904\n",
      "epoch: 4, batch: 282, loss: 1.0169719457626343\n",
      "epoch: 4, batch: 283, loss: 0.9685357809066772\n",
      "epoch: 4, batch: 284, loss: 0.6939672827720642\n",
      "epoch: 4, batch: 285, loss: 0.8694239854812622\n",
      "epoch: 4, batch: 286, loss: 0.9503635168075562\n",
      "epoch: 4, batch: 287, loss: 1.0107247829437256\n",
      "epoch: 4, batch: 288, loss: 0.8977633714675903\n",
      "epoch: 4, batch: 289, loss: 0.9057210087776184\n",
      "epoch: 4, batch: 290, loss: 0.9641038179397583\n",
      "epoch: 4, batch: 291, loss: 0.8380119800567627\n",
      "epoch: 4, batch: 292, loss: 1.0943546295166016\n",
      "epoch: 4, batch: 293, loss: 0.8652076721191406\n",
      "epoch: 4, batch: 294, loss: 0.9056087136268616\n",
      "epoch: 4, batch: 295, loss: 1.088021993637085\n",
      "epoch: 4, batch: 296, loss: 0.9328980445861816\n",
      "epoch: 4, batch: 297, loss: 0.8394618630409241\n",
      "epoch: 4, batch: 298, loss: 0.974754273891449\n",
      "epoch: 4, batch: 299, loss: 0.8903605937957764\n",
      "epoch: 4, batch: 300, loss: 0.9691008925437927\n",
      "epoch: 4, batch: 301, loss: 1.048539161682129\n",
      "epoch: 4, batch: 302, loss: 1.0129525661468506\n",
      "epoch: 4, batch: 303, loss: 0.9504438042640686\n",
      "epoch: 4, batch: 304, loss: 1.0347877740859985\n",
      "epoch: 4, batch: 305, loss: 0.8969443440437317\n",
      "epoch: 4, batch: 306, loss: 1.1648149490356445\n",
      "epoch: 4, batch: 307, loss: 0.931493878364563\n",
      "epoch: 4, batch: 308, loss: 0.7748956084251404\n",
      "epoch: 4, batch: 309, loss: 0.9918246269226074\n",
      "epoch: 4, batch: 310, loss: 0.9222387671470642\n",
      "epoch: 4, batch: 311, loss: 0.9888843297958374\n",
      "epoch: 4, batch: 312, loss: 0.9588673114776611\n",
      "epoch: 4, batch: 313, loss: 1.02205228805542\n",
      "epoch: 4, batch: 314, loss: 0.9422939419746399\n",
      "epoch: 4, batch: 315, loss: 0.8303937315940857\n",
      "epoch: 4, batch: 316, loss: 0.9876278638839722\n",
      "epoch: 4, batch: 317, loss: 0.745773434638977\n",
      "epoch: 4, batch: 318, loss: 0.8406809568405151\n",
      "epoch: 4, batch: 319, loss: 1.000426173210144\n",
      "epoch: 4, batch: 320, loss: 1.0539003610610962\n",
      "epoch: 4, batch: 321, loss: 1.0374256372451782\n",
      "epoch: 4, batch: 322, loss: 0.9139178991317749\n",
      "epoch: 4, batch: 323, loss: 1.0522822141647339\n",
      "epoch: 4, batch: 324, loss: 0.8368140459060669\n",
      "epoch: 4, batch: 325, loss: 0.9730699062347412\n",
      "epoch: 4, batch: 326, loss: 0.9592287540435791\n",
      "epoch: 4, batch: 327, loss: 0.989996075630188\n",
      "epoch: 4, batch: 328, loss: 1.069068431854248\n",
      "epoch: 4, batch: 329, loss: 0.8944641947746277\n",
      "epoch: 4, batch: 330, loss: 1.3497432470321655\n",
      "epoch: 4, batch: 331, loss: 1.058432936668396\n",
      "epoch: 4, batch: 332, loss: 0.9658157825469971\n",
      "epoch: 4, batch: 333, loss: 0.8608499765396118\n",
      "epoch: 4, batch: 334, loss: 0.8961663246154785\n",
      "epoch: 4, batch: 335, loss: 0.9903762340545654\n",
      "epoch: 4, batch: 336, loss: 0.8297701478004456\n",
      "epoch: 4, batch: 337, loss: 1.006057858467102\n",
      "epoch: 4, batch: 338, loss: 0.902298629283905\n",
      "epoch: 4, batch: 339, loss: 1.0658042430877686\n",
      "epoch: 4, batch: 340, loss: 0.9065348505973816\n",
      "epoch: 4, batch: 341, loss: 0.9177917242050171\n",
      "epoch: 4, batch: 342, loss: 0.8965071439743042\n",
      "epoch: 4, batch: 343, loss: 0.9040729999542236\n",
      "epoch: 4, batch: 344, loss: 0.9386667609214783\n",
      "epoch: 4, batch: 345, loss: 1.1257659196853638\n",
      "epoch: 4, batch: 346, loss: 1.0815095901489258\n",
      "epoch: 4, batch: 347, loss: 0.9203229546546936\n",
      "epoch: 4, batch: 348, loss: 1.011168122291565\n",
      "epoch: 4, batch: 349, loss: 0.9539957642555237\n",
      "epoch: 4, batch: 350, loss: 0.945137619972229\n",
      "epoch: 4, batch: 351, loss: 1.064754843711853\n",
      "epoch: 4, batch: 352, loss: 0.9340559840202332\n",
      "epoch: 4, batch: 353, loss: 0.9817532300949097\n",
      "epoch: 4, batch: 354, loss: 0.8543635606765747\n",
      "epoch: 4, batch: 355, loss: 0.9615638852119446\n",
      "epoch: 4, batch: 356, loss: 1.1444377899169922\n",
      "epoch: 4, batch: 357, loss: 1.2673087120056152\n",
      "epoch: 4, batch: 358, loss: 0.8356410264968872\n",
      "epoch: 4, batch: 359, loss: 0.8789797425270081\n",
      "epoch: 4, batch: 360, loss: 0.9440115094184875\n",
      "epoch: 4, batch: 361, loss: 0.9894393682479858\n",
      "epoch: 4, batch: 362, loss: 0.8519241213798523\n",
      "epoch: 4, batch: 363, loss: 1.2041414976119995\n",
      "epoch: 4, batch: 364, loss: 0.8751746416091919\n",
      "epoch: 4, batch: 365, loss: 0.8087900876998901\n",
      "epoch: 4, batch: 366, loss: 1.075722575187683\n",
      "epoch: 4, batch: 367, loss: 0.940274178981781\n",
      "epoch: 4, batch: 368, loss: 0.9259340167045593\n",
      "epoch: 4, batch: 369, loss: 0.9499548673629761\n",
      "epoch: 4, batch: 370, loss: 0.8255985379219055\n",
      "epoch: 4, batch: 371, loss: 0.9520463943481445\n",
      "epoch: 4, batch: 372, loss: 0.9312193393707275\n",
      "epoch: 4, batch: 373, loss: 1.1293667554855347\n",
      "epoch: 4, batch: 374, loss: 0.9001480937004089\n",
      "epoch: 4, batch: 375, loss: 1.0917811393737793\n",
      "epoch: 4, batch: 376, loss: 0.9623039960861206\n",
      "epoch: 4, batch: 377, loss: 1.024948000907898\n",
      "epoch: 4, batch: 378, loss: 0.7090766429901123\n",
      "epoch: 4, batch: 379, loss: 0.9679247736930847\n",
      "epoch: 4, batch: 380, loss: 0.9009187817573547\n",
      "epoch: 4, batch: 381, loss: 0.8982836008071899\n",
      "epoch: 4, batch: 382, loss: 0.9600815176963806\n",
      "epoch: 4, batch: 383, loss: 0.8736645579338074\n",
      "epoch: 4, batch: 384, loss: 0.9407111406326294\n",
      "epoch: 4, batch: 385, loss: 1.006193995475769\n",
      "epoch: 4, batch: 386, loss: 0.9234458804130554\n",
      "epoch: 4, batch: 387, loss: 1.1055095195770264\n",
      "epoch: 4, batch: 388, loss: 0.9578731656074524\n",
      "epoch: 4, batch: 389, loss: 0.9667484760284424\n",
      "epoch: 4, batch: 390, loss: 0.9387874603271484\n",
      "epoch: 4, batch: 391, loss: 0.9972353577613831\n",
      "epoch: 4, batch: 392, loss: 0.9098837375640869\n",
      "epoch: 4, batch: 393, loss: 0.922980546951294\n",
      "epoch: 4, batch: 394, loss: 1.0314042568206787\n",
      "epoch: 4, batch: 395, loss: 0.8623069524765015\n",
      "epoch: 4, batch: 396, loss: 0.9721744656562805\n",
      "epoch: 4, batch: 397, loss: 0.7572183609008789\n",
      "epoch: 4, batch: 398, loss: 0.9058448672294617\n",
      "epoch: 4, batch: 399, loss: 0.9592790603637695\n",
      "epoch: 4, batch: 400, loss: 0.9092175960540771\n",
      "epoch: 4, batch: 401, loss: 0.8040372133255005\n",
      "epoch: 4, batch: 402, loss: 0.7995700240135193\n",
      "epoch: 4, batch: 403, loss: 0.8962225317955017\n",
      "epoch: 4, batch: 404, loss: 0.8508618474006653\n",
      "epoch: 4, batch: 405, loss: 0.9933101534843445\n",
      "epoch: 4, batch: 406, loss: 1.0823369026184082\n",
      "epoch: 4, batch: 407, loss: 0.8014559745788574\n",
      "epoch: 4, batch: 408, loss: 0.9185158014297485\n",
      "epoch: 4, batch: 409, loss: 0.8976305723190308\n",
      "epoch: 4, batch: 410, loss: 0.8420903086662292\n",
      "epoch: 4, batch: 411, loss: 0.9247422814369202\n",
      "epoch: 4, batch: 412, loss: 1.0109456777572632\n",
      "epoch: 4, batch: 413, loss: 0.9941625595092773\n",
      "epoch: 4, batch: 414, loss: 0.9658420085906982\n",
      "epoch: 4, batch: 415, loss: 0.8814967274665833\n",
      "epoch: 4, batch: 416, loss: 0.7353556156158447\n",
      "epoch: 4, batch: 417, loss: 1.0072640180587769\n",
      "epoch: 4, batch: 418, loss: 0.8074988126754761\n",
      "epoch: 4, batch: 419, loss: 0.882012128829956\n",
      "epoch: 4, batch: 420, loss: 1.0237447023391724\n",
      "epoch: 4, batch: 421, loss: 0.8926818370819092\n",
      "epoch: 4, batch: 422, loss: 1.042425513267517\n",
      "epoch: 4, batch: 423, loss: 1.0118560791015625\n",
      "epoch: 4, batch: 424, loss: 0.9076333045959473\n",
      "epoch: 4, batch: 425, loss: 0.8670681118965149\n",
      "epoch: 4, batch: 426, loss: 0.9257026314735413\n",
      "epoch: 4, batch: 427, loss: 1.1694355010986328\n",
      "epoch: 4, batch: 428, loss: 0.8841428160667419\n",
      "epoch: 4, batch: 429, loss: 1.118443250656128\n",
      "epoch: 4, batch: 430, loss: 1.054693341255188\n",
      "epoch: 4, batch: 431, loss: 0.9526727795600891\n",
      "epoch: 4, batch: 432, loss: 0.9050422310829163\n",
      "epoch: 4, batch: 433, loss: 0.8347704410552979\n",
      "epoch: 4, batch: 434, loss: 0.812851071357727\n",
      "epoch: 4, batch: 435, loss: 1.0969891548156738\n",
      "epoch: 4, batch: 436, loss: 0.8660839200019836\n",
      "epoch: 4, batch: 437, loss: 0.9388465285301208\n",
      "epoch: 4, batch: 438, loss: 0.9311649203300476\n",
      "epoch: 4, batch: 439, loss: 0.8933038711547852\n",
      "epoch: 4, batch: 440, loss: 0.9441662430763245\n",
      "epoch: 4, batch: 441, loss: 1.1394081115722656\n",
      "epoch: 4, batch: 442, loss: 0.9326146245002747\n",
      "epoch: 4, batch: 443, loss: 0.8473379611968994\n",
      "epoch: 4, batch: 444, loss: 0.7989169955253601\n",
      "epoch: 4, batch: 445, loss: 1.0317877531051636\n",
      "epoch: 4, batch: 446, loss: 0.9589429497718811\n",
      "epoch: 4, batch: 447, loss: 0.9767798185348511\n",
      "epoch: 4, batch: 448, loss: 1.0023707151412964\n",
      "epoch: 4, batch: 449, loss: 0.814000129699707\n",
      "epoch: 4, batch: 450, loss: 1.0434901714324951\n",
      "epoch: 4, batch: 451, loss: 1.159714937210083\n",
      "epoch: 4, batch: 452, loss: 0.7495219707489014\n",
      "epoch: 4, batch: 453, loss: 0.9052160382270813\n",
      "epoch: 4, batch: 454, loss: 1.06351637840271\n",
      "epoch: 4, batch: 455, loss: 0.8344681262969971\n",
      "epoch: 4, batch: 456, loss: 1.1182972192764282\n",
      "epoch: 4, batch: 457, loss: 1.0334500074386597\n",
      "epoch: 4, batch: 458, loss: 0.8736920356750488\n",
      "epoch: 4, batch: 459, loss: 1.0585569143295288\n",
      "epoch: 4, batch: 460, loss: 0.9428694248199463\n",
      "epoch: 4, batch: 461, loss: 0.9141518473625183\n",
      "epoch: 4, batch: 462, loss: 0.9928836822509766\n",
      "epoch: 4, batch: 463, loss: 1.0543055534362793\n",
      "epoch: 4, batch: 464, loss: 1.0209139585494995\n",
      "epoch: 4, batch: 465, loss: 1.144182562828064\n",
      "epoch: 4, batch: 466, loss: 1.111133337020874\n",
      "epoch: 4, batch: 467, loss: 0.809088408946991\n",
      "epoch: 4, batch: 468, loss: 0.7866423726081848\n",
      "epoch: 4, batch: 469, loss: 0.8787389397621155\n",
      "epoch: 4, batch: 470, loss: 0.9063003063201904\n",
      "epoch: 4, batch: 471, loss: 0.9394505620002747\n",
      "epoch: 4, batch: 472, loss: 0.797849178314209\n",
      "epoch: 4, batch: 473, loss: 0.8320174813270569\n",
      "epoch: 4, batch: 474, loss: 0.8673552870750427\n",
      "epoch: 4, batch: 475, loss: 0.8336292505264282\n",
      "epoch: 4, batch: 476, loss: 0.8423765301704407\n",
      "epoch: 4, batch: 477, loss: 1.1178700923919678\n",
      "epoch: 4, batch: 478, loss: 1.0714679956436157\n",
      "epoch: 4, batch: 479, loss: 0.8114140629768372\n",
      "epoch: 4, batch: 480, loss: 0.772079586982727\n",
      "epoch: 4, batch: 481, loss: 0.7553662657737732\n",
      "epoch: 4, batch: 482, loss: 0.8598362803459167\n",
      "epoch: 4, batch: 483, loss: 0.9596884250640869\n",
      "epoch: 4, batch: 484, loss: 0.9893326163291931\n",
      "epoch: 4, batch: 485, loss: 0.9790349006652832\n",
      "epoch: 4, batch: 486, loss: 0.7739349603652954\n",
      "epoch: 4, batch: 487, loss: 0.8904265761375427\n",
      "epoch: 4, batch: 488, loss: 1.0265495777130127\n",
      "epoch: 4, batch: 489, loss: 0.8336439728736877\n",
      "epoch: 4, batch: 490, loss: 0.8440929651260376\n",
      "epoch: 4, batch: 491, loss: 0.9210617542266846\n",
      "epoch: 4, batch: 492, loss: 0.8940368294715881\n",
      "epoch: 4, batch: 493, loss: 0.9321967959403992\n",
      "epoch: 4, batch: 494, loss: 0.7817973494529724\n",
      "epoch: 4, batch: 495, loss: 1.199251651763916\n",
      "epoch: 4, batch: 496, loss: 0.7236918807029724\n",
      "epoch: 4, batch: 497, loss: 0.9111127853393555\n",
      "epoch: 4, batch: 498, loss: 0.9505711793899536\n",
      "epoch: 4, batch: 499, loss: 1.0044641494750977\n",
      "epoch: 4, batch: 500, loss: 0.8561317920684814\n",
      "epoch: 4, batch: 501, loss: 1.0924649238586426\n",
      "epoch: 4, batch: 502, loss: 1.041955828666687\n",
      "epoch: 4, batch: 503, loss: 0.91133713722229\n",
      "epoch: 4, batch: 504, loss: 0.9255744218826294\n",
      "epoch: 4, batch: 505, loss: 0.9404947757720947\n",
      "epoch: 4, batch: 506, loss: 0.908735990524292\n",
      "epoch: 4, batch: 507, loss: 1.014768362045288\n",
      "epoch: 4, batch: 508, loss: 0.8241406083106995\n",
      "epoch: 4, batch: 509, loss: 0.8225446343421936\n",
      "epoch: 4, batch: 510, loss: 0.8309547901153564\n",
      "epoch: 4, batch: 511, loss: 1.0036076307296753\n",
      "epoch: 4, batch: 512, loss: 0.8080944418907166\n",
      "epoch: 4, batch: 513, loss: 1.0714812278747559\n",
      "epoch: 4, batch: 514, loss: 0.9381481409072876\n",
      "epoch: 4, batch: 515, loss: 0.8324418067932129\n",
      "epoch: 4, batch: 516, loss: 0.9601356983184814\n",
      "epoch: 4, batch: 517, loss: 0.9527763724327087\n",
      "epoch: 4, batch: 518, loss: 0.6755660176277161\n",
      "epoch: 4, batch: 519, loss: 0.7551658749580383\n",
      "epoch: 4, batch: 520, loss: 0.7597152590751648\n",
      "epoch: 4, batch: 521, loss: 1.0201717615127563\n",
      "epoch: 4, batch: 522, loss: 1.1146342754364014\n",
      "epoch: 4, batch: 523, loss: 0.8933802247047424\n",
      "epoch: 4, batch: 524, loss: 1.0093700885772705\n",
      "epoch: 4, batch: 525, loss: 1.0599128007888794\n",
      "epoch: 4, batch: 526, loss: 0.972842276096344\n",
      "epoch: 4, batch: 527, loss: 1.0930440425872803\n",
      "epoch: 4, batch: 528, loss: 0.8555911779403687\n",
      "epoch: 4, batch: 529, loss: 0.9125592708587646\n",
      "epoch: 4, batch: 530, loss: 1.0379517078399658\n",
      "epoch: 4, batch: 531, loss: 0.8884708285331726\n",
      "epoch: 4, batch: 532, loss: 1.0918654203414917\n",
      "epoch: 4, batch: 533, loss: 1.0336202383041382\n",
      "epoch: 4, batch: 534, loss: 0.7638487219810486\n",
      "epoch: 4, batch: 535, loss: 0.9021325707435608\n",
      "epoch: 4, batch: 536, loss: 1.062410593032837\n",
      "epoch: 4, batch: 537, loss: 1.0400699377059937\n",
      "epoch: 4, batch: 538, loss: 1.0480053424835205\n",
      "epoch: 4, batch: 539, loss: 1.0681308507919312\n",
      "epoch: 4, batch: 540, loss: 0.8988364338874817\n",
      "epoch: 4, batch: 541, loss: 0.9196831583976746\n",
      "epoch: 4, batch: 542, loss: 1.006972074508667\n",
      "epoch: 4, batch: 543, loss: 0.958742082118988\n",
      "epoch: 4, batch: 544, loss: 1.075972557067871\n",
      "epoch: 4, batch: 545, loss: 0.9147276878356934\n",
      "epoch: 4, batch: 546, loss: 0.8302865624427795\n",
      "epoch: 4, batch: 547, loss: 1.1229959726333618\n",
      "epoch: 4, batch: 548, loss: 0.9259717464447021\n",
      "epoch: 4, batch: 549, loss: 0.8856722116470337\n",
      "epoch: 4, batch: 550, loss: 0.8338602781295776\n",
      "epoch: 4, batch: 551, loss: 0.7360324859619141\n",
      "epoch: 4, batch: 552, loss: 0.81709223985672\n",
      "epoch: 4, batch: 553, loss: 0.8356573581695557\n",
      "epoch: 4, batch: 554, loss: 0.8774735331535339\n",
      "epoch: 4, batch: 555, loss: 1.0118738412857056\n",
      "epoch: 4, batch: 556, loss: 0.7543672919273376\n",
      "epoch: 4, batch: 557, loss: 0.9777081608772278\n",
      "epoch: 4, batch: 558, loss: 0.903183102607727\n",
      "epoch: 4, batch: 559, loss: 0.7794516682624817\n",
      "epoch: 4, batch: 560, loss: 1.0633224248886108\n",
      "epoch: 4, batch: 561, loss: 0.9052616953849792\n",
      "epoch: 4, batch: 562, loss: 0.9998463988304138\n",
      "epoch: 4, batch: 563, loss: 0.7854072451591492\n",
      "epoch: 4, batch: 564, loss: 1.0630426406860352\n",
      "epoch: 4, batch: 565, loss: 0.9382413625717163\n",
      "epoch: 4, batch: 566, loss: 1.0230454206466675\n",
      "epoch: 4, batch: 567, loss: 0.8777890205383301\n",
      "epoch: 4, batch: 568, loss: 0.9534968733787537\n",
      "epoch: 4, batch: 569, loss: 0.8090395331382751\n",
      "epoch: 4, batch: 570, loss: 0.920985758304596\n",
      "epoch: 4, batch: 571, loss: 0.9336531162261963\n",
      "epoch: 4, batch: 572, loss: 0.8666301369667053\n",
      "epoch: 4, batch: 573, loss: 0.7139951586723328\n",
      "epoch: 4, batch: 574, loss: 0.9886206984519958\n",
      "epoch: 4, batch: 575, loss: 0.7801752686500549\n",
      "epoch: 4, batch: 576, loss: 0.671152651309967\n",
      "epoch: 4, batch: 577, loss: 0.9104897975921631\n",
      "epoch: 4, batch: 578, loss: 0.8209521770477295\n",
      "epoch: 4, batch: 579, loss: 0.8836803436279297\n",
      "epoch: 4, batch: 580, loss: 0.998072624206543\n",
      "epoch: 4, batch: 581, loss: 1.0403519868850708\n",
      "epoch: 4, batch: 582, loss: 1.1245055198669434\n",
      "epoch: 4, batch: 583, loss: 0.9662647247314453\n",
      "epoch: 4, batch: 584, loss: 0.8092958927154541\n",
      "epoch: 4, batch: 585, loss: 1.0949163436889648\n",
      "epoch: 4, batch: 586, loss: 0.9684813022613525\n",
      "epoch: 4, batch: 587, loss: 0.9275693893432617\n",
      "epoch: 4, batch: 588, loss: 0.9783986806869507\n",
      "epoch: 4, batch: 589, loss: 0.7813289165496826\n",
      "epoch: 4, batch: 590, loss: 0.6946097612380981\n",
      "epoch: 4, batch: 591, loss: 1.0434181690216064\n",
      "epoch: 4, batch: 592, loss: 0.8405488133430481\n",
      "epoch: 4, batch: 593, loss: 1.0394699573516846\n",
      "epoch: 4, batch: 594, loss: 0.7583562135696411\n",
      "epoch: 4, batch: 595, loss: 0.9985361695289612\n",
      "epoch: 4, batch: 596, loss: 1.201352834701538\n",
      "epoch: 4, batch: 597, loss: 0.9008714556694031\n",
      "epoch: 4, batch: 598, loss: 0.7229853868484497\n",
      "epoch: 4, batch: 599, loss: 1.177284836769104\n",
      "epoch: 4, batch: 600, loss: 1.03587806224823\n",
      "epoch: 4, batch: 601, loss: 0.815843939781189\n",
      "epoch: 4, batch: 602, loss: 0.7457261085510254\n",
      "epoch: 4, batch: 603, loss: 0.7271979451179504\n",
      "epoch: 4, batch: 604, loss: 0.8487236499786377\n",
      "epoch: 4, batch: 605, loss: 0.9998804330825806\n",
      "epoch: 4, batch: 606, loss: 0.9235008955001831\n",
      "epoch: 4, batch: 607, loss: 0.8094490766525269\n",
      "epoch: 4, batch: 608, loss: 1.1177178621292114\n",
      "epoch: 4, batch: 609, loss: 1.0771193504333496\n",
      "epoch: 4, batch: 610, loss: 0.8089041709899902\n",
      "epoch: 4, batch: 611, loss: 0.8655708432197571\n",
      "epoch: 4, batch: 612, loss: 0.927274763584137\n",
      "epoch: 4, batch: 613, loss: 1.0060718059539795\n",
      "epoch: 4, batch: 614, loss: 0.8829167485237122\n",
      "epoch: 4, batch: 615, loss: 1.0958504676818848\n",
      "epoch: 4, batch: 616, loss: 1.1037720441818237\n",
      "epoch: 4, batch: 617, loss: 0.7553647756576538\n",
      "epoch: 4, batch: 618, loss: 0.7305391430854797\n",
      "epoch: 4, batch: 619, loss: 0.7492169141769409\n",
      "epoch: 4, batch: 620, loss: 0.9556987285614014\n",
      "epoch: 4, batch: 621, loss: 0.8966686725616455\n",
      "epoch: 4, batch: 622, loss: 0.9210520386695862\n",
      "epoch: 4, batch: 623, loss: 0.945993959903717\n",
      "epoch: 4, batch: 624, loss: 0.8261448740959167\n",
      "epoch: 4, batch: 625, loss: 0.926654577255249\n",
      "epoch: 4, batch: 626, loss: 0.9030405879020691\n",
      "epoch: 4, batch: 627, loss: 0.9792613983154297\n",
      "epoch: 4, batch: 628, loss: 0.8411080241203308\n",
      "epoch: 4, batch: 629, loss: 0.6566757559776306\n",
      "epoch: 4, batch: 630, loss: 0.9627578854560852\n",
      "epoch: 4, batch: 631, loss: 0.9963982701301575\n",
      "epoch: 4, batch: 632, loss: 0.9628641605377197\n",
      "epoch: 4, batch: 633, loss: 1.0276899337768555\n",
      "epoch: 4, batch: 634, loss: 0.8695214986801147\n",
      "epoch: 4, batch: 635, loss: 0.9674612879753113\n",
      "epoch: 4, batch: 636, loss: 0.7925964593887329\n",
      "epoch: 4, batch: 637, loss: 0.9952861070632935\n",
      "epoch: 4, batch: 638, loss: 0.7238480448722839\n",
      "epoch: 4, batch: 639, loss: 1.1004011631011963\n",
      "epoch: 4, batch: 640, loss: 1.0072839260101318\n",
      "epoch: 4, batch: 641, loss: 0.8807066679000854\n",
      "epoch: 4, batch: 642, loss: 0.9137148857116699\n",
      "epoch: 4, batch: 643, loss: 0.8280256390571594\n",
      "epoch: 4, batch: 644, loss: 0.8942177891731262\n",
      "epoch: 4, batch: 645, loss: 0.9340067505836487\n",
      "epoch: 4, batch: 646, loss: 0.9741162657737732\n",
      "epoch: 4, batch: 647, loss: 0.8642770051956177\n",
      "epoch: 4, batch: 648, loss: 0.651443600654602\n",
      "epoch: 4, batch: 649, loss: 0.8461211919784546\n",
      "epoch: 4, batch: 650, loss: 1.1556192636489868\n",
      "epoch: 4, batch: 651, loss: 0.8868674039840698\n",
      "epoch: 4, batch: 652, loss: 0.9563463926315308\n",
      "epoch: 4, batch: 653, loss: 0.8178391456604004\n",
      "epoch: 4, batch: 654, loss: 0.9120135307312012\n",
      "epoch: 4, batch: 655, loss: 0.7030574083328247\n",
      "epoch: 4, batch: 656, loss: 0.8877511620521545\n",
      "epoch: 4, batch: 657, loss: 0.8181825876235962\n",
      "epoch: 4, batch: 658, loss: 1.197543740272522\n",
      "epoch: 4, batch: 659, loss: 1.1281508207321167\n",
      "epoch: 4, batch: 660, loss: 0.8472790122032166\n",
      "epoch: 4, batch: 661, loss: 1.0895206928253174\n",
      "epoch: 4, batch: 662, loss: 1.0171284675598145\n",
      "epoch: 4, batch: 663, loss: 0.8637194037437439\n",
      "epoch: 4, batch: 664, loss: 0.9960508346557617\n",
      "epoch: 4, batch: 665, loss: 0.8987405300140381\n",
      "epoch: 4, batch: 666, loss: 0.6691592931747437\n",
      "epoch: 4, batch: 667, loss: 0.8972883224487305\n",
      "epoch: 4, batch: 668, loss: 0.9540553689002991\n",
      "epoch: 4, batch: 669, loss: 0.9606434106826782\n",
      "epoch: 4, batch: 670, loss: 0.9143937826156616\n",
      "epoch: 4, batch: 671, loss: 0.8491986393928528\n",
      "epoch: 4, batch: 672, loss: 1.049901008605957\n",
      "epoch: 4, batch: 673, loss: 0.9356215596199036\n",
      "epoch: 4, batch: 674, loss: 0.6886566281318665\n",
      "epoch: 4, batch: 675, loss: 0.7673811912536621\n",
      "epoch: 4, batch: 676, loss: 0.9096533060073853\n",
      "epoch: 4, batch: 677, loss: 0.9313583970069885\n",
      "epoch: 4, batch: 678, loss: 1.0057398080825806\n",
      "epoch: 4, batch: 679, loss: 1.0395753383636475\n",
      "epoch: 4, batch: 680, loss: 0.9671870470046997\n",
      "epoch: 4, batch: 681, loss: 0.9316316843032837\n",
      "epoch: 4, batch: 682, loss: 0.9448382258415222\n",
      "epoch: 4, batch: 683, loss: 0.8982176184654236\n",
      "epoch: 4, batch: 684, loss: 0.9189921617507935\n",
      "epoch: 4, batch: 685, loss: 0.903877854347229\n",
      "epoch: 4, batch: 686, loss: 0.7850394248962402\n",
      "epoch: 4, batch: 687, loss: 0.9154608249664307\n",
      "epoch: 4, batch: 688, loss: 0.8834578394889832\n",
      "epoch: 4, batch: 689, loss: 1.169732928276062\n",
      "epoch: 4, batch: 690, loss: 0.9863061904907227\n",
      "epoch: 4, batch: 691, loss: 1.009463906288147\n",
      "epoch: 4, batch: 692, loss: 0.9242143630981445\n",
      "epoch: 4, batch: 693, loss: 0.8784573078155518\n",
      "epoch: 4, batch: 694, loss: 0.9784843325614929\n",
      "epoch: 4, batch: 695, loss: 0.8905457854270935\n",
      "epoch: 4, batch: 696, loss: 0.793581485748291\n",
      "epoch: 4, batch: 697, loss: 0.7976616621017456\n",
      "epoch: 4, batch: 698, loss: 0.998259425163269\n",
      "epoch: 4, batch: 699, loss: 0.9672207236289978\n",
      "epoch: 4, batch: 700, loss: 0.8240123987197876\n",
      "epoch: 4, batch: 701, loss: 0.9306625127792358\n",
      "epoch: 4, batch: 702, loss: 0.8265243768692017\n",
      "epoch: 4, batch: 703, loss: 0.9848405718803406\n",
      "epoch: 4, batch: 704, loss: 0.6540547609329224\n",
      "epoch: 4, batch: 705, loss: 0.9444096684455872\n",
      "epoch: 4, batch: 706, loss: 0.9643005728721619\n",
      "epoch: 4, batch: 707, loss: 1.2703394889831543\n",
      "epoch: 4, batch: 708, loss: 0.9444304704666138\n",
      "epoch: 4, batch: 709, loss: 0.8735530376434326\n",
      "epoch: 4, batch: 710, loss: 0.6459765434265137\n",
      "epoch: 4, batch: 711, loss: 0.9225965142250061\n",
      "epoch: 4, batch: 712, loss: 0.9397228360176086\n",
      "epoch: 4, batch: 713, loss: 0.815605640411377\n",
      "epoch: 4, batch: 714, loss: 0.9691015481948853\n",
      "epoch: 4, batch: 715, loss: 0.9054361581802368\n",
      "epoch: 4, batch: 716, loss: 0.9341465830802917\n",
      "epoch: 4, batch: 717, loss: 0.7519277930259705\n",
      "epoch: 4, batch: 718, loss: 0.9391344785690308\n",
      "epoch: 4, batch: 719, loss: 0.9669084548950195\n",
      "epoch: 4, batch: 720, loss: 0.9290983080863953\n",
      "epoch: 4, batch: 721, loss: 0.8677486181259155\n",
      "epoch: 4, batch: 722, loss: 0.9613853693008423\n",
      "epoch: 4, batch: 723, loss: 0.9547319412231445\n",
      "epoch: 4, batch: 724, loss: 0.8345817923545837\n",
      "epoch: 4, batch: 725, loss: 0.9109915494918823\n",
      "epoch: 4, batch: 726, loss: 0.8914490938186646\n",
      "epoch: 4, batch: 727, loss: 0.8422842025756836\n",
      "epoch: 4, batch: 728, loss: 1.0028272867202759\n",
      "epoch: 4, batch: 729, loss: 0.8799993395805359\n",
      "epoch: 4, batch: 730, loss: 0.8544908761978149\n",
      "epoch: 4, batch: 731, loss: 0.6666320562362671\n",
      "epoch: 4, batch: 732, loss: 0.8878732323646545\n",
      "epoch: 4, batch: 733, loss: 0.8146855235099792\n",
      "epoch: 4, batch: 734, loss: 0.7457684278488159\n",
      "epoch: 4, batch: 735, loss: 0.9752888083457947\n",
      "epoch: 4, batch: 736, loss: 0.9251812696456909\n",
      "epoch: 4, batch: 737, loss: 0.8848814964294434\n",
      "epoch: 4, batch: 738, loss: 0.90065997838974\n",
      "epoch: 4, batch: 739, loss: 0.9994542002677917\n",
      "epoch: 4, batch: 740, loss: 0.9895367622375488\n",
      "epoch: 4, batch: 741, loss: 0.951566219329834\n",
      "epoch: 4, batch: 742, loss: 0.8536884188652039\n",
      "epoch: 4, batch: 743, loss: 1.0135656595230103\n",
      "epoch: 4, batch: 744, loss: 0.9060847759246826\n",
      "epoch: 4, batch: 745, loss: 0.8948858380317688\n",
      "epoch: 4, batch: 746, loss: 1.048575758934021\n",
      "epoch: 4, batch: 747, loss: 1.1684818267822266\n",
      "epoch: 4, batch: 748, loss: 1.0901250839233398\n",
      "epoch: 4, batch: 749, loss: 0.8179707527160645\n",
      "epoch: 4, batch: 750, loss: 0.7430604696273804\n",
      "epoch: 4, batch: 751, loss: 0.7944891452789307\n",
      "epoch: 4, batch: 752, loss: 0.800820529460907\n",
      "epoch: 4, batch: 753, loss: 1.0018620491027832\n",
      "epoch: 4, batch: 754, loss: 0.741633415222168\n",
      "epoch: 4, batch: 755, loss: 0.7841005325317383\n",
      "epoch: 4, batch: 756, loss: 0.9336027503013611\n",
      "epoch: 4, batch: 757, loss: 0.862193763256073\n",
      "epoch: 4, batch: 758, loss: 0.9177930951118469\n",
      "epoch: 4, batch: 759, loss: 0.7735317349433899\n",
      "epoch: 4, batch: 760, loss: 1.0117743015289307\n",
      "epoch: 4, batch: 761, loss: 0.9565420746803284\n",
      "epoch: 4, batch: 762, loss: 0.6413036584854126\n",
      "epoch: 4, batch: 763, loss: 0.8114988803863525\n",
      "epoch: 4, batch: 764, loss: 0.631140947341919\n",
      "epoch: 4, batch: 765, loss: 1.0160515308380127\n",
      "epoch: 4, batch: 766, loss: 0.8898362517356873\n",
      "epoch: 4, batch: 767, loss: 1.0228016376495361\n",
      "epoch: 4, batch: 768, loss: 1.0784395933151245\n",
      "epoch: 4, batch: 769, loss: 1.0068637132644653\n",
      "epoch: 4, batch: 770, loss: 1.2937066555023193\n",
      "epoch: 4, batch: 771, loss: 0.8365928530693054\n",
      "epoch: 4, batch: 772, loss: 0.9973488450050354\n",
      "epoch: 4, batch: 773, loss: 0.9291736483573914\n",
      "epoch: 4, batch: 774, loss: 0.746248722076416\n",
      "epoch: 4, batch: 775, loss: 0.6434572339057922\n",
      "epoch: 4, batch: 776, loss: 0.8368828892707825\n",
      "epoch: 4, batch: 777, loss: 0.8946384787559509\n",
      "epoch: 4, batch: 778, loss: 0.8660807013511658\n",
      "epoch: 4, batch: 779, loss: 0.9125322699546814\n",
      "epoch: 4, batch: 780, loss: 0.8884149193763733\n",
      "epoch: 4, batch: 781, loss: 0.9880170822143555\n",
      "epoch: 4, batch: 782, loss: 0.9019407629966736\n",
      "epoch: 4, batch: 783, loss: 0.9353052377700806\n",
      "epoch: 4, batch: 784, loss: 0.957900881767273\n",
      "epoch: 4, batch: 785, loss: 0.9693083763122559\n",
      "epoch: 4, batch: 786, loss: 0.8966343402862549\n",
      "epoch: 4, batch: 787, loss: 0.9119166135787964\n",
      "epoch: 4, batch: 788, loss: 0.9058473706245422\n",
      "epoch: 4, batch: 789, loss: 0.7481013536453247\n",
      "epoch: 4, batch: 790, loss: 0.8810642957687378\n",
      "epoch: 4, batch: 791, loss: 0.7829061150550842\n",
      "epoch: 4, batch: 792, loss: 0.852047860622406\n",
      "epoch: 4, batch: 793, loss: 0.889144778251648\n",
      "epoch: 4, batch: 794, loss: 0.6769359707832336\n",
      "epoch: 4, batch: 795, loss: 0.8872365355491638\n",
      "epoch: 4, batch: 796, loss: 1.045271635055542\n",
      "epoch: 4, batch: 797, loss: 0.779126763343811\n",
      "epoch: 4, batch: 798, loss: 0.9499953985214233\n",
      "epoch: 4, batch: 799, loss: 0.8579512238502502\n",
      "epoch: 4, batch: 800, loss: 0.8659259676933289\n",
      "epoch: 4, batch: 801, loss: 0.9088159203529358\n",
      "epoch: 4, batch: 802, loss: 0.8204975724220276\n",
      "epoch: 4, batch: 803, loss: 1.0414502620697021\n",
      "epoch: 4, batch: 804, loss: 0.9081590175628662\n",
      "epoch: 4, batch: 805, loss: 0.7396059036254883\n",
      "epoch: 4, batch: 806, loss: 0.7850796580314636\n",
      "epoch: 4, batch: 807, loss: 0.8777957558631897\n",
      "epoch: 4, batch: 808, loss: 0.8196008205413818\n",
      "epoch: 4, batch: 809, loss: 0.9592519998550415\n",
      "epoch: 4, batch: 810, loss: 0.9097045660018921\n",
      "epoch: 4, batch: 811, loss: 1.0495355129241943\n",
      "epoch: 4, batch: 812, loss: 1.015600323677063\n",
      "epoch: 4, batch: 813, loss: 0.8873511552810669\n",
      "epoch: 4, batch: 814, loss: 0.8598650693893433\n",
      "epoch: 4, batch: 815, loss: 1.15597403049469\n",
      "epoch: 4, batch: 816, loss: 1.0256524085998535\n",
      "epoch: 4, batch: 817, loss: 0.8596641421318054\n",
      "epoch: 4, batch: 818, loss: 0.9726623892784119\n",
      "epoch: 4, batch: 819, loss: 0.7090476751327515\n",
      "epoch: 4, batch: 820, loss: 0.7751230597496033\n",
      "epoch: 4, batch: 821, loss: 0.8226873874664307\n",
      "epoch: 4, batch: 822, loss: 1.1504820585250854\n",
      "epoch: 4, batch: 823, loss: 0.7739246487617493\n",
      "epoch: 4, batch: 824, loss: 0.7444458603858948\n",
      "epoch: 4, batch: 825, loss: 1.2179979085922241\n",
      "epoch: 4, batch: 826, loss: 0.9682932496070862\n",
      "epoch: 4, batch: 827, loss: 0.9196947813034058\n",
      "epoch: 4, batch: 828, loss: 0.7499847412109375\n",
      "epoch: 4, batch: 829, loss: 0.9654777646064758\n",
      "epoch: 4, batch: 830, loss: 0.9185241460800171\n",
      "epoch: 4, batch: 831, loss: 0.9340083003044128\n",
      "epoch: 4, batch: 832, loss: 0.9051182866096497\n",
      "epoch: 4, batch: 833, loss: 0.9765819311141968\n",
      "epoch: 4, batch: 834, loss: 0.998540997505188\n",
      "epoch: 4, batch: 835, loss: 0.8460327982902527\n",
      "epoch: 4, batch: 836, loss: 0.7659072875976562\n",
      "epoch: 4, batch: 837, loss: 0.8031660318374634\n",
      "epoch: 4, batch: 838, loss: 0.9611471891403198\n",
      "epoch: 4, batch: 839, loss: 1.0275040864944458\n",
      "epoch: 4, batch: 840, loss: 0.8322641849517822\n",
      "epoch: 4, batch: 841, loss: 0.9483449459075928\n",
      "epoch: 4, batch: 842, loss: 0.9178413152694702\n",
      "epoch: 4, batch: 843, loss: 0.9353835582733154\n",
      "epoch: 4, batch: 844, loss: 0.9306793212890625\n",
      "epoch: 4, batch: 845, loss: 0.852690577507019\n",
      "epoch: 4, batch: 846, loss: 0.8789381980895996\n",
      "epoch: 4, batch: 847, loss: 0.8517249226570129\n",
      "epoch: 4, batch: 848, loss: 0.7101441621780396\n",
      "epoch: 4, batch: 849, loss: 1.0364580154418945\n",
      "epoch: 4, batch: 850, loss: 0.9688841700553894\n",
      "epoch: 4, batch: 851, loss: 0.9675641059875488\n",
      "epoch: 4, batch: 852, loss: 0.9438441395759583\n",
      "epoch: 4, batch: 853, loss: 0.7460120320320129\n",
      "epoch: 4, batch: 854, loss: 0.8479058742523193\n",
      "epoch: 4, batch: 855, loss: 0.76988685131073\n",
      "epoch: 4, batch: 856, loss: 0.9053850173950195\n",
      "epoch: 4, batch: 857, loss: 1.0059605836868286\n",
      "epoch: 4, batch: 858, loss: 0.8536096215248108\n",
      "epoch: 4, batch: 859, loss: 0.9892356395721436\n",
      "epoch: 4, batch: 860, loss: 0.7731978893280029\n",
      "epoch: 4, batch: 861, loss: 1.0811288356781006\n",
      "epoch: 4, batch: 862, loss: 1.0393943786621094\n",
      "epoch: 4, batch: 863, loss: 0.7034822702407837\n",
      "epoch: 4, batch: 864, loss: 1.0125584602355957\n",
      "epoch: 4, batch: 865, loss: 0.7136788964271545\n",
      "epoch: 4, batch: 866, loss: 0.8301798701286316\n",
      "epoch: 4, batch: 867, loss: 0.7605971097946167\n",
      "epoch: 4, batch: 868, loss: 1.073678731918335\n",
      "epoch: 4, batch: 869, loss: 0.7927546501159668\n",
      "epoch: 4, batch: 870, loss: 0.900763750076294\n",
      "epoch: 4, batch: 871, loss: 0.7487546801567078\n",
      "epoch: 4, batch: 872, loss: 0.7651203274726868\n",
      "epoch: 4, batch: 873, loss: 0.7072151899337769\n",
      "epoch: 4, batch: 874, loss: 0.7630017399787903\n",
      "epoch: 4, batch: 875, loss: 0.9401344060897827\n",
      "epoch: 4, batch: 876, loss: 0.9781110882759094\n",
      "epoch: 4, batch: 877, loss: 0.930427610874176\n",
      "epoch: 4, batch: 878, loss: 0.8193758726119995\n",
      "epoch: 4, batch: 879, loss: 0.8019595742225647\n",
      "epoch: 4, batch: 880, loss: 0.9872610569000244\n",
      "epoch: 4, batch: 881, loss: 0.9647549390792847\n",
      "epoch: 4, batch: 882, loss: 0.7173327207565308\n",
      "epoch: 4, batch: 883, loss: 0.9876460433006287\n",
      "epoch: 4, batch: 884, loss: 0.90080326795578\n",
      "epoch: 4, batch: 885, loss: 0.855329155921936\n",
      "epoch: 4, batch: 886, loss: 0.8138161897659302\n",
      "epoch: 4, batch: 887, loss: 0.7372642755508423\n",
      "epoch: 4, batch: 888, loss: 0.8273542523384094\n",
      "epoch: 4, batch: 889, loss: 0.9608783721923828\n",
      "epoch: 4, batch: 890, loss: 0.7848541736602783\n",
      "epoch: 4, batch: 891, loss: 0.9275391697883606\n",
      "epoch: 4, batch: 892, loss: 0.8561131954193115\n",
      "epoch: 4, batch: 893, loss: 0.7861345410346985\n",
      "epoch: 4, batch: 894, loss: 1.0913136005401611\n",
      "epoch: 4, batch: 895, loss: 0.8576894402503967\n",
      "epoch: 4, batch: 896, loss: 0.92349773645401\n",
      "epoch: 4, batch: 897, loss: 0.7318927049636841\n",
      "epoch: 4, batch: 898, loss: 0.9674694538116455\n",
      "epoch: 4, batch: 899, loss: 0.9362204074859619\n",
      "epoch: 4, batch: 900, loss: 0.8810573220252991\n",
      "epoch: 4, batch: 901, loss: 0.7189589738845825\n",
      "epoch: 4, batch: 902, loss: 1.0181587934494019\n",
      "epoch: 4, batch: 903, loss: 0.9863959550857544\n",
      "epoch: 4, batch: 904, loss: 0.9083573818206787\n",
      "epoch: 4, batch: 905, loss: 0.8587296605110168\n",
      "epoch: 4, batch: 906, loss: 0.8015874028205872\n",
      "epoch: 4, batch: 907, loss: 0.9383659362792969\n",
      "epoch: 4, batch: 908, loss: 0.9337345957756042\n",
      "epoch: 4, batch: 909, loss: 1.02580988407135\n",
      "epoch: 4, batch: 910, loss: 0.9761728644371033\n",
      "epoch: 4, batch: 911, loss: 0.9852712154388428\n",
      "epoch: 4, batch: 912, loss: 0.9536783695220947\n",
      "epoch: 4, batch: 913, loss: 0.7814412713050842\n",
      "epoch: 4, batch: 914, loss: 0.9004030823707581\n",
      "epoch: 4, batch: 915, loss: 0.9708779454231262\n",
      "epoch: 4, batch: 916, loss: 1.0005230903625488\n",
      "epoch: 4, batch: 917, loss: 0.9411085247993469\n",
      "epoch: 4, batch: 918, loss: 0.8598095774650574\n",
      "epoch: 4, batch: 919, loss: 0.8888520002365112\n",
      "epoch: 4, batch: 920, loss: 0.9093230962753296\n",
      "epoch: 4, batch: 921, loss: 0.8701174855232239\n",
      "epoch: 4, batch: 922, loss: 0.8232128024101257\n",
      "epoch: 4, batch: 923, loss: 0.7946737408638\n",
      "epoch: 4, batch: 924, loss: 0.7698663473129272\n",
      "epoch: 4, batch: 925, loss: 0.7398598194122314\n",
      "epoch: 4, batch: 926, loss: 0.6507376432418823\n",
      "epoch: 4, batch: 927, loss: 0.8972779512405396\n",
      "epoch: 4, batch: 928, loss: 0.8787443041801453\n",
      "epoch: 4, batch: 929, loss: 0.7926414608955383\n",
      "epoch: 4, batch: 930, loss: 0.8087499141693115\n",
      "epoch: 4, batch: 931, loss: 0.8480488657951355\n",
      "epoch: 4, batch: 932, loss: 1.215574860572815\n",
      "epoch: 4, batch: 933, loss: 0.9204067587852478\n",
      "epoch: 4, batch: 934, loss: 0.6421108245849609\n",
      "epoch: 4, batch: 935, loss: 0.7603684067726135\n",
      "epoch: 4, batch: 936, loss: 1.165716290473938\n",
      "epoch: 4, batch: 937, loss: 0.8829954862594604\n",
      "epoch: 4, batch: 938, loss: 0.6479669809341431\n",
      "epoch: 4, batch: 939, loss: 0.9529616236686707\n",
      "epoch: 4, batch: 940, loss: 0.7304354310035706\n",
      "epoch: 4, batch: 941, loss: 0.9597102999687195\n",
      "epoch: 4, batch: 942, loss: 0.7958178520202637\n",
      "epoch: 4, batch: 943, loss: 0.9475911259651184\n",
      "epoch: 4, batch: 944, loss: 0.9192679524421692\n",
      "epoch: 4, batch: 945, loss: 0.7964922189712524\n",
      "epoch: 4, batch: 946, loss: 0.8804838061332703\n",
      "epoch: 4, batch: 947, loss: 0.9749464392662048\n",
      "epoch: 4, batch: 948, loss: 0.8040343523025513\n",
      "epoch: 4, batch: 949, loss: 0.9396638870239258\n",
      "epoch: 4, batch: 950, loss: 0.8430100083351135\n",
      "epoch: 4, batch: 951, loss: 0.9830532670021057\n",
      "epoch: 4, batch: 952, loss: 0.7868873476982117\n",
      "epoch: 4, batch: 953, loss: 0.8259872198104858\n",
      "epoch: 4, batch: 954, loss: 0.8926303386688232\n",
      "epoch: 4, batch: 955, loss: 0.7467263340950012\n",
      "epoch: 4, batch: 956, loss: 0.7680150866508484\n",
      "epoch: 4, batch: 957, loss: 1.0728143453598022\n",
      "epoch: 4, batch: 958, loss: 0.7687088847160339\n",
      "epoch: 4, batch: 959, loss: 0.7828217148780823\n",
      "epoch: 4, batch: 960, loss: 0.8705971240997314\n",
      "epoch: 4, batch: 961, loss: 0.7103809714317322\n",
      "epoch: 4, batch: 962, loss: 0.7851718068122864\n",
      "epoch: 4, batch: 963, loss: 1.001908302307129\n",
      "epoch: 4, batch: 964, loss: 0.826405942440033\n",
      "epoch: 4, batch: 965, loss: 0.943164587020874\n",
      "epoch: 4, batch: 966, loss: 0.820758044719696\n",
      "epoch: 4, batch: 967, loss: 0.9065744280815125\n",
      "epoch: 4, batch: 968, loss: 0.7529621124267578\n",
      "epoch: 4, batch: 969, loss: 0.6855087876319885\n",
      "epoch: 4, batch: 970, loss: 0.8607680201530457\n",
      "epoch: 4, batch: 971, loss: 0.8384380340576172\n",
      "epoch: 4, batch: 972, loss: 0.773061215877533\n",
      "epoch: 4, batch: 973, loss: 0.7443575859069824\n",
      "epoch: 4, batch: 974, loss: 0.9177822470664978\n",
      "epoch: 4, batch: 975, loss: 0.931930661201477\n",
      "epoch: 4, batch: 976, loss: 0.9581804275512695\n",
      "epoch: 4, batch: 977, loss: 0.6863027215003967\n",
      "epoch: 4, batch: 978, loss: 0.8389163017272949\n",
      "epoch: 4, batch: 979, loss: 0.7935508489608765\n",
      "epoch: 4, batch: 980, loss: 0.7394067645072937\n",
      "epoch: 4, batch: 981, loss: 0.8684316277503967\n",
      "epoch: 4, batch: 982, loss: 0.9222965836524963\n",
      "epoch: 4, batch: 983, loss: 0.9836583137512207\n",
      "epoch: 4, batch: 984, loss: 0.8441430926322937\n",
      "epoch: 4, batch: 985, loss: 1.0487604141235352\n",
      "epoch: 4, batch: 986, loss: 0.6726096868515015\n",
      "epoch: 4, batch: 987, loss: 0.8802252411842346\n",
      "epoch: 4, batch: 988, loss: 0.9316439628601074\n",
      "epoch: 4, batch: 989, loss: 0.8075509071350098\n",
      "epoch: 4, batch: 990, loss: 0.7863911986351013\n",
      "epoch: 4, batch: 991, loss: 0.6657650470733643\n",
      "epoch: 4, batch: 992, loss: 0.9236273169517517\n",
      "epoch: 4, batch: 993, loss: 0.6668158173561096\n",
      "epoch: 4, batch: 994, loss: 0.7539297938346863\n",
      "epoch: 4, batch: 995, loss: 1.0441185235977173\n",
      "epoch: 4, batch: 996, loss: 0.9485688209533691\n",
      "epoch: 4, batch: 997, loss: 0.8094794750213623\n",
      "epoch: 4, batch: 998, loss: 0.8983398079872131\n",
      "epoch: 4, batch: 999, loss: 0.901192843914032\n",
      "epoch: 4, batch: 1000, loss: 0.6615161299705505\n",
      "epoch: 4, batch: 1001, loss: 1.1410690546035767\n",
      "epoch: 4, batch: 1002, loss: 0.898047685623169\n",
      "epoch: 4, batch: 1003, loss: 0.8020153641700745\n",
      "epoch: 4, batch: 1004, loss: 0.7585359215736389\n",
      "epoch: 4, batch: 1005, loss: 0.7756754159927368\n",
      "epoch: 4, batch: 1006, loss: 0.6547493934631348\n",
      "epoch: 4, batch: 1007, loss: 0.9398715496063232\n",
      "epoch: 4, batch: 1008, loss: 1.0377362966537476\n",
      "epoch: 4, batch: 1009, loss: 0.819400429725647\n",
      "epoch: 4, batch: 1010, loss: 0.9242658019065857\n",
      "epoch: 4, batch: 1011, loss: 0.782313346862793\n",
      "epoch: 4, batch: 1012, loss: 1.0812422037124634\n",
      "epoch: 4, batch: 1013, loss: 0.8398120999336243\n",
      "epoch: 4, batch: 1014, loss: 0.8366473913192749\n",
      "epoch: 4, batch: 1015, loss: 0.905389666557312\n",
      "epoch: 4, batch: 1016, loss: 0.7892646193504333\n",
      "epoch: 4, batch: 1017, loss: 0.9380919933319092\n",
      "epoch: 4, batch: 1018, loss: 0.8813021183013916\n",
      "epoch: 4, batch: 1019, loss: 0.8645269870758057\n",
      "epoch: 4, batch: 1020, loss: 0.6929253935813904\n",
      "epoch: 4, batch: 1021, loss: 0.8082584142684937\n",
      "epoch: 4, batch: 1022, loss: 0.7752373218536377\n",
      "epoch: 4, batch: 1023, loss: 0.8109517693519592\n",
      "epoch: 4, batch: 1024, loss: 0.9105299711227417\n",
      "epoch: 4, batch: 1025, loss: 0.8221225738525391\n",
      "epoch: 4, batch: 1026, loss: 0.6963250041007996\n",
      "epoch: 4, batch: 1027, loss: 1.105776071548462\n",
      "epoch: 4, batch: 1028, loss: 0.7245187163352966\n",
      "epoch: 4, batch: 1029, loss: 0.8080849647521973\n",
      "epoch: 4, batch: 1030, loss: 0.9352557063102722\n",
      "epoch: 4, batch: 1031, loss: 1.0798530578613281\n",
      "epoch: 4, batch: 1032, loss: 0.8813197612762451\n",
      "epoch: 4, batch: 1033, loss: 0.84809410572052\n",
      "epoch: 4, batch: 1034, loss: 0.9414341449737549\n",
      "epoch: 4, batch: 1035, loss: 1.0382416248321533\n",
      "epoch: 4, batch: 1036, loss: 0.8133007884025574\n",
      "epoch: 4, batch: 1037, loss: 0.803173840045929\n",
      "epoch: 4, batch: 1038, loss: 1.2031760215759277\n",
      "epoch: 4, batch: 1039, loss: 0.7456443309783936\n",
      "epoch: 4, batch: 1040, loss: 0.5745882987976074\n",
      "epoch: 4, batch: 1041, loss: 0.9470278024673462\n",
      "epoch: 4, batch: 1042, loss: 0.690057098865509\n",
      "epoch: 4, batch: 1043, loss: 0.8239397406578064\n",
      "epoch: 4, batch: 1044, loss: 0.8757264018058777\n",
      "epoch: 4, batch: 1045, loss: 0.9108381867408752\n",
      "epoch: 4, batch: 1046, loss: 0.9639604091644287\n",
      "epoch: 4, batch: 1047, loss: 0.9501490592956543\n",
      "epoch: 4, batch: 1048, loss: 0.8161025643348694\n",
      "epoch: 4, batch: 1049, loss: 0.8519626259803772\n",
      "epoch: 4, batch: 1050, loss: 0.640399694442749\n",
      "epoch: 4, batch: 1051, loss: 0.8282338380813599\n",
      "epoch: 4, batch: 1052, loss: 0.7290157675743103\n",
      "epoch: 4, batch: 1053, loss: 0.9969438910484314\n",
      "epoch: 4, batch: 1054, loss: 0.8321858048439026\n",
      "epoch: 4, batch: 1055, loss: 0.6870169639587402\n",
      "epoch: 4, batch: 1056, loss: 0.9821931719779968\n",
      "epoch: 4, batch: 1057, loss: 0.7921339869499207\n",
      "epoch: 4, batch: 1058, loss: 0.858272135257721\n",
      "epoch: 4, batch: 1059, loss: 0.7431932687759399\n",
      "epoch: 4, batch: 1060, loss: 0.998529314994812\n",
      "epoch: 4, batch: 1061, loss: 0.8247076272964478\n",
      "epoch: 4, batch: 1062, loss: 1.0179877281188965\n",
      "epoch: 4, batch: 1063, loss: 0.9642242789268494\n",
      "epoch: 4, batch: 1064, loss: 0.9496965408325195\n",
      "epoch: 4, batch: 1065, loss: 0.7546389102935791\n",
      "epoch: 4, batch: 1066, loss: 0.826204240322113\n",
      "epoch: 4, batch: 1067, loss: 0.8195191025733948\n",
      "epoch: 4, batch: 1068, loss: 0.630200207233429\n",
      "epoch: 4, batch: 1069, loss: 0.9183225035667419\n",
      "epoch: 4, batch: 1070, loss: 0.920383632183075\n",
      "epoch: 4, batch: 1071, loss: 0.9985177516937256\n",
      "epoch: 4, batch: 1072, loss: 0.91005539894104\n",
      "epoch: 4, batch: 1073, loss: 1.118356704711914\n",
      "epoch: 4, batch: 1074, loss: 1.163194179534912\n",
      "epoch: 4, batch: 1075, loss: 0.7354810237884521\n",
      "epoch: 4, batch: 1076, loss: 0.7194547057151794\n",
      "epoch: 4, batch: 1077, loss: 0.9003520607948303\n",
      "epoch: 4, batch: 1078, loss: 0.793728232383728\n",
      "epoch: 4, batch: 1079, loss: 0.9991737604141235\n",
      "epoch: 4, batch: 1080, loss: 0.9152004718780518\n",
      "epoch: 4, batch: 1081, loss: 0.6973168849945068\n",
      "epoch: 4, batch: 1082, loss: 0.7286499738693237\n",
      "epoch: 4, batch: 1083, loss: 0.890889048576355\n",
      "epoch: 4, batch: 1084, loss: 1.0417921543121338\n",
      "epoch: 4, batch: 1085, loss: 0.7953585982322693\n",
      "epoch: 4, batch: 1086, loss: 0.8069509267807007\n",
      "epoch: 4, batch: 1087, loss: 0.9043410420417786\n",
      "epoch: 4, batch: 1088, loss: 0.7466847896575928\n",
      "epoch: 4, batch: 1089, loss: 1.0635144710540771\n",
      "epoch: 4, batch: 1090, loss: 1.049621343612671\n",
      "epoch: 4, batch: 1091, loss: 0.8449652791023254\n",
      "epoch: 4, batch: 1092, loss: 0.8219202756881714\n",
      "epoch: 4, batch: 1093, loss: 0.9438769817352295\n",
      "epoch: 4, batch: 1094, loss: 0.8369383811950684\n",
      "epoch: 4, batch: 1095, loss: 0.9886419773101807\n",
      "epoch: 4, batch: 1096, loss: 0.84854656457901\n",
      "epoch: 4, batch: 1097, loss: 0.8412072658538818\n",
      "epoch: 4, batch: 1098, loss: 0.7945677638053894\n",
      "epoch: 4, batch: 1099, loss: 0.8536559343338013\n",
      "epoch: 4, batch: 1100, loss: 0.7248048782348633\n",
      "epoch: 4, batch: 1101, loss: 0.9647355675697327\n",
      "epoch: 4, batch: 1102, loss: 1.0540410280227661\n",
      "epoch: 4, batch: 1103, loss: 0.8940345048904419\n",
      "epoch: 4, batch: 1104, loss: 0.7604737281799316\n",
      "epoch: 4, batch: 1105, loss: 1.0250478982925415\n",
      "epoch: 4, batch: 1106, loss: 0.8716952204704285\n",
      "epoch: 4, batch: 1107, loss: 0.8296443819999695\n",
      "epoch: 4, batch: 1108, loss: 0.8081011772155762\n",
      "epoch: 4, batch: 1109, loss: 0.6778154373168945\n",
      "epoch: 4, batch: 1110, loss: 0.8979337811470032\n",
      "epoch: 4, batch: 1111, loss: 0.6871501803398132\n",
      "epoch: 4, batch: 1112, loss: 0.5998526811599731\n",
      "epoch: 4, batch: 1113, loss: 0.8152590394020081\n",
      "epoch: 4, batch: 1114, loss: 1.055478572845459\n",
      "epoch: 4, batch: 1115, loss: 0.9086251258850098\n",
      "epoch: 4, batch: 1116, loss: 0.7298663258552551\n",
      "epoch: 4, batch: 1117, loss: 0.7862713932991028\n",
      "epoch: 4, batch: 1118, loss: 0.5543559193611145\n",
      "epoch: 4, batch: 1119, loss: 0.7755491137504578\n",
      "epoch: 4, batch: 1120, loss: 0.6709845066070557\n",
      "epoch: 4, batch: 1121, loss: 0.7761887311935425\n",
      "epoch: 4, batch: 1122, loss: 0.9603434801101685\n",
      "epoch: 4, batch: 1123, loss: 0.8277764320373535\n",
      "epoch: 4, batch: 1124, loss: 0.8459150195121765\n",
      "epoch: 4, batch: 1125, loss: 0.7517880797386169\n",
      "epoch: 4, batch: 1126, loss: 0.7705312371253967\n",
      "epoch: 4, batch: 1127, loss: 0.7077234983444214\n",
      "epoch: 4, batch: 1128, loss: 0.7379429340362549\n",
      "epoch: 4, batch: 1129, loss: 0.815055787563324\n",
      "epoch: 4, batch: 1130, loss: 0.8388590812683105\n",
      "epoch: 4, batch: 1131, loss: 0.8710601329803467\n",
      "epoch: 4, batch: 1132, loss: 0.9485990405082703\n",
      "epoch: 4, batch: 1133, loss: 0.7675166130065918\n",
      "epoch: 4, batch: 1134, loss: 0.8325709700584412\n",
      "epoch: 4, batch: 1135, loss: 0.8379786014556885\n",
      "epoch: 4, batch: 1136, loss: 0.9005991816520691\n",
      "epoch: 4, batch: 1137, loss: 0.823219358921051\n",
      "epoch: 4, batch: 1138, loss: 0.8330697417259216\n",
      "epoch: 4, batch: 1139, loss: 0.7807371616363525\n",
      "epoch: 4, batch: 1140, loss: 0.9084411263465881\n",
      "epoch: 4, batch: 1141, loss: 0.70143723487854\n",
      "epoch: 4, batch: 1142, loss: 0.729330837726593\n",
      "epoch: 4, batch: 1143, loss: 0.6884974241256714\n",
      "epoch: 4, batch: 1144, loss: 1.0530483722686768\n",
      "epoch: 4, batch: 1145, loss: 1.0524686574935913\n",
      "epoch: 4, batch: 1146, loss: 0.9188228249549866\n",
      "epoch: 4, batch: 1147, loss: 0.7529278993606567\n",
      "epoch: 4, batch: 1148, loss: 0.6784811019897461\n",
      "epoch: 4, batch: 1149, loss: 0.8185393810272217\n",
      "epoch: 4, batch: 1150, loss: 1.0535236597061157\n",
      "epoch: 4, batch: 1151, loss: 0.9689005017280579\n",
      "epoch: 4, batch: 1152, loss: 0.8227592706680298\n",
      "epoch: 4, batch: 1153, loss: 0.7386534810066223\n",
      "epoch: 4, batch: 1154, loss: 0.7800042629241943\n",
      "epoch: 4, batch: 1155, loss: 0.8409761190414429\n",
      "epoch: 4, batch: 1156, loss: 0.9256532788276672\n",
      "epoch: 4, batch: 1157, loss: 0.9479273557662964\n",
      "epoch: 4, batch: 1158, loss: 0.8855605721473694\n",
      "epoch: 4, batch: 1159, loss: 0.7754514217376709\n",
      "epoch: 4, batch: 1160, loss: 0.9530755281448364\n",
      "epoch: 4, batch: 1161, loss: 1.020563006401062\n",
      "epoch: 4, batch: 1162, loss: 1.0192667245864868\n",
      "epoch: 4, batch: 1163, loss: 0.9128709435462952\n",
      "epoch: 4, batch: 1164, loss: 0.7713586091995239\n",
      "epoch: 4, batch: 1165, loss: 0.8569700717926025\n",
      "epoch: 4, batch: 1166, loss: 0.8705394864082336\n",
      "epoch: 4, batch: 1167, loss: 0.7431077361106873\n",
      "epoch: 4, batch: 1168, loss: 0.82286137342453\n",
      "epoch: 4, batch: 1169, loss: 0.8289575576782227\n",
      "epoch: 4, batch: 1170, loss: 0.9204680919647217\n",
      "epoch: 4, batch: 1171, loss: 0.7121957540512085\n",
      "epoch: 4, batch: 1172, loss: 0.8008686304092407\n",
      "epoch: 4, batch: 1173, loss: 0.7648574709892273\n",
      "epoch: 4, batch: 1174, loss: 0.8544917106628418\n",
      "epoch: 4, batch: 1175, loss: 0.9408983588218689\n",
      "epoch: 4, batch: 1176, loss: 0.7282383441925049\n",
      "epoch: 4, batch: 1177, loss: 0.9687514901161194\n",
      "epoch: 4, batch: 1178, loss: 0.723801851272583\n",
      "epoch: 4, batch: 1179, loss: 1.0156084299087524\n",
      "epoch: 4, batch: 1180, loss: 0.5907436609268188\n",
      "epoch: 4, batch: 1181, loss: 0.9031647443771362\n",
      "epoch: 4, batch: 1182, loss: 0.8258972764015198\n",
      "epoch: 4, batch: 1183, loss: 0.698418140411377\n",
      "epoch: 4, batch: 1184, loss: 0.7220967411994934\n",
      "epoch: 4, batch: 1185, loss: 0.719632625579834\n",
      "epoch: 4, batch: 1186, loss: 0.7295054197311401\n",
      "epoch: 4, batch: 1187, loss: 0.7700332403182983\n",
      "epoch: 4, batch: 1188, loss: 0.8351761698722839\n",
      "epoch: 4, batch: 1189, loss: 0.915320634841919\n",
      "epoch: 4, batch: 1190, loss: 0.8121375441551208\n",
      "epoch: 4, batch: 1191, loss: 0.8996629118919373\n",
      "epoch: 4, batch: 1192, loss: 0.7060774564743042\n",
      "epoch: 4, batch: 1193, loss: 0.7418054938316345\n",
      "epoch: 4, batch: 1194, loss: 0.7980222105979919\n",
      "epoch: 4, batch: 1195, loss: 0.7492256760597229\n",
      "epoch: 4, batch: 1196, loss: 0.8639509081840515\n",
      "epoch: 4, batch: 1197, loss: 0.6823053956031799\n",
      "epoch: 4, batch: 1198, loss: 0.984506368637085\n",
      "epoch: 4, batch: 1199, loss: 0.8089227080345154\n",
      "epoch: 4, batch: 1200, loss: 0.6420465111732483\n",
      "epoch: 4, batch: 1201, loss: 0.9780725240707397\n",
      "epoch: 4, batch: 1202, loss: 0.8644348382949829\n",
      "epoch: 4, batch: 1203, loss: 0.666436493396759\n",
      "epoch: 4, batch: 1204, loss: 0.8268070816993713\n",
      "epoch: 4, batch: 1205, loss: 0.6951883435249329\n",
      "epoch: 4, batch: 1206, loss: 0.7443878650665283\n",
      "epoch: 4, batch: 1207, loss: 0.7874237895011902\n",
      "epoch: 4, batch: 1208, loss: 0.950811505317688\n",
      "epoch: 4, batch: 1209, loss: 0.6718751192092896\n",
      "epoch: 4, batch: 1210, loss: 0.772078275680542\n",
      "epoch: 4, batch: 1211, loss: 0.6991360783576965\n",
      "epoch: 4, batch: 1212, loss: 0.8737086057662964\n",
      "epoch: 4, batch: 1213, loss: 0.7226744890213013\n",
      "epoch: 4, batch: 1214, loss: 0.8370881080627441\n",
      "epoch: 4, batch: 1215, loss: 0.7335344552993774\n",
      "epoch: 4, batch: 1216, loss: 0.6334516406059265\n",
      "epoch: 4, batch: 1217, loss: 0.889578104019165\n",
      "epoch: 4, batch: 1218, loss: 0.8130178451538086\n",
      "epoch: 4, batch: 1219, loss: 1.102300763130188\n",
      "epoch: 4, batch: 1220, loss: 0.6954821944236755\n",
      "epoch: 4, batch: 1221, loss: 0.6933423280715942\n",
      "epoch: 4, batch: 1222, loss: 0.7821515202522278\n",
      "epoch: 4, batch: 1223, loss: 0.6363006234169006\n",
      "epoch: 4, batch: 1224, loss: 0.8725001215934753\n",
      "epoch: 4, batch: 1225, loss: 0.7661450505256653\n",
      "epoch: 4, batch: 1226, loss: 0.6804578304290771\n",
      "epoch: 4, batch: 1227, loss: 1.0454753637313843\n",
      "epoch: 4, batch: 1228, loss: 1.0007283687591553\n",
      "epoch: 4, batch: 1229, loss: 0.6834102272987366\n",
      "epoch: 4, batch: 1230, loss: 0.9712324738502502\n",
      "epoch: 4, batch: 1231, loss: 0.9544500112533569\n",
      "epoch: 4, batch: 1232, loss: 0.6783325672149658\n",
      "epoch: 4, batch: 1233, loss: 0.7759128212928772\n",
      "epoch: 4, batch: 1234, loss: 0.9823490977287292\n",
      "epoch: 4, batch: 1235, loss: 0.8157327175140381\n",
      "epoch: 4, batch: 1236, loss: 0.9331813454627991\n",
      "epoch: 4, batch: 1237, loss: 1.0154119729995728\n",
      "epoch: 4, batch: 1238, loss: 0.8141389489173889\n",
      "epoch: 4, batch: 1239, loss: 0.8847891688346863\n",
      "epoch: 4, batch: 1240, loss: 0.9180810451507568\n",
      "epoch: 4, batch: 1241, loss: 0.6373780965805054\n",
      "epoch: 4, batch: 1242, loss: 0.896091639995575\n",
      "epoch: 4, batch: 1243, loss: 0.948681116104126\n",
      "epoch: 4, batch: 1244, loss: 0.7065398693084717\n",
      "epoch: 4, batch: 1245, loss: 0.6288005709648132\n",
      "epoch: 4, batch: 1246, loss: 0.9904861450195312\n",
      "epoch: 4, batch: 1247, loss: 0.8385562896728516\n",
      "epoch: 4, batch: 1248, loss: 0.7266281843185425\n",
      "epoch: 4, batch: 1249, loss: 0.8936712145805359\n",
      "epoch: 4, batch: 1250, loss: 1.1197006702423096\n",
      "epoch: 4, batch: 1251, loss: 0.9501172304153442\n",
      "epoch: 4, batch: 1252, loss: 0.660283088684082\n",
      "epoch: 4, batch: 1253, loss: 0.7295388579368591\n",
      "epoch: 4, batch: 1254, loss: 0.7876153588294983\n",
      "epoch: 4, batch: 1255, loss: 0.6728558540344238\n",
      "epoch: 4, batch: 1256, loss: 0.8319935202598572\n",
      "epoch: 4, batch: 1257, loss: 0.8906744122505188\n",
      "epoch: 4, batch: 1258, loss: 0.868154764175415\n",
      "epoch: 4, batch: 1259, loss: 0.6935732960700989\n",
      "epoch: 4, batch: 1260, loss: 0.8627837300300598\n",
      "epoch: 4, batch: 1261, loss: 0.6049089431762695\n",
      "epoch: 4, batch: 1262, loss: 0.7894689440727234\n",
      "epoch: 4, batch: 1263, loss: 0.627593994140625\n",
      "epoch: 4, batch: 1264, loss: 1.1270688772201538\n",
      "epoch: 4, batch: 1265, loss: 1.031753659248352\n",
      "epoch: 4, batch: 1266, loss: 0.9888024926185608\n",
      "epoch: 4, batch: 1267, loss: 1.0096927881240845\n",
      "epoch: 4, batch: 1268, loss: 0.8827328681945801\n",
      "epoch: 4, batch: 1269, loss: 0.8277162909507751\n",
      "epoch: 4, batch: 1270, loss: 0.7723827958106995\n",
      "epoch: 4, batch: 1271, loss: 0.7371106743812561\n",
      "epoch: 4, batch: 1272, loss: 0.8271623849868774\n",
      "epoch: 4, batch: 1273, loss: 0.8532679677009583\n",
      "epoch: 4, batch: 1274, loss: 0.8726043105125427\n",
      "epoch: 4, batch: 1275, loss: 0.7061060667037964\n",
      "epoch: 4, batch: 1276, loss: 1.1170856952667236\n",
      "epoch: 4, batch: 1277, loss: 0.9229442477226257\n",
      "epoch: 4, batch: 1278, loss: 0.899275004863739\n",
      "epoch: 4, batch: 1279, loss: 1.0090081691741943\n",
      "epoch: 4, batch: 1280, loss: 0.890658438205719\n",
      "epoch: 4, batch: 1281, loss: 0.775834858417511\n",
      "epoch: 4, batch: 1282, loss: 0.6899934411048889\n",
      "epoch: 4, batch: 1283, loss: 0.8248509168624878\n",
      "epoch: 4, batch: 1284, loss: 0.6191071271896362\n",
      "epoch: 4, batch: 1285, loss: 0.8772596120834351\n",
      "epoch: 4, batch: 1286, loss: 0.917142391204834\n",
      "epoch: 4, batch: 1287, loss: 0.8813117742538452\n",
      "epoch: 4, batch: 1288, loss: 0.8063498139381409\n",
      "epoch: 4, batch: 1289, loss: 0.7223794460296631\n",
      "epoch: 4, batch: 1290, loss: 0.7969271540641785\n",
      "epoch: 4, batch: 1291, loss: 0.6876968145370483\n",
      "epoch: 4, batch: 1292, loss: 0.8190819025039673\n",
      "epoch: 4, batch: 1293, loss: 1.0104241371154785\n",
      "epoch: 4, batch: 1294, loss: 0.7909906506538391\n",
      "epoch: 4, batch: 1295, loss: 0.7134656310081482\n",
      "epoch: 4, batch: 1296, loss: 0.8106738328933716\n",
      "epoch: 4, batch: 1297, loss: 0.7966645359992981\n",
      "epoch: 4, batch: 1298, loss: 0.8931355476379395\n",
      "epoch: 4, batch: 1299, loss: 0.9423456788063049\n",
      "epoch: 4, batch: 1300, loss: 0.6736382246017456\n",
      "epoch: 4, batch: 1301, loss: 1.062356948852539\n",
      "epoch: 4, batch: 1302, loss: 0.7026217579841614\n",
      "epoch: 4, batch: 1303, loss: 1.1494392156600952\n",
      "epoch: 4, batch: 1304, loss: 0.8872965574264526\n",
      "epoch: 4, batch: 1305, loss: 0.9381404519081116\n",
      "epoch: 4, batch: 1306, loss: 0.7800846695899963\n",
      "epoch: 4, batch: 1307, loss: 0.7363110184669495\n",
      "epoch: 4, batch: 1308, loss: 0.7310912609100342\n",
      "epoch: 4, batch: 1309, loss: 1.0673511028289795\n",
      "epoch: 4, batch: 1310, loss: 0.8215657472610474\n",
      "epoch: 4, batch: 1311, loss: 0.9323803186416626\n",
      "epoch: 4, batch: 1312, loss: 0.9342333078384399\n",
      "epoch: 4, batch: 1313, loss: 0.7879531979560852\n",
      "epoch: 4, batch: 1314, loss: 0.8318279981613159\n",
      "epoch: 4, batch: 1315, loss: 0.8965332508087158\n",
      "epoch: 4, batch: 1316, loss: 0.8095713257789612\n",
      "epoch: 4, batch: 1317, loss: 0.818163275718689\n",
      "epoch: 4, batch: 1318, loss: 0.7091922163963318\n",
      "epoch: 4, batch: 1319, loss: 0.8860906958580017\n",
      "epoch: 4, batch: 1320, loss: 0.7047639489173889\n",
      "epoch: 4, batch: 1321, loss: 1.00027596950531\n",
      "epoch: 4, batch: 1322, loss: 0.8632655739784241\n",
      "epoch: 4, batch: 1323, loss: 1.0320427417755127\n",
      "epoch: 4, batch: 1324, loss: 0.8168976902961731\n",
      "epoch: 4, batch: 1325, loss: 0.7758727669715881\n",
      "epoch: 4, batch: 1326, loss: 0.9603346586227417\n",
      "epoch: 4, batch: 1327, loss: 0.7917545437812805\n",
      "epoch: 4, batch: 1328, loss: 0.8697876930236816\n",
      "epoch: 4, batch: 1329, loss: 0.7110446095466614\n",
      "epoch: 4, batch: 1330, loss: 0.9103968143463135\n",
      "epoch: 4, batch: 1331, loss: 0.8643016219139099\n",
      "epoch: 4, batch: 1332, loss: 0.9076226949691772\n",
      "epoch: 4, batch: 1333, loss: 0.7696816325187683\n",
      "epoch: 4, batch: 1334, loss: 0.724902868270874\n",
      "epoch: 4, batch: 1335, loss: 0.7553873658180237\n",
      "epoch: 4, batch: 1336, loss: 0.8344860076904297\n",
      "epoch: 4, batch: 1337, loss: 0.8677376508712769\n",
      "epoch: 4, batch: 1338, loss: 0.9775176048278809\n",
      "epoch: 4, batch: 1339, loss: 1.0307332277297974\n",
      "epoch: 4, batch: 1340, loss: 0.7597867846488953\n",
      "epoch: 4, batch: 1341, loss: 0.9294487833976746\n",
      "epoch: 4, batch: 1342, loss: 0.7078595757484436\n",
      "epoch: 4, batch: 1343, loss: 0.8111265897750854\n",
      "epoch: 4, batch: 1344, loss: 0.8113306164741516\n",
      "epoch: 4, batch: 1345, loss: 0.9457887411117554\n",
      "epoch: 4, batch: 1346, loss: 0.8542448878288269\n",
      "epoch: 4, batch: 1347, loss: 0.9458284378051758\n",
      "epoch: 4, batch: 1348, loss: 0.7953900694847107\n",
      "epoch: 4, batch: 1349, loss: 0.8131568431854248\n",
      "epoch: 4, batch: 1350, loss: 0.8666617274284363\n",
      "epoch: 4, batch: 1351, loss: 0.86085444688797\n",
      "epoch: 4, batch: 1352, loss: 0.9111722707748413\n",
      "epoch: 4, batch: 1353, loss: 0.7575560808181763\n",
      "epoch: 4, batch: 1354, loss: 0.982539713382721\n",
      "epoch: 4, batch: 1355, loss: 0.7776170969009399\n",
      "epoch: 4, batch: 1356, loss: 0.8037051558494568\n",
      "epoch: 4, batch: 1357, loss: 0.8239745497703552\n",
      "epoch: 4, batch: 1358, loss: 0.8280549049377441\n",
      "epoch: 4, batch: 1359, loss: 0.7426980137825012\n",
      "epoch: 4, batch: 1360, loss: 0.8802192211151123\n",
      "epoch: 4, batch: 1361, loss: 0.7408087253570557\n",
      "epoch: 4, batch: 1362, loss: 0.9621405601501465\n",
      "epoch: 4, batch: 1363, loss: 0.9455262422561646\n",
      "epoch: 4, batch: 1364, loss: 0.7173352837562561\n",
      "epoch: 4, batch: 1365, loss: 0.8933684825897217\n",
      "epoch: 4, batch: 1366, loss: 0.8020764589309692\n",
      "epoch: 4, batch: 1367, loss: 0.9855166077613831\n",
      "epoch: 4, batch: 1368, loss: 0.8707853555679321\n",
      "epoch: 4, batch: 1369, loss: 0.807332456111908\n",
      "epoch: 4, batch: 1370, loss: 0.9644438028335571\n",
      "epoch: 4, batch: 1371, loss: 0.6826850175857544\n",
      "epoch: 4, batch: 1372, loss: 0.8753167986869812\n",
      "epoch: 4, batch: 1373, loss: 0.9888725280761719\n",
      "epoch: 4, batch: 1374, loss: 0.8101028203964233\n",
      "epoch: 4, batch: 1375, loss: 1.1116458177566528\n",
      "epoch: 4, batch: 1376, loss: 0.8465006947517395\n",
      "epoch: 4, batch: 1377, loss: 0.6826073527336121\n",
      "epoch: 4, batch: 1378, loss: 0.9444054365158081\n",
      "epoch: 4, batch: 1379, loss: 0.7242805361747742\n",
      "epoch: 4, batch: 1380, loss: 0.8118667006492615\n",
      "epoch: 4, batch: 1381, loss: 0.5503418445587158\n",
      "epoch: 4, batch: 1382, loss: 0.8102284669876099\n",
      "epoch: 4, batch: 1383, loss: 0.796553909778595\n",
      "epoch: 4, batch: 1384, loss: 0.8123241066932678\n",
      "epoch: 4, batch: 1385, loss: 0.7664097547531128\n",
      "epoch: 4, batch: 1386, loss: 1.0120570659637451\n",
      "epoch: 4, batch: 1387, loss: 0.6009389758110046\n",
      "epoch: 4, batch: 1388, loss: 0.8555223941802979\n",
      "epoch: 4, batch: 1389, loss: 0.8289830684661865\n",
      "epoch: 4, batch: 1390, loss: 0.9550413489341736\n",
      "epoch: 4, batch: 1391, loss: 0.9070354700088501\n",
      "epoch: 4, batch: 1392, loss: 1.0886993408203125\n",
      "epoch: 4, batch: 1393, loss: 0.6417971253395081\n",
      "epoch: 4, batch: 1394, loss: 0.9021806120872498\n",
      "epoch: 4, batch: 1395, loss: 0.6690757870674133\n",
      "epoch: 4, batch: 1396, loss: 0.7934043407440186\n",
      "epoch: 4, batch: 1397, loss: 0.9776452779769897\n",
      "epoch: 4, batch: 1398, loss: 0.832722008228302\n",
      "epoch: 4, batch: 1399, loss: 0.9213732481002808\n",
      "epoch: 4, batch: 1400, loss: 0.8493764996528625\n",
      "epoch: 4, batch: 1401, loss: 0.8969595432281494\n",
      "epoch: 4, batch: 1402, loss: 0.6699342727661133\n",
      "epoch: 4, batch: 1403, loss: 1.071793556213379\n",
      "epoch: 4, batch: 1404, loss: 0.68208909034729\n",
      "epoch: 4, batch: 1405, loss: 0.7745140790939331\n",
      "epoch: 4, batch: 1406, loss: 0.9031417369842529\n",
      "epoch: 4, batch: 1407, loss: 0.6530108451843262\n",
      "epoch: 4, batch: 1408, loss: 0.9806938767433167\n",
      "epoch: 4, batch: 1409, loss: 0.9147472381591797\n",
      "epoch: 4, batch: 1410, loss: 1.0316065549850464\n",
      "epoch: 4, batch: 1411, loss: 0.9495899677276611\n",
      "epoch: 4, batch: 1412, loss: 0.8325359225273132\n",
      "epoch: 4, batch: 1413, loss: 0.8801261782646179\n",
      "epoch: 4, batch: 1414, loss: 0.8710563778877258\n",
      "epoch: 4, batch: 1415, loss: 0.7517618536949158\n",
      "epoch: 4, batch: 1416, loss: 0.6823879480361938\n",
      "epoch: 4, batch: 1417, loss: 0.8701555132865906\n",
      "epoch: 4, batch: 1418, loss: 0.841495931148529\n",
      "epoch: 4, batch: 1419, loss: 0.7269403338432312\n",
      "epoch: 4, batch: 1420, loss: 0.8057879209518433\n",
      "epoch: 4, batch: 1421, loss: 1.0877982378005981\n",
      "epoch: 4, batch: 1422, loss: 0.754112720489502\n",
      "epoch: 4, batch: 1423, loss: 0.7640513181686401\n",
      "epoch: 4, batch: 1424, loss: 0.7310860753059387\n",
      "epoch: 4, batch: 1425, loss: 0.7869205474853516\n",
      "epoch: 4, batch: 1426, loss: 0.9586005806922913\n",
      "epoch: 4, batch: 1427, loss: 0.8257768750190735\n",
      "epoch: 4, batch: 1428, loss: 0.7777817249298096\n",
      "epoch: 4, batch: 1429, loss: 0.939559280872345\n",
      "epoch: 4, batch: 1430, loss: 0.7559250593185425\n",
      "epoch: 4, batch: 1431, loss: 0.8233803510665894\n",
      "epoch: 4, batch: 1432, loss: 0.6854779720306396\n",
      "epoch: 4, batch: 1433, loss: 0.886222779750824\n",
      "epoch: 4, batch: 1434, loss: 0.9513989686965942\n",
      "epoch: 4, batch: 1435, loss: 0.7192152738571167\n",
      "epoch: 4, batch: 1436, loss: 0.5593079924583435\n",
      "epoch: 4, batch: 1437, loss: 0.6671164631843567\n",
      "epoch: 4, batch: 1438, loss: 0.7765662670135498\n",
      "epoch: 4, batch: 1439, loss: 0.982398271560669\n",
      "epoch: 4, batch: 1440, loss: 0.822170078754425\n",
      "epoch: 4, batch: 1441, loss: 0.6718809008598328\n",
      "epoch: 4, batch: 1442, loss: 0.9215681552886963\n",
      "epoch: 4, batch: 1443, loss: 0.799850344657898\n",
      "epoch: 4, batch: 1444, loss: 0.8252046704292297\n",
      "epoch: 4, batch: 1445, loss: 0.7779396176338196\n",
      "epoch: 4, batch: 1446, loss: 0.6264700889587402\n",
      "epoch: 4, batch: 1447, loss: 0.7879550457000732\n",
      "epoch: 4, batch: 1448, loss: 0.6091935634613037\n",
      "epoch: 4, batch: 1449, loss: 0.8350949883460999\n",
      "epoch: 4, batch: 1450, loss: 0.8597779870033264\n",
      "epoch: 4, batch: 1451, loss: 0.7261374592781067\n",
      "epoch: 4, batch: 1452, loss: 0.8580062389373779\n",
      "epoch: 4, batch: 1453, loss: 0.9845192432403564\n",
      "epoch: 4, batch: 1454, loss: 0.9094025492668152\n",
      "epoch: 4, batch: 1455, loss: 0.8187932372093201\n",
      "epoch: 4, batch: 1456, loss: 0.5686210989952087\n",
      "epoch: 4, batch: 1457, loss: 0.7451438307762146\n",
      "epoch: 4, batch: 1458, loss: 0.7063780426979065\n",
      "epoch: 4, batch: 1459, loss: 0.8123756647109985\n",
      "epoch: 4, batch: 1460, loss: 0.7498320937156677\n",
      "epoch: 4, batch: 1461, loss: 0.7005202174186707\n",
      "epoch: 4, batch: 1462, loss: 0.8377187252044678\n",
      "epoch: 4, batch: 1463, loss: 0.8145416378974915\n",
      "epoch: 4, batch: 1464, loss: 0.9457051157951355\n",
      "epoch: 4, batch: 1465, loss: 0.6818578243255615\n",
      "epoch: 4, batch: 1466, loss: 0.8415114879608154\n",
      "epoch: 4, batch: 1467, loss: 0.9257060885429382\n",
      "epoch: 4, batch: 1468, loss: 1.0857958793640137\n",
      "epoch: 4, batch: 1469, loss: 0.8308660984039307\n",
      "epoch: 4, batch: 1470, loss: 0.7746926546096802\n",
      "epoch: 4, batch: 1471, loss: 0.8623353838920593\n",
      "epoch: 4, batch: 1472, loss: 0.7837304472923279\n",
      "epoch: 4, batch: 1473, loss: 0.8867844939231873\n",
      "epoch: 4, batch: 1474, loss: 0.8468944430351257\n",
      "epoch: 4, batch: 1475, loss: 0.7800014019012451\n",
      "epoch: 4, batch: 1476, loss: 0.7963191866874695\n",
      "epoch: 4, batch: 1477, loss: 0.7816221714019775\n",
      "epoch: 4, batch: 1478, loss: 0.9357218146324158\n",
      "epoch: 4, batch: 1479, loss: 0.9324050545692444\n",
      "epoch: 4, batch: 1480, loss: 0.9650697112083435\n",
      "epoch: 4, batch: 1481, loss: 0.8170055747032166\n",
      "epoch: 4, batch: 1482, loss: 0.8753626942634583\n",
      "epoch: 4, batch: 1483, loss: 1.022324562072754\n",
      "epoch: 4, batch: 1484, loss: 0.7664828300476074\n",
      "epoch: 4, batch: 1485, loss: 0.781146764755249\n",
      "epoch: 4, batch: 1486, loss: 0.7764791250228882\n",
      "epoch: 4, batch: 1487, loss: 0.8766338229179382\n",
      "epoch: 4, batch: 1488, loss: 0.8422936797142029\n",
      "epoch: 4, batch: 1489, loss: 0.8406777381896973\n",
      "epoch: 4, batch: 1490, loss: 0.6978323459625244\n",
      "epoch: 4, batch: 1491, loss: 0.8119394183158875\n",
      "epoch: 4, batch: 1492, loss: 0.8317704796791077\n",
      "epoch: 4, batch: 1493, loss: 0.8993984460830688\n",
      "epoch: 4, batch: 1494, loss: 0.925263524055481\n",
      "epoch: 4, batch: 1495, loss: 0.7931315302848816\n",
      "epoch: 4, batch: 1496, loss: 0.8094132542610168\n",
      "epoch: 4, batch: 1497, loss: 0.91468745470047\n",
      "epoch: 4, batch: 1498, loss: 1.019838571548462\n",
      "epoch: 4, batch: 1499, loss: 0.691461980342865\n",
      "epoch: 4, batch: 1500, loss: 0.9664424061775208\n",
      "epoch: 4, batch: 1501, loss: 0.8184686899185181\n",
      "epoch: 4, batch: 1502, loss: 0.6917387843132019\n",
      "epoch: 4, batch: 1503, loss: 0.7950405478477478\n",
      "epoch: 4, batch: 1504, loss: 0.8813135623931885\n",
      "epoch: 4, batch: 1505, loss: 0.7633644342422485\n",
      "epoch: 4, batch: 1506, loss: 0.9497941732406616\n",
      "epoch: 4, batch: 1507, loss: 0.8142815232276917\n",
      "epoch: 4, batch: 1508, loss: 0.8626155853271484\n",
      "epoch: 4, batch: 1509, loss: 0.6829360127449036\n",
      "epoch: 4, batch: 1510, loss: 0.9392829537391663\n",
      "epoch: 4, batch: 1511, loss: 0.8194020390510559\n",
      "epoch: 4, batch: 1512, loss: 0.8252279758453369\n",
      "epoch: 4, batch: 1513, loss: 0.8054954409599304\n",
      "epoch: 4, batch: 1514, loss: 0.8644030094146729\n",
      "epoch: 4, batch: 1515, loss: 0.6437476873397827\n",
      "epoch: 4, batch: 1516, loss: 0.6320086121559143\n",
      "epoch: 4, batch: 1517, loss: 0.8484227657318115\n",
      "epoch: 4, batch: 1518, loss: 0.6392796635627747\n",
      "epoch: 4, batch: 1519, loss: 0.6919152736663818\n",
      "epoch: 4, batch: 1520, loss: 1.0900572538375854\n",
      "epoch: 4, batch: 1521, loss: 0.7876785397529602\n",
      "epoch: 4, batch: 1522, loss: 0.8452582359313965\n",
      "epoch: 4, batch: 1523, loss: 0.7826559543609619\n",
      "epoch: 4, batch: 1524, loss: 0.9888031482696533\n",
      "epoch: 4, batch: 1525, loss: 0.7628931403160095\n",
      "epoch: 4, batch: 1526, loss: 0.9010958671569824\n",
      "epoch: 4, batch: 1527, loss: 0.6897661685943604\n",
      "epoch: 4, batch: 1528, loss: 0.6635259985923767\n",
      "epoch: 4, batch: 1529, loss: 0.9794526100158691\n",
      "epoch: 4, batch: 1530, loss: 0.8287192583084106\n",
      "epoch: 4, batch: 1531, loss: 0.6248077750205994\n",
      "epoch: 4, batch: 1532, loss: 0.7578155994415283\n",
      "epoch: 4, batch: 1533, loss: 0.7571547031402588\n",
      "epoch: 4, batch: 1534, loss: 0.7432183027267456\n",
      "epoch: 4, batch: 1535, loss: 0.8591486215591431\n",
      "epoch: 4, batch: 1536, loss: 0.9924894571304321\n",
      "epoch: 4, batch: 1537, loss: 0.7686681747436523\n",
      "epoch: 4, batch: 1538, loss: 0.7942864298820496\n",
      "epoch: 4, batch: 1539, loss: 0.9248761534690857\n",
      "epoch: 4, batch: 1540, loss: 0.7101205587387085\n",
      "epoch: 4, batch: 1541, loss: 0.9810715317726135\n",
      "epoch: 4, batch: 1542, loss: 0.7120932340621948\n",
      "epoch: 4, batch: 1543, loss: 0.7158152461051941\n",
      "epoch: 4, batch: 1544, loss: 1.0460197925567627\n",
      "epoch: 4, batch: 1545, loss: 0.8654873371124268\n",
      "epoch: 4, batch: 1546, loss: 0.6998447775840759\n",
      "epoch: 4, batch: 1547, loss: 0.7646125555038452\n",
      "epoch: 4, batch: 1548, loss: 0.8443851470947266\n",
      "epoch: 4, batch: 1549, loss: 0.8496737480163574\n",
      "epoch: 4, batch: 1550, loss: 1.0047357082366943\n",
      "epoch: 4, batch: 1551, loss: 0.6756933927536011\n",
      "epoch: 4, batch: 1552, loss: 0.935981035232544\n",
      "epoch: 4, batch: 1553, loss: 0.9809280633926392\n",
      "epoch: 4, batch: 1554, loss: 0.8125746250152588\n",
      "epoch: 4, batch: 1555, loss: 0.8461303114891052\n",
      "epoch: 4, batch: 1556, loss: 0.8091908693313599\n",
      "epoch: 4, batch: 1557, loss: 0.9122055768966675\n",
      "epoch: 4, batch: 1558, loss: 0.9787221550941467\n",
      "epoch: 4, batch: 1559, loss: 0.7292129993438721\n",
      "epoch: 4, batch: 1560, loss: 0.9258328676223755\n",
      "epoch: 4, batch: 1561, loss: 0.904737114906311\n",
      "epoch: 4, batch: 1562, loss: 0.8079476356506348\n",
      "epoch: 4, batch: 1563, loss: 0.7143105268478394\n",
      "epoch: 4, batch: 1564, loss: 0.7642536163330078\n",
      "epoch: 4, batch: 1565, loss: 0.6815040111541748\n",
      "epoch: 4, batch: 1566, loss: 0.726716160774231\n",
      "epoch: 4, batch: 1567, loss: 0.5147841572761536\n",
      "epoch: 4, batch: 1568, loss: 0.7936590909957886\n",
      "epoch: 4, batch: 1569, loss: 0.6841042041778564\n",
      "epoch: 4, batch: 1570, loss: 0.7897135019302368\n",
      "epoch: 4, batch: 1571, loss: 0.9004546403884888\n",
      "epoch: 4, batch: 1572, loss: 0.893390417098999\n",
      "epoch: 4, batch: 1573, loss: 0.8381631970405579\n",
      "epoch: 4, batch: 1574, loss: 0.9803943634033203\n",
      "epoch: 4, batch: 1575, loss: 0.675674557685852\n",
      "epoch: 4, batch: 1576, loss: 0.7177432775497437\n",
      "epoch: 4, batch: 1577, loss: 0.7817880511283875\n",
      "epoch: 4, batch: 1578, loss: 0.7414259314537048\n",
      "epoch: 4, batch: 1579, loss: 0.9143837094306946\n",
      "epoch: 4, batch: 1580, loss: 0.8349097967147827\n",
      "epoch: 4, batch: 1581, loss: 0.6439411640167236\n",
      "epoch: 4, batch: 1582, loss: 0.9032468795776367\n",
      "epoch: 4, batch: 1583, loss: 0.8576634526252747\n",
      "epoch: 4, batch: 1584, loss: 0.825558066368103\n",
      "epoch: 4, batch: 1585, loss: 0.8506860136985779\n",
      "epoch: 4, batch: 1586, loss: 1.013292908668518\n",
      "epoch: 4, batch: 1587, loss: 0.6824468970298767\n",
      "epoch: 4, batch: 1588, loss: 0.6901999711990356\n",
      "epoch: 4, batch: 1589, loss: 0.7830333113670349\n",
      "epoch: 4, batch: 1590, loss: 0.8183863759040833\n",
      "epoch: 4, batch: 1591, loss: 0.698983371257782\n",
      "epoch: 4, batch: 1592, loss: 0.8301808834075928\n",
      "epoch: 4, batch: 1593, loss: 0.5957196354866028\n",
      "epoch: 4, batch: 1594, loss: 0.8828122019767761\n",
      "epoch: 4, batch: 1595, loss: 0.7767221331596375\n",
      "epoch: 4, batch: 1596, loss: 1.0014986991882324\n",
      "epoch: 4, batch: 1597, loss: 0.7782864570617676\n",
      "epoch: 4, batch: 1598, loss: 0.7856432795524597\n",
      "epoch: 4, batch: 1599, loss: 0.8391470909118652\n",
      "epoch: 4, batch: 1600, loss: 0.6016684770584106\n",
      "epoch: 4, batch: 1601, loss: 0.7922574877738953\n",
      "epoch: 4, batch: 1602, loss: 0.7255325317382812\n",
      "epoch: 4, batch: 1603, loss: 0.850874662399292\n",
      "epoch: 4, batch: 1604, loss: 0.6579587459564209\n",
      "epoch: 4, batch: 1605, loss: 0.5825059413909912\n",
      "epoch: 4, batch: 1606, loss: 0.9370015859603882\n",
      "epoch: 4, batch: 1607, loss: 0.6547825932502747\n",
      "epoch: 4, batch: 1608, loss: 0.7162319421768188\n",
      "epoch: 4, batch: 1609, loss: 0.7454493045806885\n",
      "epoch: 4, batch: 1610, loss: 0.6447649002075195\n",
      "epoch: 4, batch: 1611, loss: 0.8550812005996704\n",
      "epoch: 4, batch: 1612, loss: 0.7672215104103088\n",
      "epoch: 4, batch: 1613, loss: 0.7748138904571533\n",
      "epoch: 4, batch: 1614, loss: 0.7837013006210327\n",
      "epoch: 4, batch: 1615, loss: 0.7664439678192139\n",
      "epoch: 4, batch: 1616, loss: 0.7132894992828369\n",
      "epoch: 4, batch: 1617, loss: 0.7301822900772095\n",
      "epoch: 4, batch: 1618, loss: 0.7562878131866455\n",
      "epoch: 4, batch: 1619, loss: 0.8042981624603271\n",
      "epoch: 4, batch: 1620, loss: 0.6733025312423706\n",
      "epoch: 4, batch: 1621, loss: 0.7251634001731873\n",
      "epoch: 4, batch: 1622, loss: 0.7738404870033264\n",
      "epoch: 4, batch: 1623, loss: 0.9254966974258423\n",
      "epoch: 4, batch: 1624, loss: 0.6532715559005737\n",
      "epoch: 4, batch: 1625, loss: 0.803698718547821\n",
      "epoch: 4, batch: 1626, loss: 0.6931777596473694\n",
      "epoch: 4, batch: 1627, loss: 0.7019382119178772\n",
      "epoch: 4, batch: 1628, loss: 0.8434348702430725\n",
      "epoch: 4, batch: 1629, loss: 0.6912623643875122\n",
      "epoch: 4, batch: 1630, loss: 0.7493478059768677\n",
      "epoch: 4, batch: 1631, loss: 0.8587322235107422\n",
      "epoch: 4, batch: 1632, loss: 0.8986546993255615\n",
      "epoch: 4, batch: 1633, loss: 0.9058725833892822\n",
      "epoch: 4, batch: 1634, loss: 0.7258148193359375\n",
      "epoch: 4, batch: 1635, loss: 0.737152636051178\n",
      "epoch: 4, batch: 1636, loss: 0.7096849083900452\n",
      "epoch: 4, batch: 1637, loss: 0.9275914430618286\n",
      "epoch: 4, batch: 1638, loss: 0.75704026222229\n",
      "epoch: 4, batch: 1639, loss: 1.0092663764953613\n",
      "epoch: 4, batch: 1640, loss: 0.6554151773452759\n",
      "epoch: 4, batch: 1641, loss: 0.6961439251899719\n",
      "epoch: 4, batch: 1642, loss: 0.8794882297515869\n",
      "epoch: 4, batch: 1643, loss: 0.9438866376876831\n",
      "epoch: 4, batch: 1644, loss: 0.5688351392745972\n",
      "epoch: 4, batch: 1645, loss: 0.9054074287414551\n",
      "epoch: 4, batch: 1646, loss: 0.6264255046844482\n",
      "epoch: 4, batch: 1647, loss: 0.9386330246925354\n",
      "epoch: 4, batch: 1648, loss: 0.954994797706604\n",
      "epoch: 4, batch: 1649, loss: 0.7540784478187561\n",
      "epoch: 4, batch: 1650, loss: 0.752535343170166\n",
      "epoch: 4, batch: 1651, loss: 0.8855834007263184\n",
      "epoch: 4, batch: 1652, loss: 0.7874637842178345\n",
      "epoch: 4, batch: 1653, loss: 0.581538200378418\n",
      "epoch: 4, batch: 1654, loss: 0.8997442126274109\n",
      "epoch: 4, batch: 1655, loss: 0.7626866102218628\n",
      "epoch: 4, batch: 1656, loss: 0.8551388382911682\n",
      "epoch: 4, batch: 1657, loss: 0.8730667233467102\n",
      "epoch: 4, batch: 1658, loss: 0.7943786978721619\n",
      "epoch: 4, batch: 1659, loss: 0.5970100164413452\n",
      "epoch: 4, batch: 1660, loss: 0.6887124180793762\n",
      "epoch: 4, batch: 1661, loss: 0.7762105464935303\n",
      "epoch: 4, batch: 1662, loss: 0.7501325011253357\n",
      "epoch: 4, batch: 1663, loss: 0.6035894751548767\n",
      "epoch: 4, batch: 1664, loss: 0.820645272731781\n",
      "epoch: 4, batch: 1665, loss: 0.8292282819747925\n",
      "epoch: 4, batch: 1666, loss: 0.6945246458053589\n",
      "epoch: 4, batch: 1667, loss: 0.5677772760391235\n",
      "epoch: 4, batch: 1668, loss: 0.7236823439598083\n",
      "epoch: 4, batch: 1669, loss: 0.9141005277633667\n",
      "epoch: 4, batch: 1670, loss: 0.8562000393867493\n",
      "epoch: 4, batch: 1671, loss: 0.7520696520805359\n",
      "epoch: 4, batch: 1672, loss: 0.8055753111839294\n",
      "epoch: 4, batch: 1673, loss: 0.7579352259635925\n",
      "epoch: 4, batch: 1674, loss: 0.7351229190826416\n",
      "epoch: 4, batch: 1675, loss: 0.9047704339027405\n",
      "epoch: 4, batch: 1676, loss: 0.5920702219009399\n",
      "epoch: 4, batch: 1677, loss: 0.6121934652328491\n",
      "epoch: 4, batch: 1678, loss: 0.865791380405426\n",
      "epoch: 4, batch: 1679, loss: 0.675905704498291\n",
      "epoch: 4, batch: 1680, loss: 0.6863119602203369\n",
      "epoch: 4, batch: 1681, loss: 0.7844314575195312\n",
      "epoch: 4, batch: 1682, loss: 0.8537778854370117\n",
      "epoch: 4, batch: 1683, loss: 0.8100646734237671\n",
      "epoch: 4, batch: 1684, loss: 0.614570140838623\n",
      "epoch: 4, batch: 1685, loss: 0.8381450176239014\n",
      "epoch: 4, batch: 1686, loss: 0.7766525149345398\n",
      "epoch: 4, batch: 1687, loss: 0.7960796356201172\n",
      "epoch: 4, batch: 1688, loss: 0.6019762754440308\n",
      "epoch: 4, batch: 1689, loss: 0.5911179184913635\n",
      "epoch: 4, batch: 1690, loss: 0.9599916934967041\n",
      "epoch: 4, batch: 1691, loss: 0.6560829281806946\n",
      "epoch: 4, batch: 1692, loss: 0.925786018371582\n",
      "epoch: 4, batch: 1693, loss: 0.8879761099815369\n",
      "epoch: 4, batch: 1694, loss: 0.799623966217041\n",
      "epoch: 4, batch: 1695, loss: 0.8112950325012207\n",
      "epoch: 4, batch: 1696, loss: 0.9936450123786926\n",
      "epoch: 4, batch: 1697, loss: 0.7590320110321045\n",
      "epoch: 4, batch: 1698, loss: 0.7660744786262512\n",
      "epoch: 4, batch: 1699, loss: 0.7089081406593323\n",
      "epoch: 4, batch: 1700, loss: 0.9141316413879395\n",
      "epoch: 4, batch: 1701, loss: 0.5864930152893066\n",
      "epoch: 4, batch: 1702, loss: 0.761553943157196\n",
      "epoch: 4, batch: 1703, loss: 0.6186515092849731\n",
      "epoch: 4, batch: 1704, loss: 0.7394484281539917\n",
      "epoch: 4, batch: 1705, loss: 0.6255279779434204\n",
      "epoch: 4, batch: 1706, loss: 0.926497220993042\n",
      "epoch: 4, batch: 1707, loss: 0.7361835837364197\n",
      "epoch: 4, batch: 1708, loss: 0.7758744955062866\n",
      "epoch: 4, batch: 1709, loss: 0.7162997722625732\n",
      "epoch: 4, batch: 1710, loss: 0.881064772605896\n",
      "epoch: 4, batch: 1711, loss: 0.7158776521682739\n",
      "epoch: 4, batch: 1712, loss: 0.8591679930686951\n",
      "epoch: 4, batch: 1713, loss: 0.8669723272323608\n",
      "epoch: 4, batch: 1714, loss: 0.9033440947532654\n",
      "epoch: 4, batch: 1715, loss: 1.0779881477355957\n",
      "epoch: 4, batch: 1716, loss: 0.6559101343154907\n",
      "epoch: 4, batch: 1717, loss: 0.8560293316841125\n",
      "epoch: 4, batch: 1718, loss: 0.8617863655090332\n",
      "epoch: 4, batch: 1719, loss: 0.848533570766449\n",
      "epoch: 4, batch: 1720, loss: 0.7470572590827942\n",
      "epoch: 4, batch: 1721, loss: 0.6240947246551514\n",
      "epoch: 4, batch: 1722, loss: 0.6625379920005798\n",
      "epoch: 4, batch: 1723, loss: 0.8035992980003357\n",
      "epoch: 4, batch: 1724, loss: 0.8328440189361572\n",
      "epoch: 4, batch: 1725, loss: 0.8006559610366821\n",
      "epoch: 4, batch: 1726, loss: 0.7579799294471741\n",
      "epoch: 4, batch: 1727, loss: 0.8586299419403076\n",
      "epoch: 4, batch: 1728, loss: 0.7156434059143066\n",
      "epoch: 4, batch: 1729, loss: 0.7142968773841858\n",
      "epoch: 4, batch: 1730, loss: 0.7748821973800659\n",
      "epoch: 4, batch: 1731, loss: 0.7757543921470642\n",
      "epoch: 4, batch: 1732, loss: 0.6623777151107788\n",
      "epoch: 4, batch: 1733, loss: 0.7789250612258911\n",
      "epoch: 4, batch: 1734, loss: 0.8301525115966797\n",
      "epoch: 4, batch: 1735, loss: 0.9670580625534058\n",
      "epoch: 4, batch: 1736, loss: 0.6440790295600891\n",
      "epoch: 4, batch: 1737, loss: 0.9261163473129272\n",
      "epoch: 4, batch: 1738, loss: 0.5411012768745422\n",
      "epoch: 4, batch: 1739, loss: 0.9366449117660522\n",
      "epoch: 4, batch: 1740, loss: 0.8358383178710938\n",
      "epoch: 4, batch: 1741, loss: 0.6899822950363159\n",
      "epoch: 4, batch: 1742, loss: 0.7412847876548767\n",
      "epoch: 4, batch: 1743, loss: 0.8061462044715881\n",
      "epoch: 4, batch: 1744, loss: 0.8518211841583252\n",
      "epoch: 4, batch: 1745, loss: 0.685437798500061\n",
      "epoch: 4, batch: 1746, loss: 0.7413920760154724\n",
      "epoch: 4, batch: 1747, loss: 0.7668339014053345\n",
      "epoch: 4, batch: 1748, loss: 0.714783251285553\n",
      "epoch: 4, batch: 1749, loss: 0.8295890688896179\n",
      "epoch: 4, batch: 1750, loss: 0.7708118557929993\n",
      "epoch: 4, batch: 1751, loss: 0.9218485951423645\n",
      "epoch: 4, batch: 1752, loss: 0.6067430973052979\n",
      "epoch: 4, batch: 1753, loss: 0.6635034680366516\n",
      "epoch: 4, batch: 1754, loss: 0.9414981603622437\n",
      "epoch: 4, batch: 1755, loss: 0.7221857905387878\n",
      "epoch: 4, batch: 1756, loss: 0.8800349831581116\n",
      "epoch: 4, batch: 1757, loss: 0.9138566851615906\n",
      "epoch: 4, batch: 1758, loss: 0.6375592947006226\n",
      "epoch: 4, batch: 1759, loss: 0.819446861743927\n",
      "epoch: 4, batch: 1760, loss: 0.7753406167030334\n",
      "epoch: 4, batch: 1761, loss: 0.793272852897644\n",
      "epoch: 4, batch: 1762, loss: 0.7349453568458557\n",
      "epoch: 4, batch: 1763, loss: 0.8393081426620483\n",
      "epoch: 4, batch: 1764, loss: 0.788585364818573\n",
      "epoch: 4, batch: 1765, loss: 0.8748854994773865\n",
      "epoch: 4, batch: 1766, loss: 0.6481080055236816\n",
      "epoch: 4, batch: 1767, loss: 0.85953688621521\n",
      "epoch: 4, batch: 1768, loss: 0.6553565263748169\n",
      "epoch: 4, batch: 1769, loss: 0.9715169072151184\n",
      "epoch: 4, batch: 1770, loss: 0.8655257821083069\n",
      "epoch: 4, batch: 1771, loss: 0.7142170071601868\n",
      "epoch: 4, batch: 1772, loss: 0.7518017292022705\n",
      "epoch: 4, batch: 1773, loss: 0.7281624674797058\n",
      "epoch: 4, batch: 1774, loss: 0.7606484293937683\n",
      "epoch: 4, batch: 1775, loss: 0.6905596852302551\n",
      "epoch: 4, batch: 1776, loss: 0.8701851963996887\n",
      "epoch: 4, batch: 1777, loss: 0.46407726407051086\n",
      "epoch: 4, batch: 1778, loss: 0.4661262333393097\n",
      "epoch: 4, batch: 1779, loss: 0.7008509039878845\n",
      "epoch: 4, batch: 1780, loss: 0.7765520215034485\n",
      "epoch: 4, batch: 1781, loss: 0.8011792898178101\n",
      "epoch: 4, batch: 1782, loss: 0.6970469355583191\n",
      "epoch: 4, batch: 1783, loss: 0.8675342798233032\n",
      "epoch: 4, batch: 1784, loss: 0.6433489918708801\n",
      "epoch: 4, batch: 1785, loss: 0.6803152561187744\n",
      "epoch: 4, batch: 1786, loss: 0.7426770925521851\n",
      "epoch: 4, batch: 1787, loss: 0.7699996829032898\n",
      "epoch: 4, batch: 1788, loss: 1.0324925184249878\n",
      "epoch: 4, batch: 1789, loss: 0.8655073642730713\n",
      "epoch: 4, batch: 1790, loss: 0.8176829218864441\n",
      "epoch: 4, batch: 1791, loss: 0.9669151902198792\n",
      "epoch: 4, batch: 1792, loss: 1.1870085000991821\n",
      "epoch: 4, batch: 1793, loss: 0.898953378200531\n",
      "epoch: 4, batch: 1794, loss: 0.7564814686775208\n",
      "epoch: 4, batch: 1795, loss: 0.6776532530784607\n",
      "epoch: 4, batch: 1796, loss: 0.7495532631874084\n",
      "epoch: 4, batch: 1797, loss: 0.6574127674102783\n",
      "epoch: 4, batch: 1798, loss: 0.7616583704948425\n",
      "epoch: 4, batch: 1799, loss: 0.6148327589035034\n",
      "epoch: 4, batch: 1800, loss: 0.6531639099121094\n",
      "epoch: 4, batch: 1801, loss: 0.898550808429718\n",
      "epoch: 4, batch: 1802, loss: 0.66782146692276\n",
      "epoch: 4, batch: 1803, loss: 0.8677839636802673\n",
      "epoch: 4, batch: 1804, loss: 0.6518768668174744\n",
      "epoch: 4, batch: 1805, loss: 0.5590693354606628\n",
      "epoch: 4, batch: 1806, loss: 0.6550928354263306\n",
      "epoch: 4, batch: 1807, loss: 0.647989809513092\n",
      "epoch: 4, batch: 1808, loss: 0.9343057870864868\n",
      "epoch: 4, batch: 1809, loss: 0.7601497173309326\n",
      "epoch: 4, batch: 1810, loss: 0.7087213397026062\n",
      "epoch: 4, batch: 1811, loss: 0.6085461378097534\n",
      "epoch: 4, batch: 1812, loss: 0.9099864363670349\n",
      "epoch: 4, batch: 1813, loss: 0.8897135257720947\n",
      "epoch: 4, batch: 1814, loss: 0.8508676886558533\n",
      "epoch: 4, batch: 1815, loss: 0.553425133228302\n",
      "epoch: 4, batch: 1816, loss: 0.7629916667938232\n",
      "epoch: 4, batch: 1817, loss: 0.7580484747886658\n",
      "epoch: 4, batch: 1818, loss: 0.844214916229248\n",
      "epoch: 4, batch: 1819, loss: 0.8425329923629761\n",
      "epoch: 4, batch: 1820, loss: 0.7038635611534119\n",
      "epoch: 4, batch: 1821, loss: 0.6869087815284729\n",
      "epoch: 4, batch: 1822, loss: 0.7159715890884399\n",
      "epoch: 4, batch: 1823, loss: 0.6892905831336975\n",
      "epoch: 4, batch: 1824, loss: 0.8824501633644104\n",
      "epoch: 4, batch: 1825, loss: 0.5317803025245667\n",
      "epoch: 4, batch: 1826, loss: 0.9283421635627747\n",
      "epoch: 4, batch: 1827, loss: 0.8132213950157166\n",
      "epoch: 4, batch: 1828, loss: 0.6311571002006531\n",
      "epoch: 4, batch: 1829, loss: 0.8930835723876953\n",
      "epoch: 4, batch: 1830, loss: 0.6005115509033203\n",
      "epoch: 4, batch: 1831, loss: 0.7430025935173035\n",
      "epoch: 4, batch: 1832, loss: 0.7239471077919006\n",
      "epoch: 4, batch: 1833, loss: 0.7909155488014221\n",
      "epoch: 4, batch: 1834, loss: 0.7249597311019897\n",
      "epoch: 4, batch: 1835, loss: 0.8170520067214966\n",
      "epoch: 4, batch: 1836, loss: 0.5770993828773499\n",
      "epoch: 4, batch: 1837, loss: 0.8528474569320679\n",
      "epoch: 4, batch: 1838, loss: 0.6392637491226196\n",
      "epoch: 4, batch: 1839, loss: 0.9515994787216187\n",
      "epoch: 4, batch: 1840, loss: 0.7936145067214966\n",
      "epoch: 4, batch: 1841, loss: 0.9031116962432861\n",
      "epoch: 4, batch: 1842, loss: 0.6706147789955139\n",
      "epoch: 4, batch: 1843, loss: 0.6510186195373535\n",
      "epoch: 4, batch: 1844, loss: 0.8327386379241943\n",
      "epoch: 4, batch: 1845, loss: 0.5689055919647217\n",
      "epoch: 4, batch: 1846, loss: 0.7710708975791931\n",
      "epoch: 4, batch: 1847, loss: 1.0523134469985962\n",
      "epoch: 4, batch: 1848, loss: 0.6201924681663513\n",
      "epoch: 4, batch: 1849, loss: 0.6949257850646973\n",
      "epoch: 4, batch: 1850, loss: 0.955674946308136\n",
      "epoch: 4, batch: 1851, loss: 0.5099093914031982\n",
      "epoch: 4, batch: 1852, loss: 0.5213045477867126\n",
      "epoch: 4, batch: 1853, loss: 0.7505125999450684\n",
      "epoch: 4, batch: 1854, loss: 0.7837475538253784\n",
      "epoch: 4, batch: 1855, loss: 0.6706234812736511\n",
      "epoch: 4, batch: 1856, loss: 0.8602933883666992\n",
      "epoch: 4, batch: 1857, loss: 0.7948704361915588\n",
      "epoch: 4, batch: 1858, loss: 0.8463354110717773\n",
      "epoch: 4, batch: 1859, loss: 0.7439625263214111\n",
      "epoch: 4, batch: 1860, loss: 0.5842881202697754\n",
      "epoch: 4, batch: 1861, loss: 0.9596463441848755\n",
      "epoch: 4, batch: 1862, loss: 0.6819472312927246\n",
      "epoch: 4, batch: 1863, loss: 0.9505970478057861\n",
      "epoch: 4, batch: 1864, loss: 0.8823374509811401\n",
      "epoch: 4, batch: 1865, loss: 0.6233399510383606\n",
      "epoch: 4, batch: 1866, loss: 0.9037232398986816\n",
      "epoch: 4, batch: 1867, loss: 0.7508531212806702\n",
      "epoch: 4, batch: 1868, loss: 0.6256348490715027\n",
      "epoch: 4, batch: 1869, loss: 0.8246966600418091\n",
      "epoch: 4, batch: 1870, loss: 0.7057836055755615\n",
      "epoch: 4, batch: 1871, loss: 0.8145268559455872\n",
      "epoch: 4, batch: 1872, loss: 0.707008421421051\n",
      "epoch: 4, batch: 1873, loss: 0.7267569899559021\n",
      "epoch: 4, batch: 1874, loss: 0.7435172200202942\n",
      "epoch: 5, batch: 0, loss: 0.7223084568977356\n",
      "epoch: 5, batch: 1, loss: 0.7604021430015564\n",
      "epoch: 5, batch: 2, loss: 0.8735569715499878\n",
      "epoch: 5, batch: 3, loss: 0.6436333060264587\n",
      "epoch: 5, batch: 4, loss: 0.864539384841919\n",
      "epoch: 5, batch: 5, loss: 0.7189363837242126\n",
      "epoch: 5, batch: 6, loss: 0.8526657223701477\n",
      "epoch: 5, batch: 7, loss: 0.7188968062400818\n",
      "epoch: 5, batch: 8, loss: 0.8268532752990723\n",
      "epoch: 5, batch: 9, loss: 0.7646670937538147\n",
      "epoch: 5, batch: 10, loss: 0.8341928720474243\n",
      "epoch: 5, batch: 11, loss: 1.0651969909667969\n",
      "epoch: 5, batch: 12, loss: 0.7253785729408264\n",
      "epoch: 5, batch: 13, loss: 0.7196061611175537\n",
      "epoch: 5, batch: 14, loss: 0.6752138733863831\n",
      "epoch: 5, batch: 15, loss: 0.6719146370887756\n",
      "epoch: 5, batch: 16, loss: 0.8136696815490723\n",
      "epoch: 5, batch: 17, loss: 0.6992309093475342\n",
      "epoch: 5, batch: 18, loss: 0.7555497884750366\n",
      "epoch: 5, batch: 19, loss: 0.6418251395225525\n",
      "epoch: 5, batch: 20, loss: 0.8056502938270569\n",
      "epoch: 5, batch: 21, loss: 0.9185928702354431\n",
      "epoch: 5, batch: 22, loss: 0.6762160062789917\n",
      "epoch: 5, batch: 23, loss: 0.84654301404953\n",
      "epoch: 5, batch: 24, loss: 0.6853007078170776\n",
      "epoch: 5, batch: 25, loss: 0.8794710636138916\n",
      "epoch: 5, batch: 26, loss: 0.6820786595344543\n",
      "epoch: 5, batch: 27, loss: 0.8173299431800842\n",
      "epoch: 5, batch: 28, loss: 0.5998481512069702\n",
      "epoch: 5, batch: 29, loss: 0.7299671769142151\n",
      "epoch: 5, batch: 30, loss: 0.9127522110939026\n",
      "epoch: 5, batch: 31, loss: 0.8107626438140869\n",
      "epoch: 5, batch: 32, loss: 0.6525347828865051\n",
      "epoch: 5, batch: 33, loss: 0.6062251329421997\n",
      "epoch: 5, batch: 34, loss: 0.7720214128494263\n",
      "epoch: 5, batch: 35, loss: 0.6520843505859375\n",
      "epoch: 5, batch: 36, loss: 0.7384954690933228\n",
      "epoch: 5, batch: 37, loss: 0.7247899174690247\n",
      "epoch: 5, batch: 38, loss: 0.9064661860466003\n",
      "epoch: 5, batch: 39, loss: 0.7930519580841064\n",
      "epoch: 5, batch: 40, loss: 0.7064560651779175\n",
      "epoch: 5, batch: 41, loss: 0.5891755819320679\n",
      "epoch: 5, batch: 42, loss: 0.8021522760391235\n",
      "epoch: 5, batch: 43, loss: 0.5385560393333435\n",
      "epoch: 5, batch: 44, loss: 0.843989372253418\n",
      "epoch: 5, batch: 45, loss: 0.5120317935943604\n",
      "epoch: 5, batch: 46, loss: 0.7151052951812744\n",
      "epoch: 5, batch: 47, loss: 0.9222289323806763\n",
      "epoch: 5, batch: 48, loss: 0.7754251956939697\n",
      "epoch: 5, batch: 49, loss: 0.6286612153053284\n",
      "epoch: 5, batch: 50, loss: 0.6355070471763611\n",
      "epoch: 5, batch: 51, loss: 0.721379280090332\n",
      "epoch: 5, batch: 52, loss: 0.648216962814331\n",
      "epoch: 5, batch: 53, loss: 0.5316072106361389\n",
      "epoch: 5, batch: 54, loss: 0.7643319964408875\n",
      "epoch: 5, batch: 55, loss: 0.821466326713562\n",
      "epoch: 5, batch: 56, loss: 0.6805381178855896\n",
      "epoch: 5, batch: 57, loss: 0.7519366145133972\n",
      "epoch: 5, batch: 58, loss: 0.6831573843955994\n",
      "epoch: 5, batch: 59, loss: 0.8822072744369507\n",
      "epoch: 5, batch: 60, loss: 0.6836041212081909\n",
      "epoch: 5, batch: 61, loss: 0.7190917134284973\n",
      "epoch: 5, batch: 62, loss: 0.670015275478363\n",
      "epoch: 5, batch: 63, loss: 0.590568482875824\n",
      "epoch: 5, batch: 64, loss: 0.7234783172607422\n",
      "epoch: 5, batch: 65, loss: 0.5504650473594666\n",
      "epoch: 5, batch: 66, loss: 0.9041720032691956\n",
      "epoch: 5, batch: 67, loss: 0.6014417409896851\n",
      "epoch: 5, batch: 68, loss: 0.6911370158195496\n",
      "epoch: 5, batch: 69, loss: 0.7299057245254517\n",
      "epoch: 5, batch: 70, loss: 0.6106848120689392\n",
      "epoch: 5, batch: 71, loss: 0.7403305172920227\n",
      "epoch: 5, batch: 72, loss: 0.6473730206489563\n",
      "epoch: 5, batch: 73, loss: 0.6077211499214172\n",
      "epoch: 5, batch: 74, loss: 0.6655910611152649\n",
      "epoch: 5, batch: 75, loss: 0.7296581268310547\n",
      "epoch: 5, batch: 76, loss: 0.6914002299308777\n",
      "epoch: 5, batch: 77, loss: 0.7219449877738953\n",
      "epoch: 5, batch: 78, loss: 0.8119139075279236\n",
      "epoch: 5, batch: 79, loss: 0.9535679817199707\n",
      "epoch: 5, batch: 80, loss: 0.6288230419158936\n",
      "epoch: 5, batch: 81, loss: 0.9555182456970215\n",
      "epoch: 5, batch: 82, loss: 0.8128781914710999\n",
      "epoch: 5, batch: 83, loss: 0.7283939719200134\n",
      "epoch: 5, batch: 84, loss: 0.7576598525047302\n",
      "epoch: 5, batch: 85, loss: 0.970036506652832\n",
      "epoch: 5, batch: 86, loss: 0.7207821607589722\n",
      "epoch: 5, batch: 87, loss: 0.7712216973304749\n",
      "epoch: 5, batch: 88, loss: 0.7103486061096191\n",
      "epoch: 5, batch: 89, loss: 0.5427482724189758\n",
      "epoch: 5, batch: 90, loss: 0.801618218421936\n",
      "epoch: 5, batch: 91, loss: 0.8693782091140747\n",
      "epoch: 5, batch: 92, loss: 0.6219000220298767\n",
      "epoch: 5, batch: 93, loss: 0.8426831960678101\n",
      "epoch: 5, batch: 94, loss: 0.6883882880210876\n",
      "epoch: 5, batch: 95, loss: 0.8719996213912964\n",
      "epoch: 5, batch: 96, loss: 0.516994297504425\n",
      "epoch: 5, batch: 97, loss: 0.9064913392066956\n",
      "epoch: 5, batch: 98, loss: 1.0765140056610107\n",
      "epoch: 5, batch: 99, loss: 0.9822465181350708\n",
      "epoch: 5, batch: 100, loss: 0.9313021302223206\n",
      "epoch: 5, batch: 101, loss: 0.628749430179596\n",
      "epoch: 5, batch: 102, loss: 0.8023545145988464\n",
      "epoch: 5, batch: 103, loss: 0.7911975979804993\n",
      "epoch: 5, batch: 104, loss: 0.6064274311065674\n",
      "epoch: 5, batch: 105, loss: 0.9974876046180725\n",
      "epoch: 5, batch: 106, loss: 0.6222842931747437\n",
      "epoch: 5, batch: 107, loss: 0.8042387962341309\n",
      "epoch: 5, batch: 108, loss: 0.8404797911643982\n",
      "epoch: 5, batch: 109, loss: 0.8607769012451172\n",
      "epoch: 5, batch: 110, loss: 0.6851503252983093\n",
      "epoch: 5, batch: 111, loss: 0.6094741225242615\n",
      "epoch: 5, batch: 112, loss: 0.7186279892921448\n",
      "epoch: 5, batch: 113, loss: 0.7308458089828491\n",
      "epoch: 5, batch: 114, loss: 0.6744856238365173\n",
      "epoch: 5, batch: 115, loss: 0.7131698131561279\n",
      "epoch: 5, batch: 116, loss: 0.5137885808944702\n",
      "epoch: 5, batch: 117, loss: 0.9177966713905334\n",
      "epoch: 5, batch: 118, loss: 0.7306666374206543\n",
      "epoch: 5, batch: 119, loss: 0.8373615145683289\n",
      "epoch: 5, batch: 120, loss: 0.6373583674430847\n",
      "epoch: 5, batch: 121, loss: 0.7810797691345215\n",
      "epoch: 5, batch: 122, loss: 0.6815573573112488\n",
      "epoch: 5, batch: 123, loss: 0.6009662747383118\n",
      "epoch: 5, batch: 124, loss: 0.7456797361373901\n",
      "epoch: 5, batch: 125, loss: 0.5158727765083313\n",
      "epoch: 5, batch: 126, loss: 0.6685760021209717\n",
      "epoch: 5, batch: 127, loss: 0.7730758786201477\n",
      "epoch: 5, batch: 128, loss: 0.9485777616500854\n",
      "epoch: 5, batch: 129, loss: 0.6038044691085815\n",
      "epoch: 5, batch: 130, loss: 0.7638323307037354\n",
      "epoch: 5, batch: 131, loss: 0.829541802406311\n",
      "epoch: 5, batch: 132, loss: 0.7138679027557373\n",
      "epoch: 5, batch: 133, loss: 0.6177722215652466\n",
      "epoch: 5, batch: 134, loss: 0.5543338656425476\n",
      "epoch: 5, batch: 135, loss: 0.6917111873626709\n",
      "epoch: 5, batch: 136, loss: 0.8044227957725525\n",
      "epoch: 5, batch: 137, loss: 0.7839281558990479\n",
      "epoch: 5, batch: 138, loss: 0.5945628881454468\n",
      "epoch: 5, batch: 139, loss: 0.7191767692565918\n",
      "epoch: 5, batch: 140, loss: 0.7173710465431213\n",
      "epoch: 5, batch: 141, loss: 0.8124120235443115\n",
      "epoch: 5, batch: 142, loss: 0.7982179522514343\n",
      "epoch: 5, batch: 143, loss: 0.6706701517105103\n",
      "epoch: 5, batch: 144, loss: 0.7351543307304382\n",
      "epoch: 5, batch: 145, loss: 0.6280772686004639\n",
      "epoch: 5, batch: 146, loss: 0.7281983494758606\n",
      "epoch: 5, batch: 147, loss: 0.8057321310043335\n",
      "epoch: 5, batch: 148, loss: 0.9524375200271606\n",
      "epoch: 5, batch: 149, loss: 0.873717725276947\n",
      "epoch: 5, batch: 150, loss: 0.8662671446800232\n",
      "epoch: 5, batch: 151, loss: 0.697300910949707\n",
      "epoch: 5, batch: 152, loss: 0.6653024554252625\n",
      "epoch: 5, batch: 153, loss: 0.9198484420776367\n",
      "epoch: 5, batch: 154, loss: 0.6672894954681396\n",
      "epoch: 5, batch: 155, loss: 0.9397636651992798\n",
      "epoch: 5, batch: 156, loss: 0.777858316898346\n",
      "epoch: 5, batch: 157, loss: 0.8510276079177856\n",
      "epoch: 5, batch: 158, loss: 0.6273497939109802\n",
      "epoch: 5, batch: 159, loss: 0.5871734619140625\n",
      "epoch: 5, batch: 160, loss: 0.9070317149162292\n",
      "epoch: 5, batch: 161, loss: 0.7444876432418823\n",
      "epoch: 5, batch: 162, loss: 0.6212976574897766\n",
      "epoch: 5, batch: 163, loss: 0.8444110155105591\n",
      "epoch: 5, batch: 164, loss: 0.7044816017150879\n",
      "epoch: 5, batch: 165, loss: 0.8468834161758423\n",
      "epoch: 5, batch: 166, loss: 0.7360870838165283\n",
      "epoch: 5, batch: 167, loss: 0.690553605556488\n",
      "epoch: 5, batch: 168, loss: 0.680061936378479\n",
      "epoch: 5, batch: 169, loss: 0.6946238279342651\n",
      "epoch: 5, batch: 170, loss: 0.6298182606697083\n",
      "epoch: 5, batch: 171, loss: 0.6857377290725708\n",
      "epoch: 5, batch: 172, loss: 0.8315081596374512\n",
      "epoch: 5, batch: 173, loss: 0.8318291902542114\n",
      "epoch: 5, batch: 174, loss: 0.8415399193763733\n",
      "epoch: 5, batch: 175, loss: 0.812053382396698\n",
      "epoch: 5, batch: 176, loss: 0.8008331656455994\n",
      "epoch: 5, batch: 177, loss: 0.8255282640457153\n",
      "epoch: 5, batch: 178, loss: 0.5983093976974487\n",
      "epoch: 5, batch: 179, loss: 0.5807046294212341\n",
      "epoch: 5, batch: 180, loss: 0.678587794303894\n",
      "epoch: 5, batch: 181, loss: 0.7468734383583069\n",
      "epoch: 5, batch: 182, loss: 0.754749059677124\n",
      "epoch: 5, batch: 183, loss: 1.038865327835083\n",
      "epoch: 5, batch: 184, loss: 0.7318819761276245\n",
      "epoch: 5, batch: 185, loss: 0.667880654335022\n",
      "epoch: 5, batch: 186, loss: 0.5272048115730286\n",
      "epoch: 5, batch: 187, loss: 0.7301163673400879\n",
      "epoch: 5, batch: 188, loss: 0.654800295829773\n",
      "epoch: 5, batch: 189, loss: 0.6943004131317139\n",
      "epoch: 5, batch: 190, loss: 0.7304314374923706\n",
      "epoch: 5, batch: 191, loss: 0.6514360904693604\n",
      "epoch: 5, batch: 192, loss: 0.6761248707771301\n",
      "epoch: 5, batch: 193, loss: 0.6098388433456421\n",
      "epoch: 5, batch: 194, loss: 0.6456255912780762\n",
      "epoch: 5, batch: 195, loss: 0.6117607951164246\n",
      "epoch: 5, batch: 196, loss: 0.713808000087738\n",
      "epoch: 5, batch: 197, loss: 0.9405601024627686\n",
      "epoch: 5, batch: 198, loss: 0.680286169052124\n",
      "epoch: 5, batch: 199, loss: 0.7295867800712585\n",
      "epoch: 5, batch: 200, loss: 0.883690357208252\n",
      "epoch: 5, batch: 201, loss: 0.902379035949707\n",
      "epoch: 5, batch: 202, loss: 0.5855843424797058\n",
      "epoch: 5, batch: 203, loss: 0.6738770604133606\n",
      "epoch: 5, batch: 204, loss: 0.6116856932640076\n",
      "epoch: 5, batch: 205, loss: 0.8800716996192932\n",
      "epoch: 5, batch: 206, loss: 0.6474094390869141\n",
      "epoch: 5, batch: 207, loss: 0.8370970487594604\n",
      "epoch: 5, batch: 208, loss: 1.1746159791946411\n",
      "epoch: 5, batch: 209, loss: 0.7702613472938538\n",
      "epoch: 5, batch: 210, loss: 0.8514792919158936\n",
      "epoch: 5, batch: 211, loss: 0.7825291752815247\n",
      "epoch: 5, batch: 212, loss: 0.5502138733863831\n",
      "epoch: 5, batch: 213, loss: 0.7480387091636658\n",
      "epoch: 5, batch: 214, loss: 0.6311070919036865\n",
      "epoch: 5, batch: 215, loss: 0.7580419778823853\n",
      "epoch: 5, batch: 216, loss: 0.663518488407135\n",
      "epoch: 5, batch: 217, loss: 0.579919695854187\n",
      "epoch: 5, batch: 218, loss: 0.759143054485321\n",
      "epoch: 5, batch: 219, loss: 0.7121697068214417\n",
      "epoch: 5, batch: 220, loss: 0.8245319724082947\n",
      "epoch: 5, batch: 221, loss: 0.8805504441261292\n",
      "epoch: 5, batch: 222, loss: 0.8724932074546814\n",
      "epoch: 5, batch: 223, loss: 0.7040514349937439\n",
      "epoch: 5, batch: 224, loss: 0.8692271113395691\n",
      "epoch: 5, batch: 225, loss: 0.6146794557571411\n",
      "epoch: 5, batch: 226, loss: 0.8605949282646179\n",
      "epoch: 5, batch: 227, loss: 0.7232933044433594\n",
      "epoch: 5, batch: 228, loss: 0.7044529914855957\n",
      "epoch: 5, batch: 229, loss: 0.732656717300415\n",
      "epoch: 5, batch: 230, loss: 0.5689740777015686\n",
      "epoch: 5, batch: 231, loss: 0.8177306652069092\n",
      "epoch: 5, batch: 232, loss: 0.9611135721206665\n",
      "epoch: 5, batch: 233, loss: 0.7896496653556824\n",
      "epoch: 5, batch: 234, loss: 0.6358542442321777\n",
      "epoch: 5, batch: 235, loss: 0.6684583425521851\n",
      "epoch: 5, batch: 236, loss: 0.5881900787353516\n",
      "epoch: 5, batch: 237, loss: 0.7764430046081543\n",
      "epoch: 5, batch: 238, loss: 0.6996123790740967\n",
      "epoch: 5, batch: 239, loss: 0.5752596855163574\n",
      "epoch: 5, batch: 240, loss: 0.7010667324066162\n",
      "epoch: 5, batch: 241, loss: 0.7607743740081787\n",
      "epoch: 5, batch: 242, loss: 0.6257161498069763\n",
      "epoch: 5, batch: 243, loss: 0.8191331624984741\n",
      "epoch: 5, batch: 244, loss: 0.841245174407959\n",
      "epoch: 5, batch: 245, loss: 0.7388533353805542\n",
      "epoch: 5, batch: 246, loss: 0.9156427979469299\n",
      "epoch: 5, batch: 247, loss: 0.777441143989563\n",
      "epoch: 5, batch: 248, loss: 0.7919976711273193\n",
      "epoch: 5, batch: 249, loss: 0.8116869926452637\n",
      "epoch: 5, batch: 250, loss: 0.6112025380134583\n",
      "epoch: 5, batch: 251, loss: 0.7025323510169983\n",
      "epoch: 5, batch: 252, loss: 0.592196524143219\n",
      "epoch: 5, batch: 253, loss: 0.6763138175010681\n",
      "epoch: 5, batch: 254, loss: 0.6708487868309021\n",
      "epoch: 5, batch: 255, loss: 0.474689781665802\n",
      "epoch: 5, batch: 256, loss: 1.0563212633132935\n",
      "epoch: 5, batch: 257, loss: 0.7502326965332031\n",
      "epoch: 5, batch: 258, loss: 0.798382043838501\n",
      "epoch: 5, batch: 259, loss: 0.9641605615615845\n",
      "epoch: 5, batch: 260, loss: 0.7160875201225281\n",
      "epoch: 5, batch: 261, loss: 0.6949316263198853\n",
      "epoch: 5, batch: 262, loss: 0.812293529510498\n",
      "epoch: 5, batch: 263, loss: 0.5958710312843323\n",
      "epoch: 5, batch: 264, loss: 0.7270621657371521\n",
      "epoch: 5, batch: 265, loss: 0.8719814419746399\n",
      "epoch: 5, batch: 266, loss: 0.7315983772277832\n",
      "epoch: 5, batch: 267, loss: 0.6066009998321533\n",
      "epoch: 5, batch: 268, loss: 0.6189805269241333\n",
      "epoch: 5, batch: 269, loss: 0.9166430830955505\n",
      "epoch: 5, batch: 270, loss: 0.7684884667396545\n",
      "epoch: 5, batch: 271, loss: 0.7331812977790833\n",
      "epoch: 5, batch: 272, loss: 0.6507750749588013\n",
      "epoch: 5, batch: 273, loss: 0.8024581670761108\n",
      "epoch: 5, batch: 274, loss: 0.7781942486763\n",
      "epoch: 5, batch: 275, loss: 0.8094120621681213\n",
      "epoch: 5, batch: 276, loss: 0.8213346004486084\n",
      "epoch: 5, batch: 277, loss: 0.7506902813911438\n",
      "epoch: 5, batch: 278, loss: 0.6332178711891174\n",
      "epoch: 5, batch: 279, loss: 0.6649378538131714\n",
      "epoch: 5, batch: 280, loss: 0.7207112312316895\n",
      "epoch: 5, batch: 281, loss: 0.7991005778312683\n",
      "epoch: 5, batch: 282, loss: 0.7459949254989624\n",
      "epoch: 5, batch: 283, loss: 1.0348557233810425\n",
      "epoch: 5, batch: 284, loss: 0.7564473748207092\n",
      "epoch: 5, batch: 285, loss: 0.48091045022010803\n",
      "epoch: 5, batch: 286, loss: 0.8200767636299133\n",
      "epoch: 5, batch: 287, loss: 0.8559592962265015\n",
      "epoch: 5, batch: 288, loss: 0.4803783595561981\n",
      "epoch: 5, batch: 289, loss: 0.6047099232673645\n",
      "epoch: 5, batch: 290, loss: 0.9709405899047852\n",
      "epoch: 5, batch: 291, loss: 0.8192887902259827\n",
      "epoch: 5, batch: 292, loss: 0.6113536953926086\n",
      "epoch: 5, batch: 293, loss: 0.5103474855422974\n",
      "epoch: 5, batch: 294, loss: 0.6498804092407227\n",
      "epoch: 5, batch: 295, loss: 0.9997379779815674\n",
      "epoch: 5, batch: 296, loss: 0.6814863085746765\n",
      "epoch: 5, batch: 297, loss: 0.7767449021339417\n",
      "epoch: 5, batch: 298, loss: 0.8185637593269348\n",
      "epoch: 5, batch: 299, loss: 0.6045121550559998\n",
      "epoch: 5, batch: 300, loss: 0.6444830894470215\n",
      "epoch: 5, batch: 301, loss: 0.7949989438056946\n",
      "epoch: 5, batch: 302, loss: 0.6479654908180237\n",
      "epoch: 5, batch: 303, loss: 0.9088919162750244\n",
      "epoch: 5, batch: 304, loss: 0.7305377125740051\n",
      "epoch: 5, batch: 305, loss: 0.8953237533569336\n",
      "epoch: 5, batch: 306, loss: 0.5944316983222961\n",
      "epoch: 5, batch: 307, loss: 0.9338099956512451\n",
      "epoch: 5, batch: 308, loss: 0.7397487759590149\n",
      "epoch: 5, batch: 309, loss: 0.729675829410553\n",
      "epoch: 5, batch: 310, loss: 0.682108461856842\n",
      "epoch: 5, batch: 311, loss: 0.7842068672180176\n",
      "epoch: 5, batch: 312, loss: 0.6568050384521484\n",
      "epoch: 5, batch: 313, loss: 0.698222815990448\n",
      "epoch: 5, batch: 314, loss: 0.9275751709938049\n",
      "epoch: 5, batch: 315, loss: 0.6448361277580261\n",
      "epoch: 5, batch: 316, loss: 0.9832403659820557\n",
      "epoch: 5, batch: 317, loss: 0.8796626925468445\n",
      "epoch: 5, batch: 318, loss: 0.7059917449951172\n",
      "epoch: 5, batch: 319, loss: 0.4567912220954895\n",
      "epoch: 5, batch: 320, loss: 0.5137763023376465\n",
      "epoch: 5, batch: 321, loss: 0.7678574919700623\n",
      "epoch: 5, batch: 322, loss: 0.6734110713005066\n",
      "epoch: 5, batch: 323, loss: 0.8278787136077881\n",
      "epoch: 5, batch: 324, loss: 0.978398323059082\n",
      "epoch: 5, batch: 325, loss: 0.5441104173660278\n",
      "epoch: 5, batch: 326, loss: 0.7615284323692322\n",
      "epoch: 5, batch: 327, loss: 0.6551573276519775\n",
      "epoch: 5, batch: 328, loss: 0.7797011137008667\n",
      "epoch: 5, batch: 329, loss: 0.5191958546638489\n",
      "epoch: 5, batch: 330, loss: 0.7155543565750122\n",
      "epoch: 5, batch: 331, loss: 0.7781749963760376\n",
      "epoch: 5, batch: 332, loss: 0.9551218748092651\n",
      "epoch: 5, batch: 333, loss: 0.6427181363105774\n",
      "epoch: 5, batch: 334, loss: 0.6420441269874573\n",
      "epoch: 5, batch: 335, loss: 0.7606296539306641\n",
      "epoch: 5, batch: 336, loss: 0.7435909509658813\n",
      "epoch: 5, batch: 337, loss: 0.7045086026191711\n",
      "epoch: 5, batch: 338, loss: 0.8234308958053589\n",
      "epoch: 5, batch: 339, loss: 0.5929692387580872\n",
      "epoch: 5, batch: 340, loss: 1.023938536643982\n",
      "epoch: 5, batch: 341, loss: 0.6739737391471863\n",
      "epoch: 5, batch: 342, loss: 0.6902559399604797\n",
      "epoch: 5, batch: 343, loss: 0.5524411201477051\n",
      "epoch: 5, batch: 344, loss: 0.7345924377441406\n",
      "epoch: 5, batch: 345, loss: 0.8313649892807007\n",
      "epoch: 5, batch: 346, loss: 0.7313446402549744\n",
      "epoch: 5, batch: 347, loss: 0.7847667932510376\n",
      "epoch: 5, batch: 348, loss: 0.7097446322441101\n",
      "epoch: 5, batch: 349, loss: 0.9934635162353516\n",
      "epoch: 5, batch: 350, loss: 0.9583909511566162\n",
      "epoch: 5, batch: 351, loss: 0.7400742769241333\n",
      "epoch: 5, batch: 352, loss: 0.6036995649337769\n",
      "epoch: 5, batch: 353, loss: 0.6322340369224548\n",
      "epoch: 5, batch: 354, loss: 0.85835862159729\n",
      "epoch: 5, batch: 355, loss: 0.7658772468566895\n",
      "epoch: 5, batch: 356, loss: 0.7408661842346191\n",
      "epoch: 5, batch: 357, loss: 0.6771177649497986\n",
      "epoch: 5, batch: 358, loss: 0.6665156483650208\n",
      "epoch: 5, batch: 359, loss: 0.7032604217529297\n",
      "epoch: 5, batch: 360, loss: 0.9980493783950806\n",
      "epoch: 5, batch: 361, loss: 0.5752459168434143\n",
      "epoch: 5, batch: 362, loss: 0.7923478484153748\n",
      "epoch: 5, batch: 363, loss: 0.6640745997428894\n",
      "epoch: 5, batch: 364, loss: 0.7820024490356445\n",
      "epoch: 5, batch: 365, loss: 1.001823902130127\n",
      "epoch: 5, batch: 366, loss: 0.795601487159729\n",
      "epoch: 5, batch: 367, loss: 0.8039606809616089\n",
      "epoch: 5, batch: 368, loss: 0.7170783877372742\n",
      "epoch: 5, batch: 369, loss: 0.859700620174408\n",
      "epoch: 5, batch: 370, loss: 0.577761709690094\n",
      "epoch: 5, batch: 371, loss: 0.767052173614502\n",
      "epoch: 5, batch: 372, loss: 0.7120501399040222\n",
      "epoch: 5, batch: 373, loss: 0.601148247718811\n",
      "epoch: 5, batch: 374, loss: 0.8032868504524231\n",
      "epoch: 5, batch: 375, loss: 0.636741042137146\n",
      "epoch: 5, batch: 376, loss: 0.7165435552597046\n",
      "epoch: 5, batch: 377, loss: 0.46333616971969604\n",
      "epoch: 5, batch: 378, loss: 0.8068198561668396\n",
      "epoch: 5, batch: 379, loss: 0.6160103678703308\n",
      "epoch: 5, batch: 380, loss: 0.5512818098068237\n",
      "epoch: 5, batch: 381, loss: 0.8590352535247803\n",
      "epoch: 5, batch: 382, loss: 0.4868597686290741\n",
      "epoch: 5, batch: 383, loss: 0.73390793800354\n",
      "epoch: 5, batch: 384, loss: 0.7908492684364319\n",
      "epoch: 5, batch: 385, loss: 0.5982627272605896\n",
      "epoch: 5, batch: 386, loss: 0.7901283502578735\n",
      "epoch: 5, batch: 387, loss: 0.5412003397941589\n",
      "epoch: 5, batch: 388, loss: 0.7096700072288513\n",
      "epoch: 5, batch: 389, loss: 0.643047571182251\n",
      "epoch: 5, batch: 390, loss: 0.848402738571167\n",
      "epoch: 5, batch: 391, loss: 0.8585822582244873\n",
      "epoch: 5, batch: 392, loss: 0.6146666407585144\n",
      "epoch: 5, batch: 393, loss: 0.43819913268089294\n",
      "epoch: 5, batch: 394, loss: 0.6518232822418213\n",
      "epoch: 5, batch: 395, loss: 0.6571153402328491\n",
      "epoch: 5, batch: 396, loss: 0.6480362415313721\n",
      "epoch: 5, batch: 397, loss: 0.7011647820472717\n",
      "epoch: 5, batch: 398, loss: 0.6845972537994385\n",
      "epoch: 5, batch: 399, loss: 0.7745304703712463\n",
      "epoch: 5, batch: 400, loss: 0.855602502822876\n",
      "epoch: 5, batch: 401, loss: 0.8729951977729797\n",
      "epoch: 5, batch: 402, loss: 0.8512557744979858\n",
      "epoch: 5, batch: 403, loss: 0.5652873516082764\n",
      "epoch: 5, batch: 404, loss: 0.6783058047294617\n",
      "epoch: 5, batch: 405, loss: 0.8825127482414246\n",
      "epoch: 5, batch: 406, loss: 0.45049887895584106\n",
      "epoch: 5, batch: 407, loss: 0.8734615445137024\n",
      "epoch: 5, batch: 408, loss: 0.5984256267547607\n",
      "epoch: 5, batch: 409, loss: 0.9146330952644348\n",
      "epoch: 5, batch: 410, loss: 0.7009968161582947\n",
      "epoch: 5, batch: 411, loss: 0.7736347317695618\n",
      "epoch: 5, batch: 412, loss: 0.6601044535636902\n",
      "epoch: 5, batch: 413, loss: 1.0615836381912231\n",
      "epoch: 5, batch: 414, loss: 0.6630877256393433\n",
      "epoch: 5, batch: 415, loss: 0.7360432147979736\n",
      "epoch: 5, batch: 416, loss: 0.7128685712814331\n",
      "epoch: 5, batch: 417, loss: 0.8768457770347595\n",
      "epoch: 5, batch: 418, loss: 0.668667733669281\n",
      "epoch: 5, batch: 419, loss: 0.7967593669891357\n",
      "epoch: 5, batch: 420, loss: 0.5342912673950195\n",
      "epoch: 5, batch: 421, loss: 0.7947420477867126\n",
      "epoch: 5, batch: 422, loss: 0.9040219783782959\n",
      "epoch: 5, batch: 423, loss: 0.5785298347473145\n",
      "epoch: 5, batch: 424, loss: 0.5212652683258057\n",
      "epoch: 5, batch: 425, loss: 0.8289877772331238\n",
      "epoch: 5, batch: 426, loss: 0.707977831363678\n",
      "epoch: 5, batch: 427, loss: 0.743754506111145\n",
      "epoch: 5, batch: 428, loss: 0.9176435470581055\n",
      "epoch: 5, batch: 429, loss: 0.851901113986969\n",
      "epoch: 5, batch: 430, loss: 0.7823419570922852\n",
      "epoch: 5, batch: 431, loss: 0.8072285652160645\n",
      "epoch: 5, batch: 432, loss: 0.6924933791160583\n",
      "epoch: 5, batch: 433, loss: 0.6364205479621887\n",
      "epoch: 5, batch: 434, loss: 0.7042694687843323\n",
      "epoch: 5, batch: 435, loss: 1.0852612257003784\n",
      "epoch: 5, batch: 436, loss: 0.6056509613990784\n",
      "epoch: 5, batch: 437, loss: 0.689978837966919\n",
      "epoch: 5, batch: 438, loss: 0.67857825756073\n",
      "epoch: 5, batch: 439, loss: 0.6835275888442993\n",
      "epoch: 5, batch: 440, loss: 0.6477362513542175\n",
      "epoch: 5, batch: 441, loss: 0.9435979723930359\n",
      "epoch: 5, batch: 442, loss: 0.8382524251937866\n",
      "epoch: 5, batch: 443, loss: 0.7720929384231567\n",
      "epoch: 5, batch: 444, loss: 0.786219596862793\n",
      "epoch: 5, batch: 445, loss: 0.6417866349220276\n",
      "epoch: 5, batch: 446, loss: 0.6756687760353088\n",
      "epoch: 5, batch: 447, loss: 0.7504340410232544\n",
      "epoch: 5, batch: 448, loss: 0.7630964517593384\n",
      "epoch: 5, batch: 449, loss: 0.7963023781776428\n",
      "epoch: 5, batch: 450, loss: 0.6313478946685791\n",
      "epoch: 5, batch: 451, loss: 0.8515018224716187\n",
      "epoch: 5, batch: 452, loss: 0.6902993321418762\n",
      "epoch: 5, batch: 453, loss: 0.7409412860870361\n",
      "epoch: 5, batch: 454, loss: 0.7570792436599731\n",
      "epoch: 5, batch: 455, loss: 0.5898085236549377\n",
      "epoch: 5, batch: 456, loss: 0.7808423638343811\n",
      "epoch: 5, batch: 457, loss: 0.7110573053359985\n",
      "epoch: 5, batch: 458, loss: 0.6582881808280945\n",
      "epoch: 5, batch: 459, loss: 0.6914191246032715\n",
      "epoch: 5, batch: 460, loss: 0.66730797290802\n",
      "epoch: 5, batch: 461, loss: 0.8853934407234192\n",
      "epoch: 5, batch: 462, loss: 0.6367543339729309\n",
      "epoch: 5, batch: 463, loss: 0.4974093735218048\n",
      "epoch: 5, batch: 464, loss: 1.0526056289672852\n",
      "epoch: 5, batch: 465, loss: 0.8966209292411804\n",
      "epoch: 5, batch: 466, loss: 0.5953992009162903\n",
      "epoch: 5, batch: 467, loss: 0.7671560645103455\n",
      "epoch: 5, batch: 468, loss: 0.868492066860199\n",
      "epoch: 5, batch: 469, loss: 0.7047502398490906\n",
      "epoch: 5, batch: 470, loss: 0.6918948292732239\n",
      "epoch: 5, batch: 471, loss: 0.6654234528541565\n",
      "epoch: 5, batch: 472, loss: 0.9850575923919678\n",
      "epoch: 5, batch: 473, loss: 0.6055258512496948\n",
      "epoch: 5, batch: 474, loss: 0.6999492645263672\n",
      "epoch: 5, batch: 475, loss: 0.725735604763031\n",
      "epoch: 5, batch: 476, loss: 1.2727491855621338\n",
      "epoch: 5, batch: 477, loss: 0.7267518043518066\n",
      "epoch: 5, batch: 478, loss: 0.6403639316558838\n",
      "epoch: 5, batch: 479, loss: 0.6912103891372681\n",
      "epoch: 5, batch: 480, loss: 0.5916007161140442\n",
      "epoch: 5, batch: 481, loss: 0.8228493332862854\n",
      "epoch: 5, batch: 482, loss: 0.9874608516693115\n",
      "epoch: 5, batch: 483, loss: 0.7872940301895142\n",
      "epoch: 5, batch: 484, loss: 0.7803261280059814\n",
      "epoch: 5, batch: 485, loss: 0.9469282627105713\n",
      "epoch: 5, batch: 486, loss: 0.806825578212738\n",
      "epoch: 5, batch: 487, loss: 0.5034980177879333\n",
      "epoch: 5, batch: 488, loss: 0.5542832016944885\n",
      "epoch: 5, batch: 489, loss: 0.6503844261169434\n",
      "epoch: 5, batch: 490, loss: 0.9228534698486328\n",
      "epoch: 5, batch: 491, loss: 0.5474039316177368\n",
      "epoch: 5, batch: 492, loss: 0.6997067332267761\n",
      "epoch: 5, batch: 493, loss: 0.7028214931488037\n",
      "epoch: 5, batch: 494, loss: 0.8701731562614441\n",
      "epoch: 5, batch: 495, loss: 0.7435781359672546\n",
      "epoch: 5, batch: 496, loss: 0.8354235887527466\n",
      "epoch: 5, batch: 497, loss: 0.7600377798080444\n",
      "epoch: 5, batch: 498, loss: 0.6114999055862427\n",
      "epoch: 5, batch: 499, loss: 0.5129084587097168\n",
      "epoch: 5, batch: 500, loss: 0.7480002641677856\n",
      "epoch: 5, batch: 501, loss: 0.7644469141960144\n",
      "epoch: 5, batch: 502, loss: 0.7931222915649414\n",
      "epoch: 5, batch: 503, loss: 0.6830557584762573\n",
      "epoch: 5, batch: 504, loss: 0.772952675819397\n",
      "epoch: 5, batch: 505, loss: 0.7158185243606567\n",
      "epoch: 5, batch: 506, loss: 0.7544458508491516\n",
      "epoch: 5, batch: 507, loss: 0.7598270773887634\n",
      "epoch: 5, batch: 508, loss: 0.8269060850143433\n",
      "epoch: 5, batch: 509, loss: 0.7820904850959778\n",
      "epoch: 5, batch: 510, loss: 0.7093605995178223\n",
      "epoch: 5, batch: 511, loss: 0.6276506781578064\n",
      "epoch: 5, batch: 512, loss: 0.5811004638671875\n",
      "epoch: 5, batch: 513, loss: 0.6742299199104309\n",
      "epoch: 5, batch: 514, loss: 0.5727834701538086\n",
      "epoch: 5, batch: 515, loss: 0.6968319416046143\n",
      "epoch: 5, batch: 516, loss: 0.7638511657714844\n",
      "epoch: 5, batch: 517, loss: 0.7273664474487305\n",
      "epoch: 5, batch: 518, loss: 0.6301366686820984\n",
      "epoch: 5, batch: 519, loss: 0.748653769493103\n",
      "epoch: 5, batch: 520, loss: 0.6892606616020203\n",
      "epoch: 5, batch: 521, loss: 0.7639580965042114\n",
      "epoch: 5, batch: 522, loss: 0.8473647832870483\n",
      "epoch: 5, batch: 523, loss: 0.5380879640579224\n",
      "epoch: 5, batch: 524, loss: 0.7119216918945312\n",
      "epoch: 5, batch: 525, loss: 0.9224933981895447\n",
      "epoch: 5, batch: 526, loss: 0.8876532316207886\n",
      "epoch: 5, batch: 527, loss: 0.7179165482521057\n",
      "epoch: 5, batch: 528, loss: 0.8021868467330933\n",
      "epoch: 5, batch: 529, loss: 0.6952515840530396\n",
      "epoch: 5, batch: 530, loss: 0.8580976724624634\n",
      "epoch: 5, batch: 531, loss: 0.769711971282959\n",
      "epoch: 5, batch: 532, loss: 0.7072624564170837\n",
      "epoch: 5, batch: 533, loss: 0.6914854645729065\n",
      "epoch: 5, batch: 534, loss: 0.7100952863693237\n",
      "epoch: 5, batch: 535, loss: 0.6771834492683411\n",
      "epoch: 5, batch: 536, loss: 0.7777249813079834\n",
      "epoch: 5, batch: 537, loss: 0.6544665098190308\n",
      "epoch: 5, batch: 538, loss: 0.608648955821991\n",
      "epoch: 5, batch: 539, loss: 0.8865489959716797\n",
      "epoch: 5, batch: 540, loss: 0.7455642223358154\n",
      "epoch: 5, batch: 541, loss: 0.8156735897064209\n",
      "epoch: 5, batch: 542, loss: 0.6788467764854431\n",
      "epoch: 5, batch: 543, loss: 0.5333876013755798\n",
      "epoch: 5, batch: 544, loss: 0.5780988335609436\n",
      "epoch: 5, batch: 545, loss: 0.6821541786193848\n",
      "epoch: 5, batch: 546, loss: 0.6045336723327637\n",
      "epoch: 5, batch: 547, loss: 0.6933553218841553\n",
      "epoch: 5, batch: 548, loss: 0.7560317516326904\n",
      "epoch: 5, batch: 549, loss: 0.6094260811805725\n",
      "epoch: 5, batch: 550, loss: 0.6497083902359009\n",
      "epoch: 5, batch: 551, loss: 0.8111218214035034\n",
      "epoch: 5, batch: 552, loss: 0.7236999869346619\n",
      "epoch: 5, batch: 553, loss: 0.5300143361091614\n",
      "epoch: 5, batch: 554, loss: 0.718485414981842\n",
      "epoch: 5, batch: 555, loss: 0.6079707145690918\n",
      "epoch: 5, batch: 556, loss: 0.9197690486907959\n",
      "epoch: 5, batch: 557, loss: 0.6764652729034424\n",
      "epoch: 5, batch: 558, loss: 0.7103610038757324\n",
      "epoch: 5, batch: 559, loss: 0.7212619185447693\n",
      "epoch: 5, batch: 560, loss: 0.7827205657958984\n",
      "epoch: 5, batch: 561, loss: 0.8856798410415649\n",
      "epoch: 5, batch: 562, loss: 0.9632262587547302\n",
      "epoch: 5, batch: 563, loss: 0.5346456170082092\n",
      "epoch: 5, batch: 564, loss: 0.715232253074646\n",
      "epoch: 5, batch: 565, loss: 0.794637143611908\n",
      "epoch: 5, batch: 566, loss: 0.8882696032524109\n",
      "epoch: 5, batch: 567, loss: 0.6648094058036804\n",
      "epoch: 5, batch: 568, loss: 0.5612583756446838\n",
      "epoch: 5, batch: 569, loss: 0.7823113203048706\n",
      "epoch: 5, batch: 570, loss: 0.7009203433990479\n",
      "epoch: 5, batch: 571, loss: 0.9487666487693787\n",
      "epoch: 5, batch: 572, loss: 0.6682881712913513\n",
      "epoch: 5, batch: 573, loss: 1.0492973327636719\n",
      "epoch: 5, batch: 574, loss: 0.5168129801750183\n",
      "epoch: 5, batch: 575, loss: 0.8226922154426575\n",
      "epoch: 5, batch: 576, loss: 0.756158709526062\n",
      "epoch: 5, batch: 577, loss: 0.5339799523353577\n",
      "epoch: 5, batch: 578, loss: 0.5783840417861938\n",
      "epoch: 5, batch: 579, loss: 0.7665906548500061\n",
      "epoch: 5, batch: 580, loss: 0.684169590473175\n",
      "epoch: 5, batch: 581, loss: 0.5939767360687256\n",
      "epoch: 5, batch: 582, loss: 0.5010682344436646\n",
      "epoch: 5, batch: 583, loss: 0.6385676860809326\n",
      "epoch: 5, batch: 584, loss: 1.071432113647461\n",
      "epoch: 5, batch: 585, loss: 0.8563886284828186\n",
      "epoch: 5, batch: 586, loss: 0.6920665502548218\n",
      "epoch: 5, batch: 587, loss: 0.5515955686569214\n",
      "epoch: 5, batch: 588, loss: 0.6866060495376587\n",
      "epoch: 5, batch: 589, loss: 0.7014814615249634\n",
      "epoch: 5, batch: 590, loss: 0.4561326205730438\n",
      "epoch: 5, batch: 591, loss: 0.71617192029953\n",
      "epoch: 5, batch: 592, loss: 0.7003312110900879\n",
      "epoch: 5, batch: 593, loss: 0.6072383522987366\n",
      "epoch: 5, batch: 594, loss: 0.6210962533950806\n",
      "epoch: 5, batch: 595, loss: 0.7917336225509644\n",
      "epoch: 5, batch: 596, loss: 0.8345914483070374\n",
      "epoch: 5, batch: 597, loss: 0.46956223249435425\n",
      "epoch: 5, batch: 598, loss: 0.7307640314102173\n",
      "epoch: 5, batch: 599, loss: 0.7340551018714905\n",
      "epoch: 5, batch: 600, loss: 0.5543949604034424\n",
      "epoch: 5, batch: 601, loss: 0.8147757649421692\n",
      "epoch: 5, batch: 602, loss: 0.7839392423629761\n",
      "epoch: 5, batch: 603, loss: 0.7844992876052856\n",
      "epoch: 5, batch: 604, loss: 0.6024916172027588\n",
      "epoch: 5, batch: 605, loss: 0.5063022971153259\n",
      "epoch: 5, batch: 606, loss: 0.796841561794281\n",
      "epoch: 5, batch: 607, loss: 0.8191123604774475\n",
      "epoch: 5, batch: 608, loss: 0.6576502919197083\n",
      "epoch: 5, batch: 609, loss: 0.8583869934082031\n",
      "epoch: 5, batch: 610, loss: 0.8837839365005493\n",
      "epoch: 5, batch: 611, loss: 0.6160335540771484\n",
      "epoch: 5, batch: 612, loss: 0.6930420994758606\n",
      "epoch: 5, batch: 613, loss: 0.5761218070983887\n",
      "epoch: 5, batch: 614, loss: 0.9058020710945129\n",
      "epoch: 5, batch: 615, loss: 0.8056120872497559\n",
      "epoch: 5, batch: 616, loss: 0.8059155344963074\n",
      "epoch: 5, batch: 617, loss: 0.7954599261283875\n",
      "epoch: 5, batch: 618, loss: 0.7478982210159302\n",
      "epoch: 5, batch: 619, loss: 0.6473191380500793\n",
      "epoch: 5, batch: 620, loss: 0.8168744444847107\n",
      "epoch: 5, batch: 621, loss: 0.9494305849075317\n",
      "epoch: 5, batch: 622, loss: 0.6163610219955444\n",
      "epoch: 5, batch: 623, loss: 0.6699457764625549\n",
      "epoch: 5, batch: 624, loss: 0.750568151473999\n",
      "epoch: 5, batch: 625, loss: 0.437274307012558\n",
      "epoch: 5, batch: 626, loss: 0.6382921934127808\n",
      "epoch: 5, batch: 627, loss: 1.1776427030563354\n",
      "epoch: 5, batch: 628, loss: 0.9230154156684875\n",
      "epoch: 5, batch: 629, loss: 0.7886653542518616\n",
      "epoch: 5, batch: 630, loss: 0.5597834587097168\n",
      "epoch: 5, batch: 631, loss: 0.6441352367401123\n",
      "epoch: 5, batch: 632, loss: 0.6511209011077881\n",
      "epoch: 5, batch: 633, loss: 0.8630566596984863\n",
      "epoch: 5, batch: 634, loss: 0.6258995532989502\n",
      "epoch: 5, batch: 635, loss: 0.5857340097427368\n",
      "epoch: 5, batch: 636, loss: 0.646035373210907\n",
      "epoch: 5, batch: 637, loss: 0.9214264750480652\n",
      "epoch: 5, batch: 638, loss: 0.8247835040092468\n",
      "epoch: 5, batch: 639, loss: 0.7432558536529541\n",
      "epoch: 5, batch: 640, loss: 0.6762447357177734\n",
      "epoch: 5, batch: 641, loss: 0.6709550023078918\n",
      "epoch: 5, batch: 642, loss: 0.581512451171875\n",
      "epoch: 5, batch: 643, loss: 0.7704765200614929\n",
      "epoch: 5, batch: 644, loss: 0.8208106160163879\n",
      "epoch: 5, batch: 645, loss: 0.6961068511009216\n",
      "epoch: 5, batch: 646, loss: 0.8120099306106567\n",
      "epoch: 5, batch: 647, loss: 0.7208466529846191\n",
      "epoch: 5, batch: 648, loss: 0.8286341428756714\n",
      "epoch: 5, batch: 649, loss: 0.7583590149879456\n",
      "epoch: 5, batch: 650, loss: 0.6816155314445496\n",
      "epoch: 5, batch: 651, loss: 0.7892082333564758\n",
      "epoch: 5, batch: 652, loss: 0.7116931676864624\n",
      "epoch: 5, batch: 653, loss: 0.6851910948753357\n",
      "epoch: 5, batch: 654, loss: 0.7238339185714722\n",
      "epoch: 5, batch: 655, loss: 0.5621218085289001\n",
      "epoch: 5, batch: 656, loss: 0.7512642741203308\n",
      "epoch: 5, batch: 657, loss: 0.7223039269447327\n",
      "epoch: 5, batch: 658, loss: 0.5261586904525757\n",
      "epoch: 5, batch: 659, loss: 0.8712793588638306\n",
      "epoch: 5, batch: 660, loss: 0.6607388257980347\n",
      "epoch: 5, batch: 661, loss: 0.6792759895324707\n",
      "epoch: 5, batch: 662, loss: 0.6126399636268616\n",
      "epoch: 5, batch: 663, loss: 0.6453362107276917\n",
      "epoch: 5, batch: 664, loss: 0.6222116351127625\n",
      "epoch: 5, batch: 665, loss: 0.6096602082252502\n",
      "epoch: 5, batch: 666, loss: 0.791083037853241\n",
      "epoch: 5, batch: 667, loss: 0.7671279311180115\n",
      "epoch: 5, batch: 668, loss: 0.6159723401069641\n",
      "epoch: 5, batch: 669, loss: 0.7452324628829956\n",
      "epoch: 5, batch: 670, loss: 0.6251844167709351\n",
      "epoch: 5, batch: 671, loss: 0.45859670639038086\n",
      "epoch: 5, batch: 672, loss: 0.8271923065185547\n",
      "epoch: 5, batch: 673, loss: 0.6309887766838074\n",
      "epoch: 5, batch: 674, loss: 0.7966477870941162\n",
      "epoch: 5, batch: 675, loss: 0.8753947019577026\n",
      "epoch: 5, batch: 676, loss: 0.7274596095085144\n",
      "epoch: 5, batch: 677, loss: 0.8646165132522583\n",
      "epoch: 5, batch: 678, loss: 0.7466263771057129\n",
      "epoch: 5, batch: 679, loss: 0.8891381621360779\n",
      "epoch: 5, batch: 680, loss: 0.6376808285713196\n",
      "epoch: 5, batch: 681, loss: 0.6389378309249878\n",
      "epoch: 5, batch: 682, loss: 0.7149080038070679\n",
      "epoch: 5, batch: 683, loss: 0.49908965826034546\n",
      "epoch: 5, batch: 684, loss: 0.6299489736557007\n",
      "epoch: 5, batch: 685, loss: 0.7957982420921326\n",
      "epoch: 5, batch: 686, loss: 0.9339346885681152\n",
      "epoch: 5, batch: 687, loss: 0.7569347620010376\n",
      "epoch: 5, batch: 688, loss: 0.49932655692100525\n",
      "epoch: 5, batch: 689, loss: 0.713589072227478\n",
      "epoch: 5, batch: 690, loss: 0.6298027038574219\n",
      "epoch: 5, batch: 691, loss: 0.8027801513671875\n",
      "epoch: 5, batch: 692, loss: 0.5685407519340515\n",
      "epoch: 5, batch: 693, loss: 0.6073006391525269\n",
      "epoch: 5, batch: 694, loss: 0.7007264494895935\n",
      "epoch: 5, batch: 695, loss: 0.5306344628334045\n",
      "epoch: 5, batch: 696, loss: 0.6657740473747253\n",
      "epoch: 5, batch: 697, loss: 0.5841841697692871\n",
      "epoch: 5, batch: 698, loss: 0.6440238952636719\n",
      "epoch: 5, batch: 699, loss: 0.7976931929588318\n",
      "epoch: 5, batch: 700, loss: 0.6260426640510559\n",
      "epoch: 5, batch: 701, loss: 0.5706773996353149\n",
      "epoch: 5, batch: 702, loss: 0.7803286910057068\n",
      "epoch: 5, batch: 703, loss: 0.7392686009407043\n",
      "epoch: 5, batch: 704, loss: 0.9447547793388367\n",
      "epoch: 5, batch: 705, loss: 0.6999025344848633\n",
      "epoch: 5, batch: 706, loss: 0.68548983335495\n",
      "epoch: 5, batch: 707, loss: 0.9126003980636597\n",
      "epoch: 5, batch: 708, loss: 0.7542924284934998\n",
      "epoch: 5, batch: 709, loss: 0.7321335077285767\n",
      "epoch: 5, batch: 710, loss: 0.5758317708969116\n",
      "epoch: 5, batch: 711, loss: 0.6917285919189453\n",
      "epoch: 5, batch: 712, loss: 0.7330700755119324\n",
      "epoch: 5, batch: 713, loss: 0.7014188170433044\n",
      "epoch: 5, batch: 714, loss: 0.6997194886207581\n",
      "epoch: 5, batch: 715, loss: 0.8279638886451721\n",
      "epoch: 5, batch: 716, loss: 0.6239883303642273\n",
      "epoch: 5, batch: 717, loss: 0.7387171387672424\n",
      "epoch: 5, batch: 718, loss: 0.546367883682251\n",
      "epoch: 5, batch: 719, loss: 0.8622046113014221\n",
      "epoch: 5, batch: 720, loss: 0.5839325189590454\n",
      "epoch: 5, batch: 721, loss: 0.8025745153427124\n",
      "epoch: 5, batch: 722, loss: 0.72966468334198\n",
      "epoch: 5, batch: 723, loss: 0.6006838083267212\n",
      "epoch: 5, batch: 724, loss: 0.7778119444847107\n",
      "epoch: 5, batch: 725, loss: 0.6263819932937622\n",
      "epoch: 5, batch: 726, loss: 0.6938292980194092\n",
      "epoch: 5, batch: 727, loss: 0.6039878726005554\n",
      "epoch: 5, batch: 728, loss: 0.751394510269165\n",
      "epoch: 5, batch: 729, loss: 0.6200283765792847\n",
      "epoch: 5, batch: 730, loss: 0.7618090510368347\n",
      "epoch: 5, batch: 731, loss: 0.6775046586990356\n",
      "epoch: 5, batch: 732, loss: 0.6088513731956482\n",
      "epoch: 5, batch: 733, loss: 0.8276901245117188\n",
      "epoch: 5, batch: 734, loss: 0.7093894481658936\n",
      "epoch: 5, batch: 735, loss: 0.7040136456489563\n",
      "epoch: 5, batch: 736, loss: 0.5016796588897705\n",
      "epoch: 5, batch: 737, loss: 0.6971772313117981\n",
      "epoch: 5, batch: 738, loss: 0.6542426943778992\n",
      "epoch: 5, batch: 739, loss: 0.6211999654769897\n",
      "epoch: 5, batch: 740, loss: 0.6773690581321716\n",
      "epoch: 5, batch: 741, loss: 0.6097208857536316\n",
      "epoch: 5, batch: 742, loss: 0.9240153431892395\n",
      "epoch: 5, batch: 743, loss: 0.596835732460022\n",
      "epoch: 5, batch: 744, loss: 0.8122367858886719\n",
      "epoch: 5, batch: 745, loss: 0.5058712959289551\n",
      "epoch: 5, batch: 746, loss: 0.6577669978141785\n",
      "epoch: 5, batch: 747, loss: 0.6753316521644592\n",
      "epoch: 5, batch: 748, loss: 0.6437721252441406\n",
      "epoch: 5, batch: 749, loss: 0.7568685412406921\n",
      "epoch: 5, batch: 750, loss: 0.727741003036499\n",
      "epoch: 5, batch: 751, loss: 0.7136074304580688\n",
      "epoch: 5, batch: 752, loss: 0.6238178014755249\n",
      "epoch: 5, batch: 753, loss: 0.5418425798416138\n",
      "epoch: 5, batch: 754, loss: 0.5854083299636841\n",
      "epoch: 5, batch: 755, loss: 0.7969544529914856\n",
      "epoch: 5, batch: 756, loss: 0.5396117568016052\n",
      "epoch: 5, batch: 757, loss: 0.5113138556480408\n",
      "epoch: 5, batch: 758, loss: 0.5325257182121277\n",
      "epoch: 5, batch: 759, loss: 0.6273306608200073\n",
      "epoch: 5, batch: 760, loss: 0.5766547918319702\n",
      "epoch: 5, batch: 761, loss: 0.7779150009155273\n",
      "epoch: 5, batch: 762, loss: 0.6612927913665771\n",
      "epoch: 5, batch: 763, loss: 0.5993304252624512\n",
      "epoch: 5, batch: 764, loss: 0.7454262971878052\n",
      "epoch: 5, batch: 765, loss: 0.7265917658805847\n",
      "epoch: 5, batch: 766, loss: 0.6777162551879883\n",
      "epoch: 5, batch: 767, loss: 0.40576171875\n",
      "epoch: 5, batch: 768, loss: 0.5515526533126831\n",
      "epoch: 5, batch: 769, loss: 0.7067545652389526\n",
      "epoch: 5, batch: 770, loss: 0.7451400756835938\n",
      "epoch: 5, batch: 771, loss: 0.631443977355957\n",
      "epoch: 5, batch: 772, loss: 0.6376626491546631\n",
      "epoch: 5, batch: 773, loss: 0.838973343372345\n",
      "epoch: 5, batch: 774, loss: 0.6562161445617676\n",
      "epoch: 5, batch: 775, loss: 0.7838367223739624\n",
      "epoch: 5, batch: 776, loss: 0.7127294540405273\n",
      "epoch: 5, batch: 777, loss: 0.6599067449569702\n",
      "epoch: 5, batch: 778, loss: 0.6550161242485046\n",
      "epoch: 5, batch: 779, loss: 0.9510312080383301\n",
      "epoch: 5, batch: 780, loss: 0.6919357180595398\n",
      "epoch: 5, batch: 781, loss: 0.6197595000267029\n",
      "epoch: 5, batch: 782, loss: 0.6737003922462463\n",
      "epoch: 5, batch: 783, loss: 0.7532067894935608\n",
      "epoch: 5, batch: 784, loss: 0.7735244035720825\n",
      "epoch: 5, batch: 785, loss: 0.6713102459907532\n",
      "epoch: 5, batch: 786, loss: 0.5656823515892029\n",
      "epoch: 5, batch: 787, loss: 0.8275865912437439\n",
      "epoch: 5, batch: 788, loss: 0.7142837643623352\n",
      "epoch: 5, batch: 789, loss: 0.6222121119499207\n",
      "epoch: 5, batch: 790, loss: 0.5960930585861206\n",
      "epoch: 5, batch: 791, loss: 0.6874739527702332\n",
      "epoch: 5, batch: 792, loss: 0.6620361804962158\n",
      "epoch: 5, batch: 793, loss: 0.633635401725769\n",
      "epoch: 5, batch: 794, loss: 0.6113581657409668\n",
      "epoch: 5, batch: 795, loss: 0.6053557991981506\n",
      "epoch: 5, batch: 796, loss: 0.6369417905807495\n",
      "epoch: 5, batch: 797, loss: 0.7443898916244507\n",
      "epoch: 5, batch: 798, loss: 0.7749847769737244\n",
      "epoch: 5, batch: 799, loss: 0.7250896692276001\n",
      "epoch: 5, batch: 800, loss: 0.7950795888900757\n",
      "epoch: 5, batch: 801, loss: 0.616672694683075\n",
      "epoch: 5, batch: 802, loss: 0.7365120053291321\n",
      "epoch: 5, batch: 803, loss: 0.8166134357452393\n",
      "epoch: 5, batch: 804, loss: 0.8570138812065125\n",
      "epoch: 5, batch: 805, loss: 0.6254256367683411\n",
      "epoch: 5, batch: 806, loss: 0.691222608089447\n",
      "epoch: 5, batch: 807, loss: 0.6652792692184448\n",
      "epoch: 5, batch: 808, loss: 0.7808996438980103\n",
      "epoch: 5, batch: 809, loss: 0.6690525412559509\n",
      "epoch: 5, batch: 810, loss: 0.9655689001083374\n",
      "epoch: 5, batch: 811, loss: 0.7779663801193237\n",
      "epoch: 5, batch: 812, loss: 0.8945178985595703\n",
      "epoch: 5, batch: 813, loss: 0.3871678411960602\n",
      "epoch: 5, batch: 814, loss: 0.5812438130378723\n",
      "epoch: 5, batch: 815, loss: 0.7574540376663208\n",
      "epoch: 5, batch: 816, loss: 0.6595011949539185\n",
      "epoch: 5, batch: 817, loss: 0.8392952084541321\n",
      "epoch: 5, batch: 818, loss: 0.8039851188659668\n",
      "epoch: 5, batch: 819, loss: 0.7707929015159607\n",
      "epoch: 5, batch: 820, loss: 0.4926864504814148\n",
      "epoch: 5, batch: 821, loss: 1.0513594150543213\n",
      "epoch: 5, batch: 822, loss: 0.562095046043396\n",
      "epoch: 5, batch: 823, loss: 0.5129917860031128\n",
      "epoch: 5, batch: 824, loss: 0.6888874173164368\n",
      "epoch: 5, batch: 825, loss: 0.9230718016624451\n",
      "epoch: 5, batch: 826, loss: 0.6517326831817627\n",
      "epoch: 5, batch: 827, loss: 0.7546393871307373\n",
      "epoch: 5, batch: 828, loss: 0.7459095120429993\n",
      "epoch: 5, batch: 829, loss: 0.4673272371292114\n",
      "epoch: 5, batch: 830, loss: 0.6720337867736816\n",
      "epoch: 5, batch: 831, loss: 0.7052232623100281\n",
      "epoch: 5, batch: 832, loss: 0.9499225616455078\n",
      "epoch: 5, batch: 833, loss: 0.7315676808357239\n",
      "epoch: 5, batch: 834, loss: 0.5419653058052063\n",
      "epoch: 5, batch: 835, loss: 0.763748288154602\n",
      "epoch: 5, batch: 836, loss: 0.6765360236167908\n",
      "epoch: 5, batch: 837, loss: 0.8961315155029297\n",
      "epoch: 5, batch: 838, loss: 0.7138835787773132\n",
      "epoch: 5, batch: 839, loss: 0.8188244104385376\n",
      "epoch: 5, batch: 840, loss: 0.515760064125061\n",
      "epoch: 5, batch: 841, loss: 0.6116073131561279\n",
      "epoch: 5, batch: 842, loss: 0.7537181377410889\n",
      "epoch: 5, batch: 843, loss: 0.6644157767295837\n",
      "epoch: 5, batch: 844, loss: 0.6799662113189697\n",
      "epoch: 5, batch: 845, loss: 0.7001702785491943\n",
      "epoch: 5, batch: 846, loss: 0.7633327841758728\n",
      "epoch: 5, batch: 847, loss: 0.538949728012085\n",
      "epoch: 5, batch: 848, loss: 0.604026734828949\n",
      "epoch: 5, batch: 849, loss: 0.7044543027877808\n",
      "epoch: 5, batch: 850, loss: 0.9355753660202026\n",
      "epoch: 5, batch: 851, loss: 0.4892944395542145\n",
      "epoch: 5, batch: 852, loss: 0.7411549091339111\n",
      "epoch: 5, batch: 853, loss: 0.7598766088485718\n",
      "epoch: 5, batch: 854, loss: 0.6354972720146179\n",
      "epoch: 5, batch: 855, loss: 0.5239221453666687\n",
      "epoch: 5, batch: 856, loss: 0.5994619131088257\n",
      "epoch: 5, batch: 857, loss: 0.6064571738243103\n",
      "epoch: 5, batch: 858, loss: 0.7117042541503906\n",
      "epoch: 5, batch: 859, loss: 0.6838710308074951\n",
      "epoch: 5, batch: 860, loss: 0.8296721577644348\n",
      "epoch: 5, batch: 861, loss: 0.8497951626777649\n",
      "epoch: 5, batch: 862, loss: 0.591122567653656\n",
      "epoch: 5, batch: 863, loss: 1.0252445936203003\n",
      "epoch: 5, batch: 864, loss: 0.48254895210266113\n",
      "epoch: 5, batch: 865, loss: 0.7052175402641296\n",
      "epoch: 5, batch: 866, loss: 0.6122627258300781\n",
      "epoch: 5, batch: 867, loss: 0.5616987943649292\n",
      "epoch: 5, batch: 868, loss: 0.7172989249229431\n",
      "epoch: 5, batch: 869, loss: 0.6637080311775208\n",
      "epoch: 5, batch: 870, loss: 0.5706186294555664\n",
      "epoch: 5, batch: 871, loss: 0.8184414505958557\n",
      "epoch: 5, batch: 872, loss: 0.7842008471488953\n",
      "epoch: 5, batch: 873, loss: 0.7692569494247437\n",
      "epoch: 5, batch: 874, loss: 0.5998879671096802\n",
      "epoch: 5, batch: 875, loss: 1.1683738231658936\n",
      "epoch: 5, batch: 876, loss: 0.6843711733818054\n",
      "epoch: 5, batch: 877, loss: 0.6891362071037292\n",
      "epoch: 5, batch: 878, loss: 0.7991460561752319\n",
      "epoch: 5, batch: 879, loss: 0.8073837757110596\n",
      "epoch: 5, batch: 880, loss: 0.679737389087677\n",
      "epoch: 5, batch: 881, loss: 0.6178566217422485\n",
      "epoch: 5, batch: 882, loss: 0.7682192325592041\n",
      "epoch: 5, batch: 883, loss: 0.46282827854156494\n",
      "epoch: 5, batch: 884, loss: 0.560809850692749\n",
      "epoch: 5, batch: 885, loss: 0.7242198586463928\n",
      "epoch: 5, batch: 886, loss: 0.5949019193649292\n",
      "epoch: 5, batch: 887, loss: 0.7196364402770996\n",
      "epoch: 5, batch: 888, loss: 0.6588782072067261\n",
      "epoch: 5, batch: 889, loss: 0.6313309073448181\n",
      "epoch: 5, batch: 890, loss: 0.6408020853996277\n",
      "epoch: 5, batch: 891, loss: 1.0449475049972534\n",
      "epoch: 5, batch: 892, loss: 0.5394445657730103\n",
      "epoch: 5, batch: 893, loss: 0.7991822957992554\n",
      "epoch: 5, batch: 894, loss: 0.8511901497840881\n",
      "epoch: 5, batch: 895, loss: 0.8708853721618652\n",
      "epoch: 5, batch: 896, loss: 0.5509585738182068\n",
      "epoch: 5, batch: 897, loss: 0.6356314420700073\n",
      "epoch: 5, batch: 898, loss: 0.6809083819389343\n",
      "epoch: 5, batch: 899, loss: 0.7257992625236511\n",
      "epoch: 5, batch: 900, loss: 0.6206779479980469\n",
      "epoch: 5, batch: 901, loss: 0.86077880859375\n",
      "epoch: 5, batch: 902, loss: 0.6984406113624573\n",
      "epoch: 5, batch: 903, loss: 0.4953401982784271\n",
      "epoch: 5, batch: 904, loss: 0.7785642147064209\n",
      "epoch: 5, batch: 905, loss: 0.6647165417671204\n",
      "epoch: 5, batch: 906, loss: 0.6968307495117188\n",
      "epoch: 5, batch: 907, loss: 0.8185471892356873\n",
      "epoch: 5, batch: 908, loss: 0.71510910987854\n",
      "epoch: 5, batch: 909, loss: 0.5197528600692749\n",
      "epoch: 5, batch: 910, loss: 0.5875504612922668\n",
      "epoch: 5, batch: 911, loss: 0.7927311658859253\n",
      "epoch: 5, batch: 912, loss: 0.6140264272689819\n",
      "epoch: 5, batch: 913, loss: 0.7826636433601379\n",
      "epoch: 5, batch: 914, loss: 0.6994658708572388\n",
      "epoch: 5, batch: 915, loss: 0.7180421948432922\n",
      "epoch: 5, batch: 916, loss: 0.8353042006492615\n",
      "epoch: 5, batch: 917, loss: 0.8272388577461243\n",
      "epoch: 5, batch: 918, loss: 0.6446654200553894\n",
      "epoch: 5, batch: 919, loss: 0.8148938417434692\n",
      "epoch: 5, batch: 920, loss: 0.6715455055236816\n",
      "epoch: 5, batch: 921, loss: 0.7493065595626831\n",
      "epoch: 5, batch: 922, loss: 0.6212267279624939\n",
      "epoch: 5, batch: 923, loss: 1.0227210521697998\n",
      "epoch: 5, batch: 924, loss: 0.5248430371284485\n",
      "epoch: 5, batch: 925, loss: 0.7278327941894531\n",
      "epoch: 5, batch: 926, loss: 0.5098419189453125\n",
      "epoch: 5, batch: 927, loss: 0.59222012758255\n",
      "epoch: 5, batch: 928, loss: 0.6150129437446594\n",
      "epoch: 5, batch: 929, loss: 0.7775226831436157\n",
      "epoch: 5, batch: 930, loss: 0.6089333891868591\n",
      "epoch: 5, batch: 931, loss: 0.9577109217643738\n",
      "epoch: 5, batch: 932, loss: 0.9007070660591125\n",
      "epoch: 5, batch: 933, loss: 0.5783699750900269\n",
      "epoch: 5, batch: 934, loss: 0.888261079788208\n",
      "epoch: 5, batch: 935, loss: 0.6852646470069885\n",
      "epoch: 5, batch: 936, loss: 0.49615007638931274\n",
      "epoch: 5, batch: 937, loss: 0.6976442337036133\n",
      "epoch: 5, batch: 938, loss: 0.49991267919540405\n",
      "epoch: 5, batch: 939, loss: 0.6976528167724609\n",
      "epoch: 5, batch: 940, loss: 0.6945281028747559\n",
      "epoch: 5, batch: 941, loss: 0.7092291712760925\n",
      "epoch: 5, batch: 942, loss: 0.6160097718238831\n",
      "epoch: 5, batch: 943, loss: 0.5817999839782715\n",
      "epoch: 5, batch: 944, loss: 0.6191110014915466\n",
      "epoch: 5, batch: 945, loss: 0.4790114164352417\n",
      "epoch: 5, batch: 946, loss: 0.6479834318161011\n",
      "epoch: 5, batch: 947, loss: 0.6968264579772949\n",
      "epoch: 5, batch: 948, loss: 0.6350865960121155\n",
      "epoch: 5, batch: 949, loss: 0.6250040531158447\n",
      "epoch: 5, batch: 950, loss: 0.8664838671684265\n",
      "epoch: 5, batch: 951, loss: 1.078931450843811\n",
      "epoch: 5, batch: 952, loss: 0.7113347053527832\n",
      "epoch: 5, batch: 953, loss: 0.6029514670372009\n",
      "epoch: 5, batch: 954, loss: 0.6285655498504639\n",
      "epoch: 5, batch: 955, loss: 0.865929901599884\n",
      "epoch: 5, batch: 956, loss: 0.8823758959770203\n",
      "epoch: 5, batch: 957, loss: 1.0352659225463867\n",
      "epoch: 5, batch: 958, loss: 0.44401267170906067\n",
      "epoch: 5, batch: 959, loss: 0.7193238735198975\n",
      "epoch: 5, batch: 960, loss: 0.7911549806594849\n",
      "epoch: 5, batch: 961, loss: 0.5892177820205688\n",
      "epoch: 5, batch: 962, loss: 0.632492184638977\n",
      "epoch: 5, batch: 963, loss: 0.6803986430168152\n",
      "epoch: 5, batch: 964, loss: 0.6680202484130859\n",
      "epoch: 5, batch: 965, loss: 0.6893153786659241\n",
      "epoch: 5, batch: 966, loss: 0.5963049530982971\n",
      "epoch: 5, batch: 967, loss: 0.7123534083366394\n",
      "epoch: 5, batch: 968, loss: 0.6464904546737671\n",
      "epoch: 5, batch: 969, loss: 0.5126370787620544\n",
      "epoch: 5, batch: 970, loss: 0.6495283246040344\n",
      "epoch: 5, batch: 971, loss: 0.43857017159461975\n",
      "epoch: 5, batch: 972, loss: 0.8343212008476257\n",
      "epoch: 5, batch: 973, loss: 0.6756651401519775\n",
      "epoch: 5, batch: 974, loss: 0.7049179077148438\n",
      "epoch: 5, batch: 975, loss: 0.7158291339874268\n",
      "epoch: 5, batch: 976, loss: 0.6255290508270264\n",
      "epoch: 5, batch: 977, loss: 0.5492745041847229\n",
      "epoch: 5, batch: 978, loss: 0.5771600604057312\n",
      "epoch: 5, batch: 979, loss: 0.7059154510498047\n",
      "epoch: 5, batch: 980, loss: 0.7207753658294678\n",
      "epoch: 5, batch: 981, loss: 0.6504310965538025\n",
      "epoch: 5, batch: 982, loss: 0.9411014318466187\n",
      "epoch: 5, batch: 983, loss: 0.5124086141586304\n",
      "epoch: 5, batch: 984, loss: 0.5500131249427795\n",
      "epoch: 5, batch: 985, loss: 0.707115888595581\n",
      "epoch: 5, batch: 986, loss: 0.8956395983695984\n",
      "epoch: 5, batch: 987, loss: 0.5941664576530457\n",
      "epoch: 5, batch: 988, loss: 0.6416355967521667\n",
      "epoch: 5, batch: 989, loss: 0.5619522929191589\n",
      "epoch: 5, batch: 990, loss: 0.7361898422241211\n",
      "epoch: 5, batch: 991, loss: 0.723024845123291\n",
      "epoch: 5, batch: 992, loss: 0.6956506967544556\n",
      "epoch: 5, batch: 993, loss: 0.5254351496696472\n",
      "epoch: 5, batch: 994, loss: 0.6419416069984436\n",
      "epoch: 5, batch: 995, loss: 0.6142159700393677\n",
      "epoch: 5, batch: 996, loss: 0.5819551348686218\n",
      "epoch: 5, batch: 997, loss: 0.741174578666687\n",
      "epoch: 5, batch: 998, loss: 0.9230916500091553\n",
      "epoch: 5, batch: 999, loss: 0.906440794467926\n",
      "epoch: 5, batch: 1000, loss: 0.7395148873329163\n",
      "epoch: 5, batch: 1001, loss: 0.7113787531852722\n",
      "epoch: 5, batch: 1002, loss: 0.9194753766059875\n",
      "epoch: 5, batch: 1003, loss: 0.4212495684623718\n",
      "epoch: 5, batch: 1004, loss: 0.5989121198654175\n",
      "epoch: 5, batch: 1005, loss: 0.6080393195152283\n",
      "epoch: 5, batch: 1006, loss: 0.4451115131378174\n",
      "epoch: 5, batch: 1007, loss: 0.6332457661628723\n",
      "epoch: 5, batch: 1008, loss: 0.8594882488250732\n",
      "epoch: 5, batch: 1009, loss: 0.7014093995094299\n",
      "epoch: 5, batch: 1010, loss: 0.7280065417289734\n",
      "epoch: 5, batch: 1011, loss: 0.675125002861023\n",
      "epoch: 5, batch: 1012, loss: 0.6147270202636719\n",
      "epoch: 5, batch: 1013, loss: 0.513992428779602\n",
      "epoch: 5, batch: 1014, loss: 0.7492460012435913\n",
      "epoch: 5, batch: 1015, loss: 0.7146539688110352\n",
      "epoch: 5, batch: 1016, loss: 0.9052509665489197\n",
      "epoch: 5, batch: 1017, loss: 0.9922558665275574\n",
      "epoch: 5, batch: 1018, loss: 0.6548165082931519\n",
      "epoch: 5, batch: 1019, loss: 0.7708063125610352\n",
      "epoch: 5, batch: 1020, loss: 0.5453982949256897\n",
      "epoch: 5, batch: 1021, loss: 0.6744717955589294\n",
      "epoch: 5, batch: 1022, loss: 0.7483140826225281\n",
      "epoch: 5, batch: 1023, loss: 0.6210702657699585\n",
      "epoch: 5, batch: 1024, loss: 0.7061678171157837\n",
      "epoch: 5, batch: 1025, loss: 0.7740181088447571\n",
      "epoch: 5, batch: 1026, loss: 0.9323352575302124\n",
      "epoch: 5, batch: 1027, loss: 0.5349411964416504\n",
      "epoch: 5, batch: 1028, loss: 0.7073287963867188\n",
      "epoch: 5, batch: 1029, loss: 0.8066248893737793\n",
      "epoch: 5, batch: 1030, loss: 0.6245313286781311\n",
      "epoch: 5, batch: 1031, loss: 0.8552614450454712\n",
      "epoch: 5, batch: 1032, loss: 0.7618515491485596\n",
      "epoch: 5, batch: 1033, loss: 0.6479436755180359\n",
      "epoch: 5, batch: 1034, loss: 0.7738575339317322\n",
      "epoch: 5, batch: 1035, loss: 0.5225485563278198\n",
      "epoch: 5, batch: 1036, loss: 0.4492643177509308\n",
      "epoch: 5, batch: 1037, loss: 0.6012844443321228\n",
      "epoch: 5, batch: 1038, loss: 0.5871224999427795\n",
      "epoch: 5, batch: 1039, loss: 0.8504851460456848\n",
      "epoch: 5, batch: 1040, loss: 0.766277551651001\n",
      "epoch: 5, batch: 1041, loss: 0.5612094402313232\n",
      "epoch: 5, batch: 1042, loss: 0.8015725016593933\n",
      "epoch: 5, batch: 1043, loss: 0.5312433242797852\n",
      "epoch: 5, batch: 1044, loss: 0.5640561580657959\n",
      "epoch: 5, batch: 1045, loss: 0.6651505827903748\n",
      "epoch: 5, batch: 1046, loss: 0.5734087824821472\n",
      "epoch: 5, batch: 1047, loss: 0.7843718528747559\n",
      "epoch: 5, batch: 1048, loss: 0.7175341844558716\n",
      "epoch: 5, batch: 1049, loss: 0.7423029541969299\n",
      "epoch: 5, batch: 1050, loss: 0.6226209402084351\n",
      "epoch: 5, batch: 1051, loss: 0.5803732872009277\n",
      "epoch: 5, batch: 1052, loss: 0.6029772758483887\n",
      "epoch: 5, batch: 1053, loss: 0.693602979183197\n",
      "epoch: 5, batch: 1054, loss: 0.5122140049934387\n",
      "epoch: 5, batch: 1055, loss: 0.9073802828788757\n",
      "epoch: 5, batch: 1056, loss: 0.5334459543228149\n",
      "epoch: 5, batch: 1057, loss: 0.5931506156921387\n",
      "epoch: 5, batch: 1058, loss: 0.6794392466545105\n",
      "epoch: 5, batch: 1059, loss: 0.9008769989013672\n",
      "epoch: 5, batch: 1060, loss: 0.8257570266723633\n",
      "epoch: 5, batch: 1061, loss: 0.666190505027771\n",
      "epoch: 5, batch: 1062, loss: 0.5547553896903992\n",
      "epoch: 5, batch: 1063, loss: 0.7899255156517029\n",
      "epoch: 5, batch: 1064, loss: 0.962730884552002\n",
      "epoch: 5, batch: 1065, loss: 0.5931413173675537\n",
      "epoch: 5, batch: 1066, loss: 0.6005703210830688\n",
      "epoch: 5, batch: 1067, loss: 0.6950967311859131\n",
      "epoch: 5, batch: 1068, loss: 0.6449730396270752\n",
      "epoch: 5, batch: 1069, loss: 0.6703949570655823\n",
      "epoch: 5, batch: 1070, loss: 0.598721981048584\n",
      "epoch: 5, batch: 1071, loss: 0.686180830001831\n",
      "epoch: 5, batch: 1072, loss: 0.7420075535774231\n",
      "epoch: 5, batch: 1073, loss: 0.6102849245071411\n",
      "epoch: 5, batch: 1074, loss: 0.7342681884765625\n",
      "epoch: 5, batch: 1075, loss: 0.6614609360694885\n",
      "epoch: 5, batch: 1076, loss: 0.6171672940254211\n",
      "epoch: 5, batch: 1077, loss: 0.8416190147399902\n",
      "epoch: 5, batch: 1078, loss: 0.7449034452438354\n",
      "epoch: 5, batch: 1079, loss: 0.8287089467048645\n",
      "epoch: 5, batch: 1080, loss: 0.8942123055458069\n",
      "epoch: 5, batch: 1081, loss: 0.6625417470932007\n",
      "epoch: 5, batch: 1082, loss: 0.8415753841400146\n",
      "epoch: 5, batch: 1083, loss: 0.6928776502609253\n",
      "epoch: 5, batch: 1084, loss: 0.5437160730361938\n",
      "epoch: 5, batch: 1085, loss: 0.6835212707519531\n",
      "epoch: 5, batch: 1086, loss: 0.5287885069847107\n",
      "epoch: 5, batch: 1087, loss: 0.7105079293251038\n",
      "epoch: 5, batch: 1088, loss: 0.4938943088054657\n",
      "epoch: 5, batch: 1089, loss: 0.48221355676651\n",
      "epoch: 5, batch: 1090, loss: 0.7536603212356567\n",
      "epoch: 5, batch: 1091, loss: 0.711555540561676\n",
      "epoch: 5, batch: 1092, loss: 0.8108789920806885\n",
      "epoch: 5, batch: 1093, loss: 0.7113438248634338\n",
      "epoch: 5, batch: 1094, loss: 0.758451521396637\n",
      "epoch: 5, batch: 1095, loss: 0.5366274118423462\n",
      "epoch: 5, batch: 1096, loss: 0.722647488117218\n",
      "epoch: 5, batch: 1097, loss: 0.5634834170341492\n",
      "epoch: 5, batch: 1098, loss: 0.4465709924697876\n",
      "epoch: 5, batch: 1099, loss: 0.6765347719192505\n",
      "epoch: 5, batch: 1100, loss: 0.6166395545005798\n",
      "epoch: 5, batch: 1101, loss: 0.4705944359302521\n",
      "epoch: 5, batch: 1102, loss: 0.7828978896141052\n",
      "epoch: 5, batch: 1103, loss: 0.7207251787185669\n",
      "epoch: 5, batch: 1104, loss: 0.7519606947898865\n",
      "epoch: 5, batch: 1105, loss: 0.4486002027988434\n",
      "epoch: 5, batch: 1106, loss: 0.90567547082901\n",
      "epoch: 5, batch: 1107, loss: 0.5753324031829834\n",
      "epoch: 5, batch: 1108, loss: 0.558315098285675\n",
      "epoch: 5, batch: 1109, loss: 0.8321003317832947\n",
      "epoch: 5, batch: 1110, loss: 0.6255922317504883\n",
      "epoch: 5, batch: 1111, loss: 0.5785698890686035\n",
      "epoch: 5, batch: 1112, loss: 0.6474660634994507\n",
      "epoch: 5, batch: 1113, loss: 0.7001699209213257\n",
      "epoch: 5, batch: 1114, loss: 0.5759038925170898\n",
      "epoch: 5, batch: 1115, loss: 0.8614432215690613\n",
      "epoch: 5, batch: 1116, loss: 0.704304575920105\n",
      "epoch: 5, batch: 1117, loss: 0.6072446703910828\n",
      "epoch: 5, batch: 1118, loss: 0.8352507948875427\n",
      "epoch: 5, batch: 1119, loss: 0.68466717004776\n",
      "epoch: 5, batch: 1120, loss: 0.5224469304084778\n",
      "epoch: 5, batch: 1121, loss: 0.5348453521728516\n",
      "epoch: 5, batch: 1122, loss: 0.6474055647850037\n",
      "epoch: 5, batch: 1123, loss: 0.8182196617126465\n",
      "epoch: 5, batch: 1124, loss: 0.43541213870048523\n",
      "epoch: 5, batch: 1125, loss: 0.6218886971473694\n",
      "epoch: 5, batch: 1126, loss: 0.6892775893211365\n",
      "epoch: 5, batch: 1127, loss: 0.8569652438163757\n",
      "epoch: 5, batch: 1128, loss: 0.6313967108726501\n",
      "epoch: 5, batch: 1129, loss: 0.7244659662246704\n",
      "epoch: 5, batch: 1130, loss: 0.5141972303390503\n",
      "epoch: 5, batch: 1131, loss: 0.6604411005973816\n",
      "epoch: 5, batch: 1132, loss: 0.6510459184646606\n",
      "epoch: 5, batch: 1133, loss: 0.6447563767433167\n",
      "epoch: 5, batch: 1134, loss: 0.5497841238975525\n",
      "epoch: 5, batch: 1135, loss: 0.7098249197006226\n",
      "epoch: 5, batch: 1136, loss: 0.5345746278762817\n",
      "epoch: 5, batch: 1137, loss: 0.8378421068191528\n",
      "epoch: 5, batch: 1138, loss: 0.6483769416809082\n",
      "epoch: 5, batch: 1139, loss: 0.7260141968727112\n",
      "epoch: 5, batch: 1140, loss: 0.6004447937011719\n",
      "epoch: 5, batch: 1141, loss: 0.8093968033790588\n",
      "epoch: 5, batch: 1142, loss: 0.6451817750930786\n",
      "epoch: 5, batch: 1143, loss: 0.6794148087501526\n",
      "epoch: 5, batch: 1144, loss: 0.5907497406005859\n",
      "epoch: 5, batch: 1145, loss: 0.7574697136878967\n",
      "epoch: 5, batch: 1146, loss: 0.7729743719100952\n",
      "epoch: 5, batch: 1147, loss: 0.5729280710220337\n",
      "epoch: 5, batch: 1148, loss: 0.933452308177948\n",
      "epoch: 5, batch: 1149, loss: 0.5277669429779053\n",
      "epoch: 5, batch: 1150, loss: 0.6967172026634216\n",
      "epoch: 5, batch: 1151, loss: 0.5983192920684814\n",
      "epoch: 5, batch: 1152, loss: 0.9333994388580322\n",
      "epoch: 5, batch: 1153, loss: 0.6151685118675232\n",
      "epoch: 5, batch: 1154, loss: 0.6375485062599182\n",
      "epoch: 5, batch: 1155, loss: 0.7692790031433105\n",
      "epoch: 5, batch: 1156, loss: 0.7331658601760864\n",
      "epoch: 5, batch: 1157, loss: 0.5457272529602051\n",
      "epoch: 5, batch: 1158, loss: 0.8005698919296265\n",
      "epoch: 5, batch: 1159, loss: 0.7854503989219666\n",
      "epoch: 5, batch: 1160, loss: 0.7088309526443481\n",
      "epoch: 5, batch: 1161, loss: 0.6971794366836548\n",
      "epoch: 5, batch: 1162, loss: 0.5885503888130188\n",
      "epoch: 5, batch: 1163, loss: 0.7612934708595276\n",
      "epoch: 5, batch: 1164, loss: 0.899895429611206\n",
      "epoch: 5, batch: 1165, loss: 0.6043784618377686\n",
      "epoch: 5, batch: 1166, loss: 0.6898707747459412\n",
      "epoch: 5, batch: 1167, loss: 0.7561426758766174\n",
      "epoch: 5, batch: 1168, loss: 0.6021867990493774\n",
      "epoch: 5, batch: 1169, loss: 0.520839273929596\n",
      "epoch: 5, batch: 1170, loss: 0.7434943318367004\n",
      "epoch: 5, batch: 1171, loss: 0.7703427672386169\n",
      "epoch: 5, batch: 1172, loss: 0.6482066512107849\n",
      "epoch: 5, batch: 1173, loss: 0.6377849578857422\n",
      "epoch: 5, batch: 1174, loss: 0.8533921241760254\n",
      "epoch: 5, batch: 1175, loss: 0.5710099935531616\n",
      "epoch: 5, batch: 1176, loss: 1.08855140209198\n",
      "epoch: 5, batch: 1177, loss: 0.45177364349365234\n",
      "epoch: 5, batch: 1178, loss: 0.3998188376426697\n",
      "epoch: 5, batch: 1179, loss: 0.5677763819694519\n",
      "epoch: 5, batch: 1180, loss: 0.6973459124565125\n",
      "epoch: 5, batch: 1181, loss: 0.652995765209198\n",
      "epoch: 5, batch: 1182, loss: 0.7215185761451721\n",
      "epoch: 5, batch: 1183, loss: 0.7526724934577942\n",
      "epoch: 5, batch: 1184, loss: 0.6746134161949158\n",
      "epoch: 5, batch: 1185, loss: 0.5952114462852478\n",
      "epoch: 5, batch: 1186, loss: 0.8784510493278503\n",
      "epoch: 5, batch: 1187, loss: 0.855988085269928\n",
      "epoch: 5, batch: 1188, loss: 0.5915416479110718\n",
      "epoch: 5, batch: 1189, loss: 0.7791537046432495\n",
      "epoch: 5, batch: 1190, loss: 0.6986543536186218\n",
      "epoch: 5, batch: 1191, loss: 1.0457935333251953\n",
      "epoch: 5, batch: 1192, loss: 0.6650437712669373\n",
      "epoch: 5, batch: 1193, loss: 0.6307764053344727\n",
      "epoch: 5, batch: 1194, loss: 0.584782600402832\n",
      "epoch: 5, batch: 1195, loss: 0.6256805062294006\n",
      "epoch: 5, batch: 1196, loss: 0.6371622085571289\n",
      "epoch: 5, batch: 1197, loss: 0.5969108939170837\n",
      "epoch: 5, batch: 1198, loss: 0.6789852380752563\n",
      "epoch: 5, batch: 1199, loss: 0.5098516345024109\n",
      "epoch: 5, batch: 1200, loss: 0.5977793335914612\n",
      "epoch: 5, batch: 1201, loss: 0.7988272905349731\n",
      "epoch: 5, batch: 1202, loss: 0.6474747657775879\n",
      "epoch: 5, batch: 1203, loss: 0.5078982710838318\n",
      "epoch: 5, batch: 1204, loss: 0.5872496366500854\n",
      "epoch: 5, batch: 1205, loss: 0.6369863152503967\n",
      "epoch: 5, batch: 1206, loss: 1.0066555738449097\n",
      "epoch: 5, batch: 1207, loss: 0.9845321178436279\n",
      "epoch: 5, batch: 1208, loss: 0.6518059968948364\n",
      "epoch: 5, batch: 1209, loss: 0.6071373820304871\n",
      "epoch: 5, batch: 1210, loss: 0.8417423367500305\n",
      "epoch: 5, batch: 1211, loss: 0.5911876559257507\n",
      "epoch: 5, batch: 1212, loss: 0.5242166519165039\n",
      "epoch: 5, batch: 1213, loss: 0.7483958005905151\n",
      "epoch: 5, batch: 1214, loss: 0.697658121585846\n",
      "epoch: 5, batch: 1215, loss: 0.6051881313323975\n",
      "epoch: 5, batch: 1216, loss: 0.8902535438537598\n",
      "epoch: 5, batch: 1217, loss: 0.9182261824607849\n",
      "epoch: 5, batch: 1218, loss: 0.6546182036399841\n",
      "epoch: 5, batch: 1219, loss: 0.6332519054412842\n",
      "epoch: 5, batch: 1220, loss: 0.5983384847640991\n",
      "epoch: 5, batch: 1221, loss: 0.7182056903839111\n",
      "epoch: 5, batch: 1222, loss: 0.799505889415741\n",
      "epoch: 5, batch: 1223, loss: 0.5975618958473206\n",
      "epoch: 5, batch: 1224, loss: 0.6884746551513672\n",
      "epoch: 5, batch: 1225, loss: 0.8170055747032166\n",
      "epoch: 5, batch: 1226, loss: 0.6723408699035645\n",
      "epoch: 5, batch: 1227, loss: 0.860740065574646\n",
      "epoch: 5, batch: 1228, loss: 0.6328476071357727\n",
      "epoch: 5, batch: 1229, loss: 0.8222759366035461\n",
      "epoch: 5, batch: 1230, loss: 0.49356383085250854\n",
      "epoch: 5, batch: 1231, loss: 0.3534945249557495\n",
      "epoch: 5, batch: 1232, loss: 0.5163495540618896\n",
      "epoch: 5, batch: 1233, loss: 0.5432243347167969\n",
      "epoch: 5, batch: 1234, loss: 0.43092837929725647\n",
      "epoch: 5, batch: 1235, loss: 0.7092884182929993\n",
      "epoch: 5, batch: 1236, loss: 0.4978078305721283\n",
      "epoch: 5, batch: 1237, loss: 0.8197483420372009\n",
      "epoch: 5, batch: 1238, loss: 0.6588985919952393\n",
      "epoch: 5, batch: 1239, loss: 0.6279300451278687\n",
      "epoch: 5, batch: 1240, loss: 0.4964413642883301\n",
      "epoch: 5, batch: 1241, loss: 0.6346727013587952\n",
      "epoch: 5, batch: 1242, loss: 0.9138672351837158\n",
      "epoch: 5, batch: 1243, loss: 0.6278375387191772\n",
      "epoch: 5, batch: 1244, loss: 0.6790685653686523\n",
      "epoch: 5, batch: 1245, loss: 0.6889390349388123\n",
      "epoch: 5, batch: 1246, loss: 0.7391501069068909\n",
      "epoch: 5, batch: 1247, loss: 0.630713939666748\n",
      "epoch: 5, batch: 1248, loss: 0.8440842628479004\n",
      "epoch: 5, batch: 1249, loss: 0.49684953689575195\n",
      "epoch: 5, batch: 1250, loss: 0.4906870424747467\n",
      "epoch: 5, batch: 1251, loss: 0.7778244018554688\n",
      "epoch: 5, batch: 1252, loss: 0.6684894561767578\n",
      "epoch: 5, batch: 1253, loss: 0.6379284858703613\n",
      "epoch: 5, batch: 1254, loss: 0.8794073462486267\n",
      "epoch: 5, batch: 1255, loss: 0.504916250705719\n",
      "epoch: 5, batch: 1256, loss: 0.9077481627464294\n",
      "epoch: 5, batch: 1257, loss: 0.38316160440444946\n",
      "epoch: 5, batch: 1258, loss: 0.643917441368103\n",
      "epoch: 5, batch: 1259, loss: 0.7733080983161926\n",
      "epoch: 5, batch: 1260, loss: 0.5005208849906921\n",
      "epoch: 5, batch: 1261, loss: 0.8214124441146851\n",
      "epoch: 5, batch: 1262, loss: 0.5496995449066162\n",
      "epoch: 5, batch: 1263, loss: 0.7615419030189514\n",
      "epoch: 5, batch: 1264, loss: 0.8363218903541565\n",
      "epoch: 5, batch: 1265, loss: 0.6587937474250793\n",
      "epoch: 5, batch: 1266, loss: 0.8164496421813965\n",
      "epoch: 5, batch: 1267, loss: 0.9489851593971252\n",
      "epoch: 5, batch: 1268, loss: 0.6964930295944214\n",
      "epoch: 5, batch: 1269, loss: 0.6933611035346985\n",
      "epoch: 5, batch: 1270, loss: 0.6152041554450989\n",
      "epoch: 5, batch: 1271, loss: 0.565175473690033\n",
      "epoch: 5, batch: 1272, loss: 0.9006389379501343\n",
      "epoch: 5, batch: 1273, loss: 0.7134061455726624\n",
      "epoch: 5, batch: 1274, loss: 0.5502480864524841\n",
      "epoch: 5, batch: 1275, loss: 0.6192737817764282\n",
      "epoch: 5, batch: 1276, loss: 0.5101203918457031\n",
      "epoch: 5, batch: 1277, loss: 0.9007724523544312\n",
      "epoch: 5, batch: 1278, loss: 0.7644791603088379\n",
      "epoch: 5, batch: 1279, loss: 0.47370776534080505\n",
      "epoch: 5, batch: 1280, loss: 0.7186791300773621\n",
      "epoch: 5, batch: 1281, loss: 0.5654647946357727\n",
      "epoch: 5, batch: 1282, loss: 0.6746712923049927\n",
      "epoch: 5, batch: 1283, loss: 0.617455780506134\n",
      "epoch: 5, batch: 1284, loss: 0.6184991598129272\n",
      "epoch: 5, batch: 1285, loss: 0.7185531258583069\n",
      "epoch: 5, batch: 1286, loss: 0.43180474638938904\n",
      "epoch: 5, batch: 1287, loss: 0.5822582244873047\n",
      "epoch: 5, batch: 1288, loss: 0.6217654347419739\n",
      "epoch: 5, batch: 1289, loss: 0.7483046054840088\n",
      "epoch: 5, batch: 1290, loss: 0.73195880651474\n",
      "epoch: 5, batch: 1291, loss: 0.6939100027084351\n",
      "epoch: 5, batch: 1292, loss: 0.8740648031234741\n",
      "epoch: 5, batch: 1293, loss: 0.7563742399215698\n",
      "epoch: 5, batch: 1294, loss: 0.7031121253967285\n",
      "epoch: 5, batch: 1295, loss: 0.6259333491325378\n",
      "epoch: 5, batch: 1296, loss: 0.6681433320045471\n",
      "epoch: 5, batch: 1297, loss: 0.7393803596496582\n",
      "epoch: 5, batch: 1298, loss: 0.6056170463562012\n",
      "epoch: 5, batch: 1299, loss: 0.7063326239585876\n",
      "epoch: 5, batch: 1300, loss: 0.6635482311248779\n",
      "epoch: 5, batch: 1301, loss: 0.6531692147254944\n",
      "epoch: 5, batch: 1302, loss: 0.5363467931747437\n",
      "epoch: 5, batch: 1303, loss: 0.7429971694946289\n",
      "epoch: 5, batch: 1304, loss: 0.5481529235839844\n",
      "epoch: 5, batch: 1305, loss: 0.7116142511367798\n",
      "epoch: 5, batch: 1306, loss: 0.9366076588630676\n",
      "epoch: 5, batch: 1307, loss: 0.5745575428009033\n",
      "epoch: 5, batch: 1308, loss: 0.480862021446228\n",
      "epoch: 5, batch: 1309, loss: 0.5859493017196655\n",
      "epoch: 5, batch: 1310, loss: 0.6381165385246277\n",
      "epoch: 5, batch: 1311, loss: 0.6869663000106812\n",
      "epoch: 5, batch: 1312, loss: 0.5016892552375793\n",
      "epoch: 5, batch: 1313, loss: 0.5751624703407288\n",
      "epoch: 5, batch: 1314, loss: 0.743045449256897\n",
      "epoch: 5, batch: 1315, loss: 0.6753063797950745\n",
      "epoch: 5, batch: 1316, loss: 0.5192444324493408\n",
      "epoch: 5, batch: 1317, loss: 0.7936474680900574\n",
      "epoch: 5, batch: 1318, loss: 0.7534914612770081\n",
      "epoch: 5, batch: 1319, loss: 0.49233362078666687\n",
      "epoch: 5, batch: 1320, loss: 0.7602890133857727\n",
      "epoch: 5, batch: 1321, loss: 0.6336608529090881\n",
      "epoch: 5, batch: 1322, loss: 0.6493423581123352\n",
      "epoch: 5, batch: 1323, loss: 0.6937095522880554\n",
      "epoch: 5, batch: 1324, loss: 0.7860637903213501\n",
      "epoch: 5, batch: 1325, loss: 0.5689601898193359\n",
      "epoch: 5, batch: 1326, loss: 0.6107038259506226\n",
      "epoch: 5, batch: 1327, loss: 0.8507375121116638\n",
      "epoch: 5, batch: 1328, loss: 0.5073297619819641\n",
      "epoch: 5, batch: 1329, loss: 0.8212173581123352\n",
      "epoch: 5, batch: 1330, loss: 0.4705735743045807\n",
      "epoch: 5, batch: 1331, loss: 0.36581483483314514\n",
      "epoch: 5, batch: 1332, loss: 0.6297997832298279\n",
      "epoch: 5, batch: 1333, loss: 0.6440327167510986\n",
      "epoch: 5, batch: 1334, loss: 0.6768226027488708\n",
      "epoch: 5, batch: 1335, loss: 0.5494623184204102\n",
      "epoch: 5, batch: 1336, loss: 0.7190659046173096\n",
      "epoch: 5, batch: 1337, loss: 0.6574733257293701\n",
      "epoch: 5, batch: 1338, loss: 0.6608772277832031\n",
      "epoch: 5, batch: 1339, loss: 0.7838173508644104\n",
      "epoch: 5, batch: 1340, loss: 0.8808274269104004\n",
      "epoch: 5, batch: 1341, loss: 0.6831573843955994\n",
      "epoch: 5, batch: 1342, loss: 0.715700089931488\n",
      "epoch: 5, batch: 1343, loss: 0.6422703266143799\n",
      "epoch: 5, batch: 1344, loss: 0.6522746682167053\n",
      "epoch: 5, batch: 1345, loss: 0.8528273105621338\n",
      "epoch: 5, batch: 1346, loss: 0.8376354575157166\n",
      "epoch: 5, batch: 1347, loss: 0.5862522125244141\n",
      "epoch: 5, batch: 1348, loss: 0.64789217710495\n",
      "epoch: 5, batch: 1349, loss: 0.5488472580909729\n",
      "epoch: 5, batch: 1350, loss: 0.6008092164993286\n",
      "epoch: 5, batch: 1351, loss: 0.5358105301856995\n",
      "epoch: 5, batch: 1352, loss: 0.7052590847015381\n",
      "epoch: 5, batch: 1353, loss: 0.7820331454277039\n",
      "epoch: 5, batch: 1354, loss: 0.6964249610900879\n",
      "epoch: 5, batch: 1355, loss: 0.5393744707107544\n",
      "epoch: 5, batch: 1356, loss: 0.5541636943817139\n",
      "epoch: 5, batch: 1357, loss: 0.5726006627082825\n",
      "epoch: 5, batch: 1358, loss: 0.7529510855674744\n",
      "epoch: 5, batch: 1359, loss: 0.6764401197433472\n",
      "epoch: 5, batch: 1360, loss: 0.5885667204856873\n",
      "epoch: 5, batch: 1361, loss: 0.7546656131744385\n",
      "epoch: 5, batch: 1362, loss: 0.6749457716941833\n",
      "epoch: 5, batch: 1363, loss: 0.5102158784866333\n",
      "epoch: 5, batch: 1364, loss: 0.636382520198822\n",
      "epoch: 5, batch: 1365, loss: 0.6119797229766846\n",
      "epoch: 5, batch: 1366, loss: 0.6304973363876343\n",
      "epoch: 5, batch: 1367, loss: 0.5713027715682983\n",
      "epoch: 5, batch: 1368, loss: 0.5973068475723267\n",
      "epoch: 5, batch: 1369, loss: 0.5352226495742798\n",
      "epoch: 5, batch: 1370, loss: 0.5042420625686646\n",
      "epoch: 5, batch: 1371, loss: 0.918217658996582\n",
      "epoch: 5, batch: 1372, loss: 0.9240679144859314\n",
      "epoch: 5, batch: 1373, loss: 0.5095855593681335\n",
      "epoch: 5, batch: 1374, loss: 0.650398313999176\n",
      "epoch: 5, batch: 1375, loss: 0.5708410143852234\n",
      "epoch: 5, batch: 1376, loss: 0.6104738712310791\n",
      "epoch: 5, batch: 1377, loss: 0.721229612827301\n",
      "epoch: 5, batch: 1378, loss: 0.5859052538871765\n",
      "epoch: 5, batch: 1379, loss: 0.7039706110954285\n",
      "epoch: 5, batch: 1380, loss: 0.8779973387718201\n",
      "epoch: 5, batch: 1381, loss: 0.39053434133529663\n",
      "epoch: 5, batch: 1382, loss: 0.9468615055084229\n",
      "epoch: 5, batch: 1383, loss: 0.608315646648407\n",
      "epoch: 5, batch: 1384, loss: 0.8070933818817139\n",
      "epoch: 5, batch: 1385, loss: 0.9364216327667236\n",
      "epoch: 5, batch: 1386, loss: 0.894180178642273\n",
      "epoch: 5, batch: 1387, loss: 1.0100024938583374\n",
      "epoch: 5, batch: 1388, loss: 0.6265135407447815\n",
      "epoch: 5, batch: 1389, loss: 0.5268647074699402\n",
      "epoch: 5, batch: 1390, loss: 0.5593091249465942\n",
      "epoch: 5, batch: 1391, loss: 0.7077787518501282\n",
      "epoch: 5, batch: 1392, loss: 0.8280195593833923\n",
      "epoch: 5, batch: 1393, loss: 0.8154866695404053\n",
      "epoch: 5, batch: 1394, loss: 0.734016478061676\n",
      "epoch: 5, batch: 1395, loss: 0.46137508749961853\n",
      "epoch: 5, batch: 1396, loss: 0.8778492212295532\n",
      "epoch: 5, batch: 1397, loss: 0.7350625991821289\n",
      "epoch: 5, batch: 1398, loss: 0.5856239199638367\n",
      "epoch: 5, batch: 1399, loss: 0.9105848073959351\n",
      "epoch: 5, batch: 1400, loss: 0.6932165026664734\n",
      "epoch: 5, batch: 1401, loss: 0.4490869641304016\n",
      "epoch: 5, batch: 1402, loss: 0.4780378043651581\n",
      "epoch: 5, batch: 1403, loss: 0.6983621716499329\n",
      "epoch: 5, batch: 1404, loss: 0.7288520336151123\n",
      "epoch: 5, batch: 1405, loss: 0.6831863522529602\n",
      "epoch: 5, batch: 1406, loss: 0.6422566175460815\n",
      "epoch: 5, batch: 1407, loss: 0.7619231939315796\n",
      "epoch: 5, batch: 1408, loss: 0.5359708666801453\n",
      "epoch: 5, batch: 1409, loss: 0.5743340849876404\n",
      "epoch: 5, batch: 1410, loss: 0.598548948764801\n",
      "epoch: 5, batch: 1411, loss: 0.5877305269241333\n",
      "epoch: 5, batch: 1412, loss: 0.652512788772583\n",
      "epoch: 5, batch: 1413, loss: 0.7937259674072266\n",
      "epoch: 5, batch: 1414, loss: 0.6376807689666748\n",
      "epoch: 5, batch: 1415, loss: 0.5686820149421692\n",
      "epoch: 5, batch: 1416, loss: 0.5313223004341125\n",
      "epoch: 5, batch: 1417, loss: 0.6195473074913025\n",
      "epoch: 5, batch: 1418, loss: 0.5616647601127625\n",
      "epoch: 5, batch: 1419, loss: 0.8237524032592773\n",
      "epoch: 5, batch: 1420, loss: 0.6087390780448914\n",
      "epoch: 5, batch: 1421, loss: 0.8092069625854492\n",
      "epoch: 5, batch: 1422, loss: 0.5925222635269165\n",
      "epoch: 5, batch: 1423, loss: 0.6144495010375977\n",
      "epoch: 5, batch: 1424, loss: 0.5515972375869751\n",
      "epoch: 5, batch: 1425, loss: 0.5159887075424194\n",
      "epoch: 5, batch: 1426, loss: 0.6832220554351807\n",
      "epoch: 5, batch: 1427, loss: 0.7934902906417847\n",
      "epoch: 5, batch: 1428, loss: 0.5983980894088745\n",
      "epoch: 5, batch: 1429, loss: 0.7553380131721497\n",
      "epoch: 5, batch: 1430, loss: 0.6432189345359802\n",
      "epoch: 5, batch: 1431, loss: 0.6238864660263062\n",
      "epoch: 5, batch: 1432, loss: 0.7093586325645447\n",
      "epoch: 5, batch: 1433, loss: 0.5237674713134766\n",
      "epoch: 5, batch: 1434, loss: 0.7089343667030334\n",
      "epoch: 5, batch: 1435, loss: 0.6680752635002136\n",
      "epoch: 5, batch: 1436, loss: 0.5279532074928284\n",
      "epoch: 5, batch: 1437, loss: 0.5558428168296814\n",
      "epoch: 5, batch: 1438, loss: 0.540177047252655\n",
      "epoch: 5, batch: 1439, loss: 1.0148921012878418\n",
      "epoch: 5, batch: 1440, loss: 0.629723846912384\n",
      "epoch: 5, batch: 1441, loss: 1.0209885835647583\n",
      "epoch: 5, batch: 1442, loss: 0.698436439037323\n",
      "epoch: 5, batch: 1443, loss: 0.46692007780075073\n",
      "epoch: 5, batch: 1444, loss: 0.6540164947509766\n",
      "epoch: 5, batch: 1445, loss: 0.7496952414512634\n",
      "epoch: 5, batch: 1446, loss: 0.634829044342041\n",
      "epoch: 5, batch: 1447, loss: 0.6047624349594116\n",
      "epoch: 5, batch: 1448, loss: 0.7047520875930786\n",
      "epoch: 5, batch: 1449, loss: 0.5100986957550049\n",
      "epoch: 5, batch: 1450, loss: 0.521662175655365\n",
      "epoch: 5, batch: 1451, loss: 0.6618697047233582\n",
      "epoch: 5, batch: 1452, loss: 0.8084779977798462\n",
      "epoch: 5, batch: 1453, loss: 0.883499264717102\n",
      "epoch: 5, batch: 1454, loss: 0.7210765480995178\n",
      "epoch: 5, batch: 1455, loss: 0.4884537160396576\n",
      "epoch: 5, batch: 1456, loss: 0.6379431486129761\n",
      "epoch: 5, batch: 1457, loss: 0.7867381572723389\n",
      "epoch: 5, batch: 1458, loss: 0.8440884351730347\n",
      "epoch: 5, batch: 1459, loss: 0.7239609360694885\n",
      "epoch: 5, batch: 1460, loss: 0.5363982319831848\n",
      "epoch: 5, batch: 1461, loss: 0.3809400498867035\n",
      "epoch: 5, batch: 1462, loss: 0.6246141195297241\n",
      "epoch: 5, batch: 1463, loss: 1.0527011156082153\n",
      "epoch: 5, batch: 1464, loss: 0.6250413656234741\n",
      "epoch: 5, batch: 1465, loss: 0.5767225027084351\n",
      "epoch: 5, batch: 1466, loss: 0.5729047656059265\n",
      "epoch: 5, batch: 1467, loss: 0.7405880093574524\n",
      "epoch: 5, batch: 1468, loss: 0.5182942152023315\n",
      "epoch: 5, batch: 1469, loss: 0.7437608242034912\n",
      "epoch: 5, batch: 1470, loss: 0.46501997113227844\n",
      "epoch: 5, batch: 1471, loss: 0.9316543340682983\n",
      "epoch: 5, batch: 1472, loss: 0.657533586025238\n",
      "epoch: 5, batch: 1473, loss: 0.7227166295051575\n",
      "epoch: 5, batch: 1474, loss: 0.5638483762741089\n",
      "epoch: 5, batch: 1475, loss: 0.3496410548686981\n",
      "epoch: 5, batch: 1476, loss: 0.5078936815261841\n",
      "epoch: 5, batch: 1477, loss: 0.567247211933136\n",
      "epoch: 5, batch: 1478, loss: 0.3379145860671997\n",
      "epoch: 5, batch: 1479, loss: 0.573807954788208\n",
      "epoch: 5, batch: 1480, loss: 0.7610083818435669\n",
      "epoch: 5, batch: 1481, loss: 0.7761904001235962\n",
      "epoch: 5, batch: 1482, loss: 0.6478977799415588\n",
      "epoch: 5, batch: 1483, loss: 0.5531933903694153\n",
      "epoch: 5, batch: 1484, loss: 0.850227415561676\n",
      "epoch: 5, batch: 1485, loss: 0.5541876554489136\n",
      "epoch: 5, batch: 1486, loss: 0.7234035730361938\n",
      "epoch: 5, batch: 1487, loss: 0.7851647138595581\n",
      "epoch: 5, batch: 1488, loss: 0.5199759006500244\n",
      "epoch: 5, batch: 1489, loss: 0.6082981824874878\n",
      "epoch: 5, batch: 1490, loss: 0.6684156060218811\n",
      "epoch: 5, batch: 1491, loss: 0.6319584846496582\n",
      "epoch: 5, batch: 1492, loss: 0.8223392367362976\n",
      "epoch: 5, batch: 1493, loss: 0.7781456112861633\n",
      "epoch: 5, batch: 1494, loss: 0.3815650939941406\n",
      "epoch: 5, batch: 1495, loss: 0.8286962509155273\n",
      "epoch: 5, batch: 1496, loss: 0.5811947584152222\n",
      "epoch: 5, batch: 1497, loss: 0.6633147597312927\n",
      "epoch: 5, batch: 1498, loss: 0.7689802050590515\n",
      "epoch: 5, batch: 1499, loss: 0.565881073474884\n",
      "epoch: 5, batch: 1500, loss: 0.8099753856658936\n",
      "epoch: 5, batch: 1501, loss: 0.6218869686126709\n",
      "epoch: 5, batch: 1502, loss: 0.5393526554107666\n",
      "epoch: 5, batch: 1503, loss: 0.7056732177734375\n",
      "epoch: 5, batch: 1504, loss: 0.6261464953422546\n",
      "epoch: 5, batch: 1505, loss: 0.6864542365074158\n",
      "epoch: 5, batch: 1506, loss: 0.6095211505889893\n",
      "epoch: 5, batch: 1507, loss: 0.8096125721931458\n",
      "epoch: 5, batch: 1508, loss: 0.5380758047103882\n",
      "epoch: 5, batch: 1509, loss: 0.656189501285553\n",
      "epoch: 5, batch: 1510, loss: 0.6564978957176208\n",
      "epoch: 5, batch: 1511, loss: 0.7954940795898438\n",
      "epoch: 5, batch: 1512, loss: 0.849284291267395\n",
      "epoch: 5, batch: 1513, loss: 0.6522179245948792\n",
      "epoch: 5, batch: 1514, loss: 0.45738428831100464\n",
      "epoch: 5, batch: 1515, loss: 0.6430297493934631\n",
      "epoch: 5, batch: 1516, loss: 0.5962979197502136\n",
      "epoch: 5, batch: 1517, loss: 0.46500658988952637\n",
      "epoch: 5, batch: 1518, loss: 0.5251728296279907\n",
      "epoch: 5, batch: 1519, loss: 0.7039364576339722\n",
      "epoch: 5, batch: 1520, loss: 0.7614040970802307\n",
      "epoch: 5, batch: 1521, loss: 0.8869143724441528\n",
      "epoch: 5, batch: 1522, loss: 0.7836704850196838\n",
      "epoch: 5, batch: 1523, loss: 0.775246262550354\n",
      "epoch: 5, batch: 1524, loss: 0.5798064470291138\n",
      "epoch: 5, batch: 1525, loss: 0.7114031910896301\n",
      "epoch: 5, batch: 1526, loss: 0.6554437279701233\n",
      "epoch: 5, batch: 1527, loss: 0.7356353402137756\n",
      "epoch: 5, batch: 1528, loss: 0.7376481890678406\n",
      "epoch: 5, batch: 1529, loss: 0.5276914238929749\n",
      "epoch: 5, batch: 1530, loss: 0.784631073474884\n",
      "epoch: 5, batch: 1531, loss: 0.7455574870109558\n",
      "epoch: 5, batch: 1532, loss: 0.7170571088790894\n",
      "epoch: 5, batch: 1533, loss: 0.5317522883415222\n",
      "epoch: 5, batch: 1534, loss: 0.6701543927192688\n",
      "epoch: 5, batch: 1535, loss: 0.942392885684967\n",
      "epoch: 5, batch: 1536, loss: 0.59042888879776\n",
      "epoch: 5, batch: 1537, loss: 0.7122474908828735\n",
      "epoch: 5, batch: 1538, loss: 0.5984675884246826\n",
      "epoch: 5, batch: 1539, loss: 0.53401118516922\n",
      "epoch: 5, batch: 1540, loss: 0.9385608434677124\n",
      "epoch: 5, batch: 1541, loss: 0.7190120816230774\n",
      "epoch: 5, batch: 1542, loss: 0.6358823776245117\n",
      "epoch: 5, batch: 1543, loss: 0.6707378625869751\n",
      "epoch: 5, batch: 1544, loss: 0.7014127969741821\n",
      "epoch: 5, batch: 1545, loss: 0.6177814602851868\n",
      "epoch: 5, batch: 1546, loss: 0.7347456216812134\n",
      "epoch: 5, batch: 1547, loss: 0.5609736442565918\n",
      "epoch: 5, batch: 1548, loss: 0.614372968673706\n",
      "epoch: 5, batch: 1549, loss: 0.6088828444480896\n",
      "epoch: 5, batch: 1550, loss: 0.5549439787864685\n",
      "epoch: 5, batch: 1551, loss: 0.5018911957740784\n",
      "epoch: 5, batch: 1552, loss: 0.42803674936294556\n",
      "epoch: 5, batch: 1553, loss: 0.5933713912963867\n",
      "epoch: 5, batch: 1554, loss: 0.6150800585746765\n",
      "epoch: 5, batch: 1555, loss: 0.4989776611328125\n",
      "epoch: 5, batch: 1556, loss: 0.8082717657089233\n",
      "epoch: 5, batch: 1557, loss: 0.4574327766895294\n",
      "epoch: 5, batch: 1558, loss: 0.6016919612884521\n",
      "epoch: 5, batch: 1559, loss: 0.5980218648910522\n",
      "epoch: 5, batch: 1560, loss: 0.5895998477935791\n",
      "epoch: 5, batch: 1561, loss: 0.7752667665481567\n",
      "epoch: 5, batch: 1562, loss: 0.594326376914978\n",
      "epoch: 5, batch: 1563, loss: 0.6960881352424622\n",
      "epoch: 5, batch: 1564, loss: 0.5574926733970642\n",
      "epoch: 5, batch: 1565, loss: 0.8091533184051514\n",
      "epoch: 5, batch: 1566, loss: 0.7452293634414673\n",
      "epoch: 5, batch: 1567, loss: 0.5998080968856812\n",
      "epoch: 5, batch: 1568, loss: 0.7082592844963074\n",
      "epoch: 5, batch: 1569, loss: 0.5659165978431702\n",
      "epoch: 5, batch: 1570, loss: 0.7768844366073608\n",
      "epoch: 5, batch: 1571, loss: 0.7319243550300598\n",
      "epoch: 5, batch: 1572, loss: 0.7179369330406189\n",
      "epoch: 5, batch: 1573, loss: 0.5732937455177307\n",
      "epoch: 5, batch: 1574, loss: 0.48947373032569885\n",
      "epoch: 5, batch: 1575, loss: 0.5635562539100647\n",
      "epoch: 5, batch: 1576, loss: 0.6712455749511719\n",
      "epoch: 5, batch: 1577, loss: 0.8376184105873108\n",
      "epoch: 5, batch: 1578, loss: 0.4843444526195526\n",
      "epoch: 5, batch: 1579, loss: 0.6378280520439148\n",
      "epoch: 5, batch: 1580, loss: 0.847125768661499\n",
      "epoch: 5, batch: 1581, loss: 0.46787533164024353\n",
      "epoch: 5, batch: 1582, loss: 0.5762858986854553\n",
      "epoch: 5, batch: 1583, loss: 0.5963758826255798\n",
      "epoch: 5, batch: 1584, loss: 0.9001265168190002\n",
      "epoch: 5, batch: 1585, loss: 0.6705349683761597\n",
      "epoch: 5, batch: 1586, loss: 0.8090089559555054\n",
      "epoch: 5, batch: 1587, loss: 0.6264410018920898\n",
      "epoch: 5, batch: 1588, loss: 0.6565859317779541\n",
      "epoch: 5, batch: 1589, loss: 0.6352760195732117\n",
      "epoch: 5, batch: 1590, loss: 0.6017234325408936\n",
      "epoch: 5, batch: 1591, loss: 0.7513068914413452\n",
      "epoch: 5, batch: 1592, loss: 0.5814764499664307\n",
      "epoch: 5, batch: 1593, loss: 0.681625485420227\n",
      "epoch: 5, batch: 1594, loss: 0.666149377822876\n",
      "epoch: 5, batch: 1595, loss: 0.8268754482269287\n",
      "epoch: 5, batch: 1596, loss: 0.6429887413978577\n",
      "epoch: 5, batch: 1597, loss: 0.6052716374397278\n",
      "epoch: 5, batch: 1598, loss: 0.668974757194519\n",
      "epoch: 5, batch: 1599, loss: 0.5629816055297852\n",
      "epoch: 5, batch: 1600, loss: 0.5319806337356567\n",
      "epoch: 5, batch: 1601, loss: 1.0445078611373901\n",
      "epoch: 5, batch: 1602, loss: 0.6847420930862427\n",
      "epoch: 5, batch: 1603, loss: 0.44427284598350525\n",
      "epoch: 5, batch: 1604, loss: 0.6645420789718628\n",
      "epoch: 5, batch: 1605, loss: 0.7105733156204224\n",
      "epoch: 5, batch: 1606, loss: 0.8290103077888489\n",
      "epoch: 5, batch: 1607, loss: 0.9503092765808105\n",
      "epoch: 5, batch: 1608, loss: 0.6365094184875488\n",
      "epoch: 5, batch: 1609, loss: 0.4914401173591614\n",
      "epoch: 5, batch: 1610, loss: 0.7896206974983215\n",
      "epoch: 5, batch: 1611, loss: 0.5063862204551697\n",
      "epoch: 5, batch: 1612, loss: 0.5611635446548462\n",
      "epoch: 5, batch: 1613, loss: 0.5744174122810364\n",
      "epoch: 5, batch: 1614, loss: 0.789882242679596\n",
      "epoch: 5, batch: 1615, loss: 0.5125048756599426\n",
      "epoch: 5, batch: 1616, loss: 0.9196444749832153\n",
      "epoch: 5, batch: 1617, loss: 0.685664713382721\n",
      "epoch: 5, batch: 1618, loss: 0.8193621039390564\n",
      "epoch: 5, batch: 1619, loss: 0.6534030437469482\n",
      "epoch: 5, batch: 1620, loss: 0.6371573209762573\n",
      "epoch: 5, batch: 1621, loss: 0.552431583404541\n",
      "epoch: 5, batch: 1622, loss: 0.46601739525794983\n",
      "epoch: 5, batch: 1623, loss: 0.6140553951263428\n",
      "epoch: 5, batch: 1624, loss: 0.6408731937408447\n",
      "epoch: 5, batch: 1625, loss: 0.6259764432907104\n",
      "epoch: 5, batch: 1626, loss: 0.44265249371528625\n",
      "epoch: 5, batch: 1627, loss: 0.30144166946411133\n",
      "epoch: 5, batch: 1628, loss: 0.7565035820007324\n",
      "epoch: 5, batch: 1629, loss: 0.6214524507522583\n",
      "epoch: 5, batch: 1630, loss: 0.7381452322006226\n",
      "epoch: 5, batch: 1631, loss: 0.7479733824729919\n",
      "epoch: 5, batch: 1632, loss: 0.7214295864105225\n",
      "epoch: 5, batch: 1633, loss: 0.5997215509414673\n",
      "epoch: 5, batch: 1634, loss: 0.7314206957817078\n",
      "epoch: 5, batch: 1635, loss: 0.5640586614608765\n",
      "epoch: 5, batch: 1636, loss: 0.4793262779712677\n",
      "epoch: 5, batch: 1637, loss: 0.670525074005127\n",
      "epoch: 5, batch: 1638, loss: 0.4305703043937683\n",
      "epoch: 5, batch: 1639, loss: 0.5917814373970032\n",
      "epoch: 5, batch: 1640, loss: 1.148450493812561\n",
      "epoch: 5, batch: 1641, loss: 0.7796179056167603\n",
      "epoch: 5, batch: 1642, loss: 0.8756682276725769\n",
      "epoch: 5, batch: 1643, loss: 0.6244155764579773\n",
      "epoch: 5, batch: 1644, loss: 0.5194411873817444\n",
      "epoch: 5, batch: 1645, loss: 0.4493636190891266\n",
      "epoch: 5, batch: 1646, loss: 0.7503859996795654\n",
      "epoch: 5, batch: 1647, loss: 0.6163790822029114\n",
      "epoch: 5, batch: 1648, loss: 0.47268998622894287\n",
      "epoch: 5, batch: 1649, loss: 0.5081300139427185\n",
      "epoch: 5, batch: 1650, loss: 0.662941038608551\n",
      "epoch: 5, batch: 1651, loss: 0.4329811930656433\n",
      "epoch: 5, batch: 1652, loss: 0.5046983957290649\n",
      "epoch: 5, batch: 1653, loss: 0.6370865702629089\n",
      "epoch: 5, batch: 1654, loss: 0.5727398991584778\n",
      "epoch: 5, batch: 1655, loss: 0.4339386224746704\n",
      "epoch: 5, batch: 1656, loss: 0.5396928787231445\n",
      "epoch: 5, batch: 1657, loss: 0.6427614092826843\n",
      "epoch: 5, batch: 1658, loss: 0.6345064640045166\n",
      "epoch: 5, batch: 1659, loss: 0.5830090045928955\n",
      "epoch: 5, batch: 1660, loss: 0.6046745181083679\n",
      "epoch: 5, batch: 1661, loss: 0.5480712056159973\n",
      "epoch: 5, batch: 1662, loss: 0.5607904195785522\n",
      "epoch: 5, batch: 1663, loss: 0.7425322532653809\n",
      "epoch: 5, batch: 1664, loss: 0.6750950813293457\n",
      "epoch: 5, batch: 1665, loss: 0.6446663737297058\n",
      "epoch: 5, batch: 1666, loss: 0.6279180645942688\n",
      "epoch: 5, batch: 1667, loss: 0.89874267578125\n",
      "epoch: 5, batch: 1668, loss: 0.9449514746665955\n",
      "epoch: 5, batch: 1669, loss: 0.5922482013702393\n",
      "epoch: 5, batch: 1670, loss: 0.8626984357833862\n",
      "epoch: 5, batch: 1671, loss: 0.6394847631454468\n",
      "epoch: 5, batch: 1672, loss: 0.568183422088623\n",
      "epoch: 5, batch: 1673, loss: 0.6167473196983337\n",
      "epoch: 5, batch: 1674, loss: 0.5867308378219604\n",
      "epoch: 5, batch: 1675, loss: 0.734541118144989\n",
      "epoch: 5, batch: 1676, loss: 0.5406158566474915\n",
      "epoch: 5, batch: 1677, loss: 0.6810102462768555\n",
      "epoch: 5, batch: 1678, loss: 0.6895747780799866\n",
      "epoch: 5, batch: 1679, loss: 0.5015665292739868\n",
      "epoch: 5, batch: 1680, loss: 0.7125488519668579\n",
      "epoch: 5, batch: 1681, loss: 0.8894904851913452\n",
      "epoch: 5, batch: 1682, loss: 0.7532835006713867\n",
      "epoch: 5, batch: 1683, loss: 0.6978090405464172\n",
      "epoch: 5, batch: 1684, loss: 0.6260878443717957\n",
      "epoch: 5, batch: 1685, loss: 0.40479519963264465\n",
      "epoch: 5, batch: 1686, loss: 0.6491909027099609\n",
      "epoch: 5, batch: 1687, loss: 0.5836074948310852\n",
      "epoch: 5, batch: 1688, loss: 0.6218443512916565\n",
      "epoch: 5, batch: 1689, loss: 0.7937159538269043\n",
      "epoch: 5, batch: 1690, loss: 0.6142867207527161\n",
      "epoch: 5, batch: 1691, loss: 0.5463915467262268\n",
      "epoch: 5, batch: 1692, loss: 0.5882697701454163\n",
      "epoch: 5, batch: 1693, loss: 0.9554911255836487\n",
      "epoch: 5, batch: 1694, loss: 0.525294840335846\n",
      "epoch: 5, batch: 1695, loss: 0.6194301247596741\n",
      "epoch: 5, batch: 1696, loss: 0.6116081476211548\n",
      "epoch: 5, batch: 1697, loss: 0.6834037899971008\n",
      "epoch: 5, batch: 1698, loss: 0.45234981179237366\n",
      "epoch: 5, batch: 1699, loss: 0.49866145849227905\n",
      "epoch: 5, batch: 1700, loss: 0.3997790813446045\n",
      "epoch: 5, batch: 1701, loss: 0.6775875091552734\n",
      "epoch: 5, batch: 1702, loss: 0.7155738472938538\n",
      "epoch: 5, batch: 1703, loss: 0.6205302476882935\n",
      "epoch: 5, batch: 1704, loss: 0.6049112677574158\n",
      "epoch: 5, batch: 1705, loss: 0.7614251375198364\n",
      "epoch: 5, batch: 1706, loss: 0.5991625189781189\n",
      "epoch: 5, batch: 1707, loss: 0.4321029782295227\n",
      "epoch: 5, batch: 1708, loss: 0.5115280151367188\n",
      "epoch: 5, batch: 1709, loss: 0.6825991272926331\n",
      "epoch: 5, batch: 1710, loss: 0.4542548656463623\n",
      "epoch: 5, batch: 1711, loss: 0.8619845509529114\n",
      "epoch: 5, batch: 1712, loss: 0.6994600296020508\n",
      "epoch: 5, batch: 1713, loss: 0.7900204062461853\n",
      "epoch: 5, batch: 1714, loss: 0.7487373948097229\n",
      "epoch: 5, batch: 1715, loss: 0.6647592782974243\n",
      "epoch: 5, batch: 1716, loss: 0.7136465311050415\n",
      "epoch: 5, batch: 1717, loss: 0.6660539507865906\n",
      "epoch: 5, batch: 1718, loss: 0.8935588002204895\n",
      "epoch: 5, batch: 1719, loss: 0.47195518016815186\n",
      "epoch: 5, batch: 1720, loss: 0.8375094532966614\n",
      "epoch: 5, batch: 1721, loss: 0.6165249347686768\n",
      "epoch: 5, batch: 1722, loss: 0.6915003061294556\n",
      "epoch: 5, batch: 1723, loss: 0.4827808439731598\n",
      "epoch: 5, batch: 1724, loss: 0.5768548846244812\n",
      "epoch: 5, batch: 1725, loss: 0.6626320481300354\n",
      "epoch: 5, batch: 1726, loss: 0.6412661671638489\n",
      "epoch: 5, batch: 1727, loss: 0.7164208889007568\n",
      "epoch: 5, batch: 1728, loss: 0.8406691551208496\n",
      "epoch: 5, batch: 1729, loss: 0.5560305714607239\n",
      "epoch: 5, batch: 1730, loss: 0.4866378605365753\n",
      "epoch: 5, batch: 1731, loss: 0.8678402900695801\n",
      "epoch: 5, batch: 1732, loss: 0.8857675194740295\n",
      "epoch: 5, batch: 1733, loss: 0.6548089385032654\n",
      "epoch: 5, batch: 1734, loss: 0.8487430214881897\n",
      "epoch: 5, batch: 1735, loss: 0.5471615791320801\n",
      "epoch: 5, batch: 1736, loss: 0.7192860841751099\n",
      "epoch: 5, batch: 1737, loss: 0.6935533285140991\n",
      "epoch: 5, batch: 1738, loss: 0.4765965938568115\n",
      "epoch: 5, batch: 1739, loss: 0.6600912809371948\n",
      "epoch: 5, batch: 1740, loss: 0.6712937355041504\n",
      "epoch: 5, batch: 1741, loss: 0.5825081467628479\n",
      "epoch: 5, batch: 1742, loss: 0.3985038101673126\n",
      "epoch: 5, batch: 1743, loss: 0.5837160348892212\n",
      "epoch: 5, batch: 1744, loss: 0.5486773252487183\n",
      "epoch: 5, batch: 1745, loss: 0.6722645163536072\n",
      "epoch: 5, batch: 1746, loss: 0.5187277793884277\n",
      "epoch: 5, batch: 1747, loss: 0.7390891909599304\n",
      "epoch: 5, batch: 1748, loss: 0.5930289030075073\n",
      "epoch: 5, batch: 1749, loss: 0.633039653301239\n",
      "epoch: 5, batch: 1750, loss: 0.6153496503829956\n",
      "epoch: 5, batch: 1751, loss: 0.6931617259979248\n",
      "epoch: 5, batch: 1752, loss: 0.6135223507881165\n",
      "epoch: 5, batch: 1753, loss: 0.4950929284095764\n",
      "epoch: 5, batch: 1754, loss: 0.5100817680358887\n",
      "epoch: 5, batch: 1755, loss: 0.8624582290649414\n",
      "epoch: 5, batch: 1756, loss: 0.6625896096229553\n",
      "epoch: 5, batch: 1757, loss: 0.4498395621776581\n",
      "epoch: 5, batch: 1758, loss: 0.6095734238624573\n",
      "epoch: 5, batch: 1759, loss: 0.5154104828834534\n",
      "epoch: 5, batch: 1760, loss: 0.7601507306098938\n",
      "epoch: 5, batch: 1761, loss: 0.49721065163612366\n",
      "epoch: 5, batch: 1762, loss: 0.6061586737632751\n",
      "epoch: 5, batch: 1763, loss: 0.6260693073272705\n",
      "epoch: 5, batch: 1764, loss: 0.48091232776641846\n",
      "epoch: 5, batch: 1765, loss: 0.4689777195453644\n",
      "epoch: 5, batch: 1766, loss: 0.6217233538627625\n",
      "epoch: 5, batch: 1767, loss: 0.5227519869804382\n",
      "epoch: 5, batch: 1768, loss: 0.9473966956138611\n",
      "epoch: 5, batch: 1769, loss: 0.6239911913871765\n",
      "epoch: 5, batch: 1770, loss: 0.667933464050293\n",
      "epoch: 5, batch: 1771, loss: 0.5965505242347717\n",
      "epoch: 5, batch: 1772, loss: 0.9646263122558594\n",
      "epoch: 5, batch: 1773, loss: 0.6425652503967285\n",
      "epoch: 5, batch: 1774, loss: 0.689247727394104\n",
      "epoch: 5, batch: 1775, loss: 0.43361252546310425\n",
      "epoch: 5, batch: 1776, loss: 0.5549014806747437\n",
      "epoch: 5, batch: 1777, loss: 0.8312965035438538\n",
      "epoch: 5, batch: 1778, loss: 0.6614344716072083\n",
      "epoch: 5, batch: 1779, loss: 0.5752291083335876\n",
      "epoch: 5, batch: 1780, loss: 0.606055736541748\n",
      "epoch: 5, batch: 1781, loss: 0.4532018005847931\n",
      "epoch: 5, batch: 1782, loss: 0.6713032126426697\n",
      "epoch: 5, batch: 1783, loss: 0.4787730872631073\n",
      "epoch: 5, batch: 1784, loss: 0.6222724318504333\n",
      "epoch: 5, batch: 1785, loss: 0.6514444947242737\n",
      "epoch: 5, batch: 1786, loss: 0.824948251247406\n",
      "epoch: 5, batch: 1787, loss: 0.7649641036987305\n",
      "epoch: 5, batch: 1788, loss: 0.649315357208252\n",
      "epoch: 5, batch: 1789, loss: 0.578479528427124\n",
      "epoch: 5, batch: 1790, loss: 0.38608789443969727\n",
      "epoch: 5, batch: 1791, loss: 0.6377529501914978\n",
      "epoch: 5, batch: 1792, loss: 0.9330000877380371\n",
      "epoch: 5, batch: 1793, loss: 0.88783198595047\n",
      "epoch: 5, batch: 1794, loss: 0.4377923309803009\n",
      "epoch: 5, batch: 1795, loss: 0.5775800347328186\n",
      "epoch: 5, batch: 1796, loss: 0.8290428519248962\n",
      "epoch: 5, batch: 1797, loss: 0.6005116701126099\n",
      "epoch: 5, batch: 1798, loss: 0.4443347454071045\n",
      "epoch: 5, batch: 1799, loss: 0.788206160068512\n",
      "epoch: 5, batch: 1800, loss: 0.7013187408447266\n",
      "epoch: 5, batch: 1801, loss: 0.5885488986968994\n",
      "epoch: 5, batch: 1802, loss: 0.6354727745056152\n",
      "epoch: 5, batch: 1803, loss: 0.6685625314712524\n",
      "epoch: 5, batch: 1804, loss: 0.7734203934669495\n",
      "epoch: 5, batch: 1805, loss: 0.7137792110443115\n",
      "epoch: 5, batch: 1806, loss: 0.5407775044441223\n",
      "epoch: 5, batch: 1807, loss: 0.472895085811615\n",
      "epoch: 5, batch: 1808, loss: 0.9774669408798218\n",
      "epoch: 5, batch: 1809, loss: 0.5286831855773926\n",
      "epoch: 5, batch: 1810, loss: 0.6287058591842651\n",
      "epoch: 5, batch: 1811, loss: 0.5561831593513489\n",
      "epoch: 5, batch: 1812, loss: 0.6291576027870178\n",
      "epoch: 5, batch: 1813, loss: 0.5072515606880188\n",
      "epoch: 5, batch: 1814, loss: 0.7559637427330017\n",
      "epoch: 5, batch: 1815, loss: 0.6507524847984314\n",
      "epoch: 5, batch: 1816, loss: 0.5367692708969116\n",
      "epoch: 5, batch: 1817, loss: 0.659325361251831\n",
      "epoch: 5, batch: 1818, loss: 0.6719597578048706\n",
      "epoch: 5, batch: 1819, loss: 0.47932466864585876\n",
      "epoch: 5, batch: 1820, loss: 0.5115163922309875\n",
      "epoch: 5, batch: 1821, loss: 0.6374365091323853\n",
      "epoch: 5, batch: 1822, loss: 0.6501827239990234\n",
      "epoch: 5, batch: 1823, loss: 0.7314732074737549\n",
      "epoch: 5, batch: 1824, loss: 0.634772777557373\n",
      "epoch: 5, batch: 1825, loss: 0.4995546042919159\n",
      "epoch: 5, batch: 1826, loss: 0.7925596237182617\n",
      "epoch: 5, batch: 1827, loss: 0.779913604259491\n",
      "epoch: 5, batch: 1828, loss: 0.5488680005073547\n",
      "epoch: 5, batch: 1829, loss: 0.7180835604667664\n",
      "epoch: 5, batch: 1830, loss: 0.5954185724258423\n",
      "epoch: 5, batch: 1831, loss: 0.6133166551589966\n",
      "epoch: 5, batch: 1832, loss: 0.6433833837509155\n",
      "epoch: 5, batch: 1833, loss: 0.5250681638717651\n",
      "epoch: 5, batch: 1834, loss: 0.5803294777870178\n",
      "epoch: 5, batch: 1835, loss: 0.620704710483551\n",
      "epoch: 5, batch: 1836, loss: 0.5694704055786133\n",
      "epoch: 5, batch: 1837, loss: 0.5471630692481995\n",
      "epoch: 5, batch: 1838, loss: 0.6127898097038269\n",
      "epoch: 5, batch: 1839, loss: 0.9526482224464417\n",
      "epoch: 5, batch: 1840, loss: 0.8538105487823486\n",
      "epoch: 5, batch: 1841, loss: 0.7644597291946411\n",
      "epoch: 5, batch: 1842, loss: 0.7025535106658936\n",
      "epoch: 5, batch: 1843, loss: 0.5493526458740234\n",
      "epoch: 5, batch: 1844, loss: 0.6934356093406677\n",
      "epoch: 5, batch: 1845, loss: 0.6495352983474731\n",
      "epoch: 5, batch: 1846, loss: 0.45311495661735535\n",
      "epoch: 5, batch: 1847, loss: 0.7454836368560791\n",
      "epoch: 5, batch: 1848, loss: 0.5955606698989868\n",
      "epoch: 5, batch: 1849, loss: 0.506966769695282\n",
      "epoch: 5, batch: 1850, loss: 0.7931844592094421\n",
      "epoch: 5, batch: 1851, loss: 0.6633485555648804\n",
      "epoch: 5, batch: 1852, loss: 0.8983956575393677\n",
      "epoch: 5, batch: 1853, loss: 0.6247612237930298\n",
      "epoch: 5, batch: 1854, loss: 0.5926703810691833\n",
      "epoch: 5, batch: 1855, loss: 0.9692357778549194\n",
      "epoch: 5, batch: 1856, loss: 0.6264318823814392\n",
      "epoch: 5, batch: 1857, loss: 0.4327331483364105\n",
      "epoch: 5, batch: 1858, loss: 0.6946266293525696\n",
      "epoch: 5, batch: 1859, loss: 0.7222978472709656\n",
      "epoch: 5, batch: 1860, loss: 0.587249755859375\n",
      "epoch: 5, batch: 1861, loss: 0.9181968569755554\n",
      "epoch: 5, batch: 1862, loss: 0.6953961849212646\n",
      "epoch: 5, batch: 1863, loss: 0.6743767261505127\n",
      "epoch: 5, batch: 1864, loss: 0.5323171019554138\n",
      "epoch: 5, batch: 1865, loss: 0.7652446031570435\n",
      "epoch: 5, batch: 1866, loss: 0.6316426396369934\n",
      "epoch: 5, batch: 1867, loss: 0.7199946045875549\n",
      "epoch: 5, batch: 1868, loss: 0.6535460352897644\n",
      "epoch: 5, batch: 1869, loss: 0.4798981547355652\n",
      "epoch: 5, batch: 1870, loss: 0.7540337443351746\n",
      "epoch: 5, batch: 1871, loss: 0.6548190116882324\n",
      "epoch: 5, batch: 1872, loss: 0.7990612983703613\n",
      "epoch: 5, batch: 1873, loss: 0.6548157930374146\n",
      "epoch: 5, batch: 1874, loss: 0.541632890701294\n",
      "epoch: 6, batch: 0, loss: 0.6277601718902588\n",
      "epoch: 6, batch: 1, loss: 0.7455446720123291\n",
      "epoch: 6, batch: 2, loss: 0.6456573605537415\n",
      "epoch: 6, batch: 3, loss: 0.7642695307731628\n",
      "epoch: 6, batch: 4, loss: 0.5590775012969971\n",
      "epoch: 6, batch: 5, loss: 0.6612000465393066\n",
      "epoch: 6, batch: 6, loss: 0.5608789324760437\n",
      "epoch: 6, batch: 7, loss: 0.6645072102546692\n",
      "epoch: 6, batch: 8, loss: 0.7771131992340088\n",
      "epoch: 6, batch: 9, loss: 0.5266104340553284\n",
      "epoch: 6, batch: 10, loss: 0.4146937429904938\n",
      "epoch: 6, batch: 11, loss: 0.9847975373268127\n",
      "epoch: 6, batch: 12, loss: 0.5130462646484375\n",
      "epoch: 6, batch: 13, loss: 0.7585203051567078\n",
      "epoch: 6, batch: 14, loss: 0.41086360812187195\n",
      "epoch: 6, batch: 15, loss: 0.5685140490531921\n",
      "epoch: 6, batch: 16, loss: 0.7487877607345581\n",
      "epoch: 6, batch: 17, loss: 0.5776317119598389\n",
      "epoch: 6, batch: 18, loss: 0.7065226435661316\n",
      "epoch: 6, batch: 19, loss: 0.6785749793052673\n",
      "epoch: 6, batch: 20, loss: 0.8540663719177246\n",
      "epoch: 6, batch: 21, loss: 0.7515488266944885\n",
      "epoch: 6, batch: 22, loss: 0.6228637099266052\n",
      "epoch: 6, batch: 23, loss: 0.4971725344657898\n",
      "epoch: 6, batch: 24, loss: 0.435040682554245\n",
      "epoch: 6, batch: 25, loss: 0.5638554692268372\n",
      "epoch: 6, batch: 26, loss: 0.5915595889091492\n",
      "epoch: 6, batch: 27, loss: 0.6865211129188538\n",
      "epoch: 6, batch: 28, loss: 0.5350204706192017\n",
      "epoch: 6, batch: 29, loss: 0.48523712158203125\n",
      "epoch: 6, batch: 30, loss: 0.5859973430633545\n",
      "epoch: 6, batch: 31, loss: 0.6139492392539978\n",
      "epoch: 6, batch: 32, loss: 0.517964780330658\n",
      "epoch: 6, batch: 33, loss: 0.45441102981567383\n",
      "epoch: 6, batch: 34, loss: 0.7456132173538208\n",
      "epoch: 6, batch: 35, loss: 0.544732391834259\n",
      "epoch: 6, batch: 36, loss: 0.6539097428321838\n",
      "epoch: 6, batch: 37, loss: 0.7708633542060852\n",
      "epoch: 6, batch: 38, loss: 0.4794315695762634\n",
      "epoch: 6, batch: 39, loss: 0.7352819442749023\n",
      "epoch: 6, batch: 40, loss: 0.4361211657524109\n",
      "epoch: 6, batch: 41, loss: 0.5497516393661499\n",
      "epoch: 6, batch: 42, loss: 0.8755690455436707\n",
      "epoch: 6, batch: 43, loss: 0.48762160539627075\n",
      "epoch: 6, batch: 44, loss: 0.47455894947052\n",
      "epoch: 6, batch: 45, loss: 0.7803149223327637\n",
      "epoch: 6, batch: 46, loss: 0.8087226152420044\n",
      "epoch: 6, batch: 47, loss: 0.8732131719589233\n",
      "epoch: 6, batch: 48, loss: 0.5694124102592468\n",
      "epoch: 6, batch: 49, loss: 0.7542043924331665\n",
      "epoch: 6, batch: 50, loss: 0.6427161693572998\n",
      "epoch: 6, batch: 51, loss: 0.6857029795646667\n",
      "epoch: 6, batch: 52, loss: 0.7103003859519958\n",
      "epoch: 6, batch: 53, loss: 0.8208818435668945\n",
      "epoch: 6, batch: 54, loss: 0.6105180382728577\n",
      "epoch: 6, batch: 55, loss: 0.7096168994903564\n",
      "epoch: 6, batch: 56, loss: 0.5872140526771545\n",
      "epoch: 6, batch: 57, loss: 0.5668284296989441\n",
      "epoch: 6, batch: 58, loss: 0.6074933409690857\n",
      "epoch: 6, batch: 59, loss: 0.5783693790435791\n",
      "epoch: 6, batch: 60, loss: 0.835081160068512\n",
      "epoch: 6, batch: 61, loss: 0.46101114153862\n",
      "epoch: 6, batch: 62, loss: 0.5628626942634583\n",
      "epoch: 6, batch: 63, loss: 0.7818200588226318\n",
      "epoch: 6, batch: 64, loss: 0.582798421382904\n",
      "epoch: 6, batch: 65, loss: 0.7844261527061462\n",
      "epoch: 6, batch: 66, loss: 0.669779360294342\n",
      "epoch: 6, batch: 67, loss: 0.6435797214508057\n",
      "epoch: 6, batch: 68, loss: 0.7833396792411804\n",
      "epoch: 6, batch: 69, loss: 0.5283088088035583\n",
      "epoch: 6, batch: 70, loss: 0.6386088132858276\n",
      "epoch: 6, batch: 71, loss: 0.6177085041999817\n",
      "epoch: 6, batch: 72, loss: 0.7142846584320068\n",
      "epoch: 6, batch: 73, loss: 0.599571704864502\n",
      "epoch: 6, batch: 74, loss: 0.5973467230796814\n",
      "epoch: 6, batch: 75, loss: 0.5405321717262268\n",
      "epoch: 6, batch: 76, loss: 0.9836151003837585\n",
      "epoch: 6, batch: 77, loss: 0.5839492082595825\n",
      "epoch: 6, batch: 78, loss: 0.9244999289512634\n",
      "epoch: 6, batch: 79, loss: 0.862688422203064\n",
      "epoch: 6, batch: 80, loss: 0.6707942485809326\n",
      "epoch: 6, batch: 81, loss: 0.787554919719696\n",
      "epoch: 6, batch: 82, loss: 0.6966114044189453\n",
      "epoch: 6, batch: 83, loss: 0.5106667876243591\n",
      "epoch: 6, batch: 84, loss: 0.5645446181297302\n",
      "epoch: 6, batch: 85, loss: 0.7111228704452515\n",
      "epoch: 6, batch: 86, loss: 0.5845988988876343\n",
      "epoch: 6, batch: 87, loss: 0.8979091644287109\n",
      "epoch: 6, batch: 88, loss: 0.6813976168632507\n",
      "epoch: 6, batch: 89, loss: 0.5311475992202759\n",
      "epoch: 6, batch: 90, loss: 0.6344835758209229\n",
      "epoch: 6, batch: 91, loss: 0.6388853192329407\n",
      "epoch: 6, batch: 92, loss: 0.5016223192214966\n",
      "epoch: 6, batch: 93, loss: 0.5092755556106567\n",
      "epoch: 6, batch: 94, loss: 0.6057406067848206\n",
      "epoch: 6, batch: 95, loss: 0.898650586605072\n",
      "epoch: 6, batch: 96, loss: 0.6167052984237671\n",
      "epoch: 6, batch: 97, loss: 0.5693378448486328\n",
      "epoch: 6, batch: 98, loss: 0.8285617232322693\n",
      "epoch: 6, batch: 99, loss: 0.6971613764762878\n",
      "epoch: 6, batch: 100, loss: 0.5842027068138123\n",
      "epoch: 6, batch: 101, loss: 0.6417897939682007\n",
      "epoch: 6, batch: 102, loss: 0.5323140621185303\n",
      "epoch: 6, batch: 103, loss: 0.5776665806770325\n",
      "epoch: 6, batch: 104, loss: 0.4760645031929016\n",
      "epoch: 6, batch: 105, loss: 0.530636727809906\n",
      "epoch: 6, batch: 106, loss: 0.8021606206893921\n",
      "epoch: 6, batch: 107, loss: 0.6470319032669067\n",
      "epoch: 6, batch: 108, loss: 0.754075288772583\n",
      "epoch: 6, batch: 109, loss: 0.6463209986686707\n",
      "epoch: 6, batch: 110, loss: 0.5356213450431824\n",
      "epoch: 6, batch: 111, loss: 0.9572334289550781\n",
      "epoch: 6, batch: 112, loss: 0.4886811375617981\n",
      "epoch: 6, batch: 113, loss: 0.4659174382686615\n",
      "epoch: 6, batch: 114, loss: 0.5500186085700989\n",
      "epoch: 6, batch: 115, loss: 0.4572031497955322\n",
      "epoch: 6, batch: 116, loss: 0.3838863670825958\n",
      "epoch: 6, batch: 117, loss: 0.6729581952095032\n",
      "epoch: 6, batch: 118, loss: 0.6794446706771851\n",
      "epoch: 6, batch: 119, loss: 0.5965520739555359\n",
      "epoch: 6, batch: 120, loss: 0.8828291296958923\n",
      "epoch: 6, batch: 121, loss: 0.6674187779426575\n",
      "epoch: 6, batch: 122, loss: 0.5773880481719971\n",
      "epoch: 6, batch: 123, loss: 0.48044997453689575\n",
      "epoch: 6, batch: 124, loss: 0.8084084391593933\n",
      "epoch: 6, batch: 125, loss: 0.7359509468078613\n",
      "epoch: 6, batch: 126, loss: 0.5945599675178528\n",
      "epoch: 6, batch: 127, loss: 0.4943685829639435\n",
      "epoch: 6, batch: 128, loss: 0.6609174609184265\n",
      "epoch: 6, batch: 129, loss: 0.749836266040802\n",
      "epoch: 6, batch: 130, loss: 0.47260913252830505\n",
      "epoch: 6, batch: 131, loss: 0.5988632440567017\n",
      "epoch: 6, batch: 132, loss: 0.6952123641967773\n",
      "epoch: 6, batch: 133, loss: 0.7947799563407898\n",
      "epoch: 6, batch: 134, loss: 0.604961633682251\n",
      "epoch: 6, batch: 135, loss: 0.5235622525215149\n",
      "epoch: 6, batch: 136, loss: 0.6486684083938599\n",
      "epoch: 6, batch: 137, loss: 0.8736916184425354\n",
      "epoch: 6, batch: 138, loss: 0.4421239197254181\n",
      "epoch: 6, batch: 139, loss: 0.7066599726676941\n",
      "epoch: 6, batch: 140, loss: 0.8559884428977966\n",
      "epoch: 6, batch: 141, loss: 0.4856351613998413\n",
      "epoch: 6, batch: 142, loss: 0.6274837255477905\n",
      "epoch: 6, batch: 143, loss: 0.6122570633888245\n",
      "epoch: 6, batch: 144, loss: 0.5353107452392578\n",
      "epoch: 6, batch: 145, loss: 0.7348648309707642\n",
      "epoch: 6, batch: 146, loss: 0.45194223523139954\n",
      "epoch: 6, batch: 147, loss: 0.682027280330658\n",
      "epoch: 6, batch: 148, loss: 0.5369923114776611\n",
      "epoch: 6, batch: 149, loss: 0.6295713186264038\n",
      "epoch: 6, batch: 150, loss: 0.655076801776886\n",
      "epoch: 6, batch: 151, loss: 0.6348772644996643\n",
      "epoch: 6, batch: 152, loss: 0.8509379029273987\n",
      "epoch: 6, batch: 153, loss: 0.7363715767860413\n",
      "epoch: 6, batch: 154, loss: 0.39953845739364624\n",
      "epoch: 6, batch: 155, loss: 0.49782827496528625\n",
      "epoch: 6, batch: 156, loss: 0.5131350755691528\n",
      "epoch: 6, batch: 157, loss: 0.5128090977668762\n",
      "epoch: 6, batch: 158, loss: 0.6769669651985168\n",
      "epoch: 6, batch: 159, loss: 0.46538206934928894\n",
      "epoch: 6, batch: 160, loss: 0.8152510523796082\n",
      "epoch: 6, batch: 161, loss: 0.5317832827568054\n",
      "epoch: 6, batch: 162, loss: 0.6725172996520996\n",
      "epoch: 6, batch: 163, loss: 0.4403526782989502\n",
      "epoch: 6, batch: 164, loss: 0.45450955629348755\n",
      "epoch: 6, batch: 165, loss: 0.46079790592193604\n",
      "epoch: 6, batch: 166, loss: 0.5779647827148438\n",
      "epoch: 6, batch: 167, loss: 0.7308623790740967\n",
      "epoch: 6, batch: 168, loss: 0.7141757607460022\n",
      "epoch: 6, batch: 169, loss: 0.5900897979736328\n",
      "epoch: 6, batch: 170, loss: 0.7372812032699585\n",
      "epoch: 6, batch: 171, loss: 0.7263175845146179\n",
      "epoch: 6, batch: 172, loss: 0.39641231298446655\n",
      "epoch: 6, batch: 173, loss: 0.7930219173431396\n",
      "epoch: 6, batch: 174, loss: 0.4443202614784241\n",
      "epoch: 6, batch: 175, loss: 0.5168163776397705\n",
      "epoch: 6, batch: 176, loss: 0.6017245650291443\n",
      "epoch: 6, batch: 177, loss: 0.6621127128601074\n",
      "epoch: 6, batch: 178, loss: 0.6085032820701599\n",
      "epoch: 6, batch: 179, loss: 0.7780668139457703\n",
      "epoch: 6, batch: 180, loss: 0.6712959408760071\n",
      "epoch: 6, batch: 181, loss: 0.5621837377548218\n",
      "epoch: 6, batch: 182, loss: 0.7392864227294922\n",
      "epoch: 6, batch: 183, loss: 0.40801599621772766\n",
      "epoch: 6, batch: 184, loss: 0.6201882362365723\n",
      "epoch: 6, batch: 185, loss: 0.6511145830154419\n",
      "epoch: 6, batch: 186, loss: 0.8287292122840881\n",
      "epoch: 6, batch: 187, loss: 0.4198575019836426\n",
      "epoch: 6, batch: 188, loss: 0.8379660248756409\n",
      "epoch: 6, batch: 189, loss: 0.6276747584342957\n",
      "epoch: 6, batch: 190, loss: 0.5775256752967834\n",
      "epoch: 6, batch: 191, loss: 0.738707959651947\n",
      "epoch: 6, batch: 192, loss: 0.7524573802947998\n",
      "epoch: 6, batch: 193, loss: 0.5989071726799011\n",
      "epoch: 6, batch: 194, loss: 0.6368028521537781\n",
      "epoch: 6, batch: 195, loss: 0.48856428265571594\n",
      "epoch: 6, batch: 196, loss: 0.5169897079467773\n",
      "epoch: 6, batch: 197, loss: 0.4838326573371887\n",
      "epoch: 6, batch: 198, loss: 0.544511079788208\n",
      "epoch: 6, batch: 199, loss: 0.7371098399162292\n",
      "epoch: 6, batch: 200, loss: 0.6993525624275208\n",
      "epoch: 6, batch: 201, loss: 0.6101022958755493\n",
      "epoch: 6, batch: 202, loss: 0.49224525690078735\n",
      "epoch: 6, batch: 203, loss: 0.7321062684059143\n",
      "epoch: 6, batch: 204, loss: 0.7626352906227112\n",
      "epoch: 6, batch: 205, loss: 0.7362928986549377\n",
      "epoch: 6, batch: 206, loss: 0.5094829201698303\n",
      "epoch: 6, batch: 207, loss: 0.7399346232414246\n",
      "epoch: 6, batch: 208, loss: 0.6557300686836243\n",
      "epoch: 6, batch: 209, loss: 0.5260460376739502\n",
      "epoch: 6, batch: 210, loss: 0.5620232224464417\n",
      "epoch: 6, batch: 211, loss: 0.4953935444355011\n",
      "epoch: 6, batch: 212, loss: 0.6658541560173035\n",
      "epoch: 6, batch: 213, loss: 0.6694703102111816\n",
      "epoch: 6, batch: 214, loss: 0.8079580068588257\n",
      "epoch: 6, batch: 215, loss: 0.4805643558502197\n",
      "epoch: 6, batch: 216, loss: 0.7425419688224792\n",
      "epoch: 6, batch: 217, loss: 0.6559788584709167\n",
      "epoch: 6, batch: 218, loss: 0.6095770001411438\n",
      "epoch: 6, batch: 219, loss: 0.5979354977607727\n",
      "epoch: 6, batch: 220, loss: 0.5652848482131958\n",
      "epoch: 6, batch: 221, loss: 0.5951577425003052\n",
      "epoch: 6, batch: 222, loss: 0.5930455327033997\n",
      "epoch: 6, batch: 223, loss: 0.725917637348175\n",
      "epoch: 6, batch: 224, loss: 0.5428594350814819\n",
      "epoch: 6, batch: 225, loss: 0.5774514079093933\n",
      "epoch: 6, batch: 226, loss: 0.5107057094573975\n",
      "epoch: 6, batch: 227, loss: 0.24994350969791412\n",
      "epoch: 6, batch: 228, loss: 0.44510066509246826\n",
      "epoch: 6, batch: 229, loss: 0.5389910340309143\n",
      "epoch: 6, batch: 230, loss: 0.6910971999168396\n",
      "epoch: 6, batch: 231, loss: 0.47616806626319885\n",
      "epoch: 6, batch: 232, loss: 0.4589684307575226\n",
      "epoch: 6, batch: 233, loss: 0.7395778298377991\n",
      "epoch: 6, batch: 234, loss: 0.7041821479797363\n",
      "epoch: 6, batch: 235, loss: 0.7037575244903564\n",
      "epoch: 6, batch: 236, loss: 0.8572407960891724\n",
      "epoch: 6, batch: 237, loss: 0.7284018993377686\n",
      "epoch: 6, batch: 238, loss: 0.5774676203727722\n",
      "epoch: 6, batch: 239, loss: 0.5303675532341003\n",
      "epoch: 6, batch: 240, loss: 0.6533393859863281\n",
      "epoch: 6, batch: 241, loss: 0.5495928525924683\n",
      "epoch: 6, batch: 242, loss: 0.7225059270858765\n",
      "epoch: 6, batch: 243, loss: 0.7432399392127991\n",
      "epoch: 6, batch: 244, loss: 0.7188311815261841\n",
      "epoch: 6, batch: 245, loss: 0.5041945576667786\n",
      "epoch: 6, batch: 246, loss: 0.6878607273101807\n",
      "epoch: 6, batch: 247, loss: 0.5495449900627136\n",
      "epoch: 6, batch: 248, loss: 0.6508579850196838\n",
      "epoch: 6, batch: 249, loss: 0.7064371109008789\n",
      "epoch: 6, batch: 250, loss: 0.7828296422958374\n",
      "epoch: 6, batch: 251, loss: 0.5212395787239075\n",
      "epoch: 6, batch: 252, loss: 0.6729644536972046\n",
      "epoch: 6, batch: 253, loss: 0.7109381556510925\n",
      "epoch: 6, batch: 254, loss: 0.6949451565742493\n",
      "epoch: 6, batch: 255, loss: 0.6250331997871399\n",
      "epoch: 6, batch: 256, loss: 0.5301253795623779\n",
      "epoch: 6, batch: 257, loss: 0.47659504413604736\n",
      "epoch: 6, batch: 258, loss: 0.5694752335548401\n",
      "epoch: 6, batch: 259, loss: 0.6475451588630676\n",
      "epoch: 6, batch: 260, loss: 0.7551688551902771\n",
      "epoch: 6, batch: 261, loss: 0.6846131682395935\n",
      "epoch: 6, batch: 262, loss: 0.5769059658050537\n",
      "epoch: 6, batch: 263, loss: 0.38278764486312866\n",
      "epoch: 6, batch: 264, loss: 0.6346102356910706\n",
      "epoch: 6, batch: 265, loss: 0.5100749135017395\n",
      "epoch: 6, batch: 266, loss: 0.6401801705360413\n",
      "epoch: 6, batch: 267, loss: 0.6647645235061646\n",
      "epoch: 6, batch: 268, loss: 0.6011749505996704\n",
      "epoch: 6, batch: 269, loss: 0.6217512488365173\n",
      "epoch: 6, batch: 270, loss: 0.5152237415313721\n",
      "epoch: 6, batch: 271, loss: 0.708362877368927\n",
      "epoch: 6, batch: 272, loss: 0.5157356262207031\n",
      "epoch: 6, batch: 273, loss: 0.5744093060493469\n",
      "epoch: 6, batch: 274, loss: 0.5174959897994995\n",
      "epoch: 6, batch: 275, loss: 0.4302632510662079\n",
      "epoch: 6, batch: 276, loss: 0.6130828857421875\n",
      "epoch: 6, batch: 277, loss: 0.5749549269676208\n",
      "epoch: 6, batch: 278, loss: 0.4702942371368408\n",
      "epoch: 6, batch: 279, loss: 0.5241280794143677\n",
      "epoch: 6, batch: 280, loss: 0.5543038845062256\n",
      "epoch: 6, batch: 281, loss: 0.9958227276802063\n",
      "epoch: 6, batch: 282, loss: 0.330445259809494\n",
      "epoch: 6, batch: 283, loss: 0.6864025592803955\n",
      "epoch: 6, batch: 284, loss: 0.7086379528045654\n",
      "epoch: 6, batch: 285, loss: 0.6746060252189636\n",
      "epoch: 6, batch: 286, loss: 0.7434388399124146\n",
      "epoch: 6, batch: 287, loss: 0.44098109006881714\n",
      "epoch: 6, batch: 288, loss: 0.6833171248435974\n",
      "epoch: 6, batch: 289, loss: 0.6153352856636047\n",
      "epoch: 6, batch: 290, loss: 0.8020584583282471\n",
      "epoch: 6, batch: 291, loss: 0.572700560092926\n",
      "epoch: 6, batch: 292, loss: 0.5601800680160522\n",
      "epoch: 6, batch: 293, loss: 0.8050073981285095\n",
      "epoch: 6, batch: 294, loss: 0.8395746946334839\n",
      "epoch: 6, batch: 295, loss: 0.6631472110748291\n",
      "epoch: 6, batch: 296, loss: 0.5680043697357178\n",
      "epoch: 6, batch: 297, loss: 0.4122675359249115\n",
      "epoch: 6, batch: 298, loss: 0.46152588725090027\n",
      "epoch: 6, batch: 299, loss: 0.6640807390213013\n",
      "epoch: 6, batch: 300, loss: 0.5281974673271179\n",
      "epoch: 6, batch: 301, loss: 0.5475891828536987\n",
      "epoch: 6, batch: 302, loss: 0.767242431640625\n",
      "epoch: 6, batch: 303, loss: 0.7576011419296265\n",
      "epoch: 6, batch: 304, loss: 0.4557017982006073\n",
      "epoch: 6, batch: 305, loss: 0.39435523748397827\n",
      "epoch: 6, batch: 306, loss: 0.8018792867660522\n",
      "epoch: 6, batch: 307, loss: 0.6026040315628052\n",
      "epoch: 6, batch: 308, loss: 0.7204329967498779\n",
      "epoch: 6, batch: 309, loss: 0.6063722372055054\n",
      "epoch: 6, batch: 310, loss: 0.7117687463760376\n",
      "epoch: 6, batch: 311, loss: 0.6690724492073059\n",
      "epoch: 6, batch: 312, loss: 0.5823990702629089\n",
      "epoch: 6, batch: 313, loss: 0.6493337154388428\n",
      "epoch: 6, batch: 314, loss: 0.626801073551178\n",
      "epoch: 6, batch: 315, loss: 0.8234544396400452\n",
      "epoch: 6, batch: 316, loss: 0.7074768543243408\n",
      "epoch: 6, batch: 317, loss: 0.906180202960968\n",
      "epoch: 6, batch: 318, loss: 0.48048514127731323\n",
      "epoch: 6, batch: 319, loss: 0.6789637207984924\n",
      "epoch: 6, batch: 320, loss: 0.49182868003845215\n",
      "epoch: 6, batch: 321, loss: 0.45665478706359863\n",
      "epoch: 6, batch: 322, loss: 0.5407226085662842\n",
      "epoch: 6, batch: 323, loss: 0.5576192736625671\n",
      "epoch: 6, batch: 324, loss: 0.45975735783576965\n",
      "epoch: 6, batch: 325, loss: 0.45640242099761963\n",
      "epoch: 6, batch: 326, loss: 0.49160581827163696\n",
      "epoch: 6, batch: 327, loss: 0.6973065733909607\n",
      "epoch: 6, batch: 328, loss: 0.5464280843734741\n",
      "epoch: 6, batch: 329, loss: 0.6589887142181396\n",
      "epoch: 6, batch: 330, loss: 0.6733222603797913\n",
      "epoch: 6, batch: 331, loss: 0.5915821194648743\n",
      "epoch: 6, batch: 332, loss: 0.6887873411178589\n",
      "epoch: 6, batch: 333, loss: 0.5522159337997437\n",
      "epoch: 6, batch: 334, loss: 0.5616094470024109\n",
      "epoch: 6, batch: 335, loss: 0.7415600419044495\n",
      "epoch: 6, batch: 336, loss: 0.7051361203193665\n",
      "epoch: 6, batch: 337, loss: 0.5214278697967529\n",
      "epoch: 6, batch: 338, loss: 1.1190545558929443\n",
      "epoch: 6, batch: 339, loss: 0.5429361462593079\n",
      "epoch: 6, batch: 340, loss: 0.6795106530189514\n",
      "epoch: 6, batch: 341, loss: 0.73216712474823\n",
      "epoch: 6, batch: 342, loss: 0.6090824604034424\n",
      "epoch: 6, batch: 343, loss: 0.6591198444366455\n",
      "epoch: 6, batch: 344, loss: 0.8926493525505066\n",
      "epoch: 6, batch: 345, loss: 0.5159034729003906\n",
      "epoch: 6, batch: 346, loss: 0.6308337450027466\n",
      "epoch: 6, batch: 347, loss: 0.8700050115585327\n",
      "epoch: 6, batch: 348, loss: 0.5914551019668579\n",
      "epoch: 6, batch: 349, loss: 0.6262111067771912\n",
      "epoch: 6, batch: 350, loss: 0.8004589080810547\n",
      "epoch: 6, batch: 351, loss: 0.5387431383132935\n",
      "epoch: 6, batch: 352, loss: 0.5150377750396729\n",
      "epoch: 6, batch: 353, loss: 0.5423071980476379\n",
      "epoch: 6, batch: 354, loss: 0.5896575450897217\n",
      "epoch: 6, batch: 355, loss: 0.6089854836463928\n",
      "epoch: 6, batch: 356, loss: 0.638041079044342\n",
      "epoch: 6, batch: 357, loss: 0.601329505443573\n",
      "epoch: 6, batch: 358, loss: 0.5868393182754517\n",
      "epoch: 6, batch: 359, loss: 0.6586088538169861\n",
      "epoch: 6, batch: 360, loss: 0.7093386650085449\n",
      "epoch: 6, batch: 361, loss: 0.7049884796142578\n",
      "epoch: 6, batch: 362, loss: 0.38780274987220764\n",
      "epoch: 6, batch: 363, loss: 0.42266133427619934\n",
      "epoch: 6, batch: 364, loss: 0.5741899609565735\n",
      "epoch: 6, batch: 365, loss: 0.48530343174934387\n",
      "epoch: 6, batch: 366, loss: 0.6091780066490173\n",
      "epoch: 6, batch: 367, loss: 0.46200570464134216\n",
      "epoch: 6, batch: 368, loss: 0.585090160369873\n",
      "epoch: 6, batch: 369, loss: 0.5683611631393433\n",
      "epoch: 6, batch: 370, loss: 0.617478609085083\n",
      "epoch: 6, batch: 371, loss: 0.3877870738506317\n",
      "epoch: 6, batch: 372, loss: 0.6713101267814636\n",
      "epoch: 6, batch: 373, loss: 0.6486954092979431\n",
      "epoch: 6, batch: 374, loss: 0.740426242351532\n",
      "epoch: 6, batch: 375, loss: 0.5080879926681519\n",
      "epoch: 6, batch: 376, loss: 0.8304396867752075\n",
      "epoch: 6, batch: 377, loss: 0.5936416387557983\n",
      "epoch: 6, batch: 378, loss: 0.5837476253509521\n",
      "epoch: 6, batch: 379, loss: 0.5964531302452087\n",
      "epoch: 6, batch: 380, loss: 1.0746214389801025\n",
      "epoch: 6, batch: 381, loss: 0.6155904531478882\n",
      "epoch: 6, batch: 382, loss: 0.559683084487915\n",
      "epoch: 6, batch: 383, loss: 0.6954734325408936\n",
      "epoch: 6, batch: 384, loss: 0.695956289768219\n",
      "epoch: 6, batch: 385, loss: 0.8144324421882629\n",
      "epoch: 6, batch: 386, loss: 0.6794705986976624\n",
      "epoch: 6, batch: 387, loss: 0.5678316354751587\n",
      "epoch: 6, batch: 388, loss: 0.3691391944885254\n",
      "epoch: 6, batch: 389, loss: 0.7444283366203308\n",
      "epoch: 6, batch: 390, loss: 0.6718518733978271\n",
      "epoch: 6, batch: 391, loss: 0.5747984647750854\n",
      "epoch: 6, batch: 392, loss: 0.5029754042625427\n",
      "epoch: 6, batch: 393, loss: 0.740408718585968\n",
      "epoch: 6, batch: 394, loss: 0.8081973195075989\n",
      "epoch: 6, batch: 395, loss: 0.5774188041687012\n",
      "epoch: 6, batch: 396, loss: 0.5516704320907593\n",
      "epoch: 6, batch: 397, loss: 0.3835368752479553\n",
      "epoch: 6, batch: 398, loss: 1.089005470275879\n",
      "epoch: 6, batch: 399, loss: 0.47323739528656006\n",
      "epoch: 6, batch: 400, loss: 0.548265814781189\n",
      "epoch: 6, batch: 401, loss: 0.6250492334365845\n",
      "epoch: 6, batch: 402, loss: 0.9893413782119751\n",
      "epoch: 6, batch: 403, loss: 0.6723405122756958\n",
      "epoch: 6, batch: 404, loss: 0.41512638330459595\n",
      "epoch: 6, batch: 405, loss: 0.7104089260101318\n",
      "epoch: 6, batch: 406, loss: 0.8253806233406067\n",
      "epoch: 6, batch: 407, loss: 0.751238226890564\n",
      "epoch: 6, batch: 408, loss: 0.3653627336025238\n",
      "epoch: 6, batch: 409, loss: 0.40683862566947937\n",
      "epoch: 6, batch: 410, loss: 0.7448937296867371\n",
      "epoch: 6, batch: 411, loss: 0.6582247018814087\n",
      "epoch: 6, batch: 412, loss: 0.7738965153694153\n",
      "epoch: 6, batch: 413, loss: 0.8658602237701416\n",
      "epoch: 6, batch: 414, loss: 0.5031359195709229\n",
      "epoch: 6, batch: 415, loss: 0.7485578656196594\n",
      "epoch: 6, batch: 416, loss: 0.6249768733978271\n",
      "epoch: 6, batch: 417, loss: 0.48647186160087585\n",
      "epoch: 6, batch: 418, loss: 0.5961191058158875\n",
      "epoch: 6, batch: 419, loss: 0.8006731271743774\n",
      "epoch: 6, batch: 420, loss: 0.7433873414993286\n",
      "epoch: 6, batch: 421, loss: 0.50042325258255\n",
      "epoch: 6, batch: 422, loss: 0.5710004568099976\n",
      "epoch: 6, batch: 423, loss: 0.6106412410736084\n",
      "epoch: 6, batch: 424, loss: 0.7467213273048401\n",
      "epoch: 6, batch: 425, loss: 0.5746892094612122\n",
      "epoch: 6, batch: 426, loss: 0.46122419834136963\n",
      "epoch: 6, batch: 427, loss: 0.44467851519584656\n",
      "epoch: 6, batch: 428, loss: 0.47717568278312683\n",
      "epoch: 6, batch: 429, loss: 0.6159748435020447\n",
      "epoch: 6, batch: 430, loss: 0.6566068530082703\n",
      "epoch: 6, batch: 431, loss: 0.7118791341781616\n",
      "epoch: 6, batch: 432, loss: 0.6386416554450989\n",
      "epoch: 6, batch: 433, loss: 0.4909583628177643\n",
      "epoch: 6, batch: 434, loss: 0.5919861793518066\n",
      "epoch: 6, batch: 435, loss: 0.6835573315620422\n",
      "epoch: 6, batch: 436, loss: 0.7443633079528809\n",
      "epoch: 6, batch: 437, loss: 0.5774940848350525\n",
      "epoch: 6, batch: 438, loss: 0.4413904547691345\n",
      "epoch: 6, batch: 439, loss: 0.706019401550293\n",
      "epoch: 6, batch: 440, loss: 0.41059160232543945\n",
      "epoch: 6, batch: 441, loss: 0.5808582305908203\n",
      "epoch: 6, batch: 442, loss: 0.7330946326255798\n",
      "epoch: 6, batch: 443, loss: 0.48491817712783813\n",
      "epoch: 6, batch: 444, loss: 0.7940241098403931\n",
      "epoch: 6, batch: 445, loss: 0.5537859797477722\n",
      "epoch: 6, batch: 446, loss: 0.6817730665206909\n",
      "epoch: 6, batch: 447, loss: 0.4976734220981598\n",
      "epoch: 6, batch: 448, loss: 0.571985125541687\n",
      "epoch: 6, batch: 449, loss: 0.7043980956077576\n",
      "epoch: 6, batch: 450, loss: 0.4112912714481354\n",
      "epoch: 6, batch: 451, loss: 0.5138958692550659\n",
      "epoch: 6, batch: 452, loss: 0.5608687996864319\n",
      "epoch: 6, batch: 453, loss: 0.4273201525211334\n",
      "epoch: 6, batch: 454, loss: 0.6157475113868713\n",
      "epoch: 6, batch: 455, loss: 0.5849918127059937\n",
      "epoch: 6, batch: 456, loss: 0.5068224668502808\n",
      "epoch: 6, batch: 457, loss: 0.6180524826049805\n",
      "epoch: 6, batch: 458, loss: 0.5864402055740356\n",
      "epoch: 6, batch: 459, loss: 0.5724350214004517\n",
      "epoch: 6, batch: 460, loss: 0.6839127540588379\n",
      "epoch: 6, batch: 461, loss: 0.8045821189880371\n",
      "epoch: 6, batch: 462, loss: 0.6371359825134277\n",
      "epoch: 6, batch: 463, loss: 0.5484103560447693\n",
      "epoch: 6, batch: 464, loss: 0.43654829263687134\n",
      "epoch: 6, batch: 465, loss: 0.6751890182495117\n",
      "epoch: 6, batch: 466, loss: 0.5379154682159424\n",
      "epoch: 6, batch: 467, loss: 0.6150333285331726\n",
      "epoch: 6, batch: 468, loss: 0.5823085308074951\n",
      "epoch: 6, batch: 469, loss: 0.7635704278945923\n",
      "epoch: 6, batch: 470, loss: 0.5110318660736084\n",
      "epoch: 6, batch: 471, loss: 0.665398895740509\n",
      "epoch: 6, batch: 472, loss: 0.521432638168335\n",
      "epoch: 6, batch: 473, loss: 0.42330288887023926\n",
      "epoch: 6, batch: 474, loss: 0.45126456022262573\n",
      "epoch: 6, batch: 475, loss: 0.3511347472667694\n",
      "epoch: 6, batch: 476, loss: 0.7652760744094849\n",
      "epoch: 6, batch: 477, loss: 0.4713423550128937\n",
      "epoch: 6, batch: 478, loss: 0.6798617839813232\n",
      "epoch: 6, batch: 479, loss: 0.5323362946510315\n",
      "epoch: 6, batch: 480, loss: 0.7988392114639282\n",
      "epoch: 6, batch: 481, loss: 0.4257272183895111\n",
      "epoch: 6, batch: 482, loss: 0.554107666015625\n",
      "epoch: 6, batch: 483, loss: 0.5471279621124268\n",
      "epoch: 6, batch: 484, loss: 0.6742163896560669\n",
      "epoch: 6, batch: 485, loss: 0.7411724328994751\n",
      "epoch: 6, batch: 486, loss: 0.6669198870658875\n",
      "epoch: 6, batch: 487, loss: 0.4822928309440613\n",
      "epoch: 6, batch: 488, loss: 0.4819517731666565\n",
      "epoch: 6, batch: 489, loss: 0.5307974815368652\n",
      "epoch: 6, batch: 490, loss: 0.6065192222595215\n",
      "epoch: 6, batch: 491, loss: 0.5843591690063477\n",
      "epoch: 6, batch: 492, loss: 0.7011363506317139\n",
      "epoch: 6, batch: 493, loss: 0.6646112203598022\n",
      "epoch: 6, batch: 494, loss: 0.56764155626297\n",
      "epoch: 6, batch: 495, loss: 0.5427908897399902\n",
      "epoch: 6, batch: 496, loss: 0.8508099913597107\n",
      "epoch: 6, batch: 497, loss: 1.0037593841552734\n",
      "epoch: 6, batch: 498, loss: 0.40953800082206726\n",
      "epoch: 6, batch: 499, loss: 0.49214237928390503\n",
      "epoch: 6, batch: 500, loss: 0.46670591831207275\n",
      "epoch: 6, batch: 501, loss: 0.4989936947822571\n",
      "epoch: 6, batch: 502, loss: 0.45620787143707275\n",
      "epoch: 6, batch: 503, loss: 0.8494763970375061\n",
      "epoch: 6, batch: 504, loss: 0.9272136092185974\n",
      "epoch: 6, batch: 505, loss: 0.6722897291183472\n",
      "epoch: 6, batch: 506, loss: 0.43593859672546387\n",
      "epoch: 6, batch: 507, loss: 0.40115201473236084\n",
      "epoch: 6, batch: 508, loss: 0.7427986264228821\n",
      "epoch: 6, batch: 509, loss: 0.5805966854095459\n",
      "epoch: 6, batch: 510, loss: 0.6946675777435303\n",
      "epoch: 6, batch: 511, loss: 0.5520035028457642\n",
      "epoch: 6, batch: 512, loss: 0.5709562301635742\n",
      "epoch: 6, batch: 513, loss: 0.805150032043457\n",
      "epoch: 6, batch: 514, loss: 0.6084035038948059\n",
      "epoch: 6, batch: 515, loss: 0.6046996116638184\n",
      "epoch: 6, batch: 516, loss: 0.6908180713653564\n",
      "epoch: 6, batch: 517, loss: 0.5036331415176392\n",
      "epoch: 6, batch: 518, loss: 0.45316287875175476\n",
      "epoch: 6, batch: 519, loss: 0.5368767976760864\n",
      "epoch: 6, batch: 520, loss: 0.805952787399292\n",
      "epoch: 6, batch: 521, loss: 0.6183590292930603\n",
      "epoch: 6, batch: 522, loss: 0.5213984847068787\n",
      "epoch: 6, batch: 523, loss: 0.6297563314437866\n",
      "epoch: 6, batch: 524, loss: 0.5241490006446838\n",
      "epoch: 6, batch: 525, loss: 0.6300868391990662\n",
      "epoch: 6, batch: 526, loss: 0.46490421891212463\n",
      "epoch: 6, batch: 527, loss: 0.49257364869117737\n",
      "epoch: 6, batch: 528, loss: 0.45017534494400024\n",
      "epoch: 6, batch: 529, loss: 0.4469086229801178\n",
      "epoch: 6, batch: 530, loss: 0.9176007509231567\n",
      "epoch: 6, batch: 531, loss: 0.5739560127258301\n",
      "epoch: 6, batch: 532, loss: 0.4270370304584503\n",
      "epoch: 6, batch: 533, loss: 0.7036816477775574\n",
      "epoch: 6, batch: 534, loss: 0.6238287091255188\n",
      "epoch: 6, batch: 535, loss: 0.561486005783081\n",
      "epoch: 6, batch: 536, loss: 0.7013654708862305\n",
      "epoch: 6, batch: 537, loss: 0.6380570530891418\n",
      "epoch: 6, batch: 538, loss: 0.46515536308288574\n",
      "epoch: 6, batch: 539, loss: 0.4676702320575714\n",
      "epoch: 6, batch: 540, loss: 0.6952977776527405\n",
      "epoch: 6, batch: 541, loss: 0.6049360632896423\n",
      "epoch: 6, batch: 542, loss: 0.48847267031669617\n",
      "epoch: 6, batch: 543, loss: 0.5037117004394531\n",
      "epoch: 6, batch: 544, loss: 0.5834178924560547\n",
      "epoch: 6, batch: 545, loss: 0.5093584656715393\n",
      "epoch: 6, batch: 546, loss: 0.6555527448654175\n",
      "epoch: 6, batch: 547, loss: 0.6845056414604187\n",
      "epoch: 6, batch: 548, loss: 0.5811825394630432\n",
      "epoch: 6, batch: 549, loss: 0.5814244747161865\n",
      "epoch: 6, batch: 550, loss: 0.678601086139679\n",
      "epoch: 6, batch: 551, loss: 0.6188827157020569\n",
      "epoch: 6, batch: 552, loss: 0.7134689092636108\n",
      "epoch: 6, batch: 553, loss: 0.5005346536636353\n",
      "epoch: 6, batch: 554, loss: 0.515548050403595\n",
      "epoch: 6, batch: 555, loss: 0.4232167601585388\n",
      "epoch: 6, batch: 556, loss: 0.47071561217308044\n",
      "epoch: 6, batch: 557, loss: 0.8010483384132385\n",
      "epoch: 6, batch: 558, loss: 0.8068425059318542\n",
      "epoch: 6, batch: 559, loss: 0.5924714207649231\n",
      "epoch: 6, batch: 560, loss: 0.541475772857666\n",
      "epoch: 6, batch: 561, loss: 0.6482723951339722\n",
      "epoch: 6, batch: 562, loss: 0.622985303401947\n",
      "epoch: 6, batch: 563, loss: 0.5312032103538513\n",
      "epoch: 6, batch: 564, loss: 0.6967930197715759\n",
      "epoch: 6, batch: 565, loss: 0.435587078332901\n",
      "epoch: 6, batch: 566, loss: 0.40990006923675537\n",
      "epoch: 6, batch: 567, loss: 0.3751327097415924\n",
      "epoch: 6, batch: 568, loss: 0.514260470867157\n",
      "epoch: 6, batch: 569, loss: 0.4701937735080719\n",
      "epoch: 6, batch: 570, loss: 0.5921515226364136\n",
      "epoch: 6, batch: 571, loss: 0.7045385241508484\n",
      "epoch: 6, batch: 572, loss: 0.48371583223342896\n",
      "epoch: 6, batch: 573, loss: 0.7540383338928223\n",
      "epoch: 6, batch: 574, loss: 0.3949587345123291\n",
      "epoch: 6, batch: 575, loss: 0.5188699960708618\n",
      "epoch: 6, batch: 576, loss: 0.4203965365886688\n",
      "epoch: 6, batch: 577, loss: 0.5174158215522766\n",
      "epoch: 6, batch: 578, loss: 0.4623083472251892\n",
      "epoch: 6, batch: 579, loss: 0.7344040870666504\n",
      "epoch: 6, batch: 580, loss: 0.46714091300964355\n",
      "epoch: 6, batch: 581, loss: 0.6465998888015747\n",
      "epoch: 6, batch: 582, loss: 0.6500895619392395\n",
      "epoch: 6, batch: 583, loss: 0.6391059756278992\n",
      "epoch: 6, batch: 584, loss: 0.5209078192710876\n",
      "epoch: 6, batch: 585, loss: 0.5247432589530945\n",
      "epoch: 6, batch: 586, loss: 0.5700145363807678\n",
      "epoch: 6, batch: 587, loss: 0.4271385371685028\n",
      "epoch: 6, batch: 588, loss: 0.4387561082839966\n",
      "epoch: 6, batch: 589, loss: 0.6620023250579834\n",
      "epoch: 6, batch: 590, loss: 0.7987968921661377\n",
      "epoch: 6, batch: 591, loss: 0.4309840202331543\n",
      "epoch: 6, batch: 592, loss: 0.716114342212677\n",
      "epoch: 6, batch: 593, loss: 0.7703723311424255\n",
      "epoch: 6, batch: 594, loss: 0.6725050210952759\n",
      "epoch: 6, batch: 595, loss: 0.44880032539367676\n",
      "epoch: 6, batch: 596, loss: 0.5187984704971313\n",
      "epoch: 6, batch: 597, loss: 0.9639803171157837\n",
      "epoch: 6, batch: 598, loss: 0.7480381727218628\n",
      "epoch: 6, batch: 599, loss: 0.670671284198761\n",
      "epoch: 6, batch: 600, loss: 0.5794880390167236\n",
      "epoch: 6, batch: 601, loss: 0.5613665580749512\n",
      "epoch: 6, batch: 602, loss: 0.6761322021484375\n",
      "epoch: 6, batch: 603, loss: 0.5726138949394226\n",
      "epoch: 6, batch: 604, loss: 0.7174031734466553\n",
      "epoch: 6, batch: 605, loss: 0.5216547250747681\n",
      "epoch: 6, batch: 606, loss: 0.7225885987281799\n",
      "epoch: 6, batch: 607, loss: 0.5608376860618591\n",
      "epoch: 6, batch: 608, loss: 0.6398264169692993\n",
      "epoch: 6, batch: 609, loss: 0.533357560634613\n",
      "epoch: 6, batch: 610, loss: 0.4118136167526245\n",
      "epoch: 6, batch: 611, loss: 0.6855796575546265\n",
      "epoch: 6, batch: 612, loss: 0.5927961468696594\n",
      "epoch: 6, batch: 613, loss: 0.7816176414489746\n",
      "epoch: 6, batch: 614, loss: 0.50861656665802\n",
      "epoch: 6, batch: 615, loss: 0.44241049885749817\n",
      "epoch: 6, batch: 616, loss: 0.46493247151374817\n",
      "epoch: 6, batch: 617, loss: 0.6222608089447021\n",
      "epoch: 6, batch: 618, loss: 0.5069120526313782\n",
      "epoch: 6, batch: 619, loss: 0.5960219502449036\n",
      "epoch: 6, batch: 620, loss: 0.6704246401786804\n",
      "epoch: 6, batch: 621, loss: 0.7284137010574341\n",
      "epoch: 6, batch: 622, loss: 0.6171134114265442\n",
      "epoch: 6, batch: 623, loss: 0.5145578980445862\n",
      "epoch: 6, batch: 624, loss: 0.6215485334396362\n",
      "epoch: 6, batch: 625, loss: 0.6802843809127808\n",
      "epoch: 6, batch: 626, loss: 0.6062194108963013\n",
      "epoch: 6, batch: 627, loss: 0.4594610631465912\n",
      "epoch: 6, batch: 628, loss: 0.4967935085296631\n",
      "epoch: 6, batch: 629, loss: 0.6965231895446777\n",
      "epoch: 6, batch: 630, loss: 0.589321494102478\n",
      "epoch: 6, batch: 631, loss: 1.0372122526168823\n",
      "epoch: 6, batch: 632, loss: 0.5893354415893555\n",
      "epoch: 6, batch: 633, loss: 0.41619622707366943\n",
      "epoch: 6, batch: 634, loss: 0.6609804034233093\n",
      "epoch: 6, batch: 635, loss: 0.622615396976471\n",
      "epoch: 6, batch: 636, loss: 0.43354085087776184\n",
      "epoch: 6, batch: 637, loss: 0.5899474024772644\n",
      "epoch: 6, batch: 638, loss: 0.6789472103118896\n",
      "epoch: 6, batch: 639, loss: 0.5110566020011902\n",
      "epoch: 6, batch: 640, loss: 0.5987095236778259\n",
      "epoch: 6, batch: 641, loss: 0.5274389982223511\n",
      "epoch: 6, batch: 642, loss: 0.7125644683837891\n",
      "epoch: 6, batch: 643, loss: 0.47968295216560364\n",
      "epoch: 6, batch: 644, loss: 0.4347088634967804\n",
      "epoch: 6, batch: 645, loss: 0.7156146168708801\n",
      "epoch: 6, batch: 646, loss: 0.6145657896995544\n",
      "epoch: 6, batch: 647, loss: 0.41087809205055237\n",
      "epoch: 6, batch: 648, loss: 0.8043798804283142\n",
      "epoch: 6, batch: 649, loss: 0.6559053659439087\n",
      "epoch: 6, batch: 650, loss: 0.9385764598846436\n",
      "epoch: 6, batch: 651, loss: 0.47563156485557556\n",
      "epoch: 6, batch: 652, loss: 0.5736660361289978\n",
      "epoch: 6, batch: 653, loss: 0.7363789081573486\n",
      "epoch: 6, batch: 654, loss: 0.7240217328071594\n",
      "epoch: 6, batch: 655, loss: 0.3976394534111023\n",
      "epoch: 6, batch: 656, loss: 0.5655885338783264\n",
      "epoch: 6, batch: 657, loss: 0.6872128248214722\n",
      "epoch: 6, batch: 658, loss: 0.610795795917511\n",
      "epoch: 6, batch: 659, loss: 0.5709050893783569\n",
      "epoch: 6, batch: 660, loss: 0.4531012773513794\n",
      "epoch: 6, batch: 661, loss: 0.5583311319351196\n",
      "epoch: 6, batch: 662, loss: 0.4695335030555725\n",
      "epoch: 6, batch: 663, loss: 0.5139704942703247\n",
      "epoch: 6, batch: 664, loss: 0.5779522061347961\n",
      "epoch: 6, batch: 665, loss: 0.5494522452354431\n",
      "epoch: 6, batch: 666, loss: 0.622384786605835\n",
      "epoch: 6, batch: 667, loss: 0.44041746854782104\n",
      "epoch: 6, batch: 668, loss: 0.5306960344314575\n",
      "epoch: 6, batch: 669, loss: 0.5320286750793457\n",
      "epoch: 6, batch: 670, loss: 0.5492949485778809\n",
      "epoch: 6, batch: 671, loss: 0.5305883884429932\n",
      "epoch: 6, batch: 672, loss: 0.6215612888336182\n",
      "epoch: 6, batch: 673, loss: 0.8700859546661377\n",
      "epoch: 6, batch: 674, loss: 0.47198212146759033\n",
      "epoch: 6, batch: 675, loss: 0.4727642834186554\n",
      "epoch: 6, batch: 676, loss: 0.4972001016139984\n",
      "epoch: 6, batch: 677, loss: 0.6952896118164062\n",
      "epoch: 6, batch: 678, loss: 0.4790092706680298\n",
      "epoch: 6, batch: 679, loss: 0.5343477725982666\n",
      "epoch: 6, batch: 680, loss: 0.5244885683059692\n",
      "epoch: 6, batch: 681, loss: 0.9059534668922424\n",
      "epoch: 6, batch: 682, loss: 0.6597192883491516\n",
      "epoch: 6, batch: 683, loss: 0.46489688754081726\n",
      "epoch: 6, batch: 684, loss: 0.7087615132331848\n",
      "epoch: 6, batch: 685, loss: 0.6503452062606812\n",
      "epoch: 6, batch: 686, loss: 0.6886146664619446\n",
      "epoch: 6, batch: 687, loss: 0.5717121362686157\n",
      "epoch: 6, batch: 688, loss: 0.6238248944282532\n",
      "epoch: 6, batch: 689, loss: 0.5534988641738892\n",
      "epoch: 6, batch: 690, loss: 0.6449056267738342\n",
      "epoch: 6, batch: 691, loss: 0.8269426226615906\n",
      "epoch: 6, batch: 692, loss: 0.587274968624115\n",
      "epoch: 6, batch: 693, loss: 0.47294914722442627\n",
      "epoch: 6, batch: 694, loss: 0.4725894331932068\n",
      "epoch: 6, batch: 695, loss: 0.48141542077064514\n",
      "epoch: 6, batch: 696, loss: 0.41463321447372437\n",
      "epoch: 6, batch: 697, loss: 0.7602283358573914\n",
      "epoch: 6, batch: 698, loss: 0.6761476993560791\n",
      "epoch: 6, batch: 699, loss: 0.43452170491218567\n",
      "epoch: 6, batch: 700, loss: 0.7158337235450745\n",
      "epoch: 6, batch: 701, loss: 0.5027267932891846\n",
      "epoch: 6, batch: 702, loss: 0.5697872638702393\n",
      "epoch: 6, batch: 703, loss: 0.5840435028076172\n",
      "epoch: 6, batch: 704, loss: 0.3461747169494629\n",
      "epoch: 6, batch: 705, loss: 0.4199482798576355\n",
      "epoch: 6, batch: 706, loss: 0.6465692520141602\n",
      "epoch: 6, batch: 707, loss: 0.680016279220581\n",
      "epoch: 6, batch: 708, loss: 0.6986241340637207\n",
      "epoch: 6, batch: 709, loss: 0.5113497972488403\n",
      "epoch: 6, batch: 710, loss: 0.49530887603759766\n",
      "epoch: 6, batch: 711, loss: 0.5650895237922668\n",
      "epoch: 6, batch: 712, loss: 0.3992537558078766\n",
      "epoch: 6, batch: 713, loss: 0.5375409722328186\n",
      "epoch: 6, batch: 714, loss: 0.8110089898109436\n",
      "epoch: 6, batch: 715, loss: 0.6813914775848389\n",
      "epoch: 6, batch: 716, loss: 0.5437064170837402\n",
      "epoch: 6, batch: 717, loss: 0.8474381566047668\n",
      "epoch: 6, batch: 718, loss: 0.6213486194610596\n",
      "epoch: 6, batch: 719, loss: 0.538849949836731\n",
      "epoch: 6, batch: 720, loss: 0.6869345307350159\n",
      "epoch: 6, batch: 721, loss: 0.539833128452301\n",
      "epoch: 6, batch: 722, loss: 0.5385839343070984\n",
      "epoch: 6, batch: 723, loss: 0.6456924080848694\n",
      "epoch: 6, batch: 724, loss: 0.6636223196983337\n",
      "epoch: 6, batch: 725, loss: 0.5277496576309204\n",
      "epoch: 6, batch: 726, loss: 0.7449158430099487\n",
      "epoch: 6, batch: 727, loss: 0.8547999858856201\n",
      "epoch: 6, batch: 728, loss: 0.6748701333999634\n",
      "epoch: 6, batch: 729, loss: 0.5196807384490967\n",
      "epoch: 6, batch: 730, loss: 0.4919402301311493\n",
      "epoch: 6, batch: 731, loss: 0.6378297805786133\n",
      "epoch: 6, batch: 732, loss: 0.4637034833431244\n",
      "epoch: 6, batch: 733, loss: 0.5603135824203491\n",
      "epoch: 6, batch: 734, loss: 0.5316821932792664\n",
      "epoch: 6, batch: 735, loss: 0.6418310403823853\n",
      "epoch: 6, batch: 736, loss: 0.3846568465232849\n",
      "epoch: 6, batch: 737, loss: 0.5934991240501404\n",
      "epoch: 6, batch: 738, loss: 0.5093796253204346\n",
      "epoch: 6, batch: 739, loss: 0.5781700015068054\n",
      "epoch: 6, batch: 740, loss: 0.5901774168014526\n",
      "epoch: 6, batch: 741, loss: 0.7508484721183777\n",
      "epoch: 6, batch: 742, loss: 0.5677803158760071\n",
      "epoch: 6, batch: 743, loss: 0.5531611442565918\n",
      "epoch: 6, batch: 744, loss: 0.45720794796943665\n",
      "epoch: 6, batch: 745, loss: 0.47583505511283875\n",
      "epoch: 6, batch: 746, loss: 0.8137163519859314\n",
      "epoch: 6, batch: 747, loss: 0.5479004979133606\n",
      "epoch: 6, batch: 748, loss: 0.6442992687225342\n",
      "epoch: 6, batch: 749, loss: 0.8508459329605103\n",
      "epoch: 6, batch: 750, loss: 0.7462207078933716\n",
      "epoch: 6, batch: 751, loss: 0.5670866966247559\n",
      "epoch: 6, batch: 752, loss: 0.6436482667922974\n",
      "epoch: 6, batch: 753, loss: 0.7325458526611328\n",
      "epoch: 6, batch: 754, loss: 0.7820488214492798\n",
      "epoch: 6, batch: 755, loss: 0.5486043691635132\n",
      "epoch: 6, batch: 756, loss: 0.5817883610725403\n",
      "epoch: 6, batch: 757, loss: 0.7363832592964172\n",
      "epoch: 6, batch: 758, loss: 0.449939101934433\n",
      "epoch: 6, batch: 759, loss: 0.3874135911464691\n",
      "epoch: 6, batch: 760, loss: 0.5989174842834473\n",
      "epoch: 6, batch: 761, loss: 0.5587726831436157\n",
      "epoch: 6, batch: 762, loss: 0.480077862739563\n",
      "epoch: 6, batch: 763, loss: 0.8708353638648987\n",
      "epoch: 6, batch: 764, loss: 0.41395074129104614\n",
      "epoch: 6, batch: 765, loss: 0.6515273451805115\n",
      "epoch: 6, batch: 766, loss: 0.5391010046005249\n",
      "epoch: 6, batch: 767, loss: 0.5418393611907959\n",
      "epoch: 6, batch: 768, loss: 0.7919702529907227\n",
      "epoch: 6, batch: 769, loss: 0.5252422094345093\n",
      "epoch: 6, batch: 770, loss: 0.5246736407279968\n",
      "epoch: 6, batch: 771, loss: 0.5797533392906189\n",
      "epoch: 6, batch: 772, loss: 0.5076397061347961\n",
      "epoch: 6, batch: 773, loss: 0.5533830523490906\n",
      "epoch: 6, batch: 774, loss: 0.9973316788673401\n",
      "epoch: 6, batch: 775, loss: 0.46762967109680176\n",
      "epoch: 6, batch: 776, loss: 0.6182999014854431\n",
      "epoch: 6, batch: 777, loss: 0.46731317043304443\n",
      "epoch: 6, batch: 778, loss: 0.47493696212768555\n",
      "epoch: 6, batch: 779, loss: 0.7905981540679932\n",
      "epoch: 6, batch: 780, loss: 0.5236468315124512\n",
      "epoch: 6, batch: 781, loss: 0.5455747246742249\n",
      "epoch: 6, batch: 782, loss: 0.38461363315582275\n",
      "epoch: 6, batch: 783, loss: 0.5661535263061523\n",
      "epoch: 6, batch: 784, loss: 0.6373561024665833\n",
      "epoch: 6, batch: 785, loss: 0.45437344908714294\n",
      "epoch: 6, batch: 786, loss: 0.49475330114364624\n",
      "epoch: 6, batch: 787, loss: 0.39025795459747314\n",
      "epoch: 6, batch: 788, loss: 0.3850289285182953\n",
      "epoch: 6, batch: 789, loss: 0.77580726146698\n",
      "epoch: 6, batch: 790, loss: 0.6173818707466125\n",
      "epoch: 6, batch: 791, loss: 0.5235744118690491\n",
      "epoch: 6, batch: 792, loss: 0.6568474769592285\n",
      "epoch: 6, batch: 793, loss: 0.7271623015403748\n",
      "epoch: 6, batch: 794, loss: 0.49656006693840027\n",
      "epoch: 6, batch: 795, loss: 0.7127479314804077\n",
      "epoch: 6, batch: 796, loss: 0.8063764572143555\n",
      "epoch: 6, batch: 797, loss: 0.5310328006744385\n",
      "epoch: 6, batch: 798, loss: 0.5545194745063782\n",
      "epoch: 6, batch: 799, loss: 0.6932520270347595\n",
      "epoch: 6, batch: 800, loss: 0.41863834857940674\n",
      "epoch: 6, batch: 801, loss: 0.527528703212738\n",
      "epoch: 6, batch: 802, loss: 0.5931323766708374\n",
      "epoch: 6, batch: 803, loss: 0.5741786360740662\n",
      "epoch: 6, batch: 804, loss: 0.35671094059944153\n",
      "epoch: 6, batch: 805, loss: 0.41855093836784363\n",
      "epoch: 6, batch: 806, loss: 0.713632345199585\n",
      "epoch: 6, batch: 807, loss: 0.5840080380439758\n",
      "epoch: 6, batch: 808, loss: 0.3880816400051117\n",
      "epoch: 6, batch: 809, loss: 0.598702073097229\n",
      "epoch: 6, batch: 810, loss: 0.4839956760406494\n",
      "epoch: 6, batch: 811, loss: 0.5393401980400085\n",
      "epoch: 6, batch: 812, loss: 0.5021430253982544\n",
      "epoch: 6, batch: 813, loss: 0.5634097456932068\n",
      "epoch: 6, batch: 814, loss: 0.49403664469718933\n",
      "epoch: 6, batch: 815, loss: 0.5881712436676025\n",
      "epoch: 6, batch: 816, loss: 0.6509348750114441\n",
      "epoch: 6, batch: 817, loss: 0.4373849928379059\n",
      "epoch: 6, batch: 818, loss: 0.7494698166847229\n",
      "epoch: 6, batch: 819, loss: 0.4164775609970093\n",
      "epoch: 6, batch: 820, loss: 0.4776236414909363\n",
      "epoch: 6, batch: 821, loss: 0.4693651795387268\n",
      "epoch: 6, batch: 822, loss: 0.39508768916130066\n",
      "epoch: 6, batch: 823, loss: 0.5566397309303284\n",
      "epoch: 6, batch: 824, loss: 0.516435444355011\n",
      "epoch: 6, batch: 825, loss: 0.7660239934921265\n",
      "epoch: 6, batch: 826, loss: 0.5877093076705933\n",
      "epoch: 6, batch: 827, loss: 0.6164685487747192\n",
      "epoch: 6, batch: 828, loss: 0.46508559584617615\n",
      "epoch: 6, batch: 829, loss: 0.4074661135673523\n",
      "epoch: 6, batch: 830, loss: 0.49947449564933777\n",
      "epoch: 6, batch: 831, loss: 0.6900048851966858\n",
      "epoch: 6, batch: 832, loss: 0.6059516072273254\n",
      "epoch: 6, batch: 833, loss: 0.7278682589530945\n",
      "epoch: 6, batch: 834, loss: 0.6573697924613953\n",
      "epoch: 6, batch: 835, loss: 0.6115140914916992\n",
      "epoch: 6, batch: 836, loss: 0.5480998754501343\n",
      "epoch: 6, batch: 837, loss: 0.4287239909172058\n",
      "epoch: 6, batch: 838, loss: 0.45911625027656555\n",
      "epoch: 6, batch: 839, loss: 0.5050306916236877\n",
      "epoch: 6, batch: 840, loss: 0.5325036644935608\n",
      "epoch: 6, batch: 841, loss: 0.5139818787574768\n",
      "epoch: 6, batch: 842, loss: 0.7038518786430359\n",
      "epoch: 6, batch: 843, loss: 0.5432754158973694\n",
      "epoch: 6, batch: 844, loss: 0.34806177020072937\n",
      "epoch: 6, batch: 845, loss: 0.6443411707878113\n",
      "epoch: 6, batch: 846, loss: 0.7226132154464722\n",
      "epoch: 6, batch: 847, loss: 0.6045039296150208\n",
      "epoch: 6, batch: 848, loss: 0.7292807102203369\n",
      "epoch: 6, batch: 849, loss: 0.7062338590621948\n",
      "epoch: 6, batch: 850, loss: 0.6251878142356873\n",
      "epoch: 6, batch: 851, loss: 0.6535593867301941\n",
      "epoch: 6, batch: 852, loss: 0.7141438126564026\n",
      "epoch: 6, batch: 853, loss: 0.4439616799354553\n",
      "epoch: 6, batch: 854, loss: 0.8029930591583252\n",
      "epoch: 6, batch: 855, loss: 0.5433880686759949\n",
      "epoch: 6, batch: 856, loss: 0.6641104817390442\n",
      "epoch: 6, batch: 857, loss: 0.4779750406742096\n",
      "epoch: 6, batch: 858, loss: 0.5727622509002686\n",
      "epoch: 6, batch: 859, loss: 0.6700921654701233\n",
      "epoch: 6, batch: 860, loss: 0.38724401593208313\n",
      "epoch: 6, batch: 861, loss: 0.7639029622077942\n",
      "epoch: 6, batch: 862, loss: 0.6503223776817322\n",
      "epoch: 6, batch: 863, loss: 0.5585945844650269\n",
      "epoch: 6, batch: 864, loss: 0.7405439019203186\n",
      "epoch: 6, batch: 865, loss: 0.5769352912902832\n",
      "epoch: 6, batch: 866, loss: 0.4924984574317932\n",
      "epoch: 6, batch: 867, loss: 0.47823745012283325\n",
      "epoch: 6, batch: 868, loss: 0.3691427707672119\n",
      "epoch: 6, batch: 869, loss: 0.6685914397239685\n",
      "epoch: 6, batch: 870, loss: 0.5666454434394836\n",
      "epoch: 6, batch: 871, loss: 0.5856810808181763\n",
      "epoch: 6, batch: 872, loss: 0.8945614695549011\n",
      "epoch: 6, batch: 873, loss: 0.6296691298484802\n",
      "epoch: 6, batch: 874, loss: 0.6116170883178711\n",
      "epoch: 6, batch: 875, loss: 0.6233119964599609\n",
      "epoch: 6, batch: 876, loss: 0.5817851424217224\n",
      "epoch: 6, batch: 877, loss: 0.8473185300827026\n",
      "epoch: 6, batch: 878, loss: 0.3830054700374603\n",
      "epoch: 6, batch: 879, loss: 0.5027173757553101\n",
      "epoch: 6, batch: 880, loss: 0.47672224044799805\n",
      "epoch: 6, batch: 881, loss: 0.7170052528381348\n",
      "epoch: 6, batch: 882, loss: 0.7501780390739441\n",
      "epoch: 6, batch: 883, loss: 0.3954256474971771\n",
      "epoch: 6, batch: 884, loss: 0.40385499596595764\n",
      "epoch: 6, batch: 885, loss: 0.4912758469581604\n",
      "epoch: 6, batch: 886, loss: 0.6807276606559753\n",
      "epoch: 6, batch: 887, loss: 0.5342851281166077\n",
      "epoch: 6, batch: 888, loss: 0.6773573756217957\n",
      "epoch: 6, batch: 889, loss: 0.5881009697914124\n",
      "epoch: 6, batch: 890, loss: 0.8416154384613037\n",
      "epoch: 6, batch: 891, loss: 0.6340299248695374\n",
      "epoch: 6, batch: 892, loss: 0.6865637898445129\n",
      "epoch: 6, batch: 893, loss: 0.5395686030387878\n",
      "epoch: 6, batch: 894, loss: 0.5475667119026184\n",
      "epoch: 6, batch: 895, loss: 0.6128374934196472\n",
      "epoch: 6, batch: 896, loss: 0.9135377407073975\n",
      "epoch: 6, batch: 897, loss: 0.3456571698188782\n",
      "epoch: 6, batch: 898, loss: 0.549020528793335\n",
      "epoch: 6, batch: 899, loss: 0.5948159694671631\n",
      "epoch: 6, batch: 900, loss: 0.4903234541416168\n",
      "epoch: 6, batch: 901, loss: 0.556110143661499\n",
      "epoch: 6, batch: 902, loss: 0.4260365664958954\n",
      "epoch: 6, batch: 903, loss: 0.9110809564590454\n",
      "epoch: 6, batch: 904, loss: 0.5923135876655579\n",
      "epoch: 6, batch: 905, loss: 0.5415967702865601\n",
      "epoch: 6, batch: 906, loss: 0.8081946969032288\n",
      "epoch: 6, batch: 907, loss: 0.7082870006561279\n",
      "epoch: 6, batch: 908, loss: 0.5696061253547668\n",
      "epoch: 6, batch: 909, loss: 0.5683236718177795\n",
      "epoch: 6, batch: 910, loss: 0.40170586109161377\n",
      "epoch: 6, batch: 911, loss: 0.47433292865753174\n",
      "epoch: 6, batch: 912, loss: 0.5505078434944153\n",
      "epoch: 6, batch: 913, loss: 0.77085942029953\n",
      "epoch: 6, batch: 914, loss: 0.6263041496276855\n",
      "epoch: 6, batch: 915, loss: 0.531520664691925\n",
      "epoch: 6, batch: 916, loss: 0.4060800075531006\n",
      "epoch: 6, batch: 917, loss: 0.7274661660194397\n",
      "epoch: 6, batch: 918, loss: 0.4887509346008301\n",
      "epoch: 6, batch: 919, loss: 0.6943942308425903\n",
      "epoch: 6, batch: 920, loss: 0.6065934896469116\n",
      "epoch: 6, batch: 921, loss: 0.5653755068778992\n",
      "epoch: 6, batch: 922, loss: 0.43997472524642944\n",
      "epoch: 6, batch: 923, loss: 0.5755846500396729\n",
      "epoch: 6, batch: 924, loss: 0.9277887940406799\n",
      "epoch: 6, batch: 925, loss: 0.572180986404419\n",
      "epoch: 6, batch: 926, loss: 0.6706441640853882\n",
      "epoch: 6, batch: 927, loss: 1.1214985847473145\n",
      "epoch: 6, batch: 928, loss: 0.5767331719398499\n",
      "epoch: 6, batch: 929, loss: 0.5672817230224609\n",
      "epoch: 6, batch: 930, loss: 0.7117456793785095\n",
      "epoch: 6, batch: 931, loss: 0.6097266674041748\n",
      "epoch: 6, batch: 932, loss: 0.5339294075965881\n",
      "epoch: 6, batch: 933, loss: 0.6982550024986267\n",
      "epoch: 6, batch: 934, loss: 0.5455145239830017\n",
      "epoch: 6, batch: 935, loss: 0.54651939868927\n",
      "epoch: 6, batch: 936, loss: 0.8611281514167786\n",
      "epoch: 6, batch: 937, loss: 0.6661671996116638\n",
      "epoch: 6, batch: 938, loss: 0.5498125553131104\n",
      "epoch: 6, batch: 939, loss: 0.7187992930412292\n",
      "epoch: 6, batch: 940, loss: 0.5901737809181213\n",
      "epoch: 6, batch: 941, loss: 0.43633460998535156\n",
      "epoch: 6, batch: 942, loss: 0.7381255030632019\n",
      "epoch: 6, batch: 943, loss: 0.5540426969528198\n",
      "epoch: 6, batch: 944, loss: 0.44481414556503296\n",
      "epoch: 6, batch: 945, loss: 0.5725829005241394\n",
      "epoch: 6, batch: 946, loss: 0.8514492511749268\n",
      "epoch: 6, batch: 947, loss: 0.5403326153755188\n",
      "epoch: 6, batch: 948, loss: 0.733159065246582\n",
      "epoch: 6, batch: 949, loss: 0.4403878152370453\n",
      "epoch: 6, batch: 950, loss: 0.7329655885696411\n",
      "epoch: 6, batch: 951, loss: 0.6797555088996887\n",
      "epoch: 6, batch: 952, loss: 0.768962025642395\n",
      "epoch: 6, batch: 953, loss: 0.7346777319908142\n",
      "epoch: 6, batch: 954, loss: 0.32075801491737366\n",
      "epoch: 6, batch: 955, loss: 0.4272312521934509\n",
      "epoch: 6, batch: 956, loss: 0.6399445533752441\n",
      "epoch: 6, batch: 957, loss: 0.401758074760437\n",
      "epoch: 6, batch: 958, loss: 0.5434365272521973\n",
      "epoch: 6, batch: 959, loss: 0.7366472482681274\n",
      "epoch: 6, batch: 960, loss: 0.8745610117912292\n",
      "epoch: 6, batch: 961, loss: 0.46418583393096924\n",
      "epoch: 6, batch: 962, loss: 0.47899529337882996\n",
      "epoch: 6, batch: 963, loss: 0.6528546214103699\n",
      "epoch: 6, batch: 964, loss: 0.3956852853298187\n",
      "epoch: 6, batch: 965, loss: 0.7744011878967285\n",
      "epoch: 6, batch: 966, loss: 0.7872849106788635\n",
      "epoch: 6, batch: 967, loss: 0.60247802734375\n",
      "epoch: 6, batch: 968, loss: 0.43491530418395996\n",
      "epoch: 6, batch: 969, loss: 0.47239235043525696\n",
      "epoch: 6, batch: 970, loss: 0.54057776927948\n",
      "epoch: 6, batch: 971, loss: 0.5671761631965637\n",
      "epoch: 6, batch: 972, loss: 0.5422962307929993\n",
      "epoch: 6, batch: 973, loss: 0.592140793800354\n",
      "epoch: 6, batch: 974, loss: 0.5037853121757507\n",
      "epoch: 6, batch: 975, loss: 0.3879507780075073\n",
      "epoch: 6, batch: 976, loss: 0.4328519403934479\n",
      "epoch: 6, batch: 977, loss: 0.3737046718597412\n",
      "epoch: 6, batch: 978, loss: 0.6606601476669312\n",
      "epoch: 6, batch: 979, loss: 0.547012448310852\n",
      "epoch: 6, batch: 980, loss: 0.4839474558830261\n",
      "epoch: 6, batch: 981, loss: 0.4534035623073578\n",
      "epoch: 6, batch: 982, loss: 0.4683915078639984\n",
      "epoch: 6, batch: 983, loss: 0.45961830019950867\n",
      "epoch: 6, batch: 984, loss: 0.5997923612594604\n",
      "epoch: 6, batch: 985, loss: 0.6048514246940613\n",
      "epoch: 6, batch: 986, loss: 0.5057014226913452\n",
      "epoch: 6, batch: 987, loss: 0.5592244267463684\n",
      "epoch: 6, batch: 988, loss: 0.46520864963531494\n",
      "epoch: 6, batch: 989, loss: 0.6606755256652832\n",
      "epoch: 6, batch: 990, loss: 0.4310300350189209\n",
      "epoch: 6, batch: 991, loss: 0.451291024684906\n",
      "epoch: 6, batch: 992, loss: 0.8054633736610413\n",
      "epoch: 6, batch: 993, loss: 0.7664211988449097\n",
      "epoch: 6, batch: 994, loss: 0.6978147625923157\n",
      "epoch: 6, batch: 995, loss: 0.5761306285858154\n",
      "epoch: 6, batch: 996, loss: 0.7267055511474609\n",
      "epoch: 6, batch: 997, loss: 0.44496750831604004\n",
      "epoch: 6, batch: 998, loss: 0.6759401559829712\n",
      "epoch: 6, batch: 999, loss: 0.7386335730552673\n",
      "epoch: 6, batch: 1000, loss: 0.6381935477256775\n",
      "epoch: 6, batch: 1001, loss: 0.35028979182243347\n",
      "epoch: 6, batch: 1002, loss: 0.391020268201828\n",
      "epoch: 6, batch: 1003, loss: 0.6653996109962463\n",
      "epoch: 6, batch: 1004, loss: 0.6934345960617065\n",
      "epoch: 6, batch: 1005, loss: 0.5218626856803894\n",
      "epoch: 6, batch: 1006, loss: 0.5354147553443909\n",
      "epoch: 6, batch: 1007, loss: 0.4859682321548462\n",
      "epoch: 6, batch: 1008, loss: 0.661139726638794\n",
      "epoch: 6, batch: 1009, loss: 0.6934369802474976\n",
      "epoch: 6, batch: 1010, loss: 0.49346330761909485\n",
      "epoch: 6, batch: 1011, loss: 0.48778030276298523\n",
      "epoch: 6, batch: 1012, loss: 0.6316574811935425\n",
      "epoch: 6, batch: 1013, loss: 0.5103732347488403\n",
      "epoch: 6, batch: 1014, loss: 0.5458747744560242\n",
      "epoch: 6, batch: 1015, loss: 0.4891057014465332\n",
      "epoch: 6, batch: 1016, loss: 0.4394370913505554\n",
      "epoch: 6, batch: 1017, loss: 0.5082497596740723\n",
      "epoch: 6, batch: 1018, loss: 0.5372808575630188\n",
      "epoch: 6, batch: 1019, loss: 0.5782036781311035\n",
      "epoch: 6, batch: 1020, loss: 0.5196601748466492\n",
      "epoch: 6, batch: 1021, loss: 0.5595489740371704\n",
      "epoch: 6, batch: 1022, loss: 0.43864476680755615\n",
      "epoch: 6, batch: 1023, loss: 0.49534347653388977\n",
      "epoch: 6, batch: 1024, loss: 0.4353712797164917\n",
      "epoch: 6, batch: 1025, loss: 0.8232011795043945\n",
      "epoch: 6, batch: 1026, loss: 0.542913019657135\n",
      "epoch: 6, batch: 1027, loss: 0.52494877576828\n",
      "epoch: 6, batch: 1028, loss: 0.6287885904312134\n",
      "epoch: 6, batch: 1029, loss: 0.5000067353248596\n",
      "epoch: 6, batch: 1030, loss: 0.8270457983016968\n",
      "epoch: 6, batch: 1031, loss: 0.521939218044281\n",
      "epoch: 6, batch: 1032, loss: 0.5222905874252319\n",
      "epoch: 6, batch: 1033, loss: 0.5292642712593079\n",
      "epoch: 6, batch: 1034, loss: 0.9563063979148865\n",
      "epoch: 6, batch: 1035, loss: 0.7406193614006042\n",
      "epoch: 6, batch: 1036, loss: 0.46910443902015686\n",
      "epoch: 6, batch: 1037, loss: 0.816541850566864\n",
      "epoch: 6, batch: 1038, loss: 0.512567400932312\n",
      "epoch: 6, batch: 1039, loss: 0.5724093317985535\n",
      "epoch: 6, batch: 1040, loss: 0.499702125787735\n",
      "epoch: 6, batch: 1041, loss: 0.5361968278884888\n",
      "epoch: 6, batch: 1042, loss: 0.7539693713188171\n",
      "epoch: 6, batch: 1043, loss: 0.5173278450965881\n",
      "epoch: 6, batch: 1044, loss: 0.585088312625885\n",
      "epoch: 6, batch: 1045, loss: 0.7355688214302063\n",
      "epoch: 6, batch: 1046, loss: 0.6820991635322571\n",
      "epoch: 6, batch: 1047, loss: 0.6199659705162048\n",
      "epoch: 6, batch: 1048, loss: 0.7134908437728882\n",
      "epoch: 6, batch: 1049, loss: 0.5642918944358826\n",
      "epoch: 6, batch: 1050, loss: 0.39159855246543884\n",
      "epoch: 6, batch: 1051, loss: 0.5080558061599731\n",
      "epoch: 6, batch: 1052, loss: 0.4819616377353668\n",
      "epoch: 6, batch: 1053, loss: 0.5397047400474548\n",
      "epoch: 6, batch: 1054, loss: 0.5161586403846741\n",
      "epoch: 6, batch: 1055, loss: 0.5755125284194946\n",
      "epoch: 6, batch: 1056, loss: 0.4366101026535034\n",
      "epoch: 6, batch: 1057, loss: 0.5949470400810242\n",
      "epoch: 6, batch: 1058, loss: 0.7171417474746704\n",
      "epoch: 6, batch: 1059, loss: 0.4917982816696167\n",
      "epoch: 6, batch: 1060, loss: 0.4622887969017029\n",
      "epoch: 6, batch: 1061, loss: 0.6939702033996582\n",
      "epoch: 6, batch: 1062, loss: 0.6951476335525513\n",
      "epoch: 6, batch: 1063, loss: 0.6305702328681946\n",
      "epoch: 6, batch: 1064, loss: 0.6216335296630859\n",
      "epoch: 6, batch: 1065, loss: 0.8002383708953857\n",
      "epoch: 6, batch: 1066, loss: 0.5530919432640076\n",
      "epoch: 6, batch: 1067, loss: 0.7630009055137634\n",
      "epoch: 6, batch: 1068, loss: 0.6332058906555176\n",
      "epoch: 6, batch: 1069, loss: 0.6868013739585876\n",
      "epoch: 6, batch: 1070, loss: 0.6868010759353638\n",
      "epoch: 6, batch: 1071, loss: 0.6593928933143616\n",
      "epoch: 6, batch: 1072, loss: 0.4946424961090088\n",
      "epoch: 6, batch: 1073, loss: 0.4754815101623535\n",
      "epoch: 6, batch: 1074, loss: 0.41705846786499023\n",
      "epoch: 6, batch: 1075, loss: 0.5155696272850037\n",
      "epoch: 6, batch: 1076, loss: 0.6419532895088196\n",
      "epoch: 6, batch: 1077, loss: 0.5963712930679321\n",
      "epoch: 6, batch: 1078, loss: 0.5000467896461487\n",
      "epoch: 6, batch: 1079, loss: 0.3414222300052643\n",
      "epoch: 6, batch: 1080, loss: 0.58344566822052\n",
      "epoch: 6, batch: 1081, loss: 0.46355608105659485\n",
      "epoch: 6, batch: 1082, loss: 0.6822953820228577\n",
      "epoch: 6, batch: 1083, loss: 0.7022212743759155\n",
      "epoch: 6, batch: 1084, loss: 0.5203620195388794\n",
      "epoch: 6, batch: 1085, loss: 0.5652327537536621\n",
      "epoch: 6, batch: 1086, loss: 0.5118760466575623\n",
      "epoch: 6, batch: 1087, loss: 0.6482208371162415\n",
      "epoch: 6, batch: 1088, loss: 0.5836019515991211\n",
      "epoch: 6, batch: 1089, loss: 0.5365825295448303\n",
      "epoch: 6, batch: 1090, loss: 0.5807672739028931\n",
      "epoch: 6, batch: 1091, loss: 0.555375337600708\n",
      "epoch: 6, batch: 1092, loss: 0.5396264791488647\n",
      "epoch: 6, batch: 1093, loss: 0.4463600218296051\n",
      "epoch: 6, batch: 1094, loss: 0.47240689396858215\n",
      "epoch: 6, batch: 1095, loss: 0.39702776074409485\n",
      "epoch: 6, batch: 1096, loss: 0.5705484747886658\n",
      "epoch: 6, batch: 1097, loss: 0.9135744571685791\n",
      "epoch: 6, batch: 1098, loss: 0.6005873680114746\n",
      "epoch: 6, batch: 1099, loss: 0.5850765705108643\n",
      "epoch: 6, batch: 1100, loss: 0.3823021352291107\n",
      "epoch: 6, batch: 1101, loss: 0.6054551601409912\n",
      "epoch: 6, batch: 1102, loss: 0.5452884435653687\n",
      "epoch: 6, batch: 1103, loss: 0.7906017899513245\n",
      "epoch: 6, batch: 1104, loss: 0.7654038071632385\n",
      "epoch: 6, batch: 1105, loss: 0.5294190049171448\n",
      "epoch: 6, batch: 1106, loss: 0.5043500661849976\n",
      "epoch: 6, batch: 1107, loss: 0.7082516551017761\n",
      "epoch: 6, batch: 1108, loss: 0.4199427664279938\n",
      "epoch: 6, batch: 1109, loss: 0.7727811932563782\n",
      "epoch: 6, batch: 1110, loss: 0.5416163206100464\n",
      "epoch: 6, batch: 1111, loss: 0.4273625612258911\n",
      "epoch: 6, batch: 1112, loss: 0.6039348244667053\n",
      "epoch: 6, batch: 1113, loss: 0.4121982157230377\n",
      "epoch: 6, batch: 1114, loss: 0.4518545866012573\n",
      "epoch: 6, batch: 1115, loss: 0.6620091795921326\n",
      "epoch: 6, batch: 1116, loss: 0.6685066819190979\n",
      "epoch: 6, batch: 1117, loss: 0.584219753742218\n",
      "epoch: 6, batch: 1118, loss: 0.5074126124382019\n",
      "epoch: 6, batch: 1119, loss: 0.6551705002784729\n",
      "epoch: 6, batch: 1120, loss: 0.7296087145805359\n",
      "epoch: 6, batch: 1121, loss: 0.7482309341430664\n",
      "epoch: 6, batch: 1122, loss: 0.6321460604667664\n",
      "epoch: 6, batch: 1123, loss: 0.7153102159500122\n",
      "epoch: 6, batch: 1124, loss: 0.6286495327949524\n",
      "epoch: 6, batch: 1125, loss: 0.6033356785774231\n",
      "epoch: 6, batch: 1126, loss: 0.5225237607955933\n",
      "epoch: 6, batch: 1127, loss: 0.5306634902954102\n",
      "epoch: 6, batch: 1128, loss: 0.40992218255996704\n",
      "epoch: 6, batch: 1129, loss: 0.5674796104431152\n",
      "epoch: 6, batch: 1130, loss: 0.6960382461547852\n",
      "epoch: 6, batch: 1131, loss: 0.637631893157959\n",
      "epoch: 6, batch: 1132, loss: 0.5463011264801025\n",
      "epoch: 6, batch: 1133, loss: 0.5152149200439453\n",
      "epoch: 6, batch: 1134, loss: 0.4798506498336792\n",
      "epoch: 6, batch: 1135, loss: 0.5174256563186646\n",
      "epoch: 6, batch: 1136, loss: 0.4840337634086609\n",
      "epoch: 6, batch: 1137, loss: 0.6568400859832764\n",
      "epoch: 6, batch: 1138, loss: 0.7187184691429138\n",
      "epoch: 6, batch: 1139, loss: 0.4073619246482849\n",
      "epoch: 6, batch: 1140, loss: 0.6687512993812561\n",
      "epoch: 6, batch: 1141, loss: 0.562751054763794\n",
      "epoch: 6, batch: 1142, loss: 0.5203908085823059\n",
      "epoch: 6, batch: 1143, loss: 0.6015958786010742\n",
      "epoch: 6, batch: 1144, loss: 0.5059640407562256\n",
      "epoch: 6, batch: 1145, loss: 0.45111992955207825\n",
      "epoch: 6, batch: 1146, loss: 0.755669116973877\n",
      "epoch: 6, batch: 1147, loss: 0.778042197227478\n",
      "epoch: 6, batch: 1148, loss: 0.7642437219619751\n",
      "epoch: 6, batch: 1149, loss: 0.5088739991188049\n",
      "epoch: 6, batch: 1150, loss: 0.43622395396232605\n",
      "epoch: 6, batch: 1151, loss: 0.6742396354675293\n",
      "epoch: 6, batch: 1152, loss: 0.5462940335273743\n",
      "epoch: 6, batch: 1153, loss: 0.6739267110824585\n",
      "epoch: 6, batch: 1154, loss: 0.6256167888641357\n",
      "epoch: 6, batch: 1155, loss: 0.5454585552215576\n",
      "epoch: 6, batch: 1156, loss: 0.7576830983161926\n",
      "epoch: 6, batch: 1157, loss: 0.4580228626728058\n",
      "epoch: 6, batch: 1158, loss: 0.7935108542442322\n",
      "epoch: 6, batch: 1159, loss: 0.4077772796154022\n",
      "epoch: 6, batch: 1160, loss: 0.45052438974380493\n",
      "epoch: 6, batch: 1161, loss: 0.4874928295612335\n",
      "epoch: 6, batch: 1162, loss: 0.6027208566665649\n",
      "epoch: 6, batch: 1163, loss: 0.4114627242088318\n",
      "epoch: 6, batch: 1164, loss: 0.8335389494895935\n",
      "epoch: 6, batch: 1165, loss: 0.7539929747581482\n",
      "epoch: 6, batch: 1166, loss: 0.5498659610748291\n",
      "epoch: 6, batch: 1167, loss: 0.3921850621700287\n",
      "epoch: 6, batch: 1168, loss: 0.5949988961219788\n",
      "epoch: 6, batch: 1169, loss: 0.834639847278595\n",
      "epoch: 6, batch: 1170, loss: 0.5765604376792908\n",
      "epoch: 6, batch: 1171, loss: 0.42345160245895386\n",
      "epoch: 6, batch: 1172, loss: 0.536800742149353\n",
      "epoch: 6, batch: 1173, loss: 0.6190457344055176\n",
      "epoch: 6, batch: 1174, loss: 0.410988986492157\n",
      "epoch: 6, batch: 1175, loss: 0.4885401129722595\n",
      "epoch: 6, batch: 1176, loss: 0.5525028705596924\n",
      "epoch: 6, batch: 1177, loss: 0.6595152616500854\n",
      "epoch: 6, batch: 1178, loss: 0.4371589124202728\n",
      "epoch: 6, batch: 1179, loss: 0.46709144115448\n",
      "epoch: 6, batch: 1180, loss: 0.6673552989959717\n",
      "epoch: 6, batch: 1181, loss: 0.40496909618377686\n",
      "epoch: 6, batch: 1182, loss: 0.4769853353500366\n",
      "epoch: 6, batch: 1183, loss: 0.551445722579956\n",
      "epoch: 6, batch: 1184, loss: 0.6763781309127808\n",
      "epoch: 6, batch: 1185, loss: 0.4457792341709137\n",
      "epoch: 6, batch: 1186, loss: 0.4351799786090851\n",
      "epoch: 6, batch: 1187, loss: 0.8717977404594421\n",
      "epoch: 6, batch: 1188, loss: 0.3597925901412964\n",
      "epoch: 6, batch: 1189, loss: 0.3888593912124634\n",
      "epoch: 6, batch: 1190, loss: 0.3263944387435913\n",
      "epoch: 6, batch: 1191, loss: 0.637404203414917\n",
      "epoch: 6, batch: 1192, loss: 0.7147073149681091\n",
      "epoch: 6, batch: 1193, loss: 0.5950968861579895\n",
      "epoch: 6, batch: 1194, loss: 0.7595566511154175\n",
      "epoch: 6, batch: 1195, loss: 0.4713229537010193\n",
      "epoch: 6, batch: 1196, loss: 0.4731205701828003\n",
      "epoch: 6, batch: 1197, loss: 0.611522376537323\n",
      "epoch: 6, batch: 1198, loss: 0.6672022342681885\n",
      "epoch: 6, batch: 1199, loss: 0.8208214044570923\n",
      "epoch: 6, batch: 1200, loss: 0.45574522018432617\n",
      "epoch: 6, batch: 1201, loss: 0.8565682172775269\n",
      "epoch: 6, batch: 1202, loss: 0.4158121943473816\n",
      "epoch: 6, batch: 1203, loss: 0.3979347348213196\n",
      "epoch: 6, batch: 1204, loss: 0.6635352373123169\n",
      "epoch: 6, batch: 1205, loss: 0.5431727170944214\n",
      "epoch: 6, batch: 1206, loss: 0.5454888939857483\n",
      "epoch: 6, batch: 1207, loss: 0.47364288568496704\n",
      "epoch: 6, batch: 1208, loss: 0.5548579096794128\n",
      "epoch: 6, batch: 1209, loss: 0.6811097264289856\n",
      "epoch: 6, batch: 1210, loss: 0.6468552350997925\n",
      "epoch: 6, batch: 1211, loss: 0.6488475799560547\n",
      "epoch: 6, batch: 1212, loss: 0.5749158263206482\n",
      "epoch: 6, batch: 1213, loss: 0.7000521421432495\n",
      "epoch: 6, batch: 1214, loss: 0.5105476975440979\n",
      "epoch: 6, batch: 1215, loss: 0.7701666355133057\n",
      "epoch: 6, batch: 1216, loss: 0.5511041879653931\n",
      "epoch: 6, batch: 1217, loss: 0.6331256031990051\n",
      "epoch: 6, batch: 1218, loss: 0.3847076892852783\n",
      "epoch: 6, batch: 1219, loss: 0.5549919009208679\n",
      "epoch: 6, batch: 1220, loss: 0.6694828867912292\n",
      "epoch: 6, batch: 1221, loss: 0.373202919960022\n",
      "epoch: 6, batch: 1222, loss: 0.49655574560165405\n",
      "epoch: 6, batch: 1223, loss: 0.5090912580490112\n",
      "epoch: 6, batch: 1224, loss: 0.43088674545288086\n",
      "epoch: 6, batch: 1225, loss: 0.638691782951355\n",
      "epoch: 6, batch: 1226, loss: 0.48408252000808716\n",
      "epoch: 6, batch: 1227, loss: 0.28980496525764465\n",
      "epoch: 6, batch: 1228, loss: 0.5855689644813538\n",
      "epoch: 6, batch: 1229, loss: 0.5480697154998779\n",
      "epoch: 6, batch: 1230, loss: 0.6054303050041199\n",
      "epoch: 6, batch: 1231, loss: 0.41057705879211426\n",
      "epoch: 6, batch: 1232, loss: 0.5803590416908264\n",
      "epoch: 6, batch: 1233, loss: 0.3893122375011444\n",
      "epoch: 6, batch: 1234, loss: 0.544823169708252\n",
      "epoch: 6, batch: 1235, loss: 0.5191854238510132\n",
      "epoch: 6, batch: 1236, loss: 0.5260369181632996\n",
      "epoch: 6, batch: 1237, loss: 0.4815439283847809\n",
      "epoch: 6, batch: 1238, loss: 0.44761011004447937\n",
      "epoch: 6, batch: 1239, loss: 0.7961931228637695\n",
      "epoch: 6, batch: 1240, loss: 0.6992231011390686\n",
      "epoch: 6, batch: 1241, loss: 0.47123652696609497\n",
      "epoch: 6, batch: 1242, loss: 0.46996280550956726\n",
      "epoch: 6, batch: 1243, loss: 0.6177157163619995\n",
      "epoch: 6, batch: 1244, loss: 0.45586490631103516\n",
      "epoch: 6, batch: 1245, loss: 0.6056832075119019\n",
      "epoch: 6, batch: 1246, loss: 0.6873716115951538\n",
      "epoch: 6, batch: 1247, loss: 0.7337551712989807\n",
      "epoch: 6, batch: 1248, loss: 0.3452673554420471\n",
      "epoch: 6, batch: 1249, loss: 0.4588812589645386\n",
      "epoch: 6, batch: 1250, loss: 0.4066246449947357\n",
      "epoch: 6, batch: 1251, loss: 0.503807008266449\n",
      "epoch: 6, batch: 1252, loss: 0.4923356771469116\n",
      "epoch: 6, batch: 1253, loss: 0.5990603566169739\n",
      "epoch: 6, batch: 1254, loss: 0.4681239426136017\n",
      "epoch: 6, batch: 1255, loss: 0.4634123146533966\n",
      "epoch: 6, batch: 1256, loss: 0.7578042149543762\n",
      "epoch: 6, batch: 1257, loss: 0.5255967974662781\n",
      "epoch: 6, batch: 1258, loss: 0.5932592153549194\n",
      "epoch: 6, batch: 1259, loss: 0.5120283961296082\n",
      "epoch: 6, batch: 1260, loss: 0.8087610602378845\n",
      "epoch: 6, batch: 1261, loss: 0.7460973858833313\n",
      "epoch: 6, batch: 1262, loss: 0.5391161441802979\n",
      "epoch: 6, batch: 1263, loss: 0.5744485855102539\n",
      "epoch: 6, batch: 1264, loss: 0.7094813585281372\n",
      "epoch: 6, batch: 1265, loss: 0.7383655905723572\n",
      "epoch: 6, batch: 1266, loss: 0.5262860059738159\n",
      "epoch: 6, batch: 1267, loss: 0.7296249270439148\n",
      "epoch: 6, batch: 1268, loss: 0.4618031084537506\n",
      "epoch: 6, batch: 1269, loss: 0.7188925743103027\n",
      "epoch: 6, batch: 1270, loss: 0.5460771918296814\n",
      "epoch: 6, batch: 1271, loss: 0.5911417007446289\n",
      "epoch: 6, batch: 1272, loss: 0.4205162823200226\n",
      "epoch: 6, batch: 1273, loss: 0.688659131526947\n",
      "epoch: 6, batch: 1274, loss: 0.42048633098602295\n",
      "epoch: 6, batch: 1275, loss: 0.8219213485717773\n",
      "epoch: 6, batch: 1276, loss: 0.610325038433075\n",
      "epoch: 6, batch: 1277, loss: 0.5361965298652649\n",
      "epoch: 6, batch: 1278, loss: 0.5236498713493347\n",
      "epoch: 6, batch: 1279, loss: 0.5527087450027466\n",
      "epoch: 6, batch: 1280, loss: 0.5734662413597107\n",
      "epoch: 6, batch: 1281, loss: 0.5650026798248291\n",
      "epoch: 6, batch: 1282, loss: 0.5028002858161926\n",
      "epoch: 6, batch: 1283, loss: 0.716062068939209\n",
      "epoch: 6, batch: 1284, loss: 0.50871342420578\n",
      "epoch: 6, batch: 1285, loss: 0.46281659603118896\n",
      "epoch: 6, batch: 1286, loss: 0.6079736948013306\n",
      "epoch: 6, batch: 1287, loss: 0.5918852686882019\n",
      "epoch: 6, batch: 1288, loss: 0.8185409307479858\n",
      "epoch: 6, batch: 1289, loss: 0.7566049695014954\n",
      "epoch: 6, batch: 1290, loss: 0.5729568600654602\n",
      "epoch: 6, batch: 1291, loss: 0.32769975066185\n",
      "epoch: 6, batch: 1292, loss: 0.4878441393375397\n",
      "epoch: 6, batch: 1293, loss: 0.48015257716178894\n",
      "epoch: 6, batch: 1294, loss: 0.5053945183753967\n",
      "epoch: 6, batch: 1295, loss: 0.4869284927845001\n",
      "epoch: 6, batch: 1296, loss: 0.6572290062904358\n",
      "epoch: 6, batch: 1297, loss: 0.7776995301246643\n",
      "epoch: 6, batch: 1298, loss: 0.4366048276424408\n",
      "epoch: 6, batch: 1299, loss: 0.8885543346405029\n",
      "epoch: 6, batch: 1300, loss: 0.4960508346557617\n",
      "epoch: 6, batch: 1301, loss: 0.6272238492965698\n",
      "epoch: 6, batch: 1302, loss: 0.8676931262016296\n",
      "epoch: 6, batch: 1303, loss: 0.6048420071601868\n",
      "epoch: 6, batch: 1304, loss: 0.6213530898094177\n",
      "epoch: 6, batch: 1305, loss: 0.509718656539917\n",
      "epoch: 6, batch: 1306, loss: 0.5394352674484253\n",
      "epoch: 6, batch: 1307, loss: 0.4392673075199127\n",
      "epoch: 6, batch: 1308, loss: 0.641609251499176\n",
      "epoch: 6, batch: 1309, loss: 0.3818986713886261\n",
      "epoch: 6, batch: 1310, loss: 0.5330522060394287\n",
      "epoch: 6, batch: 1311, loss: 0.45863860845565796\n",
      "epoch: 6, batch: 1312, loss: 0.6732804775238037\n",
      "epoch: 6, batch: 1313, loss: 0.5681224465370178\n",
      "epoch: 6, batch: 1314, loss: 0.7450219988822937\n",
      "epoch: 6, batch: 1315, loss: 0.7463672161102295\n",
      "epoch: 6, batch: 1316, loss: 0.6354625821113586\n",
      "epoch: 6, batch: 1317, loss: 0.5020405650138855\n",
      "epoch: 6, batch: 1318, loss: 0.6501691937446594\n",
      "epoch: 6, batch: 1319, loss: 0.5583330392837524\n",
      "epoch: 6, batch: 1320, loss: 0.7713479399681091\n",
      "epoch: 6, batch: 1321, loss: 0.5253996849060059\n",
      "epoch: 6, batch: 1322, loss: 0.5426555871963501\n",
      "epoch: 6, batch: 1323, loss: 0.5773206949234009\n",
      "epoch: 6, batch: 1324, loss: 0.7361983060836792\n",
      "epoch: 6, batch: 1325, loss: 0.3646351099014282\n",
      "epoch: 6, batch: 1326, loss: 0.5953253507614136\n",
      "epoch: 6, batch: 1327, loss: 0.5127529501914978\n",
      "epoch: 6, batch: 1328, loss: 0.5277617573738098\n",
      "epoch: 6, batch: 1329, loss: 0.5555307865142822\n",
      "epoch: 6, batch: 1330, loss: 0.6123481392860413\n",
      "epoch: 6, batch: 1331, loss: 0.525428295135498\n",
      "epoch: 6, batch: 1332, loss: 0.5916450619697571\n",
      "epoch: 6, batch: 1333, loss: 0.3640821576118469\n",
      "epoch: 6, batch: 1334, loss: 0.423385888338089\n",
      "epoch: 6, batch: 1335, loss: 0.4934276342391968\n",
      "epoch: 6, batch: 1336, loss: 0.6372716426849365\n",
      "epoch: 6, batch: 1337, loss: 0.40692850947380066\n",
      "epoch: 6, batch: 1338, loss: 0.5978705883026123\n",
      "epoch: 6, batch: 1339, loss: 1.1392230987548828\n",
      "epoch: 6, batch: 1340, loss: 0.5382286310195923\n",
      "epoch: 6, batch: 1341, loss: 0.9251036047935486\n",
      "epoch: 6, batch: 1342, loss: 0.6788895130157471\n",
      "epoch: 6, batch: 1343, loss: 0.47062039375305176\n",
      "epoch: 6, batch: 1344, loss: 0.787663996219635\n",
      "epoch: 6, batch: 1345, loss: 0.6067132353782654\n",
      "epoch: 6, batch: 1346, loss: 0.6494103670120239\n",
      "epoch: 6, batch: 1347, loss: 0.8655586242675781\n",
      "epoch: 6, batch: 1348, loss: 0.5129215717315674\n",
      "epoch: 6, batch: 1349, loss: 0.6439623236656189\n",
      "epoch: 6, batch: 1350, loss: 0.5389417409896851\n",
      "epoch: 6, batch: 1351, loss: 0.5400310158729553\n",
      "epoch: 6, batch: 1352, loss: 0.6088945865631104\n",
      "epoch: 6, batch: 1353, loss: 0.5554512143135071\n",
      "epoch: 6, batch: 1354, loss: 0.6261981129646301\n",
      "epoch: 6, batch: 1355, loss: 0.37380561232566833\n",
      "epoch: 6, batch: 1356, loss: 0.645201563835144\n",
      "epoch: 6, batch: 1357, loss: 0.43041154742240906\n",
      "epoch: 6, batch: 1358, loss: 0.46036288142204285\n",
      "epoch: 6, batch: 1359, loss: 0.46679922938346863\n",
      "epoch: 6, batch: 1360, loss: 0.4902228116989136\n",
      "epoch: 6, batch: 1361, loss: 0.6222743391990662\n",
      "epoch: 6, batch: 1362, loss: 0.2914067506790161\n",
      "epoch: 6, batch: 1363, loss: 0.4637678265571594\n",
      "epoch: 6, batch: 1364, loss: 0.3831043243408203\n",
      "epoch: 6, batch: 1365, loss: 0.6671598553657532\n",
      "epoch: 6, batch: 1366, loss: 0.7453569173812866\n",
      "epoch: 6, batch: 1367, loss: 0.6153392195701599\n",
      "epoch: 6, batch: 1368, loss: 0.494228720664978\n",
      "epoch: 6, batch: 1369, loss: 0.6604871153831482\n",
      "epoch: 6, batch: 1370, loss: 0.3288097381591797\n",
      "epoch: 6, batch: 1371, loss: 0.6291857957839966\n",
      "epoch: 6, batch: 1372, loss: 0.669001579284668\n",
      "epoch: 6, batch: 1373, loss: 0.4495503902435303\n",
      "epoch: 6, batch: 1374, loss: 0.5193690061569214\n",
      "epoch: 6, batch: 1375, loss: 0.4610159993171692\n",
      "epoch: 6, batch: 1376, loss: 0.508273720741272\n",
      "epoch: 6, batch: 1377, loss: 0.5153623819351196\n",
      "epoch: 6, batch: 1378, loss: 0.8972141146659851\n",
      "epoch: 6, batch: 1379, loss: 0.5632639527320862\n",
      "epoch: 6, batch: 1380, loss: 0.5791012048721313\n",
      "epoch: 6, batch: 1381, loss: 0.49500536918640137\n",
      "epoch: 6, batch: 1382, loss: 0.5968433618545532\n",
      "epoch: 6, batch: 1383, loss: 0.7237313985824585\n",
      "epoch: 6, batch: 1384, loss: 0.5322348475456238\n",
      "epoch: 6, batch: 1385, loss: 0.41014963388442993\n",
      "epoch: 6, batch: 1386, loss: 0.8953787684440613\n",
      "epoch: 6, batch: 1387, loss: 0.5056301355361938\n",
      "epoch: 6, batch: 1388, loss: 0.5056431293487549\n",
      "epoch: 6, batch: 1389, loss: 0.7068538069725037\n",
      "epoch: 6, batch: 1390, loss: 0.6192495822906494\n",
      "epoch: 6, batch: 1391, loss: 0.45073193311691284\n",
      "epoch: 6, batch: 1392, loss: 0.7001911997795105\n",
      "epoch: 6, batch: 1393, loss: 0.3707946538925171\n",
      "epoch: 6, batch: 1394, loss: 0.575903594493866\n",
      "epoch: 6, batch: 1395, loss: 0.48289740085601807\n",
      "epoch: 6, batch: 1396, loss: 0.5488715767860413\n",
      "epoch: 6, batch: 1397, loss: 0.45324546098709106\n",
      "epoch: 6, batch: 1398, loss: 0.8115918040275574\n",
      "epoch: 6, batch: 1399, loss: 0.3807292878627777\n",
      "epoch: 6, batch: 1400, loss: 0.5297227501869202\n",
      "epoch: 6, batch: 1401, loss: 0.594845175743103\n",
      "epoch: 6, batch: 1402, loss: 0.4496407210826874\n",
      "epoch: 6, batch: 1403, loss: 0.43649211525917053\n",
      "epoch: 6, batch: 1404, loss: 0.4213889241218567\n",
      "epoch: 6, batch: 1405, loss: 0.5064219236373901\n",
      "epoch: 6, batch: 1406, loss: 0.29466402530670166\n",
      "epoch: 6, batch: 1407, loss: 0.705661416053772\n",
      "epoch: 6, batch: 1408, loss: 0.49574580788612366\n",
      "epoch: 6, batch: 1409, loss: 0.4771329462528229\n",
      "epoch: 6, batch: 1410, loss: 0.41405022144317627\n",
      "epoch: 6, batch: 1411, loss: 0.6486228108406067\n",
      "epoch: 6, batch: 1412, loss: 0.5472238063812256\n",
      "epoch: 6, batch: 1413, loss: 0.3774222135543823\n",
      "epoch: 6, batch: 1414, loss: 0.7514988780021667\n",
      "epoch: 6, batch: 1415, loss: 0.4934389889240265\n",
      "epoch: 6, batch: 1416, loss: 0.477141410112381\n",
      "epoch: 6, batch: 1417, loss: 0.5110985040664673\n",
      "epoch: 6, batch: 1418, loss: 0.6906101703643799\n",
      "epoch: 6, batch: 1419, loss: 0.5929144620895386\n",
      "epoch: 6, batch: 1420, loss: 0.6406410336494446\n",
      "epoch: 6, batch: 1421, loss: 0.5155709385871887\n",
      "epoch: 6, batch: 1422, loss: 0.6534942388534546\n",
      "epoch: 6, batch: 1423, loss: 0.7665216326713562\n",
      "epoch: 6, batch: 1424, loss: 0.5143887400627136\n",
      "epoch: 6, batch: 1425, loss: 0.6558865308761597\n",
      "epoch: 6, batch: 1426, loss: 0.617540180683136\n",
      "epoch: 6, batch: 1427, loss: 0.7168856263160706\n",
      "epoch: 6, batch: 1428, loss: 0.48863181471824646\n",
      "epoch: 6, batch: 1429, loss: 0.6638695001602173\n",
      "epoch: 6, batch: 1430, loss: 0.9239673018455505\n",
      "epoch: 6, batch: 1431, loss: 0.4411012530326843\n",
      "epoch: 6, batch: 1432, loss: 0.5354466438293457\n",
      "epoch: 6, batch: 1433, loss: 0.5786187052726746\n",
      "epoch: 6, batch: 1434, loss: 0.439077228307724\n",
      "epoch: 6, batch: 1435, loss: 0.6560123562812805\n",
      "epoch: 6, batch: 1436, loss: 0.22395120561122894\n",
      "epoch: 6, batch: 1437, loss: 0.5642279982566833\n",
      "epoch: 6, batch: 1438, loss: 0.6761669516563416\n",
      "epoch: 6, batch: 1439, loss: 0.6484645009040833\n",
      "epoch: 6, batch: 1440, loss: 0.8096654415130615\n",
      "epoch: 6, batch: 1441, loss: 0.4958101511001587\n",
      "epoch: 6, batch: 1442, loss: 0.5524682998657227\n",
      "epoch: 6, batch: 1443, loss: 0.41562896966934204\n",
      "epoch: 6, batch: 1444, loss: 0.644913375377655\n",
      "epoch: 6, batch: 1445, loss: 0.5487856864929199\n",
      "epoch: 6, batch: 1446, loss: 0.7511157393455505\n",
      "epoch: 6, batch: 1447, loss: 0.5139350891113281\n",
      "epoch: 6, batch: 1448, loss: 0.609853208065033\n",
      "epoch: 6, batch: 1449, loss: 0.49135756492614746\n",
      "epoch: 6, batch: 1450, loss: 0.795753002166748\n",
      "epoch: 6, batch: 1451, loss: 0.5246489644050598\n",
      "epoch: 6, batch: 1452, loss: 0.7894660234451294\n",
      "epoch: 6, batch: 1453, loss: 0.5026136040687561\n",
      "epoch: 6, batch: 1454, loss: 0.6993519067764282\n",
      "epoch: 6, batch: 1455, loss: 0.61222904920578\n",
      "epoch: 6, batch: 1456, loss: 0.36896976828575134\n",
      "epoch: 6, batch: 1457, loss: 0.671112596988678\n",
      "epoch: 6, batch: 1458, loss: 0.6204488277435303\n",
      "epoch: 6, batch: 1459, loss: 0.5759051442146301\n",
      "epoch: 6, batch: 1460, loss: 0.4834193289279938\n",
      "epoch: 6, batch: 1461, loss: 0.4034869968891144\n",
      "epoch: 6, batch: 1462, loss: 0.7732152938842773\n",
      "epoch: 6, batch: 1463, loss: 0.5369391441345215\n",
      "epoch: 6, batch: 1464, loss: 0.6173412799835205\n",
      "epoch: 6, batch: 1465, loss: 0.6027410626411438\n",
      "epoch: 6, batch: 1466, loss: 0.41636914014816284\n",
      "epoch: 6, batch: 1467, loss: 0.62693852186203\n",
      "epoch: 6, batch: 1468, loss: 0.4526313543319702\n",
      "epoch: 6, batch: 1469, loss: 0.6283632516860962\n",
      "epoch: 6, batch: 1470, loss: 0.5637949705123901\n",
      "epoch: 6, batch: 1471, loss: 0.38827240467071533\n",
      "epoch: 6, batch: 1472, loss: 1.120079517364502\n",
      "epoch: 6, batch: 1473, loss: 0.5704577565193176\n",
      "epoch: 6, batch: 1474, loss: 0.4362204372882843\n",
      "epoch: 6, batch: 1475, loss: 0.5975654125213623\n",
      "epoch: 6, batch: 1476, loss: 0.5364759564399719\n",
      "epoch: 6, batch: 1477, loss: 0.45337975025177\n",
      "epoch: 6, batch: 1478, loss: 0.5357890725135803\n",
      "epoch: 6, batch: 1479, loss: 0.6685035228729248\n",
      "epoch: 6, batch: 1480, loss: 0.4721410870552063\n",
      "epoch: 6, batch: 1481, loss: 0.47938621044158936\n",
      "epoch: 6, batch: 1482, loss: 0.3466731309890747\n",
      "epoch: 6, batch: 1483, loss: 0.7128037214279175\n",
      "epoch: 6, batch: 1484, loss: 0.4579427242279053\n",
      "epoch: 6, batch: 1485, loss: 0.49002769589424133\n",
      "epoch: 6, batch: 1486, loss: 0.5697783827781677\n",
      "epoch: 6, batch: 1487, loss: 0.7231279611587524\n",
      "epoch: 6, batch: 1488, loss: 0.47875136137008667\n",
      "epoch: 6, batch: 1489, loss: 0.5053423047065735\n",
      "epoch: 6, batch: 1490, loss: 0.6325188875198364\n",
      "epoch: 6, batch: 1491, loss: 0.4592377543449402\n",
      "epoch: 6, batch: 1492, loss: 0.5943270325660706\n",
      "epoch: 6, batch: 1493, loss: 0.833383321762085\n",
      "epoch: 6, batch: 1494, loss: 0.5714263319969177\n",
      "epoch: 6, batch: 1495, loss: 0.7075265645980835\n",
      "epoch: 6, batch: 1496, loss: 0.6187591552734375\n",
      "epoch: 6, batch: 1497, loss: 0.6944512128829956\n",
      "epoch: 6, batch: 1498, loss: 0.6534140706062317\n",
      "epoch: 6, batch: 1499, loss: 0.6929638385772705\n",
      "epoch: 6, batch: 1500, loss: 0.6625451445579529\n",
      "epoch: 6, batch: 1501, loss: 0.719607949256897\n",
      "epoch: 6, batch: 1502, loss: 0.6043880581855774\n",
      "epoch: 6, batch: 1503, loss: 0.7197597622871399\n",
      "epoch: 6, batch: 1504, loss: 0.5062520503997803\n",
      "epoch: 6, batch: 1505, loss: 0.5194292068481445\n",
      "epoch: 6, batch: 1506, loss: 0.5165289640426636\n",
      "epoch: 6, batch: 1507, loss: 0.6368594169616699\n",
      "epoch: 6, batch: 1508, loss: 0.7557332515716553\n",
      "epoch: 6, batch: 1509, loss: 0.46945929527282715\n",
      "epoch: 6, batch: 1510, loss: 0.6599666476249695\n",
      "epoch: 6, batch: 1511, loss: 0.5508946180343628\n",
      "epoch: 6, batch: 1512, loss: 0.5950732827186584\n",
      "epoch: 6, batch: 1513, loss: 0.5271708369255066\n",
      "epoch: 6, batch: 1514, loss: 0.7450338006019592\n",
      "epoch: 6, batch: 1515, loss: 0.5518353581428528\n",
      "epoch: 6, batch: 1516, loss: 0.5171541571617126\n",
      "epoch: 6, batch: 1517, loss: 0.6867185235023499\n",
      "epoch: 6, batch: 1518, loss: 0.7494144439697266\n",
      "epoch: 6, batch: 1519, loss: 0.5825133323669434\n",
      "epoch: 6, batch: 1520, loss: 0.49246224761009216\n",
      "epoch: 6, batch: 1521, loss: 0.6863767504692078\n",
      "epoch: 6, batch: 1522, loss: 0.4204808175563812\n",
      "epoch: 6, batch: 1523, loss: 0.5887069702148438\n",
      "epoch: 6, batch: 1524, loss: 0.5090359449386597\n",
      "epoch: 6, batch: 1525, loss: 0.4451005756855011\n",
      "epoch: 6, batch: 1526, loss: 0.8154209852218628\n",
      "epoch: 6, batch: 1527, loss: 0.7067175507545471\n",
      "epoch: 6, batch: 1528, loss: 0.5507664680480957\n",
      "epoch: 6, batch: 1529, loss: 0.5441229343414307\n",
      "epoch: 6, batch: 1530, loss: 0.44891902804374695\n",
      "epoch: 6, batch: 1531, loss: 0.7099941968917847\n",
      "epoch: 6, batch: 1532, loss: 0.9045771956443787\n",
      "epoch: 6, batch: 1533, loss: 0.7525717616081238\n",
      "epoch: 6, batch: 1534, loss: 0.7052420377731323\n",
      "epoch: 6, batch: 1535, loss: 0.7193707823753357\n",
      "epoch: 6, batch: 1536, loss: 0.6562861800193787\n",
      "epoch: 6, batch: 1537, loss: 0.5004628300666809\n",
      "epoch: 6, batch: 1538, loss: 0.4706071615219116\n",
      "epoch: 6, batch: 1539, loss: 0.38927173614501953\n",
      "epoch: 6, batch: 1540, loss: 0.5386757254600525\n",
      "epoch: 6, batch: 1541, loss: 0.8794835805892944\n",
      "epoch: 6, batch: 1542, loss: 0.643976092338562\n",
      "epoch: 6, batch: 1543, loss: 0.4140915870666504\n",
      "epoch: 6, batch: 1544, loss: 0.5174692869186401\n",
      "epoch: 6, batch: 1545, loss: 0.7327017784118652\n",
      "epoch: 6, batch: 1546, loss: 0.7109431624412537\n",
      "epoch: 6, batch: 1547, loss: 0.4066910743713379\n",
      "epoch: 6, batch: 1548, loss: 0.44098910689353943\n",
      "epoch: 6, batch: 1549, loss: 0.590819776058197\n",
      "epoch: 6, batch: 1550, loss: 0.6291544437408447\n",
      "epoch: 6, batch: 1551, loss: 0.5294609665870667\n",
      "epoch: 6, batch: 1552, loss: 0.5282191634178162\n",
      "epoch: 6, batch: 1553, loss: 0.7881022095680237\n",
      "epoch: 6, batch: 1554, loss: 0.4594610631465912\n",
      "epoch: 6, batch: 1555, loss: 0.3728666305541992\n",
      "epoch: 6, batch: 1556, loss: 0.6827548146247864\n",
      "epoch: 6, batch: 1557, loss: 0.5481757521629333\n",
      "epoch: 6, batch: 1558, loss: 0.7487484216690063\n",
      "epoch: 6, batch: 1559, loss: 0.609000027179718\n",
      "epoch: 6, batch: 1560, loss: 0.4023394286632538\n",
      "epoch: 6, batch: 1561, loss: 0.8315459489822388\n",
      "epoch: 6, batch: 1562, loss: 0.6698572635650635\n",
      "epoch: 6, batch: 1563, loss: 0.4842897951602936\n",
      "epoch: 6, batch: 1564, loss: 0.7244188189506531\n",
      "epoch: 6, batch: 1565, loss: 0.535027801990509\n",
      "epoch: 6, batch: 1566, loss: 0.8278720378875732\n",
      "epoch: 6, batch: 1567, loss: 0.6826169490814209\n",
      "epoch: 6, batch: 1568, loss: 1.013056993484497\n",
      "epoch: 6, batch: 1569, loss: 0.5363922715187073\n",
      "epoch: 6, batch: 1570, loss: 0.6630935668945312\n",
      "epoch: 6, batch: 1571, loss: 0.5158939957618713\n",
      "epoch: 6, batch: 1572, loss: 0.5732582211494446\n",
      "epoch: 6, batch: 1573, loss: 0.43916603922843933\n",
      "epoch: 6, batch: 1574, loss: 0.3271183669567108\n",
      "epoch: 6, batch: 1575, loss: 0.6194891333580017\n",
      "epoch: 6, batch: 1576, loss: 0.6666328310966492\n",
      "epoch: 6, batch: 1577, loss: 0.705077588558197\n",
      "epoch: 6, batch: 1578, loss: 0.5386149883270264\n",
      "epoch: 6, batch: 1579, loss: 0.6351510286331177\n",
      "epoch: 6, batch: 1580, loss: 0.5667864680290222\n",
      "epoch: 6, batch: 1581, loss: 0.6437674164772034\n",
      "epoch: 6, batch: 1582, loss: 0.984483540058136\n",
      "epoch: 6, batch: 1583, loss: 0.7033432126045227\n",
      "epoch: 6, batch: 1584, loss: 0.4234813451766968\n",
      "epoch: 6, batch: 1585, loss: 0.26350173354148865\n",
      "epoch: 6, batch: 1586, loss: 0.48003625869750977\n",
      "epoch: 6, batch: 1587, loss: 0.8698118925094604\n",
      "epoch: 6, batch: 1588, loss: 0.7438358068466187\n",
      "epoch: 6, batch: 1589, loss: 0.8681362867355347\n",
      "epoch: 6, batch: 1590, loss: 0.4918254613876343\n",
      "epoch: 6, batch: 1591, loss: 0.686866283416748\n",
      "epoch: 6, batch: 1592, loss: 0.5555378794670105\n",
      "epoch: 6, batch: 1593, loss: 0.41179054975509644\n",
      "epoch: 6, batch: 1594, loss: 0.33346474170684814\n",
      "epoch: 6, batch: 1595, loss: 0.727996289730072\n",
      "epoch: 6, batch: 1596, loss: 0.3717881143093109\n",
      "epoch: 6, batch: 1597, loss: 0.3690352141857147\n",
      "epoch: 6, batch: 1598, loss: 0.6025593280792236\n",
      "epoch: 6, batch: 1599, loss: 0.390042245388031\n",
      "epoch: 6, batch: 1600, loss: 0.5193129777908325\n",
      "epoch: 6, batch: 1601, loss: 0.6350788474082947\n",
      "epoch: 6, batch: 1602, loss: 0.5989190340042114\n",
      "epoch: 6, batch: 1603, loss: 0.5165805816650391\n",
      "epoch: 6, batch: 1604, loss: 0.8516917824745178\n",
      "epoch: 6, batch: 1605, loss: 0.7313827872276306\n",
      "epoch: 6, batch: 1606, loss: 0.7352010011672974\n",
      "epoch: 6, batch: 1607, loss: 0.44523885846138\n",
      "epoch: 6, batch: 1608, loss: 0.3496473431587219\n",
      "epoch: 6, batch: 1609, loss: 0.6181315779685974\n",
      "epoch: 6, batch: 1610, loss: 0.4670190215110779\n",
      "epoch: 6, batch: 1611, loss: 0.7742102146148682\n",
      "epoch: 6, batch: 1612, loss: 0.49181801080703735\n",
      "epoch: 6, batch: 1613, loss: 0.5269550681114197\n",
      "epoch: 6, batch: 1614, loss: 0.7448614239692688\n",
      "epoch: 6, batch: 1615, loss: 0.5006593465805054\n",
      "epoch: 6, batch: 1616, loss: 0.5474498867988586\n",
      "epoch: 6, batch: 1617, loss: 0.539071261882782\n",
      "epoch: 6, batch: 1618, loss: 0.6384902596473694\n",
      "epoch: 6, batch: 1619, loss: 0.5090893507003784\n",
      "epoch: 6, batch: 1620, loss: 0.41076233983039856\n",
      "epoch: 6, batch: 1621, loss: 0.5732209086418152\n",
      "epoch: 6, batch: 1622, loss: 0.5868487358093262\n",
      "epoch: 6, batch: 1623, loss: 0.47073206305503845\n",
      "epoch: 6, batch: 1624, loss: 0.4781199097633362\n",
      "epoch: 6, batch: 1625, loss: 0.5756559371948242\n",
      "epoch: 6, batch: 1626, loss: 0.5549900531768799\n",
      "epoch: 6, batch: 1627, loss: 0.5164493918418884\n",
      "epoch: 6, batch: 1628, loss: 0.6284360885620117\n",
      "epoch: 6, batch: 1629, loss: 0.37256717681884766\n",
      "epoch: 6, batch: 1630, loss: 0.47661304473876953\n",
      "epoch: 6, batch: 1631, loss: 0.6463078856468201\n",
      "epoch: 6, batch: 1632, loss: 0.5251564979553223\n",
      "epoch: 6, batch: 1633, loss: 0.5754635334014893\n",
      "epoch: 6, batch: 1634, loss: 0.672031819820404\n",
      "epoch: 6, batch: 1635, loss: 0.5432015061378479\n",
      "epoch: 6, batch: 1636, loss: 0.700188398361206\n",
      "epoch: 6, batch: 1637, loss: 0.39859285950660706\n",
      "epoch: 6, batch: 1638, loss: 0.457564115524292\n",
      "epoch: 6, batch: 1639, loss: 0.31905779242515564\n",
      "epoch: 6, batch: 1640, loss: 0.6446996927261353\n",
      "epoch: 6, batch: 1641, loss: 0.5191211700439453\n",
      "epoch: 6, batch: 1642, loss: 0.4656095802783966\n",
      "epoch: 6, batch: 1643, loss: 0.780330240726471\n",
      "epoch: 6, batch: 1644, loss: 0.5051592588424683\n",
      "epoch: 6, batch: 1645, loss: 0.4848887324333191\n",
      "epoch: 6, batch: 1646, loss: 0.4859325885772705\n",
      "epoch: 6, batch: 1647, loss: 0.6371505260467529\n",
      "epoch: 6, batch: 1648, loss: 0.5858154892921448\n",
      "epoch: 6, batch: 1649, loss: 0.6479377746582031\n",
      "epoch: 6, batch: 1650, loss: 0.5480806827545166\n",
      "epoch: 6, batch: 1651, loss: 0.5785111784934998\n",
      "epoch: 6, batch: 1652, loss: 0.5049152970314026\n",
      "epoch: 6, batch: 1653, loss: 0.6686117649078369\n",
      "epoch: 6, batch: 1654, loss: 0.6474586725234985\n",
      "epoch: 6, batch: 1655, loss: 0.5214974880218506\n",
      "epoch: 6, batch: 1656, loss: 0.49006664752960205\n",
      "epoch: 6, batch: 1657, loss: 0.32974573969841003\n",
      "epoch: 6, batch: 1658, loss: 0.39508962631225586\n",
      "epoch: 6, batch: 1659, loss: 0.49587106704711914\n",
      "epoch: 6, batch: 1660, loss: 0.5790482759475708\n",
      "epoch: 6, batch: 1661, loss: 0.8503477573394775\n",
      "epoch: 6, batch: 1662, loss: 0.48333606123924255\n",
      "epoch: 6, batch: 1663, loss: 0.5117573738098145\n",
      "epoch: 6, batch: 1664, loss: 0.5662363171577454\n",
      "epoch: 6, batch: 1665, loss: 0.512662947177887\n",
      "epoch: 6, batch: 1666, loss: 0.5758414268493652\n",
      "epoch: 6, batch: 1667, loss: 0.45597562193870544\n",
      "epoch: 6, batch: 1668, loss: 0.5302844047546387\n",
      "epoch: 6, batch: 1669, loss: 0.406887412071228\n",
      "epoch: 6, batch: 1670, loss: 0.3285348415374756\n",
      "epoch: 6, batch: 1671, loss: 0.5109668970108032\n",
      "epoch: 6, batch: 1672, loss: 0.4474748969078064\n",
      "epoch: 6, batch: 1673, loss: 0.2629363536834717\n",
      "epoch: 6, batch: 1674, loss: 0.4717223048210144\n",
      "epoch: 6, batch: 1675, loss: 0.4568363428115845\n",
      "epoch: 6, batch: 1676, loss: 0.6247988343238831\n",
      "epoch: 6, batch: 1677, loss: 0.6320482492446899\n",
      "epoch: 6, batch: 1678, loss: 0.6320469975471497\n",
      "epoch: 6, batch: 1679, loss: 0.3295453190803528\n",
      "epoch: 6, batch: 1680, loss: 0.3899093270301819\n",
      "epoch: 6, batch: 1681, loss: 0.5670437216758728\n",
      "epoch: 6, batch: 1682, loss: 0.48399728536605835\n",
      "epoch: 6, batch: 1683, loss: 0.6120094656944275\n",
      "epoch: 6, batch: 1684, loss: 0.5846686959266663\n",
      "epoch: 6, batch: 1685, loss: 0.4554750621318817\n",
      "epoch: 6, batch: 1686, loss: 0.8825633525848389\n",
      "epoch: 6, batch: 1687, loss: 0.5175290703773499\n",
      "epoch: 6, batch: 1688, loss: 0.4639928638935089\n",
      "epoch: 6, batch: 1689, loss: 0.5706096887588501\n",
      "epoch: 6, batch: 1690, loss: 0.7274689078330994\n",
      "epoch: 6, batch: 1691, loss: 0.8315449357032776\n",
      "epoch: 6, batch: 1692, loss: 0.35334157943725586\n",
      "epoch: 6, batch: 1693, loss: 0.6435920596122742\n",
      "epoch: 6, batch: 1694, loss: 0.5764366388320923\n",
      "epoch: 6, batch: 1695, loss: 0.8090610504150391\n",
      "epoch: 6, batch: 1696, loss: 0.638513445854187\n",
      "epoch: 6, batch: 1697, loss: 0.8037003874778748\n",
      "epoch: 6, batch: 1698, loss: 0.4209710359573364\n",
      "epoch: 6, batch: 1699, loss: 0.4572089612483978\n",
      "epoch: 6, batch: 1700, loss: 0.5021997690200806\n",
      "epoch: 6, batch: 1701, loss: 0.48002487421035767\n",
      "epoch: 6, batch: 1702, loss: 0.4098284840583801\n",
      "epoch: 6, batch: 1703, loss: 0.6134190559387207\n",
      "epoch: 6, batch: 1704, loss: 0.5187038779258728\n",
      "epoch: 6, batch: 1705, loss: 0.5244259238243103\n",
      "epoch: 6, batch: 1706, loss: 0.7234554886817932\n",
      "epoch: 6, batch: 1707, loss: 0.5193681716918945\n",
      "epoch: 6, batch: 1708, loss: 0.44711071252822876\n",
      "epoch: 6, batch: 1709, loss: 0.8710848689079285\n",
      "epoch: 6, batch: 1710, loss: 0.7656334042549133\n",
      "epoch: 6, batch: 1711, loss: 0.6624309420585632\n",
      "epoch: 6, batch: 1712, loss: 0.6356549859046936\n",
      "epoch: 6, batch: 1713, loss: 0.41049280762672424\n",
      "epoch: 6, batch: 1714, loss: 0.43027812242507935\n",
      "epoch: 6, batch: 1715, loss: 0.5884278416633606\n",
      "epoch: 6, batch: 1716, loss: 0.5924227237701416\n",
      "epoch: 6, batch: 1717, loss: 0.5175197720527649\n",
      "epoch: 6, batch: 1718, loss: 0.5468645095825195\n",
      "epoch: 6, batch: 1719, loss: 0.5133431553840637\n",
      "epoch: 6, batch: 1720, loss: 0.5764641761779785\n",
      "epoch: 6, batch: 1721, loss: 1.1049305200576782\n",
      "epoch: 6, batch: 1722, loss: 0.3412574529647827\n",
      "epoch: 6, batch: 1723, loss: 0.5527963638305664\n",
      "epoch: 6, batch: 1724, loss: 0.6336832046508789\n",
      "epoch: 6, batch: 1725, loss: 0.6381127834320068\n",
      "epoch: 6, batch: 1726, loss: 0.6592134833335876\n",
      "epoch: 6, batch: 1727, loss: 0.40595194697380066\n",
      "epoch: 6, batch: 1728, loss: 0.46184632182121277\n",
      "epoch: 6, batch: 1729, loss: 0.5654022097587585\n",
      "epoch: 6, batch: 1730, loss: 0.41489800810813904\n",
      "epoch: 6, batch: 1731, loss: 0.4164011478424072\n",
      "epoch: 6, batch: 1732, loss: 0.6389399766921997\n",
      "epoch: 6, batch: 1733, loss: 0.5043512582778931\n",
      "epoch: 6, batch: 1734, loss: 0.39473193883895874\n",
      "epoch: 6, batch: 1735, loss: 0.3760782778263092\n",
      "epoch: 6, batch: 1736, loss: 0.49053049087524414\n",
      "epoch: 6, batch: 1737, loss: 0.6510298848152161\n",
      "epoch: 6, batch: 1738, loss: 0.4946358799934387\n",
      "epoch: 6, batch: 1739, loss: 0.6321932077407837\n",
      "epoch: 6, batch: 1740, loss: 0.6523088216781616\n",
      "epoch: 6, batch: 1741, loss: 0.39797523617744446\n",
      "epoch: 6, batch: 1742, loss: 0.5708441734313965\n",
      "epoch: 6, batch: 1743, loss: 0.7724713683128357\n",
      "epoch: 6, batch: 1744, loss: 0.371369868516922\n",
      "epoch: 6, batch: 1745, loss: 0.5799287557601929\n",
      "epoch: 6, batch: 1746, loss: 0.4939335882663727\n",
      "epoch: 6, batch: 1747, loss: 0.6104466915130615\n",
      "epoch: 6, batch: 1748, loss: 0.6275836229324341\n",
      "epoch: 6, batch: 1749, loss: 0.3944079875946045\n",
      "epoch: 6, batch: 1750, loss: 0.442623108625412\n",
      "epoch: 6, batch: 1751, loss: 0.6689282655715942\n",
      "epoch: 6, batch: 1752, loss: 0.45977023243904114\n",
      "epoch: 6, batch: 1753, loss: 0.37246787548065186\n",
      "epoch: 6, batch: 1754, loss: 0.7967653274536133\n",
      "epoch: 6, batch: 1755, loss: 0.5062640309333801\n",
      "epoch: 6, batch: 1756, loss: 0.7299785614013672\n",
      "epoch: 6, batch: 1757, loss: 0.6627122759819031\n",
      "epoch: 6, batch: 1758, loss: 0.5130712389945984\n",
      "epoch: 6, batch: 1759, loss: 0.6916310787200928\n",
      "epoch: 6, batch: 1760, loss: 0.48627278208732605\n",
      "epoch: 6, batch: 1761, loss: 0.6535187363624573\n",
      "epoch: 6, batch: 1762, loss: 0.4903329610824585\n",
      "epoch: 6, batch: 1763, loss: 0.5493813753128052\n",
      "epoch: 6, batch: 1764, loss: 0.4461080729961395\n",
      "epoch: 6, batch: 1765, loss: 0.695602297782898\n",
      "epoch: 6, batch: 1766, loss: 0.4577774703502655\n",
      "epoch: 6, batch: 1767, loss: 0.9219452142715454\n",
      "epoch: 6, batch: 1768, loss: 0.45867881178855896\n",
      "epoch: 6, batch: 1769, loss: 0.3471924364566803\n",
      "epoch: 6, batch: 1770, loss: 0.4515227973461151\n",
      "epoch: 6, batch: 1771, loss: 0.8068227171897888\n",
      "epoch: 6, batch: 1772, loss: 0.7186371088027954\n",
      "epoch: 6, batch: 1773, loss: 0.6261168122291565\n",
      "epoch: 6, batch: 1774, loss: 0.5196836590766907\n",
      "epoch: 6, batch: 1775, loss: 0.3853134214878082\n",
      "epoch: 6, batch: 1776, loss: 0.6155737042427063\n",
      "epoch: 6, batch: 1777, loss: 0.6420023441314697\n",
      "epoch: 6, batch: 1778, loss: 0.6278933882713318\n",
      "epoch: 6, batch: 1779, loss: 0.8313339352607727\n",
      "epoch: 6, batch: 1780, loss: 0.5213615894317627\n",
      "epoch: 6, batch: 1781, loss: 0.6030116081237793\n",
      "epoch: 6, batch: 1782, loss: 0.4914247989654541\n",
      "epoch: 6, batch: 1783, loss: 0.4682129919528961\n",
      "epoch: 6, batch: 1784, loss: 1.202229380607605\n",
      "epoch: 6, batch: 1785, loss: 0.543239414691925\n",
      "epoch: 6, batch: 1786, loss: 0.505491316318512\n",
      "epoch: 6, batch: 1787, loss: 0.35807615518569946\n",
      "epoch: 6, batch: 1788, loss: 0.34760868549346924\n",
      "epoch: 6, batch: 1789, loss: 0.3959677517414093\n",
      "epoch: 6, batch: 1790, loss: 0.42551112174987793\n",
      "epoch: 6, batch: 1791, loss: 1.0524650812149048\n",
      "epoch: 6, batch: 1792, loss: 0.4476364552974701\n",
      "epoch: 6, batch: 1793, loss: 0.6267114877700806\n",
      "epoch: 6, batch: 1794, loss: 0.5368981957435608\n",
      "epoch: 6, batch: 1795, loss: 0.3623734712600708\n",
      "epoch: 6, batch: 1796, loss: 0.6570513844490051\n",
      "epoch: 6, batch: 1797, loss: 0.4944915175437927\n",
      "epoch: 6, batch: 1798, loss: 0.342631995677948\n",
      "epoch: 6, batch: 1799, loss: 0.4997073709964752\n",
      "epoch: 6, batch: 1800, loss: 0.3688884675502777\n",
      "epoch: 6, batch: 1801, loss: 0.6409814357757568\n",
      "epoch: 6, batch: 1802, loss: 0.4655958414077759\n",
      "epoch: 6, batch: 1803, loss: 0.782600998878479\n",
      "epoch: 6, batch: 1804, loss: 0.3866925835609436\n",
      "epoch: 6, batch: 1805, loss: 0.4116470217704773\n",
      "epoch: 6, batch: 1806, loss: 0.5590678453445435\n",
      "epoch: 6, batch: 1807, loss: 0.5595669746398926\n",
      "epoch: 6, batch: 1808, loss: 0.7265597581863403\n",
      "epoch: 6, batch: 1809, loss: 0.488638699054718\n",
      "epoch: 6, batch: 1810, loss: 0.5707893967628479\n",
      "epoch: 6, batch: 1811, loss: 0.5387438535690308\n",
      "epoch: 6, batch: 1812, loss: 0.6438903212547302\n",
      "epoch: 6, batch: 1813, loss: 0.4681224226951599\n",
      "epoch: 6, batch: 1814, loss: 0.6351447701454163\n",
      "epoch: 6, batch: 1815, loss: 0.46554073691368103\n",
      "epoch: 6, batch: 1816, loss: 0.5407723784446716\n",
      "epoch: 6, batch: 1817, loss: 0.6090788245201111\n",
      "epoch: 6, batch: 1818, loss: 0.4766043722629547\n",
      "epoch: 6, batch: 1819, loss: 0.8541861176490784\n",
      "epoch: 6, batch: 1820, loss: 0.48135921359062195\n",
      "epoch: 6, batch: 1821, loss: 0.5373099446296692\n",
      "epoch: 6, batch: 1822, loss: 0.3522130250930786\n",
      "epoch: 6, batch: 1823, loss: 0.6349251866340637\n",
      "epoch: 6, batch: 1824, loss: 0.6576733589172363\n",
      "epoch: 6, batch: 1825, loss: 0.7399462461471558\n",
      "epoch: 6, batch: 1826, loss: 0.5347422957420349\n",
      "epoch: 6, batch: 1827, loss: 0.3967059552669525\n",
      "epoch: 6, batch: 1828, loss: 0.8621619939804077\n",
      "epoch: 6, batch: 1829, loss: 0.5106768608093262\n",
      "epoch: 6, batch: 1830, loss: 0.4806844890117645\n",
      "epoch: 6, batch: 1831, loss: 0.8247798085212708\n",
      "epoch: 6, batch: 1832, loss: 0.4691444933414459\n",
      "epoch: 6, batch: 1833, loss: 0.4293365478515625\n",
      "epoch: 6, batch: 1834, loss: 0.5161141157150269\n",
      "epoch: 6, batch: 1835, loss: 0.4751034677028656\n",
      "epoch: 6, batch: 1836, loss: 0.5996856689453125\n",
      "epoch: 6, batch: 1837, loss: 0.6769953370094299\n",
      "epoch: 6, batch: 1838, loss: 0.3919709622859955\n",
      "epoch: 6, batch: 1839, loss: 0.7741139531135559\n",
      "epoch: 6, batch: 1840, loss: 0.5161272883415222\n",
      "epoch: 6, batch: 1841, loss: 0.5517959594726562\n",
      "epoch: 6, batch: 1842, loss: 0.8270420432090759\n",
      "epoch: 6, batch: 1843, loss: 0.3731618821620941\n",
      "epoch: 6, batch: 1844, loss: 0.6471343636512756\n",
      "epoch: 6, batch: 1845, loss: 0.7056959271430969\n",
      "epoch: 6, batch: 1846, loss: 0.5457915663719177\n",
      "epoch: 6, batch: 1847, loss: 0.4560064673423767\n",
      "epoch: 6, batch: 1848, loss: 0.5245614647865295\n",
      "epoch: 6, batch: 1849, loss: 0.7339780330657959\n",
      "epoch: 6, batch: 1850, loss: 0.454789400100708\n",
      "epoch: 6, batch: 1851, loss: 0.5074756145477295\n",
      "epoch: 6, batch: 1852, loss: 0.49464255571365356\n",
      "epoch: 6, batch: 1853, loss: 0.5775177478790283\n",
      "epoch: 6, batch: 1854, loss: 0.3940880000591278\n",
      "epoch: 6, batch: 1855, loss: 0.40778061747550964\n",
      "epoch: 6, batch: 1856, loss: 0.5947149991989136\n",
      "epoch: 6, batch: 1857, loss: 0.6466782093048096\n",
      "epoch: 6, batch: 1858, loss: 0.5231642723083496\n",
      "epoch: 6, batch: 1859, loss: 0.5781704783439636\n",
      "epoch: 6, batch: 1860, loss: 0.5819736123085022\n",
      "epoch: 6, batch: 1861, loss: 0.5652529001235962\n",
      "epoch: 6, batch: 1862, loss: 0.47580933570861816\n",
      "epoch: 6, batch: 1863, loss: 0.3989986479282379\n",
      "epoch: 6, batch: 1864, loss: 0.6068459749221802\n",
      "epoch: 6, batch: 1865, loss: 0.4772579073905945\n",
      "epoch: 6, batch: 1866, loss: 0.6683263182640076\n",
      "epoch: 6, batch: 1867, loss: 0.7029568552970886\n",
      "epoch: 6, batch: 1868, loss: 0.4005853235721588\n",
      "epoch: 6, batch: 1869, loss: 0.5320615172386169\n",
      "epoch: 6, batch: 1870, loss: 0.3113219439983368\n",
      "epoch: 6, batch: 1871, loss: 0.4954863488674164\n",
      "epoch: 6, batch: 1872, loss: 0.4717865288257599\n",
      "epoch: 6, batch: 1873, loss: 0.5474729537963867\n",
      "epoch: 6, batch: 1874, loss: 0.6178142428398132\n",
      "epoch: 7, batch: 0, loss: 0.4319135248661041\n",
      "epoch: 7, batch: 1, loss: 0.7963313460350037\n",
      "epoch: 7, batch: 2, loss: 0.8121241927146912\n",
      "epoch: 7, batch: 3, loss: 0.5438646078109741\n",
      "epoch: 7, batch: 4, loss: 0.5150858759880066\n",
      "epoch: 7, batch: 5, loss: 0.6314340829849243\n",
      "epoch: 7, batch: 6, loss: 1.0418500900268555\n",
      "epoch: 7, batch: 7, loss: 0.6324971318244934\n",
      "epoch: 7, batch: 8, loss: 0.7285315990447998\n",
      "epoch: 7, batch: 9, loss: 0.37577903270721436\n",
      "epoch: 7, batch: 10, loss: 0.7234824299812317\n",
      "epoch: 7, batch: 11, loss: 0.5527669787406921\n",
      "epoch: 7, batch: 12, loss: 0.5761562585830688\n",
      "epoch: 7, batch: 13, loss: 0.5126475691795349\n",
      "epoch: 7, batch: 14, loss: 0.754470944404602\n",
      "epoch: 7, batch: 15, loss: 0.4976651668548584\n",
      "epoch: 7, batch: 16, loss: 0.5135294795036316\n",
      "epoch: 7, batch: 17, loss: 0.5327741503715515\n",
      "epoch: 7, batch: 18, loss: 0.6836984753608704\n",
      "epoch: 7, batch: 19, loss: 0.4155113995075226\n",
      "epoch: 7, batch: 20, loss: 0.6410234570503235\n",
      "epoch: 7, batch: 21, loss: 0.5650791525840759\n",
      "epoch: 7, batch: 22, loss: 0.625754177570343\n",
      "epoch: 7, batch: 23, loss: 0.49049919843673706\n",
      "epoch: 7, batch: 24, loss: 0.3856550455093384\n",
      "epoch: 7, batch: 25, loss: 0.3958321809768677\n",
      "epoch: 7, batch: 26, loss: 0.5748287439346313\n",
      "epoch: 7, batch: 27, loss: 0.2609797716140747\n",
      "epoch: 7, batch: 28, loss: 0.5548501014709473\n",
      "epoch: 7, batch: 29, loss: 0.41418182849884033\n",
      "epoch: 7, batch: 30, loss: 0.5293962955474854\n",
      "epoch: 7, batch: 31, loss: 0.4789791703224182\n",
      "epoch: 7, batch: 32, loss: 0.4839461147785187\n",
      "epoch: 7, batch: 33, loss: 0.4951123893260956\n",
      "epoch: 7, batch: 34, loss: 0.8009201288223267\n",
      "epoch: 7, batch: 35, loss: 0.6312130689620972\n",
      "epoch: 7, batch: 36, loss: 0.5787621140480042\n",
      "epoch: 7, batch: 37, loss: 0.6024433374404907\n",
      "epoch: 7, batch: 38, loss: 0.5401268005371094\n",
      "epoch: 7, batch: 39, loss: 0.38832196593284607\n",
      "epoch: 7, batch: 40, loss: 0.5992023348808289\n",
      "epoch: 7, batch: 41, loss: 0.3303033113479614\n",
      "epoch: 7, batch: 42, loss: 0.43204987049102783\n",
      "epoch: 7, batch: 43, loss: 0.5431919693946838\n",
      "epoch: 7, batch: 44, loss: 0.41802486777305603\n",
      "epoch: 7, batch: 45, loss: 0.532401978969574\n",
      "epoch: 7, batch: 46, loss: 0.555792510509491\n",
      "epoch: 7, batch: 47, loss: 0.5807521343231201\n",
      "epoch: 7, batch: 48, loss: 0.37882834672927856\n",
      "epoch: 7, batch: 49, loss: 0.3676642179489136\n",
      "epoch: 7, batch: 50, loss: 0.3699478507041931\n",
      "epoch: 7, batch: 51, loss: 0.4096335172653198\n",
      "epoch: 7, batch: 52, loss: 0.6089732646942139\n",
      "epoch: 7, batch: 53, loss: 0.6865500211715698\n",
      "epoch: 7, batch: 54, loss: 0.6670700311660767\n",
      "epoch: 7, batch: 55, loss: 0.5567908883094788\n",
      "epoch: 7, batch: 56, loss: 0.5895238518714905\n",
      "epoch: 7, batch: 57, loss: 0.43104618787765503\n",
      "epoch: 7, batch: 58, loss: 0.3741607367992401\n",
      "epoch: 7, batch: 59, loss: 0.6089035272598267\n",
      "epoch: 7, batch: 60, loss: 0.7366349697113037\n",
      "epoch: 7, batch: 61, loss: 0.6272780299186707\n",
      "epoch: 7, batch: 62, loss: 0.5302765369415283\n",
      "epoch: 7, batch: 63, loss: 0.5971433520317078\n",
      "epoch: 7, batch: 64, loss: 0.4484568238258362\n",
      "epoch: 7, batch: 65, loss: 0.8410506248474121\n",
      "epoch: 7, batch: 66, loss: 0.8010947704315186\n",
      "epoch: 7, batch: 67, loss: 0.621701717376709\n",
      "epoch: 7, batch: 68, loss: 1.076292872428894\n",
      "epoch: 7, batch: 69, loss: 0.7482143044471741\n",
      "epoch: 7, batch: 70, loss: 0.6660903692245483\n",
      "epoch: 7, batch: 71, loss: 0.508060097694397\n",
      "epoch: 7, batch: 72, loss: 0.4058081805706024\n",
      "epoch: 7, batch: 73, loss: 0.6429624557495117\n",
      "epoch: 7, batch: 74, loss: 0.5159041285514832\n",
      "epoch: 7, batch: 75, loss: 0.4523158669471741\n",
      "epoch: 7, batch: 76, loss: 0.6050474047660828\n",
      "epoch: 7, batch: 77, loss: 0.48527881503105164\n",
      "epoch: 7, batch: 78, loss: 0.43354687094688416\n",
      "epoch: 7, batch: 79, loss: 0.3859633803367615\n",
      "epoch: 7, batch: 80, loss: 0.6617120504379272\n",
      "epoch: 7, batch: 81, loss: 0.4346645176410675\n",
      "epoch: 7, batch: 82, loss: 0.5045220851898193\n",
      "epoch: 7, batch: 83, loss: 0.518455982208252\n",
      "epoch: 7, batch: 84, loss: 0.7206273674964905\n",
      "epoch: 7, batch: 85, loss: 0.46719056367874146\n",
      "epoch: 7, batch: 86, loss: 0.5698552131652832\n",
      "epoch: 7, batch: 87, loss: 0.47275999188423157\n",
      "epoch: 7, batch: 88, loss: 0.5587981343269348\n",
      "epoch: 7, batch: 89, loss: 0.6317540407180786\n",
      "epoch: 7, batch: 90, loss: 0.5318372845649719\n",
      "epoch: 7, batch: 91, loss: 0.44579458236694336\n",
      "epoch: 7, batch: 92, loss: 0.6673569679260254\n",
      "epoch: 7, batch: 93, loss: 0.599922239780426\n",
      "epoch: 7, batch: 94, loss: 0.44598808884620667\n",
      "epoch: 7, batch: 95, loss: 0.46723249554634094\n",
      "epoch: 7, batch: 96, loss: 0.5389965772628784\n",
      "epoch: 7, batch: 97, loss: 0.4742989242076874\n",
      "epoch: 7, batch: 98, loss: 0.5207427740097046\n",
      "epoch: 7, batch: 99, loss: 0.4000636041164398\n",
      "epoch: 7, batch: 100, loss: 0.45026931166648865\n",
      "epoch: 7, batch: 101, loss: 0.6191622614860535\n",
      "epoch: 7, batch: 102, loss: 0.5633310079574585\n",
      "epoch: 7, batch: 103, loss: 0.461041659116745\n",
      "epoch: 7, batch: 104, loss: 0.36698660254478455\n",
      "epoch: 7, batch: 105, loss: 0.8782001733779907\n",
      "epoch: 7, batch: 106, loss: 0.2498435378074646\n",
      "epoch: 7, batch: 107, loss: 0.9023652672767639\n",
      "epoch: 7, batch: 108, loss: 0.551400363445282\n",
      "epoch: 7, batch: 109, loss: 0.5395119786262512\n",
      "epoch: 7, batch: 110, loss: 0.6152791976928711\n",
      "epoch: 7, batch: 111, loss: 0.5093234777450562\n",
      "epoch: 7, batch: 112, loss: 0.4825717508792877\n",
      "epoch: 7, batch: 113, loss: 0.6039645671844482\n",
      "epoch: 7, batch: 114, loss: 0.3678421974182129\n",
      "epoch: 7, batch: 115, loss: 0.6044313311576843\n",
      "epoch: 7, batch: 116, loss: 0.584121823310852\n",
      "epoch: 7, batch: 117, loss: 0.7142235040664673\n",
      "epoch: 7, batch: 118, loss: 0.3599472641944885\n",
      "epoch: 7, batch: 119, loss: 0.3991442918777466\n",
      "epoch: 7, batch: 120, loss: 0.41213059425354004\n",
      "epoch: 7, batch: 121, loss: 0.7600661516189575\n",
      "epoch: 7, batch: 122, loss: 0.28657636046409607\n",
      "epoch: 7, batch: 123, loss: 0.5357337594032288\n",
      "epoch: 7, batch: 124, loss: 0.5031290650367737\n",
      "epoch: 7, batch: 125, loss: 0.43670445680618286\n",
      "epoch: 7, batch: 126, loss: 0.3552684187889099\n",
      "epoch: 7, batch: 127, loss: 0.4770459234714508\n",
      "epoch: 7, batch: 128, loss: 0.5923072695732117\n",
      "epoch: 7, batch: 129, loss: 0.37825456261634827\n",
      "epoch: 7, batch: 130, loss: 0.6377325057983398\n",
      "epoch: 7, batch: 131, loss: 0.5372169017791748\n",
      "epoch: 7, batch: 132, loss: 0.42659711837768555\n",
      "epoch: 7, batch: 133, loss: 0.3462830185890198\n",
      "epoch: 7, batch: 134, loss: 0.3894997537136078\n",
      "epoch: 7, batch: 135, loss: 0.6868082284927368\n",
      "epoch: 7, batch: 136, loss: 0.6278794407844543\n",
      "epoch: 7, batch: 137, loss: 0.6442753672599792\n",
      "epoch: 7, batch: 138, loss: 0.6716660261154175\n",
      "epoch: 7, batch: 139, loss: 0.6745550036430359\n",
      "epoch: 7, batch: 140, loss: 0.685078501701355\n",
      "epoch: 7, batch: 141, loss: 0.4164685606956482\n",
      "epoch: 7, batch: 142, loss: 0.6841060519218445\n",
      "epoch: 7, batch: 143, loss: 0.45702657103538513\n",
      "epoch: 7, batch: 144, loss: 0.4697522222995758\n",
      "epoch: 7, batch: 145, loss: 0.6668410897254944\n",
      "epoch: 7, batch: 146, loss: 0.5464529395103455\n",
      "epoch: 7, batch: 147, loss: 0.7291719913482666\n",
      "epoch: 7, batch: 148, loss: 0.4318391978740692\n",
      "epoch: 7, batch: 149, loss: 0.5300645232200623\n",
      "epoch: 7, batch: 150, loss: 0.7696934938430786\n",
      "epoch: 7, batch: 151, loss: 0.6215028166770935\n",
      "epoch: 7, batch: 152, loss: 0.45438137650489807\n",
      "epoch: 7, batch: 153, loss: 0.5598764419555664\n",
      "epoch: 7, batch: 154, loss: 0.40986230969429016\n",
      "epoch: 7, batch: 155, loss: 0.4106130301952362\n",
      "epoch: 7, batch: 156, loss: 0.5487946271896362\n",
      "epoch: 7, batch: 157, loss: 0.632539689540863\n",
      "epoch: 7, batch: 158, loss: 0.4694056510925293\n",
      "epoch: 7, batch: 159, loss: 0.5984053611755371\n",
      "epoch: 7, batch: 160, loss: 0.376264363527298\n",
      "epoch: 7, batch: 161, loss: 0.5088917016983032\n",
      "epoch: 7, batch: 162, loss: 0.545859158039093\n",
      "epoch: 7, batch: 163, loss: 0.5034779906272888\n",
      "epoch: 7, batch: 164, loss: 0.4440230131149292\n",
      "epoch: 7, batch: 165, loss: 0.44485360383987427\n",
      "epoch: 7, batch: 166, loss: 0.6296504735946655\n",
      "epoch: 7, batch: 167, loss: 0.4690062701702118\n",
      "epoch: 7, batch: 168, loss: 0.6082979440689087\n",
      "epoch: 7, batch: 169, loss: 0.5556781888008118\n",
      "epoch: 7, batch: 170, loss: 0.5003800392150879\n",
      "epoch: 7, batch: 171, loss: 0.56058669090271\n",
      "epoch: 7, batch: 172, loss: 0.44427332282066345\n",
      "epoch: 7, batch: 173, loss: 0.5239527821540833\n",
      "epoch: 7, batch: 174, loss: 0.6895310282707214\n",
      "epoch: 7, batch: 175, loss: 0.554021954536438\n",
      "epoch: 7, batch: 176, loss: 0.35066425800323486\n",
      "epoch: 7, batch: 177, loss: 0.49650171399116516\n",
      "epoch: 7, batch: 178, loss: 0.400398313999176\n",
      "epoch: 7, batch: 179, loss: 0.5110543370246887\n",
      "epoch: 7, batch: 180, loss: 0.44388264417648315\n",
      "epoch: 7, batch: 181, loss: 0.4458395540714264\n",
      "epoch: 7, batch: 182, loss: 0.661748468875885\n",
      "epoch: 7, batch: 183, loss: 0.5129498243331909\n",
      "epoch: 7, batch: 184, loss: 0.5598888397216797\n",
      "epoch: 7, batch: 185, loss: 0.6977121233940125\n",
      "epoch: 7, batch: 186, loss: 0.36514681577682495\n",
      "epoch: 7, batch: 187, loss: 0.43743032217025757\n",
      "epoch: 7, batch: 188, loss: 0.5826733708381653\n",
      "epoch: 7, batch: 189, loss: 0.6513645052909851\n",
      "epoch: 7, batch: 190, loss: 0.5622749328613281\n",
      "epoch: 7, batch: 191, loss: 0.7890478372573853\n",
      "epoch: 7, batch: 192, loss: 0.4126565754413605\n",
      "epoch: 7, batch: 193, loss: 0.37024083733558655\n",
      "epoch: 7, batch: 194, loss: 0.8168480396270752\n",
      "epoch: 7, batch: 195, loss: 0.4798457622528076\n",
      "epoch: 7, batch: 196, loss: 0.42022958397865295\n",
      "epoch: 7, batch: 197, loss: 0.3655678629875183\n",
      "epoch: 7, batch: 198, loss: 0.5077712535858154\n",
      "epoch: 7, batch: 199, loss: 0.4761761426925659\n",
      "epoch: 7, batch: 200, loss: 0.3863682448863983\n",
      "epoch: 7, batch: 201, loss: 0.4981233775615692\n",
      "epoch: 7, batch: 202, loss: 0.49636420607566833\n",
      "epoch: 7, batch: 203, loss: 0.5561655759811401\n",
      "epoch: 7, batch: 204, loss: 0.46193066239356995\n",
      "epoch: 7, batch: 205, loss: 0.3839646875858307\n",
      "epoch: 7, batch: 206, loss: 0.44652900099754333\n",
      "epoch: 7, batch: 207, loss: 0.4643644690513611\n",
      "epoch: 7, batch: 208, loss: 0.564589262008667\n",
      "epoch: 7, batch: 209, loss: 0.7986409068107605\n",
      "epoch: 7, batch: 210, loss: 0.5829209685325623\n",
      "epoch: 7, batch: 211, loss: 0.5954439640045166\n",
      "epoch: 7, batch: 212, loss: 0.3935268223285675\n",
      "epoch: 7, batch: 213, loss: 0.7007386684417725\n",
      "epoch: 7, batch: 214, loss: 0.3971197307109833\n",
      "epoch: 7, batch: 215, loss: 0.9245661497116089\n",
      "epoch: 7, batch: 216, loss: 0.46998071670532227\n",
      "epoch: 7, batch: 217, loss: 0.6150923371315002\n",
      "epoch: 7, batch: 218, loss: 0.7034465670585632\n",
      "epoch: 7, batch: 219, loss: 0.7913792729377747\n",
      "epoch: 7, batch: 220, loss: 0.6717779040336609\n",
      "epoch: 7, batch: 221, loss: 0.7179529666900635\n",
      "epoch: 7, batch: 222, loss: 0.5744194388389587\n",
      "epoch: 7, batch: 223, loss: 0.6824387311935425\n",
      "epoch: 7, batch: 224, loss: 0.41863954067230225\n",
      "epoch: 7, batch: 225, loss: 0.7066690921783447\n",
      "epoch: 7, batch: 226, loss: 0.4296775162220001\n",
      "epoch: 7, batch: 227, loss: 0.5757030844688416\n",
      "epoch: 7, batch: 228, loss: 0.5553224086761475\n",
      "epoch: 7, batch: 229, loss: 0.5750351548194885\n",
      "epoch: 7, batch: 230, loss: 0.5171623229980469\n",
      "epoch: 7, batch: 231, loss: 0.5645193457603455\n",
      "epoch: 7, batch: 232, loss: 0.5397858023643494\n",
      "epoch: 7, batch: 233, loss: 0.5794849395751953\n",
      "epoch: 7, batch: 234, loss: 0.3587375581264496\n",
      "epoch: 7, batch: 235, loss: 0.5894085168838501\n",
      "epoch: 7, batch: 236, loss: 0.5787507891654968\n",
      "epoch: 7, batch: 237, loss: 0.33431029319763184\n",
      "epoch: 7, batch: 238, loss: 0.5401665568351746\n",
      "epoch: 7, batch: 239, loss: 0.5963333249092102\n",
      "epoch: 7, batch: 240, loss: 0.442428320646286\n",
      "epoch: 7, batch: 241, loss: 0.45128846168518066\n",
      "epoch: 7, batch: 242, loss: 0.5145974159240723\n",
      "epoch: 7, batch: 243, loss: 0.4645688831806183\n",
      "epoch: 7, batch: 244, loss: 0.41748949885368347\n",
      "epoch: 7, batch: 245, loss: 0.888843834400177\n",
      "epoch: 7, batch: 246, loss: 0.2997807562351227\n",
      "epoch: 7, batch: 247, loss: 0.38480550050735474\n",
      "epoch: 7, batch: 248, loss: 0.5559481978416443\n",
      "epoch: 7, batch: 249, loss: 0.32982081174850464\n",
      "epoch: 7, batch: 250, loss: 0.4334836006164551\n",
      "epoch: 7, batch: 251, loss: 0.5535046458244324\n",
      "epoch: 7, batch: 252, loss: 0.7184633016586304\n",
      "epoch: 7, batch: 253, loss: 0.45186880230903625\n",
      "epoch: 7, batch: 254, loss: 0.44302672147750854\n",
      "epoch: 7, batch: 255, loss: 0.7292456030845642\n",
      "epoch: 7, batch: 256, loss: 0.42960208654403687\n",
      "epoch: 7, batch: 257, loss: 0.7102482914924622\n",
      "epoch: 7, batch: 258, loss: 0.6719684600830078\n",
      "epoch: 7, batch: 259, loss: 0.7638142704963684\n",
      "epoch: 7, batch: 260, loss: 0.4111936688423157\n",
      "epoch: 7, batch: 261, loss: 0.6812232136726379\n",
      "epoch: 7, batch: 262, loss: 0.5656822919845581\n",
      "epoch: 7, batch: 263, loss: 0.5671140551567078\n",
      "epoch: 7, batch: 264, loss: 0.6380683779716492\n",
      "epoch: 7, batch: 265, loss: 0.4801548719406128\n",
      "epoch: 7, batch: 266, loss: 0.40540146827697754\n",
      "epoch: 7, batch: 267, loss: 0.4433939456939697\n",
      "epoch: 7, batch: 268, loss: 0.4624533951282501\n",
      "epoch: 7, batch: 269, loss: 0.7719466686248779\n",
      "epoch: 7, batch: 270, loss: 0.8064494729042053\n",
      "epoch: 7, batch: 271, loss: 0.6010447144508362\n",
      "epoch: 7, batch: 272, loss: 0.4439495801925659\n",
      "epoch: 7, batch: 273, loss: 0.2847704589366913\n",
      "epoch: 7, batch: 274, loss: 0.5684608817100525\n",
      "epoch: 7, batch: 275, loss: 0.2789985239505768\n",
      "epoch: 7, batch: 276, loss: 0.538191020488739\n",
      "epoch: 7, batch: 277, loss: 0.6061451435089111\n",
      "epoch: 7, batch: 278, loss: 0.5066626667976379\n",
      "epoch: 7, batch: 279, loss: 0.5764205455780029\n",
      "epoch: 7, batch: 280, loss: 0.5402224659919739\n",
      "epoch: 7, batch: 281, loss: 0.518317461013794\n",
      "epoch: 7, batch: 282, loss: 0.2898130416870117\n",
      "epoch: 7, batch: 283, loss: 0.5594581365585327\n",
      "epoch: 7, batch: 284, loss: 0.614788293838501\n",
      "epoch: 7, batch: 285, loss: 0.4506596624851227\n",
      "epoch: 7, batch: 286, loss: 0.4570051431655884\n",
      "epoch: 7, batch: 287, loss: 0.6970884799957275\n",
      "epoch: 7, batch: 288, loss: 0.29820600152015686\n",
      "epoch: 7, batch: 289, loss: 0.6500241160392761\n",
      "epoch: 7, batch: 290, loss: 0.5266771912574768\n",
      "epoch: 7, batch: 291, loss: 0.4705069661140442\n",
      "epoch: 7, batch: 292, loss: 0.566655695438385\n",
      "epoch: 7, batch: 293, loss: 0.616045355796814\n",
      "epoch: 7, batch: 294, loss: 0.6764475107192993\n",
      "epoch: 7, batch: 295, loss: 0.3984086513519287\n",
      "epoch: 7, batch: 296, loss: 0.6647024750709534\n",
      "epoch: 7, batch: 297, loss: 0.3570428788661957\n",
      "epoch: 7, batch: 298, loss: 0.4781714081764221\n",
      "epoch: 7, batch: 299, loss: 0.6284539103507996\n",
      "epoch: 7, batch: 300, loss: 0.41290757060050964\n",
      "epoch: 7, batch: 301, loss: 0.5792528986930847\n",
      "epoch: 7, batch: 302, loss: 0.7010863423347473\n",
      "epoch: 7, batch: 303, loss: 0.5007234811782837\n",
      "epoch: 7, batch: 304, loss: 0.3712875247001648\n",
      "epoch: 7, batch: 305, loss: 0.7092496156692505\n",
      "epoch: 7, batch: 306, loss: 0.6002702116966248\n",
      "epoch: 7, batch: 307, loss: 0.7697994112968445\n",
      "epoch: 7, batch: 308, loss: 0.5100858211517334\n",
      "epoch: 7, batch: 309, loss: 0.3206008970737457\n",
      "epoch: 7, batch: 310, loss: 0.3491198718547821\n",
      "epoch: 7, batch: 311, loss: 0.5380192399024963\n",
      "epoch: 7, batch: 312, loss: 0.7672134041786194\n",
      "epoch: 7, batch: 313, loss: 0.6438666582107544\n",
      "epoch: 7, batch: 314, loss: 0.6013710498809814\n",
      "epoch: 7, batch: 315, loss: 0.43264251947402954\n",
      "epoch: 7, batch: 316, loss: 0.3277074694633484\n",
      "epoch: 7, batch: 317, loss: 0.5219606757164001\n",
      "epoch: 7, batch: 318, loss: 0.27529922127723694\n",
      "epoch: 7, batch: 319, loss: 0.5200888514518738\n",
      "epoch: 7, batch: 320, loss: 0.45537227392196655\n",
      "epoch: 7, batch: 321, loss: 0.823602557182312\n",
      "epoch: 7, batch: 322, loss: 0.498510479927063\n",
      "epoch: 7, batch: 323, loss: 0.6436198949813843\n",
      "epoch: 7, batch: 324, loss: 0.3579123616218567\n",
      "epoch: 7, batch: 325, loss: 0.5018875598907471\n",
      "epoch: 7, batch: 326, loss: 0.4649936854839325\n",
      "epoch: 7, batch: 327, loss: 0.4831390976905823\n",
      "epoch: 7, batch: 328, loss: 0.5095939040184021\n",
      "epoch: 7, batch: 329, loss: 0.5041624307632446\n",
      "epoch: 7, batch: 330, loss: 0.5968084931373596\n",
      "epoch: 7, batch: 331, loss: 0.3898654282093048\n",
      "epoch: 7, batch: 332, loss: 0.3785122334957123\n",
      "epoch: 7, batch: 333, loss: 0.7762024402618408\n",
      "epoch: 7, batch: 334, loss: 0.4579734802246094\n",
      "epoch: 7, batch: 335, loss: 0.37248700857162476\n",
      "epoch: 7, batch: 336, loss: 0.7349182963371277\n",
      "epoch: 7, batch: 337, loss: 0.5833189487457275\n",
      "epoch: 7, batch: 338, loss: 0.3480336368083954\n",
      "epoch: 7, batch: 339, loss: 0.5145198106765747\n",
      "epoch: 7, batch: 340, loss: 0.6316977739334106\n",
      "epoch: 7, batch: 341, loss: 0.482332319021225\n",
      "epoch: 7, batch: 342, loss: 0.4169965088367462\n",
      "epoch: 7, batch: 343, loss: 0.40066805481910706\n",
      "epoch: 7, batch: 344, loss: 0.4196033775806427\n",
      "epoch: 7, batch: 345, loss: 0.4322671890258789\n",
      "epoch: 7, batch: 346, loss: 0.4867471754550934\n",
      "epoch: 7, batch: 347, loss: 0.6049951910972595\n",
      "epoch: 7, batch: 348, loss: 0.412392258644104\n",
      "epoch: 7, batch: 349, loss: 0.334557443857193\n",
      "epoch: 7, batch: 350, loss: 0.8974905610084534\n",
      "epoch: 7, batch: 351, loss: 0.41439950466156006\n",
      "epoch: 7, batch: 352, loss: 0.48452672362327576\n",
      "epoch: 7, batch: 353, loss: 0.6130863428115845\n",
      "epoch: 7, batch: 354, loss: 0.5953633785247803\n",
      "epoch: 7, batch: 355, loss: 0.4515613615512848\n",
      "epoch: 7, batch: 356, loss: 0.5379335880279541\n",
      "epoch: 7, batch: 357, loss: 0.6260496377944946\n",
      "epoch: 7, batch: 358, loss: 0.7463724613189697\n",
      "epoch: 7, batch: 359, loss: 0.3929397761821747\n",
      "epoch: 7, batch: 360, loss: 0.5529376864433289\n",
      "epoch: 7, batch: 361, loss: 0.39395061135292053\n",
      "epoch: 7, batch: 362, loss: 0.4768925905227661\n",
      "epoch: 7, batch: 363, loss: 0.5490924119949341\n",
      "epoch: 7, batch: 364, loss: 0.5429065823554993\n",
      "epoch: 7, batch: 365, loss: 0.7189674973487854\n",
      "epoch: 7, batch: 366, loss: 0.529958963394165\n",
      "epoch: 7, batch: 367, loss: 0.43623030185699463\n",
      "epoch: 7, batch: 368, loss: 0.28921160101890564\n",
      "epoch: 7, batch: 369, loss: 0.9175573587417603\n",
      "epoch: 7, batch: 370, loss: 0.6175071001052856\n",
      "epoch: 7, batch: 371, loss: 0.5344845056533813\n",
      "epoch: 7, batch: 372, loss: 0.4589690864086151\n",
      "epoch: 7, batch: 373, loss: 0.673781156539917\n",
      "epoch: 7, batch: 374, loss: 0.666820764541626\n",
      "epoch: 7, batch: 375, loss: 0.6204618811607361\n",
      "epoch: 7, batch: 376, loss: 0.37133970856666565\n",
      "epoch: 7, batch: 377, loss: 0.5129626989364624\n",
      "epoch: 7, batch: 378, loss: 0.5551661252975464\n",
      "epoch: 7, batch: 379, loss: 0.6015265583992004\n",
      "epoch: 7, batch: 380, loss: 0.550652027130127\n",
      "epoch: 7, batch: 381, loss: 0.336376428604126\n",
      "epoch: 7, batch: 382, loss: 0.5315164923667908\n",
      "epoch: 7, batch: 383, loss: 0.24347198009490967\n",
      "epoch: 7, batch: 384, loss: 0.47199001908302307\n",
      "epoch: 7, batch: 385, loss: 0.5554549098014832\n",
      "epoch: 7, batch: 386, loss: 0.4324379861354828\n",
      "epoch: 7, batch: 387, loss: 0.5964847803115845\n",
      "epoch: 7, batch: 388, loss: 0.4023768901824951\n",
      "epoch: 7, batch: 389, loss: 0.6859394907951355\n",
      "epoch: 7, batch: 390, loss: 0.6216481328010559\n",
      "epoch: 7, batch: 391, loss: 0.7262318730354309\n",
      "epoch: 7, batch: 392, loss: 0.5893059372901917\n",
      "epoch: 7, batch: 393, loss: 0.34854018688201904\n",
      "epoch: 7, batch: 394, loss: 0.3860101103782654\n",
      "epoch: 7, batch: 395, loss: 0.6841754913330078\n",
      "epoch: 7, batch: 396, loss: 0.47720807790756226\n",
      "epoch: 7, batch: 397, loss: 0.40243297815322876\n",
      "epoch: 7, batch: 398, loss: 0.2410254180431366\n",
      "epoch: 7, batch: 399, loss: 0.8767396211624146\n",
      "epoch: 7, batch: 400, loss: 0.6100724935531616\n",
      "epoch: 7, batch: 401, loss: 0.6716856360435486\n",
      "epoch: 7, batch: 402, loss: 0.48199206590652466\n",
      "epoch: 7, batch: 403, loss: 0.9608795046806335\n",
      "epoch: 7, batch: 404, loss: 0.6322361826896667\n",
      "epoch: 7, batch: 405, loss: 0.6277022957801819\n",
      "epoch: 7, batch: 406, loss: 0.5323309898376465\n",
      "epoch: 7, batch: 407, loss: 0.4179960787296295\n",
      "epoch: 7, batch: 408, loss: 0.2979277968406677\n",
      "epoch: 7, batch: 409, loss: 0.5849781632423401\n",
      "epoch: 7, batch: 410, loss: 0.8182477355003357\n",
      "epoch: 7, batch: 411, loss: 0.6552128791809082\n",
      "epoch: 7, batch: 412, loss: 0.4204332232475281\n",
      "epoch: 7, batch: 413, loss: 0.6373846530914307\n",
      "epoch: 7, batch: 414, loss: 0.595162034034729\n",
      "epoch: 7, batch: 415, loss: 0.38136711716651917\n",
      "epoch: 7, batch: 416, loss: 0.49546992778778076\n",
      "epoch: 7, batch: 417, loss: 0.6174450516700745\n",
      "epoch: 7, batch: 418, loss: 0.6544444561004639\n",
      "epoch: 7, batch: 419, loss: 0.42326340079307556\n",
      "epoch: 7, batch: 420, loss: 0.5654858350753784\n",
      "epoch: 7, batch: 421, loss: 0.549080491065979\n",
      "epoch: 7, batch: 422, loss: 0.4186161756515503\n",
      "epoch: 7, batch: 423, loss: 0.5369685292243958\n",
      "epoch: 7, batch: 424, loss: 0.6082453727722168\n",
      "epoch: 7, batch: 425, loss: 0.6156070828437805\n",
      "epoch: 7, batch: 426, loss: 0.3804498016834259\n",
      "epoch: 7, batch: 427, loss: 0.47316473722457886\n",
      "epoch: 7, batch: 428, loss: 0.5337182879447937\n",
      "epoch: 7, batch: 429, loss: 0.45259302854537964\n",
      "epoch: 7, batch: 430, loss: 0.6621543765068054\n",
      "epoch: 7, batch: 431, loss: 0.4518141746520996\n",
      "epoch: 7, batch: 432, loss: 0.6254113912582397\n",
      "epoch: 7, batch: 433, loss: 0.4115275740623474\n",
      "epoch: 7, batch: 434, loss: 0.6031948924064636\n",
      "epoch: 7, batch: 435, loss: 0.40848392248153687\n",
      "epoch: 7, batch: 436, loss: 0.467484712600708\n",
      "epoch: 7, batch: 437, loss: 0.44593116641044617\n",
      "epoch: 7, batch: 438, loss: 0.4696807563304901\n",
      "epoch: 7, batch: 439, loss: 0.7011984586715698\n",
      "epoch: 7, batch: 440, loss: 0.48014384508132935\n",
      "epoch: 7, batch: 441, loss: 0.4502033293247223\n",
      "epoch: 7, batch: 442, loss: 0.3551774024963379\n",
      "epoch: 7, batch: 443, loss: 0.5612509846687317\n",
      "epoch: 7, batch: 444, loss: 0.43769460916519165\n",
      "epoch: 7, batch: 445, loss: 0.5072144865989685\n",
      "epoch: 7, batch: 446, loss: 0.5210201144218445\n",
      "epoch: 7, batch: 447, loss: 0.35980328917503357\n",
      "epoch: 7, batch: 448, loss: 0.7006930708885193\n",
      "epoch: 7, batch: 449, loss: 0.24566064774990082\n",
      "epoch: 7, batch: 450, loss: 0.5061725974082947\n",
      "epoch: 7, batch: 451, loss: 0.6345981955528259\n",
      "epoch: 7, batch: 452, loss: 0.4826886057853699\n",
      "epoch: 7, batch: 453, loss: 0.3947635591030121\n",
      "epoch: 7, batch: 454, loss: 0.42537131905555725\n",
      "epoch: 7, batch: 455, loss: 0.38413500785827637\n",
      "epoch: 7, batch: 456, loss: 0.6797782182693481\n",
      "epoch: 7, batch: 457, loss: 0.5449492931365967\n",
      "epoch: 7, batch: 458, loss: 0.8887566328048706\n",
      "epoch: 7, batch: 459, loss: 0.9515373706817627\n",
      "epoch: 7, batch: 460, loss: 0.27953848242759705\n",
      "epoch: 7, batch: 461, loss: 0.7316175103187561\n",
      "epoch: 7, batch: 462, loss: 0.8648717403411865\n",
      "epoch: 7, batch: 463, loss: 0.39822328090667725\n",
      "epoch: 7, batch: 464, loss: 0.5341941118240356\n",
      "epoch: 7, batch: 465, loss: 0.4469014108181\n",
      "epoch: 7, batch: 466, loss: 0.5802004337310791\n",
      "epoch: 7, batch: 467, loss: 0.45430248975753784\n",
      "epoch: 7, batch: 468, loss: 0.26885882019996643\n",
      "epoch: 7, batch: 469, loss: 0.3778890073299408\n",
      "epoch: 7, batch: 470, loss: 0.48602592945098877\n",
      "epoch: 7, batch: 471, loss: 0.3797427713871002\n",
      "epoch: 7, batch: 472, loss: 0.5218752026557922\n",
      "epoch: 7, batch: 473, loss: 0.49671393632888794\n",
      "epoch: 7, batch: 474, loss: 0.5512754917144775\n",
      "epoch: 7, batch: 475, loss: 0.8097683191299438\n",
      "epoch: 7, batch: 476, loss: 0.45514988899230957\n",
      "epoch: 7, batch: 477, loss: 0.4179236590862274\n",
      "epoch: 7, batch: 478, loss: 0.936996579170227\n",
      "epoch: 7, batch: 479, loss: 0.45844972133636475\n",
      "epoch: 7, batch: 480, loss: 0.5501057505607605\n",
      "epoch: 7, batch: 481, loss: 0.4467424750328064\n",
      "epoch: 7, batch: 482, loss: 0.40793514251708984\n",
      "epoch: 7, batch: 483, loss: 0.4125134348869324\n",
      "epoch: 7, batch: 484, loss: 0.6155153512954712\n",
      "epoch: 7, batch: 485, loss: 0.5429002642631531\n",
      "epoch: 7, batch: 486, loss: 0.47572746872901917\n",
      "epoch: 7, batch: 487, loss: 0.47032883763313293\n",
      "epoch: 7, batch: 488, loss: 0.4278062582015991\n",
      "epoch: 7, batch: 489, loss: 0.613439679145813\n",
      "epoch: 7, batch: 490, loss: 0.4973728358745575\n",
      "epoch: 7, batch: 491, loss: 0.6726446747779846\n",
      "epoch: 7, batch: 492, loss: 0.7280163764953613\n",
      "epoch: 7, batch: 493, loss: 0.4478382170200348\n",
      "epoch: 7, batch: 494, loss: 0.6044866442680359\n",
      "epoch: 7, batch: 495, loss: 0.4337347745895386\n",
      "epoch: 7, batch: 496, loss: 0.370781809091568\n",
      "epoch: 7, batch: 497, loss: 0.5299413800239563\n",
      "epoch: 7, batch: 498, loss: 0.5515477061271667\n",
      "epoch: 7, batch: 499, loss: 0.7317302227020264\n",
      "epoch: 7, batch: 500, loss: 0.5661117434501648\n",
      "epoch: 7, batch: 501, loss: 0.37590888142585754\n",
      "epoch: 7, batch: 502, loss: 0.851906955242157\n",
      "epoch: 7, batch: 503, loss: 0.5471770167350769\n",
      "epoch: 7, batch: 504, loss: 0.5462132692337036\n",
      "epoch: 7, batch: 505, loss: 0.4454072415828705\n",
      "epoch: 7, batch: 506, loss: 0.6744340062141418\n",
      "epoch: 7, batch: 507, loss: 0.5281762480735779\n",
      "epoch: 7, batch: 508, loss: 0.34752357006073\n",
      "epoch: 7, batch: 509, loss: 0.5866363644599915\n",
      "epoch: 7, batch: 510, loss: 0.77077716588974\n",
      "epoch: 7, batch: 511, loss: 0.41544103622436523\n",
      "epoch: 7, batch: 512, loss: 0.5197342038154602\n",
      "epoch: 7, batch: 513, loss: 0.6361631751060486\n",
      "epoch: 7, batch: 514, loss: 0.5504175424575806\n",
      "epoch: 7, batch: 515, loss: 0.6707939505577087\n",
      "epoch: 7, batch: 516, loss: 0.3911731243133545\n",
      "epoch: 7, batch: 517, loss: 0.35051387548446655\n",
      "epoch: 7, batch: 518, loss: 0.49163588881492615\n",
      "epoch: 7, batch: 519, loss: 0.2940133810043335\n",
      "epoch: 7, batch: 520, loss: 0.2849214971065521\n",
      "epoch: 7, batch: 521, loss: 0.6430206894874573\n",
      "epoch: 7, batch: 522, loss: 0.5338077545166016\n",
      "epoch: 7, batch: 523, loss: 0.4509928822517395\n",
      "epoch: 7, batch: 524, loss: 0.622281014919281\n",
      "epoch: 7, batch: 525, loss: 0.5099624991416931\n",
      "epoch: 7, batch: 526, loss: 0.29049578309059143\n",
      "epoch: 7, batch: 527, loss: 0.4712672829627991\n",
      "epoch: 7, batch: 528, loss: 0.502968966960907\n",
      "epoch: 7, batch: 529, loss: 0.36787694692611694\n",
      "epoch: 7, batch: 530, loss: 0.5313596129417419\n",
      "epoch: 7, batch: 531, loss: 0.3636336624622345\n",
      "epoch: 7, batch: 532, loss: 0.5229794979095459\n",
      "epoch: 7, batch: 533, loss: 0.5456082820892334\n",
      "epoch: 7, batch: 534, loss: 0.5131800770759583\n",
      "epoch: 7, batch: 535, loss: 0.5571672320365906\n",
      "epoch: 7, batch: 536, loss: 1.0052154064178467\n",
      "epoch: 7, batch: 537, loss: 0.4633173942565918\n",
      "epoch: 7, batch: 538, loss: 0.3652151823043823\n",
      "epoch: 7, batch: 539, loss: 0.32904937863349915\n",
      "epoch: 7, batch: 540, loss: 0.4531622529029846\n",
      "epoch: 7, batch: 541, loss: 0.5359978675842285\n",
      "epoch: 7, batch: 542, loss: 0.48555123805999756\n",
      "epoch: 7, batch: 543, loss: 0.4495594799518585\n",
      "epoch: 7, batch: 544, loss: 0.36014091968536377\n",
      "epoch: 7, batch: 545, loss: 0.5002516508102417\n",
      "epoch: 7, batch: 546, loss: 0.342631995677948\n",
      "epoch: 7, batch: 547, loss: 0.7128162980079651\n",
      "epoch: 7, batch: 548, loss: 0.2677525281906128\n",
      "epoch: 7, batch: 549, loss: 0.42312419414520264\n",
      "epoch: 7, batch: 550, loss: 0.9383241534233093\n",
      "epoch: 7, batch: 551, loss: 0.4569591283798218\n",
      "epoch: 7, batch: 552, loss: 0.5381508469581604\n",
      "epoch: 7, batch: 553, loss: 0.5707738399505615\n",
      "epoch: 7, batch: 554, loss: 0.48958995938301086\n",
      "epoch: 7, batch: 555, loss: 0.3689166307449341\n",
      "epoch: 7, batch: 556, loss: 0.3301033675670624\n",
      "epoch: 7, batch: 557, loss: 0.42021244764328003\n",
      "epoch: 7, batch: 558, loss: 0.5825335383415222\n",
      "epoch: 7, batch: 559, loss: 0.6663069725036621\n",
      "epoch: 7, batch: 560, loss: 0.4494953453540802\n",
      "epoch: 7, batch: 561, loss: 0.4294315278530121\n",
      "epoch: 7, batch: 562, loss: 0.7031341195106506\n",
      "epoch: 7, batch: 563, loss: 0.30304381251335144\n",
      "epoch: 7, batch: 564, loss: 0.6022448539733887\n",
      "epoch: 7, batch: 565, loss: 0.5259612202644348\n",
      "epoch: 7, batch: 566, loss: 0.6322637796401978\n",
      "epoch: 7, batch: 567, loss: 0.8102208375930786\n",
      "epoch: 7, batch: 568, loss: 0.6666572690010071\n",
      "epoch: 7, batch: 569, loss: 0.6489284038543701\n",
      "epoch: 7, batch: 570, loss: 0.26931247115135193\n",
      "epoch: 7, batch: 571, loss: 0.38056859374046326\n",
      "epoch: 7, batch: 572, loss: 0.9068052172660828\n",
      "epoch: 7, batch: 573, loss: 0.575953483581543\n",
      "epoch: 7, batch: 574, loss: 0.401978462934494\n",
      "epoch: 7, batch: 575, loss: 0.3267970681190491\n",
      "epoch: 7, batch: 576, loss: 0.663231611251831\n",
      "epoch: 7, batch: 577, loss: 0.536735475063324\n",
      "epoch: 7, batch: 578, loss: 0.6611098051071167\n",
      "epoch: 7, batch: 579, loss: 0.4496958255767822\n",
      "epoch: 7, batch: 580, loss: 0.618425726890564\n",
      "epoch: 7, batch: 581, loss: 0.6364132165908813\n",
      "epoch: 7, batch: 582, loss: 0.6784306168556213\n",
      "epoch: 7, batch: 583, loss: 0.5135024785995483\n",
      "epoch: 7, batch: 584, loss: 0.406371146440506\n",
      "epoch: 7, batch: 585, loss: 0.5463498830795288\n",
      "epoch: 7, batch: 586, loss: 0.8409110307693481\n",
      "epoch: 7, batch: 587, loss: 0.41318896412849426\n",
      "epoch: 7, batch: 588, loss: 0.44767943024635315\n",
      "epoch: 7, batch: 589, loss: 0.6464006900787354\n",
      "epoch: 7, batch: 590, loss: 0.5585141777992249\n",
      "epoch: 7, batch: 591, loss: 0.3815137445926666\n",
      "epoch: 7, batch: 592, loss: 0.5568246841430664\n",
      "epoch: 7, batch: 593, loss: 0.3986496031284332\n",
      "epoch: 7, batch: 594, loss: 0.41351014375686646\n",
      "epoch: 7, batch: 595, loss: 0.30143529176712036\n",
      "epoch: 7, batch: 596, loss: 0.4383668899536133\n",
      "epoch: 7, batch: 597, loss: 0.4048910439014435\n",
      "epoch: 7, batch: 598, loss: 0.5642495155334473\n",
      "epoch: 7, batch: 599, loss: 0.5551983118057251\n",
      "epoch: 7, batch: 600, loss: 0.5816667079925537\n",
      "epoch: 7, batch: 601, loss: 0.4640834331512451\n",
      "epoch: 7, batch: 602, loss: 0.5704424381256104\n",
      "epoch: 7, batch: 603, loss: 0.41875559091567993\n",
      "epoch: 7, batch: 604, loss: 0.3921194076538086\n",
      "epoch: 7, batch: 605, loss: 0.6905022263526917\n",
      "epoch: 7, batch: 606, loss: 0.6032728552818298\n",
      "epoch: 7, batch: 607, loss: 0.6697896122932434\n",
      "epoch: 7, batch: 608, loss: 0.45618945360183716\n",
      "epoch: 7, batch: 609, loss: 0.7073343992233276\n",
      "epoch: 7, batch: 610, loss: 0.7269665002822876\n",
      "epoch: 7, batch: 611, loss: 0.6187031269073486\n",
      "epoch: 7, batch: 612, loss: 0.5742446184158325\n",
      "epoch: 7, batch: 613, loss: 0.5874991416931152\n",
      "epoch: 7, batch: 614, loss: 0.43607795238494873\n",
      "epoch: 7, batch: 615, loss: 0.6099568605422974\n",
      "epoch: 7, batch: 616, loss: 0.7152236104011536\n",
      "epoch: 7, batch: 617, loss: 0.4644659757614136\n",
      "epoch: 7, batch: 618, loss: 0.47769951820373535\n",
      "epoch: 7, batch: 619, loss: 0.5729092359542847\n",
      "epoch: 7, batch: 620, loss: 0.4216300845146179\n",
      "epoch: 7, batch: 621, loss: 0.47376352548599243\n",
      "epoch: 7, batch: 622, loss: 0.5067763328552246\n",
      "epoch: 7, batch: 623, loss: 0.686430037021637\n",
      "epoch: 7, batch: 624, loss: 0.4619814157485962\n",
      "epoch: 7, batch: 625, loss: 0.4892262816429138\n",
      "epoch: 7, batch: 626, loss: 0.5088316798210144\n",
      "epoch: 7, batch: 627, loss: 0.42518943548202515\n",
      "epoch: 7, batch: 628, loss: 0.5644347071647644\n",
      "epoch: 7, batch: 629, loss: 0.44453829526901245\n",
      "epoch: 7, batch: 630, loss: 0.30512404441833496\n",
      "epoch: 7, batch: 631, loss: 0.28998273611068726\n",
      "epoch: 7, batch: 632, loss: 0.5694783926010132\n",
      "epoch: 7, batch: 633, loss: 0.6258993148803711\n",
      "epoch: 7, batch: 634, loss: 0.7786052823066711\n",
      "epoch: 7, batch: 635, loss: 0.3413302004337311\n",
      "epoch: 7, batch: 636, loss: 0.2884226441383362\n",
      "epoch: 7, batch: 637, loss: 0.5990298986434937\n",
      "epoch: 7, batch: 638, loss: 0.28512415289878845\n",
      "epoch: 7, batch: 639, loss: 0.606779932975769\n",
      "epoch: 7, batch: 640, loss: 0.7234907150268555\n",
      "epoch: 7, batch: 641, loss: 0.6586069464683533\n",
      "epoch: 7, batch: 642, loss: 0.49475759267807007\n",
      "epoch: 7, batch: 643, loss: 0.5395197868347168\n",
      "epoch: 7, batch: 644, loss: 0.5840224623680115\n",
      "epoch: 7, batch: 645, loss: 0.34951671957969666\n",
      "epoch: 7, batch: 646, loss: 0.37275055050849915\n",
      "epoch: 7, batch: 647, loss: 0.6047558188438416\n",
      "epoch: 7, batch: 648, loss: 0.49044424295425415\n",
      "epoch: 7, batch: 649, loss: 0.7808173298835754\n",
      "epoch: 7, batch: 650, loss: 0.7668622136116028\n",
      "epoch: 7, batch: 651, loss: 0.8681057095527649\n",
      "epoch: 7, batch: 652, loss: 0.7167731523513794\n",
      "epoch: 7, batch: 653, loss: 0.5145158767700195\n",
      "epoch: 7, batch: 654, loss: 0.6498042941093445\n",
      "epoch: 7, batch: 655, loss: 0.8084940910339355\n",
      "epoch: 7, batch: 656, loss: 0.49673697352409363\n",
      "epoch: 7, batch: 657, loss: 0.5058693289756775\n",
      "epoch: 7, batch: 658, loss: 0.7540856599807739\n",
      "epoch: 7, batch: 659, loss: 0.6181221604347229\n",
      "epoch: 7, batch: 660, loss: 0.4954143166542053\n",
      "epoch: 7, batch: 661, loss: 0.5282196998596191\n",
      "epoch: 7, batch: 662, loss: 0.6951514482498169\n",
      "epoch: 7, batch: 663, loss: 0.6135351061820984\n",
      "epoch: 7, batch: 664, loss: 0.5741323232650757\n",
      "epoch: 7, batch: 665, loss: 0.3641393780708313\n",
      "epoch: 7, batch: 666, loss: 0.5851120352745056\n",
      "epoch: 7, batch: 667, loss: 0.46971455216407776\n",
      "epoch: 7, batch: 668, loss: 0.7637228965759277\n",
      "epoch: 7, batch: 669, loss: 0.4493604302406311\n",
      "epoch: 7, batch: 670, loss: 0.7596272230148315\n",
      "epoch: 7, batch: 671, loss: 0.6475983262062073\n",
      "epoch: 7, batch: 672, loss: 0.4090835154056549\n",
      "epoch: 7, batch: 673, loss: 0.559938371181488\n",
      "epoch: 7, batch: 674, loss: 0.48599177598953247\n",
      "epoch: 7, batch: 675, loss: 0.6226613521575928\n",
      "epoch: 7, batch: 676, loss: 0.4686812162399292\n",
      "epoch: 7, batch: 677, loss: 0.64902263879776\n",
      "epoch: 7, batch: 678, loss: 0.6184642314910889\n",
      "epoch: 7, batch: 679, loss: 0.4808253049850464\n",
      "epoch: 7, batch: 680, loss: 0.661372721195221\n",
      "epoch: 7, batch: 681, loss: 0.5108697414398193\n",
      "epoch: 7, batch: 682, loss: 0.4830031991004944\n",
      "epoch: 7, batch: 683, loss: 0.45171383023262024\n",
      "epoch: 7, batch: 684, loss: 0.6632014513015747\n",
      "epoch: 7, batch: 685, loss: 0.19329014420509338\n",
      "epoch: 7, batch: 686, loss: 0.6870510578155518\n",
      "epoch: 7, batch: 687, loss: 0.3295482099056244\n",
      "epoch: 7, batch: 688, loss: 0.4269618093967438\n",
      "epoch: 7, batch: 689, loss: 0.4492546319961548\n",
      "epoch: 7, batch: 690, loss: 0.47755295038223267\n",
      "epoch: 7, batch: 691, loss: 0.6500393748283386\n",
      "epoch: 7, batch: 692, loss: 0.6748791337013245\n",
      "epoch: 7, batch: 693, loss: 0.5555541515350342\n",
      "epoch: 7, batch: 694, loss: 0.49103260040283203\n",
      "epoch: 7, batch: 695, loss: 0.4563058018684387\n",
      "epoch: 7, batch: 696, loss: 0.3161885738372803\n",
      "epoch: 7, batch: 697, loss: 0.4290558695793152\n",
      "epoch: 7, batch: 698, loss: 0.5413724184036255\n",
      "epoch: 7, batch: 699, loss: 0.7100498080253601\n",
      "epoch: 7, batch: 700, loss: 0.38243919610977173\n",
      "epoch: 7, batch: 701, loss: 0.4584541618824005\n",
      "epoch: 7, batch: 702, loss: 0.589061439037323\n",
      "epoch: 7, batch: 703, loss: 0.4589787721633911\n",
      "epoch: 7, batch: 704, loss: 0.6189011931419373\n",
      "epoch: 7, batch: 705, loss: 0.6232234835624695\n",
      "epoch: 7, batch: 706, loss: 0.36960697174072266\n",
      "epoch: 7, batch: 707, loss: 0.48482388257980347\n",
      "epoch: 7, batch: 708, loss: 0.5733039975166321\n",
      "epoch: 7, batch: 709, loss: 0.5393915772438049\n",
      "epoch: 7, batch: 710, loss: 0.6501685976982117\n",
      "epoch: 7, batch: 711, loss: 0.30756980180740356\n",
      "epoch: 7, batch: 712, loss: 0.4531521201133728\n",
      "epoch: 7, batch: 713, loss: 0.5570771098136902\n",
      "epoch: 7, batch: 714, loss: 0.9906737804412842\n",
      "epoch: 7, batch: 715, loss: 0.31434744596481323\n",
      "epoch: 7, batch: 716, loss: 0.7493231296539307\n",
      "epoch: 7, batch: 717, loss: 0.5676084160804749\n",
      "epoch: 7, batch: 718, loss: 0.6851257681846619\n",
      "epoch: 7, batch: 719, loss: 0.5583743453025818\n",
      "epoch: 7, batch: 720, loss: 0.4618975520133972\n",
      "epoch: 7, batch: 721, loss: 0.5634093880653381\n",
      "epoch: 7, batch: 722, loss: 0.4424882233142853\n",
      "epoch: 7, batch: 723, loss: 0.486337274312973\n",
      "epoch: 7, batch: 724, loss: 0.6799542307853699\n",
      "epoch: 7, batch: 725, loss: 0.7625308036804199\n",
      "epoch: 7, batch: 726, loss: 0.5671256184577942\n",
      "epoch: 7, batch: 727, loss: 0.44581547379493713\n",
      "epoch: 7, batch: 728, loss: 0.4287258982658386\n",
      "epoch: 7, batch: 729, loss: 0.3425639569759369\n",
      "epoch: 7, batch: 730, loss: 0.4318752884864807\n",
      "epoch: 7, batch: 731, loss: 0.7179937362670898\n",
      "epoch: 7, batch: 732, loss: 0.5566410422325134\n",
      "epoch: 7, batch: 733, loss: 0.37869903445243835\n",
      "epoch: 7, batch: 734, loss: 0.749661922454834\n",
      "epoch: 7, batch: 735, loss: 0.41595080494880676\n",
      "epoch: 7, batch: 736, loss: 0.5322061777114868\n",
      "epoch: 7, batch: 737, loss: 0.4288630187511444\n",
      "epoch: 7, batch: 738, loss: 0.5242733955383301\n",
      "epoch: 7, batch: 739, loss: 0.5774071216583252\n",
      "epoch: 7, batch: 740, loss: 0.47585052251815796\n",
      "epoch: 7, batch: 741, loss: 0.4219609498977661\n",
      "epoch: 7, batch: 742, loss: 0.7066643834114075\n",
      "epoch: 7, batch: 743, loss: 0.5440361499786377\n",
      "epoch: 7, batch: 744, loss: 0.5110282301902771\n",
      "epoch: 7, batch: 745, loss: 0.5511844158172607\n",
      "epoch: 7, batch: 746, loss: 0.5048799514770508\n",
      "epoch: 7, batch: 747, loss: 0.5400403141975403\n",
      "epoch: 7, batch: 748, loss: 0.5596644878387451\n",
      "epoch: 7, batch: 749, loss: 0.47819775342941284\n",
      "epoch: 7, batch: 750, loss: 0.3870853781700134\n",
      "epoch: 7, batch: 751, loss: 0.48183852434158325\n",
      "epoch: 7, batch: 752, loss: 0.796768307685852\n",
      "epoch: 7, batch: 753, loss: 0.579771101474762\n",
      "epoch: 7, batch: 754, loss: 0.465608686208725\n",
      "epoch: 7, batch: 755, loss: 0.33787405490875244\n",
      "epoch: 7, batch: 756, loss: 0.4714925289154053\n",
      "epoch: 7, batch: 757, loss: 0.4131484627723694\n",
      "epoch: 7, batch: 758, loss: 0.4627477824687958\n",
      "epoch: 7, batch: 759, loss: 0.5396413207054138\n",
      "epoch: 7, batch: 760, loss: 0.5788815021514893\n",
      "epoch: 7, batch: 761, loss: 0.5131750702857971\n",
      "epoch: 7, batch: 762, loss: 0.6075038313865662\n",
      "epoch: 7, batch: 763, loss: 0.7554770112037659\n",
      "epoch: 7, batch: 764, loss: 0.7274263501167297\n",
      "epoch: 7, batch: 765, loss: 0.37684857845306396\n",
      "epoch: 7, batch: 766, loss: 0.5133782625198364\n",
      "epoch: 7, batch: 767, loss: 0.5080835223197937\n",
      "epoch: 7, batch: 768, loss: 0.5844846963882446\n",
      "epoch: 7, batch: 769, loss: 0.5769374370574951\n",
      "epoch: 7, batch: 770, loss: 0.34121695160865784\n",
      "epoch: 7, batch: 771, loss: 0.6484735012054443\n",
      "epoch: 7, batch: 772, loss: 0.48199424147605896\n",
      "epoch: 7, batch: 773, loss: 0.7222549319267273\n",
      "epoch: 7, batch: 774, loss: 0.6626431345939636\n",
      "epoch: 7, batch: 775, loss: 0.595731794834137\n",
      "epoch: 7, batch: 776, loss: 0.8187782764434814\n",
      "epoch: 7, batch: 777, loss: 0.45163998007774353\n",
      "epoch: 7, batch: 778, loss: 0.7310748100280762\n",
      "epoch: 7, batch: 779, loss: 0.5267186164855957\n",
      "epoch: 7, batch: 780, loss: 0.7638716697692871\n",
      "epoch: 7, batch: 781, loss: 0.7149274945259094\n",
      "epoch: 7, batch: 782, loss: 0.5521813035011292\n",
      "epoch: 7, batch: 783, loss: 0.551517903804779\n",
      "epoch: 7, batch: 784, loss: 0.4415636360645294\n",
      "epoch: 7, batch: 785, loss: 0.35901930928230286\n",
      "epoch: 7, batch: 786, loss: 0.388576865196228\n",
      "epoch: 7, batch: 787, loss: 0.547852098941803\n",
      "epoch: 7, batch: 788, loss: 0.4658123552799225\n",
      "epoch: 7, batch: 789, loss: 0.5526068210601807\n",
      "epoch: 7, batch: 790, loss: 0.4464077651500702\n",
      "epoch: 7, batch: 791, loss: 0.4604686200618744\n",
      "epoch: 7, batch: 792, loss: 0.3768247067928314\n",
      "epoch: 7, batch: 793, loss: 0.6100361943244934\n",
      "epoch: 7, batch: 794, loss: 0.5908896923065186\n",
      "epoch: 7, batch: 795, loss: 0.6553086042404175\n",
      "epoch: 7, batch: 796, loss: 0.47611579298973083\n",
      "epoch: 7, batch: 797, loss: 0.45075204968452454\n",
      "epoch: 7, batch: 798, loss: 0.4066237211227417\n",
      "epoch: 7, batch: 799, loss: 0.5479927062988281\n",
      "epoch: 7, batch: 800, loss: 0.5803729295730591\n",
      "epoch: 7, batch: 801, loss: 0.6806078553199768\n",
      "epoch: 7, batch: 802, loss: 0.558377206325531\n",
      "epoch: 7, batch: 803, loss: 0.42119333148002625\n",
      "epoch: 7, batch: 804, loss: 0.45503687858581543\n",
      "epoch: 7, batch: 805, loss: 0.8887173533439636\n",
      "epoch: 7, batch: 806, loss: 0.6047442555427551\n",
      "epoch: 7, batch: 807, loss: 0.708087682723999\n",
      "epoch: 7, batch: 808, loss: 0.3902615010738373\n",
      "epoch: 7, batch: 809, loss: 0.6244179606437683\n",
      "epoch: 7, batch: 810, loss: 0.4019917845726013\n",
      "epoch: 7, batch: 811, loss: 0.4151657521724701\n",
      "epoch: 7, batch: 812, loss: 0.5434883832931519\n",
      "epoch: 7, batch: 813, loss: 0.577651858329773\n",
      "epoch: 7, batch: 814, loss: 0.6869571805000305\n",
      "epoch: 7, batch: 815, loss: 0.6232996582984924\n",
      "epoch: 7, batch: 816, loss: 0.4399891197681427\n",
      "epoch: 7, batch: 817, loss: 0.6666164994239807\n",
      "epoch: 7, batch: 818, loss: 0.47172847390174866\n",
      "epoch: 7, batch: 819, loss: 0.7644633650779724\n",
      "epoch: 7, batch: 820, loss: 0.5016552209854126\n",
      "epoch: 7, batch: 821, loss: 0.39607325196266174\n",
      "epoch: 7, batch: 822, loss: 0.5952776074409485\n",
      "epoch: 7, batch: 823, loss: 0.4617104232311249\n",
      "epoch: 7, batch: 824, loss: 0.36593133211135864\n",
      "epoch: 7, batch: 825, loss: 0.35109570622444153\n",
      "epoch: 7, batch: 826, loss: 0.5075557827949524\n",
      "epoch: 7, batch: 827, loss: 0.46965503692626953\n",
      "epoch: 7, batch: 828, loss: 0.39394333958625793\n",
      "epoch: 7, batch: 829, loss: 0.42072585225105286\n",
      "epoch: 7, batch: 830, loss: 0.41932815313339233\n",
      "epoch: 7, batch: 831, loss: 0.6183165311813354\n",
      "epoch: 7, batch: 832, loss: 0.6497060656547546\n",
      "epoch: 7, batch: 833, loss: 0.5416997075080872\n",
      "epoch: 7, batch: 834, loss: 0.35570722818374634\n",
      "epoch: 7, batch: 835, loss: 0.7875126600265503\n",
      "epoch: 7, batch: 836, loss: 0.7098803520202637\n",
      "epoch: 7, batch: 837, loss: 0.7357895970344543\n",
      "epoch: 7, batch: 838, loss: 0.7587726712226868\n",
      "epoch: 7, batch: 839, loss: 0.3936446011066437\n",
      "epoch: 7, batch: 840, loss: 0.5958755612373352\n",
      "epoch: 7, batch: 841, loss: 0.6548614501953125\n",
      "epoch: 7, batch: 842, loss: 0.5716572999954224\n",
      "epoch: 7, batch: 843, loss: 0.5455662608146667\n",
      "epoch: 7, batch: 844, loss: 0.5331634283065796\n",
      "epoch: 7, batch: 845, loss: 0.3405071198940277\n",
      "epoch: 7, batch: 846, loss: 0.5970960855484009\n",
      "epoch: 7, batch: 847, loss: 0.5752760767936707\n",
      "epoch: 7, batch: 848, loss: 0.4828932285308838\n",
      "epoch: 7, batch: 849, loss: 0.48752540349960327\n",
      "epoch: 7, batch: 850, loss: 0.6703212857246399\n",
      "epoch: 7, batch: 851, loss: 0.4774174094200134\n",
      "epoch: 7, batch: 852, loss: 0.4632553458213806\n",
      "epoch: 7, batch: 853, loss: 0.6899915337562561\n",
      "epoch: 7, batch: 854, loss: 0.4796707034111023\n",
      "epoch: 7, batch: 855, loss: 0.6325339078903198\n",
      "epoch: 7, batch: 856, loss: 0.5899209976196289\n",
      "epoch: 7, batch: 857, loss: 0.4587743282318115\n",
      "epoch: 7, batch: 858, loss: 0.6880277991294861\n",
      "epoch: 7, batch: 859, loss: 0.291808545589447\n",
      "epoch: 7, batch: 860, loss: 0.5889887809753418\n",
      "epoch: 7, batch: 861, loss: 0.6079863905906677\n",
      "epoch: 7, batch: 862, loss: 0.518591582775116\n",
      "epoch: 7, batch: 863, loss: 0.6399999856948853\n",
      "epoch: 7, batch: 864, loss: 0.521426796913147\n",
      "epoch: 7, batch: 865, loss: 0.5063236951828003\n",
      "epoch: 7, batch: 866, loss: 0.4146186113357544\n",
      "epoch: 7, batch: 867, loss: 0.38478076457977295\n",
      "epoch: 7, batch: 868, loss: 0.6531037092208862\n",
      "epoch: 7, batch: 869, loss: 0.4678916037082672\n",
      "epoch: 7, batch: 870, loss: 0.338965505361557\n",
      "epoch: 7, batch: 871, loss: 0.6353707313537598\n",
      "epoch: 7, batch: 872, loss: 0.3667812943458557\n",
      "epoch: 7, batch: 873, loss: 0.3875504732131958\n",
      "epoch: 7, batch: 874, loss: 0.3972865343093872\n",
      "epoch: 7, batch: 875, loss: 0.34827062487602234\n",
      "epoch: 7, batch: 876, loss: 0.5930997729301453\n",
      "epoch: 7, batch: 877, loss: 0.44511547684669495\n",
      "epoch: 7, batch: 878, loss: 0.4154958426952362\n",
      "epoch: 7, batch: 879, loss: 0.6335564255714417\n",
      "epoch: 7, batch: 880, loss: 0.453340619802475\n",
      "epoch: 7, batch: 881, loss: 0.7666086554527283\n",
      "epoch: 7, batch: 882, loss: 0.48731011152267456\n",
      "epoch: 7, batch: 883, loss: 0.5439587235450745\n",
      "epoch: 7, batch: 884, loss: 0.30183663964271545\n",
      "epoch: 7, batch: 885, loss: 0.7259760499000549\n",
      "epoch: 7, batch: 886, loss: 0.4716947376728058\n",
      "epoch: 7, batch: 887, loss: 0.41180604696273804\n",
      "epoch: 7, batch: 888, loss: 0.5874902009963989\n",
      "epoch: 7, batch: 889, loss: 0.3777185380458832\n",
      "epoch: 7, batch: 890, loss: 0.49985387921333313\n",
      "epoch: 7, batch: 891, loss: 0.4419509768486023\n",
      "epoch: 7, batch: 892, loss: 0.49274227023124695\n",
      "epoch: 7, batch: 893, loss: 0.6175633668899536\n",
      "epoch: 7, batch: 894, loss: 0.37169790267944336\n",
      "epoch: 7, batch: 895, loss: 0.5229175686836243\n",
      "epoch: 7, batch: 896, loss: 0.5864766240119934\n",
      "epoch: 7, batch: 897, loss: 0.9828425049781799\n",
      "epoch: 7, batch: 898, loss: 0.6914961934089661\n",
      "epoch: 7, batch: 899, loss: 0.25093239545822144\n",
      "epoch: 7, batch: 900, loss: 0.41425758600234985\n",
      "epoch: 7, batch: 901, loss: 0.5465903282165527\n",
      "epoch: 7, batch: 902, loss: 0.3276016116142273\n",
      "epoch: 7, batch: 903, loss: 0.6291046738624573\n",
      "epoch: 7, batch: 904, loss: 0.5435967445373535\n",
      "epoch: 7, batch: 905, loss: 0.4615013003349304\n",
      "epoch: 7, batch: 906, loss: 0.5066667795181274\n",
      "epoch: 7, batch: 907, loss: 0.6048988103866577\n",
      "epoch: 7, batch: 908, loss: 0.34271615743637085\n",
      "epoch: 7, batch: 909, loss: 0.5298528075218201\n",
      "epoch: 7, batch: 910, loss: 0.7105610370635986\n",
      "epoch: 7, batch: 911, loss: 0.675751268863678\n",
      "epoch: 7, batch: 912, loss: 0.6174106597900391\n",
      "epoch: 7, batch: 913, loss: 0.4367139935493469\n",
      "epoch: 7, batch: 914, loss: 0.7831576466560364\n",
      "epoch: 7, batch: 915, loss: 0.570168673992157\n",
      "epoch: 7, batch: 916, loss: 0.5414137840270996\n",
      "epoch: 7, batch: 917, loss: 0.6123133897781372\n",
      "epoch: 7, batch: 918, loss: 0.4783829152584076\n",
      "epoch: 7, batch: 919, loss: 0.5859121680259705\n",
      "epoch: 7, batch: 920, loss: 0.3250361680984497\n",
      "epoch: 7, batch: 921, loss: 0.579686164855957\n",
      "epoch: 7, batch: 922, loss: 0.4278982877731323\n",
      "epoch: 7, batch: 923, loss: 0.5224844813346863\n",
      "epoch: 7, batch: 924, loss: 0.5410524606704712\n",
      "epoch: 7, batch: 925, loss: 0.5801910758018494\n",
      "epoch: 7, batch: 926, loss: 0.5798562169075012\n",
      "epoch: 7, batch: 927, loss: 0.5059452652931213\n",
      "epoch: 7, batch: 928, loss: 0.6545315384864807\n",
      "epoch: 7, batch: 929, loss: 0.4048589766025543\n",
      "epoch: 7, batch: 930, loss: 0.6530104279518127\n",
      "epoch: 7, batch: 931, loss: 0.628519594669342\n",
      "epoch: 7, batch: 932, loss: 0.6057573556900024\n",
      "epoch: 7, batch: 933, loss: 0.7508867383003235\n",
      "epoch: 7, batch: 934, loss: 0.7306395173072815\n",
      "epoch: 7, batch: 935, loss: 0.3482646644115448\n",
      "epoch: 7, batch: 936, loss: 0.4930577874183655\n",
      "epoch: 7, batch: 937, loss: 0.37267839908599854\n",
      "epoch: 7, batch: 938, loss: 0.584490954875946\n",
      "epoch: 7, batch: 939, loss: 0.5010849237442017\n",
      "epoch: 7, batch: 940, loss: 0.3181103765964508\n",
      "epoch: 7, batch: 941, loss: 0.6942371726036072\n",
      "epoch: 7, batch: 942, loss: 0.37576377391815186\n",
      "epoch: 7, batch: 943, loss: 0.5127213001251221\n",
      "epoch: 7, batch: 944, loss: 0.6180179119110107\n",
      "epoch: 7, batch: 945, loss: 0.35426902770996094\n",
      "epoch: 7, batch: 946, loss: 0.3481409549713135\n",
      "epoch: 7, batch: 947, loss: 0.5038102865219116\n",
      "epoch: 7, batch: 948, loss: 0.37677013874053955\n",
      "epoch: 7, batch: 949, loss: 0.7773949503898621\n",
      "epoch: 7, batch: 950, loss: 0.4936911165714264\n",
      "epoch: 7, batch: 951, loss: 0.4756557047367096\n",
      "epoch: 7, batch: 952, loss: 0.41855043172836304\n",
      "epoch: 7, batch: 953, loss: 0.3972858786582947\n",
      "epoch: 7, batch: 954, loss: 0.6001033782958984\n",
      "epoch: 7, batch: 955, loss: 0.3586450517177582\n",
      "epoch: 7, batch: 956, loss: 0.7402397394180298\n",
      "epoch: 7, batch: 957, loss: 0.5013325214385986\n",
      "epoch: 7, batch: 958, loss: 0.4416794776916504\n",
      "epoch: 7, batch: 959, loss: 0.5815148949623108\n",
      "epoch: 7, batch: 960, loss: 0.3523321747779846\n",
      "epoch: 7, batch: 961, loss: 0.38086196780204773\n",
      "epoch: 7, batch: 962, loss: 0.4346601366996765\n",
      "epoch: 7, batch: 963, loss: 1.0601035356521606\n",
      "epoch: 7, batch: 964, loss: 0.44802019000053406\n",
      "epoch: 7, batch: 965, loss: 0.32098934054374695\n",
      "epoch: 7, batch: 966, loss: 0.5131005048751831\n",
      "epoch: 7, batch: 967, loss: 0.5978252291679382\n",
      "epoch: 7, batch: 968, loss: 0.5205028057098389\n",
      "epoch: 7, batch: 969, loss: 0.37948036193847656\n",
      "epoch: 7, batch: 970, loss: 0.5278359055519104\n",
      "epoch: 7, batch: 971, loss: 0.4822007119655609\n",
      "epoch: 7, batch: 972, loss: 0.5969421863555908\n",
      "epoch: 7, batch: 973, loss: 0.6057189106941223\n",
      "epoch: 7, batch: 974, loss: 0.4445222020149231\n",
      "epoch: 7, batch: 975, loss: 0.518638551235199\n",
      "epoch: 7, batch: 976, loss: 0.37235671281814575\n",
      "epoch: 7, batch: 977, loss: 0.7502099871635437\n",
      "epoch: 7, batch: 978, loss: 0.49480846524238586\n",
      "epoch: 7, batch: 979, loss: 0.7102698683738708\n",
      "epoch: 7, batch: 980, loss: 0.24954183399677277\n",
      "epoch: 7, batch: 981, loss: 0.5588088631629944\n",
      "epoch: 7, batch: 982, loss: 0.4036869704723358\n",
      "epoch: 7, batch: 983, loss: 0.7136606574058533\n",
      "epoch: 7, batch: 984, loss: 0.5094901323318481\n",
      "epoch: 7, batch: 985, loss: 0.3308974504470825\n",
      "epoch: 7, batch: 986, loss: 0.5091357827186584\n",
      "epoch: 7, batch: 987, loss: 0.6367679834365845\n",
      "epoch: 7, batch: 988, loss: 0.5139967203140259\n",
      "epoch: 7, batch: 989, loss: 0.5106871128082275\n",
      "epoch: 7, batch: 990, loss: 0.6119748950004578\n",
      "epoch: 7, batch: 991, loss: 0.472014844417572\n",
      "epoch: 7, batch: 992, loss: 0.7448431849479675\n",
      "epoch: 7, batch: 993, loss: 0.7173210382461548\n",
      "epoch: 7, batch: 994, loss: 0.6388439536094666\n",
      "epoch: 7, batch: 995, loss: 0.6555988192558289\n",
      "epoch: 7, batch: 996, loss: 0.463802695274353\n",
      "epoch: 7, batch: 997, loss: 0.6852325201034546\n",
      "epoch: 7, batch: 998, loss: 0.3811890780925751\n",
      "epoch: 7, batch: 999, loss: 0.5618901252746582\n",
      "epoch: 7, batch: 1000, loss: 0.5125976800918579\n",
      "epoch: 7, batch: 1001, loss: 0.6400766372680664\n",
      "epoch: 7, batch: 1002, loss: 0.7107904553413391\n",
      "epoch: 7, batch: 1003, loss: 0.30520686507225037\n",
      "epoch: 7, batch: 1004, loss: 0.7352895736694336\n",
      "epoch: 7, batch: 1005, loss: 0.4168268144130707\n",
      "epoch: 7, batch: 1006, loss: 0.4088645875453949\n",
      "epoch: 7, batch: 1007, loss: 0.46487733721733093\n",
      "epoch: 7, batch: 1008, loss: 0.5266067981719971\n",
      "epoch: 7, batch: 1009, loss: 0.40482261776924133\n",
      "epoch: 7, batch: 1010, loss: 0.5759167075157166\n",
      "epoch: 7, batch: 1011, loss: 0.46912896633148193\n",
      "epoch: 7, batch: 1012, loss: 0.40744996070861816\n",
      "epoch: 7, batch: 1013, loss: 0.4417596757411957\n",
      "epoch: 7, batch: 1014, loss: 0.40655267238616943\n",
      "epoch: 7, batch: 1015, loss: 0.6294999122619629\n",
      "epoch: 7, batch: 1016, loss: 0.46605339646339417\n",
      "epoch: 7, batch: 1017, loss: 0.37051159143447876\n",
      "epoch: 7, batch: 1018, loss: 0.32486361265182495\n",
      "epoch: 7, batch: 1019, loss: 0.42445629835128784\n",
      "epoch: 7, batch: 1020, loss: 0.43655988574028015\n",
      "epoch: 7, batch: 1021, loss: 0.34502068161964417\n",
      "epoch: 7, batch: 1022, loss: 0.5680770874023438\n",
      "epoch: 7, batch: 1023, loss: 0.4008200168609619\n",
      "epoch: 7, batch: 1024, loss: 0.4313742220401764\n",
      "epoch: 7, batch: 1025, loss: 0.668872058391571\n",
      "epoch: 7, batch: 1026, loss: 0.46076852083206177\n",
      "epoch: 7, batch: 1027, loss: 0.4115198254585266\n",
      "epoch: 7, batch: 1028, loss: 0.48122718930244446\n",
      "epoch: 7, batch: 1029, loss: 0.8119799494743347\n",
      "epoch: 7, batch: 1030, loss: 0.5146157741546631\n",
      "epoch: 7, batch: 1031, loss: 0.5494349002838135\n",
      "epoch: 7, batch: 1032, loss: 0.420003741979599\n",
      "epoch: 7, batch: 1033, loss: 0.69049471616745\n",
      "epoch: 7, batch: 1034, loss: 0.7060166597366333\n",
      "epoch: 7, batch: 1035, loss: 0.45820119976997375\n",
      "epoch: 7, batch: 1036, loss: 0.5149335861206055\n",
      "epoch: 7, batch: 1037, loss: 0.8702136278152466\n",
      "epoch: 7, batch: 1038, loss: 0.4047829806804657\n",
      "epoch: 7, batch: 1039, loss: 0.41896846890449524\n",
      "epoch: 7, batch: 1040, loss: 0.4683326184749603\n",
      "epoch: 7, batch: 1041, loss: 0.4845719039440155\n",
      "epoch: 7, batch: 1042, loss: 0.4302751123905182\n",
      "epoch: 7, batch: 1043, loss: 0.5044780969619751\n",
      "epoch: 7, batch: 1044, loss: 0.43475791811943054\n",
      "epoch: 7, batch: 1045, loss: 0.6905770897865295\n",
      "epoch: 7, batch: 1046, loss: 0.5422611832618713\n",
      "epoch: 7, batch: 1047, loss: 0.5235856771469116\n",
      "epoch: 7, batch: 1048, loss: 0.554521381855011\n",
      "epoch: 7, batch: 1049, loss: 0.63368821144104\n",
      "epoch: 7, batch: 1050, loss: 0.4535294771194458\n",
      "epoch: 7, batch: 1051, loss: 0.5205226540565491\n",
      "epoch: 7, batch: 1052, loss: 0.7398781180381775\n",
      "epoch: 7, batch: 1053, loss: 0.6120478510856628\n",
      "epoch: 7, batch: 1054, loss: 0.3288188874721527\n",
      "epoch: 7, batch: 1055, loss: 0.44535306096076965\n",
      "epoch: 7, batch: 1056, loss: 0.4609234035015106\n",
      "epoch: 7, batch: 1057, loss: 0.5103449821472168\n",
      "epoch: 7, batch: 1058, loss: 0.4549619257450104\n",
      "epoch: 7, batch: 1059, loss: 0.5165737271308899\n",
      "epoch: 7, batch: 1060, loss: 0.41647404432296753\n",
      "epoch: 7, batch: 1061, loss: 0.4331066906452179\n",
      "epoch: 7, batch: 1062, loss: 0.6665219664573669\n",
      "epoch: 7, batch: 1063, loss: 0.28118833899497986\n",
      "epoch: 7, batch: 1064, loss: 0.49643072485923767\n",
      "epoch: 7, batch: 1065, loss: 0.30298417806625366\n",
      "epoch: 7, batch: 1066, loss: 0.5380215048789978\n",
      "epoch: 7, batch: 1067, loss: 0.5096287727355957\n",
      "epoch: 7, batch: 1068, loss: 0.28595179319381714\n",
      "epoch: 7, batch: 1069, loss: 0.2887535095214844\n",
      "epoch: 7, batch: 1070, loss: 0.572770357131958\n",
      "epoch: 7, batch: 1071, loss: 0.716235339641571\n",
      "epoch: 7, batch: 1072, loss: 0.7237343788146973\n",
      "epoch: 7, batch: 1073, loss: 0.5352078080177307\n",
      "epoch: 7, batch: 1074, loss: 0.6390536427497864\n",
      "epoch: 7, batch: 1075, loss: 0.6600359678268433\n",
      "epoch: 7, batch: 1076, loss: 0.5716056823730469\n",
      "epoch: 7, batch: 1077, loss: 0.6107034683227539\n",
      "epoch: 7, batch: 1078, loss: 0.4531742334365845\n",
      "epoch: 7, batch: 1079, loss: 0.6761253476142883\n",
      "epoch: 7, batch: 1080, loss: 0.49609753489494324\n",
      "epoch: 7, batch: 1081, loss: 0.6719886064529419\n",
      "epoch: 7, batch: 1082, loss: 0.4565706253051758\n",
      "epoch: 7, batch: 1083, loss: 0.6528018712997437\n",
      "epoch: 7, batch: 1084, loss: 0.3782500922679901\n",
      "epoch: 7, batch: 1085, loss: 0.28912678360939026\n",
      "epoch: 7, batch: 1086, loss: 0.44850826263427734\n",
      "epoch: 7, batch: 1087, loss: 0.5465292930603027\n",
      "epoch: 7, batch: 1088, loss: 0.4524035155773163\n",
      "epoch: 7, batch: 1089, loss: 0.4265279173851013\n",
      "epoch: 7, batch: 1090, loss: 0.7702147960662842\n",
      "epoch: 7, batch: 1091, loss: 0.6919460296630859\n",
      "epoch: 7, batch: 1092, loss: 0.48625296354293823\n",
      "epoch: 7, batch: 1093, loss: 0.5305727124214172\n",
      "epoch: 7, batch: 1094, loss: 0.31756719946861267\n",
      "epoch: 7, batch: 1095, loss: 0.3932996988296509\n",
      "epoch: 7, batch: 1096, loss: 0.35861021280288696\n",
      "epoch: 7, batch: 1097, loss: 0.6917640566825867\n",
      "epoch: 7, batch: 1098, loss: 0.3325675129890442\n",
      "epoch: 7, batch: 1099, loss: 0.4175613522529602\n",
      "epoch: 7, batch: 1100, loss: 0.43125244975090027\n",
      "epoch: 7, batch: 1101, loss: 0.6926751136779785\n",
      "epoch: 7, batch: 1102, loss: 0.47422900795936584\n",
      "epoch: 7, batch: 1103, loss: 0.6741840839385986\n",
      "epoch: 7, batch: 1104, loss: 0.5223782062530518\n",
      "epoch: 7, batch: 1105, loss: 0.5117063522338867\n",
      "epoch: 7, batch: 1106, loss: 0.26017722487449646\n",
      "epoch: 7, batch: 1107, loss: 0.36573565006256104\n",
      "epoch: 7, batch: 1108, loss: 0.5938183069229126\n",
      "epoch: 7, batch: 1109, loss: 1.0496097803115845\n",
      "epoch: 7, batch: 1110, loss: 1.015817642211914\n",
      "epoch: 7, batch: 1111, loss: 0.4200466275215149\n",
      "epoch: 7, batch: 1112, loss: 0.3901277780532837\n",
      "epoch: 7, batch: 1113, loss: 0.37280982732772827\n",
      "epoch: 7, batch: 1114, loss: 0.4897940158843994\n",
      "epoch: 7, batch: 1115, loss: 0.6863784790039062\n",
      "epoch: 7, batch: 1116, loss: 0.3801914155483246\n",
      "epoch: 7, batch: 1117, loss: 0.5648277401924133\n",
      "epoch: 7, batch: 1118, loss: 0.42522719502449036\n",
      "epoch: 7, batch: 1119, loss: 0.4925505220890045\n",
      "epoch: 7, batch: 1120, loss: 0.8604656457901001\n",
      "epoch: 7, batch: 1121, loss: 0.7552703619003296\n",
      "epoch: 7, batch: 1122, loss: 0.6582636833190918\n",
      "epoch: 7, batch: 1123, loss: 0.481214702129364\n",
      "epoch: 7, batch: 1124, loss: 0.4842483103275299\n",
      "epoch: 7, batch: 1125, loss: 0.5321061015129089\n",
      "epoch: 7, batch: 1126, loss: 0.4712529480457306\n",
      "epoch: 7, batch: 1127, loss: 0.6939904093742371\n",
      "epoch: 7, batch: 1128, loss: 0.4644363224506378\n",
      "epoch: 7, batch: 1129, loss: 0.7515016198158264\n",
      "epoch: 7, batch: 1130, loss: 0.3289380967617035\n",
      "epoch: 7, batch: 1131, loss: 0.37362560629844666\n",
      "epoch: 7, batch: 1132, loss: 0.4373170733451843\n",
      "epoch: 7, batch: 1133, loss: 0.3763740360736847\n",
      "epoch: 7, batch: 1134, loss: 0.39163219928741455\n",
      "epoch: 7, batch: 1135, loss: 0.4159417450428009\n",
      "epoch: 7, batch: 1136, loss: 0.6829235553741455\n",
      "epoch: 7, batch: 1137, loss: 0.7006433606147766\n",
      "epoch: 7, batch: 1138, loss: 0.49779826402664185\n",
      "epoch: 7, batch: 1139, loss: 0.7060695290565491\n",
      "epoch: 7, batch: 1140, loss: 0.31880518794059753\n",
      "epoch: 7, batch: 1141, loss: 0.4308472275733948\n",
      "epoch: 7, batch: 1142, loss: 0.5810564756393433\n",
      "epoch: 7, batch: 1143, loss: 0.8410892486572266\n",
      "epoch: 7, batch: 1144, loss: 0.32857099175453186\n",
      "epoch: 7, batch: 1145, loss: 0.9075305461883545\n",
      "epoch: 7, batch: 1146, loss: 0.5243579745292664\n",
      "epoch: 7, batch: 1147, loss: 0.48179110884666443\n",
      "epoch: 7, batch: 1148, loss: 0.6097335815429688\n",
      "epoch: 7, batch: 1149, loss: 0.6833126544952393\n",
      "epoch: 7, batch: 1150, loss: 0.49771496653556824\n",
      "epoch: 7, batch: 1151, loss: 0.5351041555404663\n",
      "epoch: 7, batch: 1152, loss: 0.592957615852356\n",
      "epoch: 7, batch: 1153, loss: 0.6251571178436279\n",
      "epoch: 7, batch: 1154, loss: 0.5654970407485962\n",
      "epoch: 7, batch: 1155, loss: 0.6459288597106934\n",
      "epoch: 7, batch: 1156, loss: 0.5286170244216919\n",
      "epoch: 7, batch: 1157, loss: 0.620987594127655\n",
      "epoch: 7, batch: 1158, loss: 0.428823858499527\n",
      "epoch: 7, batch: 1159, loss: 0.38899505138397217\n",
      "epoch: 7, batch: 1160, loss: 0.7114403247833252\n",
      "epoch: 7, batch: 1161, loss: 0.36837324500083923\n",
      "epoch: 7, batch: 1162, loss: 0.38964515924453735\n",
      "epoch: 7, batch: 1163, loss: 0.45435774326324463\n",
      "epoch: 7, batch: 1164, loss: 0.38217872381210327\n",
      "epoch: 7, batch: 1165, loss: 0.5365632176399231\n",
      "epoch: 7, batch: 1166, loss: 0.5451129674911499\n",
      "epoch: 7, batch: 1167, loss: 0.4983864724636078\n",
      "epoch: 7, batch: 1168, loss: 0.3897545337677002\n",
      "epoch: 7, batch: 1169, loss: 0.45486122369766235\n",
      "epoch: 7, batch: 1170, loss: 0.31256529688835144\n",
      "epoch: 7, batch: 1171, loss: 0.8218722343444824\n",
      "epoch: 7, batch: 1172, loss: 0.49531158804893494\n",
      "epoch: 7, batch: 1173, loss: 0.5139716267585754\n",
      "epoch: 7, batch: 1174, loss: 0.39485499262809753\n",
      "epoch: 7, batch: 1175, loss: 0.46821820735931396\n",
      "epoch: 7, batch: 1176, loss: 0.28365325927734375\n",
      "epoch: 7, batch: 1177, loss: 0.6111972332000732\n",
      "epoch: 7, batch: 1178, loss: 0.4947018325328827\n",
      "epoch: 7, batch: 1179, loss: 0.5313505530357361\n",
      "epoch: 7, batch: 1180, loss: 0.64533931016922\n",
      "epoch: 7, batch: 1181, loss: 0.4148690700531006\n",
      "epoch: 7, batch: 1182, loss: 0.6666101813316345\n",
      "epoch: 7, batch: 1183, loss: 0.39774033427238464\n",
      "epoch: 7, batch: 1184, loss: 0.691717267036438\n",
      "epoch: 7, batch: 1185, loss: 0.42647749185562134\n",
      "epoch: 7, batch: 1186, loss: 0.7149739265441895\n",
      "epoch: 7, batch: 1187, loss: 0.6050523519515991\n",
      "epoch: 7, batch: 1188, loss: 0.5332022309303284\n",
      "epoch: 7, batch: 1189, loss: 0.4306407868862152\n",
      "epoch: 7, batch: 1190, loss: 0.22677090764045715\n",
      "epoch: 7, batch: 1191, loss: 0.6945384740829468\n",
      "epoch: 7, batch: 1192, loss: 0.5897215604782104\n",
      "epoch: 7, batch: 1193, loss: 0.7596615552902222\n",
      "epoch: 7, batch: 1194, loss: 0.3437073826789856\n",
      "epoch: 7, batch: 1195, loss: 0.531883955001831\n",
      "epoch: 7, batch: 1196, loss: 0.6218928098678589\n",
      "epoch: 7, batch: 1197, loss: 0.7185330390930176\n",
      "epoch: 7, batch: 1198, loss: 0.6262176632881165\n",
      "epoch: 7, batch: 1199, loss: 0.8870428800582886\n",
      "epoch: 7, batch: 1200, loss: 0.3426426351070404\n",
      "epoch: 7, batch: 1201, loss: 0.5736415386199951\n",
      "epoch: 7, batch: 1202, loss: 0.555704653263092\n",
      "epoch: 7, batch: 1203, loss: 0.5033951997756958\n",
      "epoch: 7, batch: 1204, loss: 0.5995545983314514\n",
      "epoch: 7, batch: 1205, loss: 0.4167502820491791\n",
      "epoch: 7, batch: 1206, loss: 0.48485010862350464\n",
      "epoch: 7, batch: 1207, loss: 0.8386829495429993\n",
      "epoch: 7, batch: 1208, loss: 0.5885405540466309\n",
      "epoch: 7, batch: 1209, loss: 0.7482260465621948\n",
      "epoch: 7, batch: 1210, loss: 0.5087335109710693\n",
      "epoch: 7, batch: 1211, loss: 0.37350985407829285\n",
      "epoch: 7, batch: 1212, loss: 0.5263047218322754\n",
      "epoch: 7, batch: 1213, loss: 0.6217852234840393\n",
      "epoch: 7, batch: 1214, loss: 0.4821487069129944\n",
      "epoch: 7, batch: 1215, loss: 0.5426772236824036\n",
      "epoch: 7, batch: 1216, loss: 0.6288288831710815\n",
      "epoch: 7, batch: 1217, loss: 0.6450062990188599\n",
      "epoch: 7, batch: 1218, loss: 0.5740016102790833\n",
      "epoch: 7, batch: 1219, loss: 0.625481128692627\n",
      "epoch: 7, batch: 1220, loss: 0.5165520906448364\n",
      "epoch: 7, batch: 1221, loss: 0.35803672671318054\n",
      "epoch: 7, batch: 1222, loss: 0.45260345935821533\n",
      "epoch: 7, batch: 1223, loss: 0.46612706780433655\n",
      "epoch: 7, batch: 1224, loss: 0.5160054564476013\n",
      "epoch: 7, batch: 1225, loss: 0.7863739132881165\n",
      "epoch: 7, batch: 1226, loss: 0.5095615386962891\n",
      "epoch: 7, batch: 1227, loss: 0.48027777671813965\n",
      "epoch: 7, batch: 1228, loss: 0.6015807390213013\n",
      "epoch: 7, batch: 1229, loss: 0.4617609679698944\n",
      "epoch: 7, batch: 1230, loss: 0.7128021717071533\n",
      "epoch: 7, batch: 1231, loss: 0.32541340589523315\n",
      "epoch: 7, batch: 1232, loss: 0.4297010004520416\n",
      "epoch: 7, batch: 1233, loss: 0.6825938820838928\n",
      "epoch: 7, batch: 1234, loss: 0.4129336178302765\n",
      "epoch: 7, batch: 1235, loss: 0.5365892648696899\n",
      "epoch: 7, batch: 1236, loss: 0.4938347637653351\n",
      "epoch: 7, batch: 1237, loss: 0.38166114687919617\n",
      "epoch: 7, batch: 1238, loss: 0.4796864986419678\n",
      "epoch: 7, batch: 1239, loss: 0.406961590051651\n",
      "epoch: 7, batch: 1240, loss: 0.35973551869392395\n",
      "epoch: 7, batch: 1241, loss: 0.8642613291740417\n",
      "epoch: 7, batch: 1242, loss: 0.3706292510032654\n",
      "epoch: 7, batch: 1243, loss: 0.32656148076057434\n",
      "epoch: 7, batch: 1244, loss: 0.4499466121196747\n",
      "epoch: 7, batch: 1245, loss: 0.3785316050052643\n",
      "epoch: 7, batch: 1246, loss: 0.6083472967147827\n",
      "epoch: 7, batch: 1247, loss: 0.5223657488822937\n",
      "epoch: 7, batch: 1248, loss: 0.3449157476425171\n",
      "epoch: 7, batch: 1249, loss: 0.6605762839317322\n",
      "epoch: 7, batch: 1250, loss: 0.6526809334754944\n",
      "epoch: 7, batch: 1251, loss: 0.2941630780696869\n",
      "epoch: 7, batch: 1252, loss: 0.3615798354148865\n",
      "epoch: 7, batch: 1253, loss: 0.45683854818344116\n",
      "epoch: 7, batch: 1254, loss: 0.5123592615127563\n",
      "epoch: 7, batch: 1255, loss: 0.4776148796081543\n",
      "epoch: 7, batch: 1256, loss: 0.6943978071212769\n",
      "epoch: 7, batch: 1257, loss: 0.4797041118144989\n",
      "epoch: 7, batch: 1258, loss: 0.6369433999061584\n",
      "epoch: 7, batch: 1259, loss: 0.6516169309616089\n",
      "epoch: 7, batch: 1260, loss: 0.3526633679866791\n",
      "epoch: 7, batch: 1261, loss: 0.5908368825912476\n",
      "epoch: 7, batch: 1262, loss: 0.44612744450569153\n",
      "epoch: 7, batch: 1263, loss: 0.37541624903678894\n",
      "epoch: 7, batch: 1264, loss: 0.340679407119751\n",
      "epoch: 7, batch: 1265, loss: 0.6444104313850403\n",
      "epoch: 7, batch: 1266, loss: 0.2909736633300781\n",
      "epoch: 7, batch: 1267, loss: 0.3163567781448364\n",
      "epoch: 7, batch: 1268, loss: 0.623083233833313\n",
      "epoch: 7, batch: 1269, loss: 0.28992268443107605\n",
      "epoch: 7, batch: 1270, loss: 0.5714708566665649\n",
      "epoch: 7, batch: 1271, loss: 0.33142197132110596\n",
      "epoch: 7, batch: 1272, loss: 0.5047235488891602\n",
      "epoch: 7, batch: 1273, loss: 0.43375542759895325\n",
      "epoch: 7, batch: 1274, loss: 0.8312482833862305\n",
      "epoch: 7, batch: 1275, loss: 0.5269802808761597\n",
      "epoch: 7, batch: 1276, loss: 0.5022251605987549\n",
      "epoch: 7, batch: 1277, loss: 0.7648229598999023\n",
      "epoch: 7, batch: 1278, loss: 0.3603057563304901\n",
      "epoch: 7, batch: 1279, loss: 0.5689811706542969\n",
      "epoch: 7, batch: 1280, loss: 0.4878913462162018\n",
      "epoch: 7, batch: 1281, loss: 0.6409013867378235\n",
      "epoch: 7, batch: 1282, loss: 0.462593138217926\n",
      "epoch: 7, batch: 1283, loss: 0.7768597602844238\n",
      "epoch: 7, batch: 1284, loss: 0.3992634415626526\n",
      "epoch: 7, batch: 1285, loss: 0.7952635884284973\n",
      "epoch: 7, batch: 1286, loss: 0.4806358218193054\n",
      "epoch: 7, batch: 1287, loss: 0.6944937705993652\n",
      "epoch: 7, batch: 1288, loss: 0.6653785705566406\n",
      "epoch: 7, batch: 1289, loss: 0.6366243958473206\n",
      "epoch: 7, batch: 1290, loss: 0.5341368317604065\n",
      "epoch: 7, batch: 1291, loss: 0.5633490681648254\n",
      "epoch: 7, batch: 1292, loss: 0.6577599048614502\n",
      "epoch: 7, batch: 1293, loss: 0.3148953318595886\n",
      "epoch: 7, batch: 1294, loss: 0.30285361409187317\n",
      "epoch: 7, batch: 1295, loss: 0.3268986642360687\n",
      "epoch: 7, batch: 1296, loss: 0.4677644371986389\n",
      "epoch: 7, batch: 1297, loss: 0.5996260046958923\n",
      "epoch: 7, batch: 1298, loss: 0.773690938949585\n",
      "epoch: 7, batch: 1299, loss: 0.5226710438728333\n",
      "epoch: 7, batch: 1300, loss: 0.522328794002533\n",
      "epoch: 7, batch: 1301, loss: 0.42354100942611694\n",
      "epoch: 7, batch: 1302, loss: 0.6848828792572021\n",
      "epoch: 7, batch: 1303, loss: 0.545549750328064\n",
      "epoch: 7, batch: 1304, loss: 0.39194390177726746\n",
      "epoch: 7, batch: 1305, loss: 0.48542457818984985\n",
      "epoch: 7, batch: 1306, loss: 0.5075657367706299\n",
      "epoch: 7, batch: 1307, loss: 0.4468596279621124\n",
      "epoch: 7, batch: 1308, loss: 0.5208055973052979\n",
      "epoch: 7, batch: 1309, loss: 0.45213618874549866\n",
      "epoch: 7, batch: 1310, loss: 0.5358705520629883\n",
      "epoch: 7, batch: 1311, loss: 0.32795897126197815\n",
      "epoch: 7, batch: 1312, loss: 0.22701245546340942\n",
      "epoch: 7, batch: 1313, loss: 0.3520985245704651\n",
      "epoch: 7, batch: 1314, loss: 0.6774451732635498\n",
      "epoch: 7, batch: 1315, loss: 0.4706912338733673\n",
      "epoch: 7, batch: 1316, loss: 0.552574634552002\n",
      "epoch: 7, batch: 1317, loss: 0.3707527220249176\n",
      "epoch: 7, batch: 1318, loss: 0.4457567036151886\n",
      "epoch: 7, batch: 1319, loss: 0.40150949358940125\n",
      "epoch: 7, batch: 1320, loss: 0.5195239186286926\n",
      "epoch: 7, batch: 1321, loss: 0.46239015460014343\n",
      "epoch: 7, batch: 1322, loss: 0.7921883463859558\n",
      "epoch: 7, batch: 1323, loss: 0.3045419454574585\n",
      "epoch: 7, batch: 1324, loss: 0.5981923341751099\n",
      "epoch: 7, batch: 1325, loss: 0.35126805305480957\n",
      "epoch: 7, batch: 1326, loss: 0.30738598108291626\n",
      "epoch: 7, batch: 1327, loss: 0.5214691758155823\n",
      "epoch: 7, batch: 1328, loss: 0.41839084029197693\n",
      "epoch: 7, batch: 1329, loss: 0.4107522964477539\n",
      "epoch: 7, batch: 1330, loss: 0.5289435982704163\n",
      "epoch: 7, batch: 1331, loss: 0.46102291345596313\n",
      "epoch: 7, batch: 1332, loss: 0.41594502329826355\n",
      "epoch: 7, batch: 1333, loss: 0.6145316362380981\n",
      "epoch: 7, batch: 1334, loss: 0.5638233423233032\n",
      "epoch: 7, batch: 1335, loss: 0.9030386209487915\n",
      "epoch: 7, batch: 1336, loss: 0.5574842095375061\n",
      "epoch: 7, batch: 1337, loss: 0.3147766590118408\n",
      "epoch: 7, batch: 1338, loss: 0.3465856909751892\n",
      "epoch: 7, batch: 1339, loss: 0.38349243998527527\n",
      "epoch: 7, batch: 1340, loss: 0.39875301718711853\n",
      "epoch: 7, batch: 1341, loss: 0.4685298800468445\n",
      "epoch: 7, batch: 1342, loss: 0.47301626205444336\n",
      "epoch: 7, batch: 1343, loss: 0.5016047358512878\n",
      "epoch: 7, batch: 1344, loss: 0.6362253427505493\n",
      "epoch: 7, batch: 1345, loss: 0.5405428409576416\n",
      "epoch: 7, batch: 1346, loss: 0.5569537878036499\n",
      "epoch: 7, batch: 1347, loss: 0.4936051666736603\n",
      "epoch: 7, batch: 1348, loss: 0.4537763297557831\n",
      "epoch: 7, batch: 1349, loss: 0.39934277534484863\n",
      "epoch: 7, batch: 1350, loss: 0.6955143213272095\n",
      "epoch: 7, batch: 1351, loss: 0.5983179211616516\n",
      "epoch: 7, batch: 1352, loss: 0.4173439145088196\n",
      "epoch: 7, batch: 1353, loss: 0.3172001838684082\n",
      "epoch: 7, batch: 1354, loss: 0.5675716400146484\n",
      "epoch: 7, batch: 1355, loss: 0.3408438563346863\n",
      "epoch: 7, batch: 1356, loss: 0.3778005838394165\n",
      "epoch: 7, batch: 1357, loss: 0.29981833696365356\n",
      "epoch: 7, batch: 1358, loss: 0.5201553106307983\n",
      "epoch: 7, batch: 1359, loss: 0.569299578666687\n",
      "epoch: 7, batch: 1360, loss: 0.46519148349761963\n",
      "epoch: 7, batch: 1361, loss: 0.3069102466106415\n",
      "epoch: 7, batch: 1362, loss: 0.25556957721710205\n",
      "epoch: 7, batch: 1363, loss: 0.5005130171775818\n",
      "epoch: 7, batch: 1364, loss: 0.7704938054084778\n",
      "epoch: 7, batch: 1365, loss: 0.5563634037971497\n",
      "epoch: 7, batch: 1366, loss: 0.5909769535064697\n",
      "epoch: 7, batch: 1367, loss: 0.4434764087200165\n",
      "epoch: 7, batch: 1368, loss: 0.5679616332054138\n",
      "epoch: 7, batch: 1369, loss: 0.609222948551178\n",
      "epoch: 7, batch: 1370, loss: 0.45196714997291565\n",
      "epoch: 7, batch: 1371, loss: 0.3256033957004547\n",
      "epoch: 7, batch: 1372, loss: 0.6376021504402161\n",
      "epoch: 7, batch: 1373, loss: 0.37232935428619385\n",
      "epoch: 7, batch: 1374, loss: 0.40296319127082825\n",
      "epoch: 7, batch: 1375, loss: 0.505178689956665\n",
      "epoch: 7, batch: 1376, loss: 0.37068507075309753\n",
      "epoch: 7, batch: 1377, loss: 0.9252592325210571\n",
      "epoch: 7, batch: 1378, loss: 0.5515257716178894\n",
      "epoch: 7, batch: 1379, loss: 0.27217572927474976\n",
      "epoch: 7, batch: 1380, loss: 0.4198855459690094\n",
      "epoch: 7, batch: 1381, loss: 0.49938035011291504\n",
      "epoch: 7, batch: 1382, loss: 0.5854436159133911\n",
      "epoch: 7, batch: 1383, loss: 0.4134118854999542\n",
      "epoch: 7, batch: 1384, loss: 0.4133788049221039\n",
      "epoch: 7, batch: 1385, loss: 0.6570757031440735\n",
      "epoch: 7, batch: 1386, loss: 0.7229114770889282\n",
      "epoch: 7, batch: 1387, loss: 0.4106397330760956\n",
      "epoch: 7, batch: 1388, loss: 0.7688637375831604\n",
      "epoch: 7, batch: 1389, loss: 0.5034167170524597\n",
      "epoch: 7, batch: 1390, loss: 0.6890677809715271\n",
      "epoch: 7, batch: 1391, loss: 0.4402455687522888\n",
      "epoch: 7, batch: 1392, loss: 0.7286458015441895\n",
      "epoch: 7, batch: 1393, loss: 0.5051684379577637\n",
      "epoch: 7, batch: 1394, loss: 0.44216814637184143\n",
      "epoch: 7, batch: 1395, loss: 0.45782455801963806\n",
      "epoch: 7, batch: 1396, loss: 0.5583234429359436\n",
      "epoch: 7, batch: 1397, loss: 0.5092096328735352\n",
      "epoch: 7, batch: 1398, loss: 0.5252774357795715\n",
      "epoch: 7, batch: 1399, loss: 0.4734116196632385\n",
      "epoch: 7, batch: 1400, loss: 0.5374078154563904\n",
      "epoch: 7, batch: 1401, loss: 0.3293396234512329\n",
      "epoch: 7, batch: 1402, loss: 0.5679805278778076\n",
      "epoch: 7, batch: 1403, loss: 0.32353731989860535\n",
      "epoch: 7, batch: 1404, loss: 0.47120651602745056\n",
      "epoch: 7, batch: 1405, loss: 0.4949762225151062\n",
      "epoch: 7, batch: 1406, loss: 0.45615115761756897\n",
      "epoch: 7, batch: 1407, loss: 0.26636239886283875\n",
      "epoch: 7, batch: 1408, loss: 0.7493543028831482\n",
      "epoch: 7, batch: 1409, loss: 0.3899739980697632\n",
      "epoch: 7, batch: 1410, loss: 0.4706251323223114\n",
      "epoch: 7, batch: 1411, loss: 0.40801534056663513\n",
      "epoch: 7, batch: 1412, loss: 0.5678512454032898\n",
      "epoch: 7, batch: 1413, loss: 0.602663516998291\n",
      "epoch: 7, batch: 1414, loss: 0.503136932849884\n",
      "epoch: 7, batch: 1415, loss: 0.4489348828792572\n",
      "epoch: 7, batch: 1416, loss: 0.4569566547870636\n",
      "epoch: 7, batch: 1417, loss: 0.38784685730934143\n",
      "epoch: 7, batch: 1418, loss: 0.6609198451042175\n",
      "epoch: 7, batch: 1419, loss: 0.494076669216156\n",
      "epoch: 7, batch: 1420, loss: 0.5994070768356323\n",
      "epoch: 7, batch: 1421, loss: 0.3977913558483124\n",
      "epoch: 7, batch: 1422, loss: 0.35185015201568604\n",
      "epoch: 7, batch: 1423, loss: 0.3805600702762604\n",
      "epoch: 7, batch: 1424, loss: 0.8434596061706543\n",
      "epoch: 7, batch: 1425, loss: 0.5087459087371826\n",
      "epoch: 7, batch: 1426, loss: 0.795250654220581\n",
      "epoch: 7, batch: 1427, loss: 0.8080368041992188\n",
      "epoch: 7, batch: 1428, loss: 0.3438464403152466\n",
      "epoch: 7, batch: 1429, loss: 0.3961845934391022\n",
      "epoch: 7, batch: 1430, loss: 0.6019226908683777\n",
      "epoch: 7, batch: 1431, loss: 0.6390131115913391\n",
      "epoch: 7, batch: 1432, loss: 0.34801599383354187\n",
      "epoch: 7, batch: 1433, loss: 0.49413421750068665\n",
      "epoch: 7, batch: 1434, loss: 0.3961785137653351\n",
      "epoch: 7, batch: 1435, loss: 0.3804144561290741\n",
      "epoch: 7, batch: 1436, loss: 0.5452632904052734\n",
      "epoch: 7, batch: 1437, loss: 0.45065146684646606\n",
      "epoch: 7, batch: 1438, loss: 0.49795976281166077\n",
      "epoch: 7, batch: 1439, loss: 0.26855969429016113\n",
      "epoch: 7, batch: 1440, loss: 0.43432971835136414\n",
      "epoch: 7, batch: 1441, loss: 0.4317992627620697\n",
      "epoch: 7, batch: 1442, loss: 0.4367947280406952\n",
      "epoch: 7, batch: 1443, loss: 0.49364712834358215\n",
      "epoch: 7, batch: 1444, loss: 0.7014830112457275\n",
      "epoch: 7, batch: 1445, loss: 0.49564430117607117\n",
      "epoch: 7, batch: 1446, loss: 0.4798482656478882\n",
      "epoch: 7, batch: 1447, loss: 0.7715328931808472\n",
      "epoch: 7, batch: 1448, loss: 0.3665551543235779\n",
      "epoch: 7, batch: 1449, loss: 0.783860981464386\n",
      "epoch: 7, batch: 1450, loss: 0.805030882358551\n",
      "epoch: 7, batch: 1451, loss: 0.28510385751724243\n",
      "epoch: 7, batch: 1452, loss: 0.2969095706939697\n",
      "epoch: 7, batch: 1453, loss: 0.8041759133338928\n",
      "epoch: 7, batch: 1454, loss: 0.4047245681285858\n",
      "epoch: 7, batch: 1455, loss: 0.36450615525245667\n",
      "epoch: 7, batch: 1456, loss: 0.374112069606781\n",
      "epoch: 7, batch: 1457, loss: 0.21740411221981049\n",
      "epoch: 7, batch: 1458, loss: 0.6274487972259521\n",
      "epoch: 7, batch: 1459, loss: 0.2689899802207947\n",
      "epoch: 7, batch: 1460, loss: 0.5163787603378296\n",
      "epoch: 7, batch: 1461, loss: 0.5089393854141235\n",
      "epoch: 7, batch: 1462, loss: 0.4962805509567261\n",
      "epoch: 7, batch: 1463, loss: 0.5481648445129395\n",
      "epoch: 7, batch: 1464, loss: 0.4807637333869934\n",
      "epoch: 7, batch: 1465, loss: 0.33810538053512573\n",
      "epoch: 7, batch: 1466, loss: 0.5825780034065247\n",
      "epoch: 7, batch: 1467, loss: 0.312222957611084\n",
      "epoch: 7, batch: 1468, loss: 0.6114362478256226\n",
      "epoch: 7, batch: 1469, loss: 0.471772700548172\n",
      "epoch: 7, batch: 1470, loss: 0.586718738079071\n",
      "epoch: 7, batch: 1471, loss: 0.47778260707855225\n",
      "epoch: 7, batch: 1472, loss: 0.4880574941635132\n",
      "epoch: 7, batch: 1473, loss: 0.33736148476600647\n",
      "epoch: 7, batch: 1474, loss: 0.5725221037864685\n",
      "epoch: 7, batch: 1475, loss: 0.9260883927345276\n",
      "epoch: 7, batch: 1476, loss: 0.6499437689781189\n",
      "epoch: 7, batch: 1477, loss: 0.7049757242202759\n",
      "epoch: 7, batch: 1478, loss: 0.482952356338501\n",
      "epoch: 7, batch: 1479, loss: 0.4088238477706909\n",
      "epoch: 7, batch: 1480, loss: 0.7889214754104614\n",
      "epoch: 7, batch: 1481, loss: 0.4570917785167694\n",
      "epoch: 7, batch: 1482, loss: 0.24164557456970215\n",
      "epoch: 7, batch: 1483, loss: 0.3847612738609314\n",
      "epoch: 7, batch: 1484, loss: 0.5503830909729004\n",
      "epoch: 7, batch: 1485, loss: 0.501704216003418\n",
      "epoch: 7, batch: 1486, loss: 0.5428836345672607\n",
      "epoch: 7, batch: 1487, loss: 0.4477105736732483\n",
      "epoch: 7, batch: 1488, loss: 0.37726065516471863\n",
      "epoch: 7, batch: 1489, loss: 0.5163144469261169\n",
      "epoch: 7, batch: 1490, loss: 0.5726444125175476\n",
      "epoch: 7, batch: 1491, loss: 0.36537617444992065\n",
      "epoch: 7, batch: 1492, loss: 0.3548266589641571\n",
      "epoch: 7, batch: 1493, loss: 0.41365304589271545\n",
      "epoch: 7, batch: 1494, loss: 0.40188953280448914\n",
      "epoch: 7, batch: 1495, loss: 0.38917532563209534\n",
      "epoch: 7, batch: 1496, loss: 0.4354541599750519\n",
      "epoch: 7, batch: 1497, loss: 0.3880341053009033\n",
      "epoch: 7, batch: 1498, loss: 0.30425217747688293\n",
      "epoch: 7, batch: 1499, loss: 0.5041881799697876\n",
      "epoch: 7, batch: 1500, loss: 0.4865993559360504\n",
      "epoch: 7, batch: 1501, loss: 0.5454210042953491\n",
      "epoch: 7, batch: 1502, loss: 0.5891077518463135\n",
      "epoch: 7, batch: 1503, loss: 0.6769872903823853\n",
      "epoch: 7, batch: 1504, loss: 0.5179111957550049\n",
      "epoch: 7, batch: 1505, loss: 0.7031125426292419\n",
      "epoch: 7, batch: 1506, loss: 0.35105881094932556\n",
      "epoch: 7, batch: 1507, loss: 0.4577826261520386\n",
      "epoch: 7, batch: 1508, loss: 0.8343894481658936\n",
      "epoch: 7, batch: 1509, loss: 0.3884614408016205\n",
      "epoch: 7, batch: 1510, loss: 0.6196725964546204\n",
      "epoch: 7, batch: 1511, loss: 0.6833536624908447\n",
      "epoch: 7, batch: 1512, loss: 0.5543797016143799\n",
      "epoch: 7, batch: 1513, loss: 0.4354436695575714\n",
      "epoch: 7, batch: 1514, loss: 0.8120523691177368\n",
      "epoch: 7, batch: 1515, loss: 0.49345681071281433\n",
      "epoch: 7, batch: 1516, loss: 0.56919264793396\n",
      "epoch: 7, batch: 1517, loss: 0.33145231008529663\n",
      "epoch: 7, batch: 1518, loss: 0.6766167283058167\n",
      "epoch: 7, batch: 1519, loss: 0.4172641634941101\n",
      "epoch: 7, batch: 1520, loss: 0.6064841151237488\n",
      "epoch: 7, batch: 1521, loss: 0.3447767496109009\n",
      "epoch: 7, batch: 1522, loss: 0.37980517745018005\n",
      "epoch: 7, batch: 1523, loss: 0.5590397715568542\n",
      "epoch: 7, batch: 1524, loss: 0.5524337291717529\n",
      "epoch: 7, batch: 1525, loss: 0.5045823454856873\n",
      "epoch: 7, batch: 1526, loss: 0.48514026403427124\n",
      "epoch: 7, batch: 1527, loss: 0.493644118309021\n",
      "epoch: 7, batch: 1528, loss: 0.47106996178627014\n",
      "epoch: 7, batch: 1529, loss: 0.7834892272949219\n",
      "epoch: 7, batch: 1530, loss: 0.6728471517562866\n",
      "epoch: 7, batch: 1531, loss: 0.5658961534500122\n",
      "epoch: 7, batch: 1532, loss: 0.5269301533699036\n",
      "epoch: 7, batch: 1533, loss: 0.6786046028137207\n",
      "epoch: 7, batch: 1534, loss: 0.709669828414917\n",
      "epoch: 7, batch: 1535, loss: 0.6193822622299194\n",
      "epoch: 7, batch: 1536, loss: 0.6586236953735352\n",
      "epoch: 7, batch: 1537, loss: 0.9407482147216797\n",
      "epoch: 7, batch: 1538, loss: 0.6137227416038513\n",
      "epoch: 7, batch: 1539, loss: 0.27886292338371277\n",
      "epoch: 7, batch: 1540, loss: 0.5719823241233826\n",
      "epoch: 7, batch: 1541, loss: 0.49687445163726807\n",
      "epoch: 7, batch: 1542, loss: 0.6582165360450745\n",
      "epoch: 7, batch: 1543, loss: 0.5645926594734192\n",
      "epoch: 7, batch: 1544, loss: 0.6483684778213501\n",
      "epoch: 7, batch: 1545, loss: 0.49300694465637207\n",
      "epoch: 7, batch: 1546, loss: 0.4248809218406677\n",
      "epoch: 7, batch: 1547, loss: 0.6830191612243652\n",
      "epoch: 7, batch: 1548, loss: 0.7106513977050781\n",
      "epoch: 7, batch: 1549, loss: 0.3467447757720947\n",
      "epoch: 7, batch: 1550, loss: 0.6580943465232849\n",
      "epoch: 7, batch: 1551, loss: 0.7083424925804138\n",
      "epoch: 7, batch: 1552, loss: 0.33072108030319214\n",
      "epoch: 7, batch: 1553, loss: 0.5299772620201111\n",
      "epoch: 7, batch: 1554, loss: 0.519611656665802\n",
      "epoch: 7, batch: 1555, loss: 0.5827596783638\n",
      "epoch: 7, batch: 1556, loss: 0.45618507266044617\n",
      "epoch: 7, batch: 1557, loss: 0.6126002669334412\n",
      "epoch: 7, batch: 1558, loss: 0.341810941696167\n",
      "epoch: 7, batch: 1559, loss: 0.46558359265327454\n",
      "epoch: 7, batch: 1560, loss: 0.5890486836433411\n",
      "epoch: 7, batch: 1561, loss: 0.46778494119644165\n",
      "epoch: 7, batch: 1562, loss: 0.6375871300697327\n",
      "epoch: 7, batch: 1563, loss: 0.32267770171165466\n",
      "epoch: 7, batch: 1564, loss: 0.440235435962677\n",
      "epoch: 7, batch: 1565, loss: 0.6067250370979309\n",
      "epoch: 7, batch: 1566, loss: 0.2967865765094757\n",
      "epoch: 7, batch: 1567, loss: 0.36094579100608826\n",
      "epoch: 7, batch: 1568, loss: 0.3066943883895874\n",
      "epoch: 7, batch: 1569, loss: 0.6807371377944946\n",
      "epoch: 7, batch: 1570, loss: 0.4483185410499573\n",
      "epoch: 7, batch: 1571, loss: 0.6646673083305359\n",
      "epoch: 7, batch: 1572, loss: 0.37499576807022095\n",
      "epoch: 7, batch: 1573, loss: 0.5311200618743896\n",
      "epoch: 7, batch: 1574, loss: 0.5759981274604797\n",
      "epoch: 7, batch: 1575, loss: 0.4828583002090454\n",
      "epoch: 7, batch: 1576, loss: 0.49652644991874695\n",
      "epoch: 7, batch: 1577, loss: 0.36681362986564636\n",
      "epoch: 7, batch: 1578, loss: 0.7822452783584595\n",
      "epoch: 7, batch: 1579, loss: 0.5348759293556213\n",
      "epoch: 7, batch: 1580, loss: 0.6193504929542542\n",
      "epoch: 7, batch: 1581, loss: 0.5296682119369507\n",
      "epoch: 7, batch: 1582, loss: 0.43851137161254883\n",
      "epoch: 7, batch: 1583, loss: 0.5909756422042847\n",
      "epoch: 7, batch: 1584, loss: 0.31379324197769165\n",
      "epoch: 7, batch: 1585, loss: 0.20327728986740112\n",
      "epoch: 7, batch: 1586, loss: 0.37383130192756653\n",
      "epoch: 7, batch: 1587, loss: 0.7550156712532043\n",
      "epoch: 7, batch: 1588, loss: 0.3126102387905121\n",
      "epoch: 7, batch: 1589, loss: 0.4344933032989502\n",
      "epoch: 7, batch: 1590, loss: 0.7321020364761353\n",
      "epoch: 7, batch: 1591, loss: 0.4407377243041992\n",
      "epoch: 7, batch: 1592, loss: 0.3938697278499603\n",
      "epoch: 7, batch: 1593, loss: 0.5852741599082947\n",
      "epoch: 7, batch: 1594, loss: 0.5450230240821838\n",
      "epoch: 7, batch: 1595, loss: 0.29725730419158936\n",
      "epoch: 7, batch: 1596, loss: 0.3880316913127899\n",
      "epoch: 7, batch: 1597, loss: 0.531667172908783\n",
      "epoch: 7, batch: 1598, loss: 0.5057420134544373\n",
      "epoch: 7, batch: 1599, loss: 0.34791433811187744\n",
      "epoch: 7, batch: 1600, loss: 0.5182555913925171\n",
      "epoch: 7, batch: 1601, loss: 0.37642645835876465\n",
      "epoch: 7, batch: 1602, loss: 0.6196067929267883\n",
      "epoch: 7, batch: 1603, loss: 0.549933671951294\n",
      "epoch: 7, batch: 1604, loss: 0.5362885594367981\n",
      "epoch: 7, batch: 1605, loss: 0.5846557021141052\n",
      "epoch: 7, batch: 1606, loss: 0.3774244487285614\n",
      "epoch: 7, batch: 1607, loss: 0.46134161949157715\n",
      "epoch: 7, batch: 1608, loss: 0.4816119372844696\n",
      "epoch: 7, batch: 1609, loss: 0.7456830739974976\n",
      "epoch: 7, batch: 1610, loss: 0.5928436517715454\n",
      "epoch: 7, batch: 1611, loss: 0.32816174626350403\n",
      "epoch: 7, batch: 1612, loss: 0.4110144078731537\n",
      "epoch: 7, batch: 1613, loss: 0.3076619505882263\n",
      "epoch: 7, batch: 1614, loss: 0.5571850538253784\n",
      "epoch: 7, batch: 1615, loss: 0.564215898513794\n",
      "epoch: 7, batch: 1616, loss: 0.36141493916511536\n",
      "epoch: 7, batch: 1617, loss: 0.5539541244506836\n",
      "epoch: 7, batch: 1618, loss: 1.0079947710037231\n",
      "epoch: 7, batch: 1619, loss: 0.46484991908073425\n",
      "epoch: 7, batch: 1620, loss: 0.49995505809783936\n",
      "epoch: 7, batch: 1621, loss: 0.3389934003353119\n",
      "epoch: 7, batch: 1622, loss: 0.47132977843284607\n",
      "epoch: 7, batch: 1623, loss: 0.6240521669387817\n",
      "epoch: 7, batch: 1624, loss: 0.31013569235801697\n",
      "epoch: 7, batch: 1625, loss: 0.5082727074623108\n",
      "epoch: 7, batch: 1626, loss: 0.38666635751724243\n",
      "epoch: 7, batch: 1627, loss: 0.41830047965049744\n",
      "epoch: 7, batch: 1628, loss: 0.8524967432022095\n",
      "epoch: 7, batch: 1629, loss: 0.9440460801124573\n",
      "epoch: 7, batch: 1630, loss: 0.532476544380188\n",
      "epoch: 7, batch: 1631, loss: 0.5452696681022644\n",
      "epoch: 7, batch: 1632, loss: 0.6390143036842346\n",
      "epoch: 7, batch: 1633, loss: 0.5929884910583496\n",
      "epoch: 7, batch: 1634, loss: 0.4779815673828125\n",
      "epoch: 7, batch: 1635, loss: 0.5471943616867065\n",
      "epoch: 7, batch: 1636, loss: 0.5345942974090576\n",
      "epoch: 7, batch: 1637, loss: 0.4019617736339569\n",
      "epoch: 7, batch: 1638, loss: 0.48286184668540955\n",
      "epoch: 7, batch: 1639, loss: 0.513359010219574\n",
      "epoch: 7, batch: 1640, loss: 0.6780349612236023\n",
      "epoch: 7, batch: 1641, loss: 0.3272842466831207\n",
      "epoch: 7, batch: 1642, loss: 0.3538406193256378\n",
      "epoch: 7, batch: 1643, loss: 0.241449236869812\n",
      "epoch: 7, batch: 1644, loss: 0.6411887407302856\n",
      "epoch: 7, batch: 1645, loss: 0.4513241946697235\n",
      "epoch: 7, batch: 1646, loss: 0.5901155471801758\n",
      "epoch: 7, batch: 1647, loss: 0.47443023324012756\n",
      "epoch: 7, batch: 1648, loss: 0.35961294174194336\n",
      "epoch: 7, batch: 1649, loss: 0.44855329394340515\n",
      "epoch: 7, batch: 1650, loss: 0.4518894851207733\n",
      "epoch: 7, batch: 1651, loss: 0.2897253930568695\n",
      "epoch: 7, batch: 1652, loss: 0.5717319250106812\n",
      "epoch: 7, batch: 1653, loss: 0.627105176448822\n",
      "epoch: 7, batch: 1654, loss: 0.6744122505187988\n",
      "epoch: 7, batch: 1655, loss: 0.39221081137657166\n",
      "epoch: 7, batch: 1656, loss: 0.6409836411476135\n",
      "epoch: 7, batch: 1657, loss: 0.2913903594017029\n",
      "epoch: 7, batch: 1658, loss: 0.5567968487739563\n",
      "epoch: 7, batch: 1659, loss: 0.5595629811286926\n",
      "epoch: 7, batch: 1660, loss: 0.5543848276138306\n",
      "epoch: 7, batch: 1661, loss: 0.5407118797302246\n",
      "epoch: 7, batch: 1662, loss: 0.7446772456169128\n",
      "epoch: 7, batch: 1663, loss: 0.8281654119491577\n",
      "epoch: 7, batch: 1664, loss: 0.7151651978492737\n",
      "epoch: 7, batch: 1665, loss: 0.4196595549583435\n",
      "epoch: 7, batch: 1666, loss: 0.6526314616203308\n",
      "epoch: 7, batch: 1667, loss: 0.47793298959732056\n",
      "epoch: 7, batch: 1668, loss: 0.4659380614757538\n",
      "epoch: 7, batch: 1669, loss: 0.3881211280822754\n",
      "epoch: 7, batch: 1670, loss: 0.30915695428848267\n",
      "epoch: 7, batch: 1671, loss: 0.7672739028930664\n",
      "epoch: 7, batch: 1672, loss: 0.2927373945713043\n",
      "epoch: 7, batch: 1673, loss: 0.599190890789032\n",
      "epoch: 7, batch: 1674, loss: 0.39958885312080383\n",
      "epoch: 7, batch: 1675, loss: 0.3826596736907959\n",
      "epoch: 7, batch: 1676, loss: 0.544925332069397\n",
      "epoch: 7, batch: 1677, loss: 0.32094940543174744\n",
      "epoch: 7, batch: 1678, loss: 0.5163240432739258\n",
      "epoch: 7, batch: 1679, loss: 1.009476661682129\n",
      "epoch: 7, batch: 1680, loss: 0.6452552080154419\n",
      "epoch: 7, batch: 1681, loss: 0.6435847878456116\n",
      "epoch: 7, batch: 1682, loss: 0.596146285533905\n",
      "epoch: 7, batch: 1683, loss: 0.38373541831970215\n",
      "epoch: 7, batch: 1684, loss: 0.4584949314594269\n",
      "epoch: 7, batch: 1685, loss: 0.5649445652961731\n",
      "epoch: 7, batch: 1686, loss: 0.32495108246803284\n",
      "epoch: 7, batch: 1687, loss: 0.3488890826702118\n",
      "epoch: 7, batch: 1688, loss: 0.5302812457084656\n",
      "epoch: 7, batch: 1689, loss: 0.4868786633014679\n",
      "epoch: 7, batch: 1690, loss: 0.43565529584884644\n",
      "epoch: 7, batch: 1691, loss: 0.6805696487426758\n",
      "epoch: 7, batch: 1692, loss: 0.37575140595436096\n",
      "epoch: 7, batch: 1693, loss: 0.3198159635066986\n",
      "epoch: 7, batch: 1694, loss: 0.6697752475738525\n",
      "epoch: 7, batch: 1695, loss: 0.3444509506225586\n",
      "epoch: 7, batch: 1696, loss: 0.686937153339386\n",
      "epoch: 7, batch: 1697, loss: 0.4639238119125366\n",
      "epoch: 7, batch: 1698, loss: 0.5631290078163147\n",
      "epoch: 7, batch: 1699, loss: 0.4125945270061493\n",
      "epoch: 7, batch: 1700, loss: 0.5416663289070129\n",
      "epoch: 7, batch: 1701, loss: 0.4514034390449524\n",
      "epoch: 7, batch: 1702, loss: 0.4118179976940155\n",
      "epoch: 7, batch: 1703, loss: 0.5137129426002502\n",
      "epoch: 7, batch: 1704, loss: 0.5440294146537781\n",
      "epoch: 7, batch: 1705, loss: 0.5866740942001343\n",
      "epoch: 7, batch: 1706, loss: 0.49239179491996765\n",
      "epoch: 7, batch: 1707, loss: 0.4835304915904999\n",
      "epoch: 7, batch: 1708, loss: 0.42207252979278564\n",
      "epoch: 7, batch: 1709, loss: 0.4674637019634247\n",
      "epoch: 7, batch: 1710, loss: 0.4725022614002228\n",
      "epoch: 7, batch: 1711, loss: 0.5265801548957825\n",
      "epoch: 7, batch: 1712, loss: 0.592351496219635\n",
      "epoch: 7, batch: 1713, loss: 0.5245909094810486\n",
      "epoch: 7, batch: 1714, loss: 0.6172274947166443\n",
      "epoch: 7, batch: 1715, loss: 0.5619010329246521\n",
      "epoch: 7, batch: 1716, loss: 0.6183510422706604\n",
      "epoch: 7, batch: 1717, loss: 0.6571640968322754\n",
      "epoch: 7, batch: 1718, loss: 0.6239394545555115\n",
      "epoch: 7, batch: 1719, loss: 0.2918870151042938\n",
      "epoch: 7, batch: 1720, loss: 0.4636560082435608\n",
      "epoch: 7, batch: 1721, loss: 0.561160683631897\n",
      "epoch: 7, batch: 1722, loss: 0.5155519247055054\n",
      "epoch: 7, batch: 1723, loss: 0.5571486949920654\n",
      "epoch: 7, batch: 1724, loss: 0.564300000667572\n",
      "epoch: 7, batch: 1725, loss: 0.41890668869018555\n",
      "epoch: 7, batch: 1726, loss: 0.39815622568130493\n",
      "epoch: 7, batch: 1727, loss: 0.45354700088500977\n",
      "epoch: 7, batch: 1728, loss: 0.3390052318572998\n",
      "epoch: 7, batch: 1729, loss: 0.45308583974838257\n",
      "epoch: 7, batch: 1730, loss: 0.6024258732795715\n",
      "epoch: 7, batch: 1731, loss: 0.49017852544784546\n",
      "epoch: 7, batch: 1732, loss: 0.6959539651870728\n",
      "epoch: 7, batch: 1733, loss: 0.5464794635772705\n",
      "epoch: 7, batch: 1734, loss: 0.5373127460479736\n",
      "epoch: 7, batch: 1735, loss: 0.581908643245697\n",
      "epoch: 7, batch: 1736, loss: 0.702072024345398\n",
      "epoch: 7, batch: 1737, loss: 0.49574777483940125\n",
      "epoch: 7, batch: 1738, loss: 0.38460251688957214\n",
      "epoch: 7, batch: 1739, loss: 0.6545354723930359\n",
      "epoch: 7, batch: 1740, loss: 0.4553402364253998\n",
      "epoch: 7, batch: 1741, loss: 0.5103569030761719\n",
      "epoch: 7, batch: 1742, loss: 0.5157992839813232\n",
      "epoch: 7, batch: 1743, loss: 0.5477206707000732\n",
      "epoch: 7, batch: 1744, loss: 0.5781698822975159\n",
      "epoch: 7, batch: 1745, loss: 0.5877809524536133\n",
      "epoch: 7, batch: 1746, loss: 0.5081556439399719\n",
      "epoch: 7, batch: 1747, loss: 0.4669092297554016\n",
      "epoch: 7, batch: 1748, loss: 0.40618079900741577\n",
      "epoch: 7, batch: 1749, loss: 0.9377703666687012\n",
      "epoch: 7, batch: 1750, loss: 0.5595248341560364\n",
      "epoch: 7, batch: 1751, loss: 0.43018028140068054\n",
      "epoch: 7, batch: 1752, loss: 0.4733926057815552\n",
      "epoch: 7, batch: 1753, loss: 0.7894582152366638\n",
      "epoch: 7, batch: 1754, loss: 0.367708295583725\n",
      "epoch: 7, batch: 1755, loss: 0.6978381276130676\n",
      "epoch: 7, batch: 1756, loss: 0.576676070690155\n",
      "epoch: 7, batch: 1757, loss: 0.7261934876441956\n",
      "epoch: 7, batch: 1758, loss: 0.5414965152740479\n",
      "epoch: 7, batch: 1759, loss: 0.5161114931106567\n",
      "epoch: 7, batch: 1760, loss: 0.7766882181167603\n",
      "epoch: 7, batch: 1761, loss: 0.5640239715576172\n",
      "epoch: 7, batch: 1762, loss: 0.6199511289596558\n",
      "epoch: 7, batch: 1763, loss: 0.29314330220222473\n",
      "epoch: 7, batch: 1764, loss: 0.5408341884613037\n",
      "epoch: 7, batch: 1765, loss: 0.40183860063552856\n",
      "epoch: 7, batch: 1766, loss: 0.6936553120613098\n",
      "epoch: 7, batch: 1767, loss: 0.6645757555961609\n",
      "epoch: 7, batch: 1768, loss: 1.0153906345367432\n",
      "epoch: 7, batch: 1769, loss: 0.4041809141635895\n",
      "epoch: 7, batch: 1770, loss: 0.43686455488204956\n",
      "epoch: 7, batch: 1771, loss: 0.5503568053245544\n",
      "epoch: 7, batch: 1772, loss: 0.4931538701057434\n",
      "epoch: 7, batch: 1773, loss: 0.34762656688690186\n",
      "epoch: 7, batch: 1774, loss: 0.7196158170700073\n",
      "epoch: 7, batch: 1775, loss: 0.43211716413497925\n",
      "epoch: 7, batch: 1776, loss: 0.4007243812084198\n",
      "epoch: 7, batch: 1777, loss: 0.5121157765388489\n",
      "epoch: 7, batch: 1778, loss: 0.7791574597358704\n",
      "epoch: 7, batch: 1779, loss: 0.44143179059028625\n",
      "epoch: 7, batch: 1780, loss: 0.6670308113098145\n",
      "epoch: 7, batch: 1781, loss: 0.6377508044242859\n",
      "epoch: 7, batch: 1782, loss: 0.6042360067367554\n",
      "epoch: 7, batch: 1783, loss: 0.4474368691444397\n",
      "epoch: 7, batch: 1784, loss: 0.4330655038356781\n",
      "epoch: 7, batch: 1785, loss: 0.49639374017715454\n",
      "epoch: 7, batch: 1786, loss: 0.6291653513908386\n",
      "epoch: 7, batch: 1787, loss: 0.33247891068458557\n",
      "epoch: 7, batch: 1788, loss: 0.2576879858970642\n",
      "epoch: 7, batch: 1789, loss: 0.5590497255325317\n",
      "epoch: 7, batch: 1790, loss: 0.3591013252735138\n",
      "epoch: 7, batch: 1791, loss: 0.37614020705223083\n",
      "epoch: 7, batch: 1792, loss: 0.5118439197540283\n",
      "epoch: 7, batch: 1793, loss: 0.5134385228157043\n",
      "epoch: 7, batch: 1794, loss: 0.6228190064430237\n",
      "epoch: 7, batch: 1795, loss: 0.4861936569213867\n",
      "epoch: 7, batch: 1796, loss: 0.767505943775177\n",
      "epoch: 7, batch: 1797, loss: 0.6662115454673767\n",
      "epoch: 7, batch: 1798, loss: 0.5041898488998413\n",
      "epoch: 7, batch: 1799, loss: 0.44162672758102417\n",
      "epoch: 7, batch: 1800, loss: 0.5014306306838989\n",
      "epoch: 7, batch: 1801, loss: 0.5826669931411743\n",
      "epoch: 7, batch: 1802, loss: 0.5977931618690491\n",
      "epoch: 7, batch: 1803, loss: 0.4728435277938843\n",
      "epoch: 7, batch: 1804, loss: 0.6523824334144592\n",
      "epoch: 7, batch: 1805, loss: 0.23276439309120178\n",
      "epoch: 7, batch: 1806, loss: 0.5031053423881531\n",
      "epoch: 7, batch: 1807, loss: 0.4540807604789734\n",
      "epoch: 7, batch: 1808, loss: 0.5359805226325989\n",
      "epoch: 7, batch: 1809, loss: 0.4220026433467865\n",
      "epoch: 7, batch: 1810, loss: 0.45210492610931396\n",
      "epoch: 7, batch: 1811, loss: 0.5441856980323792\n",
      "epoch: 7, batch: 1812, loss: 0.28694140911102295\n",
      "epoch: 7, batch: 1813, loss: 0.5192528963088989\n",
      "epoch: 7, batch: 1814, loss: 0.5911059379577637\n",
      "epoch: 7, batch: 1815, loss: 0.6510105133056641\n",
      "epoch: 7, batch: 1816, loss: 0.5039587616920471\n",
      "epoch: 7, batch: 1817, loss: 0.5660353899002075\n",
      "epoch: 7, batch: 1818, loss: 0.8044095039367676\n",
      "epoch: 7, batch: 1819, loss: 0.509715735912323\n",
      "epoch: 7, batch: 1820, loss: 0.42599526047706604\n",
      "epoch: 7, batch: 1821, loss: 0.615067720413208\n",
      "epoch: 7, batch: 1822, loss: 0.7326542139053345\n",
      "epoch: 7, batch: 1823, loss: 0.5055598020553589\n",
      "epoch: 7, batch: 1824, loss: 0.5153122544288635\n",
      "epoch: 7, batch: 1825, loss: 0.43310102820396423\n",
      "epoch: 7, batch: 1826, loss: 0.607839822769165\n",
      "epoch: 7, batch: 1827, loss: 0.5245950222015381\n",
      "epoch: 7, batch: 1828, loss: 0.38765063881874084\n",
      "epoch: 7, batch: 1829, loss: 0.5931971073150635\n",
      "epoch: 7, batch: 1830, loss: 0.41247865557670593\n",
      "epoch: 7, batch: 1831, loss: 0.45348915457725525\n",
      "epoch: 7, batch: 1832, loss: 0.26953479647636414\n",
      "epoch: 7, batch: 1833, loss: 0.3177044987678528\n",
      "epoch: 7, batch: 1834, loss: 0.4642479717731476\n",
      "epoch: 7, batch: 1835, loss: 0.4401816725730896\n",
      "epoch: 7, batch: 1836, loss: 0.5684926509857178\n",
      "epoch: 7, batch: 1837, loss: 0.38558429479599\n",
      "epoch: 7, batch: 1838, loss: 0.5377448201179504\n",
      "epoch: 7, batch: 1839, loss: 0.5067467093467712\n",
      "epoch: 7, batch: 1840, loss: 0.541394054889679\n",
      "epoch: 7, batch: 1841, loss: 0.26886627078056335\n",
      "epoch: 7, batch: 1842, loss: 0.4576021134853363\n",
      "epoch: 7, batch: 1843, loss: 0.42589157819747925\n",
      "epoch: 7, batch: 1844, loss: 0.3740605115890503\n",
      "epoch: 7, batch: 1845, loss: 0.4862746596336365\n",
      "epoch: 7, batch: 1846, loss: 0.4378824830055237\n",
      "epoch: 7, batch: 1847, loss: 0.42826518416404724\n",
      "epoch: 7, batch: 1848, loss: 0.44777798652648926\n",
      "epoch: 7, batch: 1849, loss: 0.33405593037605286\n",
      "epoch: 7, batch: 1850, loss: 0.44439664483070374\n",
      "epoch: 7, batch: 1851, loss: 0.6370100378990173\n",
      "epoch: 7, batch: 1852, loss: 0.3751481771469116\n",
      "epoch: 7, batch: 1853, loss: 0.3915764093399048\n",
      "epoch: 7, batch: 1854, loss: 0.4209722876548767\n",
      "epoch: 7, batch: 1855, loss: 0.4414478838443756\n",
      "epoch: 7, batch: 1856, loss: 0.419400691986084\n",
      "epoch: 7, batch: 1857, loss: 0.617372453212738\n",
      "epoch: 7, batch: 1858, loss: 0.45750051736831665\n",
      "epoch: 7, batch: 1859, loss: 0.5946547389030457\n",
      "epoch: 7, batch: 1860, loss: 0.41090354323387146\n",
      "epoch: 7, batch: 1861, loss: 0.6831486821174622\n",
      "epoch: 7, batch: 1862, loss: 0.4341212511062622\n",
      "epoch: 7, batch: 1863, loss: 0.6777040958404541\n",
      "epoch: 7, batch: 1864, loss: 0.48948702216148376\n",
      "epoch: 7, batch: 1865, loss: 0.2742057144641876\n",
      "epoch: 7, batch: 1866, loss: 0.4115033745765686\n",
      "epoch: 7, batch: 1867, loss: 0.647890567779541\n",
      "epoch: 7, batch: 1868, loss: 0.7461590766906738\n",
      "epoch: 7, batch: 1869, loss: 0.5364094376564026\n",
      "epoch: 7, batch: 1870, loss: 0.6034013032913208\n",
      "epoch: 7, batch: 1871, loss: 0.7150962352752686\n",
      "epoch: 7, batch: 1872, loss: 0.6442525386810303\n",
      "epoch: 7, batch: 1873, loss: 0.4637121856212616\n",
      "epoch: 7, batch: 1874, loss: 0.4379214644432068\n",
      "epoch: 8, batch: 0, loss: 0.5913898348808289\n",
      "epoch: 8, batch: 1, loss: 0.3778461813926697\n",
      "epoch: 8, batch: 2, loss: 0.4521021544933319\n",
      "epoch: 8, batch: 3, loss: 0.4427095949649811\n",
      "epoch: 8, batch: 4, loss: 0.5324694514274597\n",
      "epoch: 8, batch: 5, loss: 0.3262873888015747\n",
      "epoch: 8, batch: 6, loss: 0.24488575756549835\n",
      "epoch: 8, batch: 7, loss: 0.8351138830184937\n",
      "epoch: 8, batch: 8, loss: 0.5487723350524902\n",
      "epoch: 8, batch: 9, loss: 0.6431227922439575\n",
      "epoch: 8, batch: 10, loss: 0.4495706856250763\n",
      "epoch: 8, batch: 11, loss: 0.7944198250770569\n",
      "epoch: 8, batch: 12, loss: 0.6263168454170227\n",
      "epoch: 8, batch: 13, loss: 0.4204239547252655\n",
      "epoch: 8, batch: 14, loss: 0.5055555701255798\n",
      "epoch: 8, batch: 15, loss: 0.5747635364532471\n",
      "epoch: 8, batch: 16, loss: 0.4697204530239105\n",
      "epoch: 8, batch: 17, loss: 0.5360717177391052\n",
      "epoch: 8, batch: 18, loss: 0.4260469377040863\n",
      "epoch: 8, batch: 19, loss: 0.6552988290786743\n",
      "epoch: 8, batch: 20, loss: 0.5348184704780579\n",
      "epoch: 8, batch: 21, loss: 0.7648460865020752\n",
      "epoch: 8, batch: 22, loss: 0.40949851274490356\n",
      "epoch: 8, batch: 23, loss: 0.550978422164917\n",
      "epoch: 8, batch: 24, loss: 0.558114767074585\n",
      "epoch: 8, batch: 25, loss: 0.4544171392917633\n",
      "epoch: 8, batch: 26, loss: 0.36074721813201904\n",
      "epoch: 8, batch: 27, loss: 0.7193114757537842\n",
      "epoch: 8, batch: 28, loss: 0.45151498913764954\n",
      "epoch: 8, batch: 29, loss: 0.2695433795452118\n",
      "epoch: 8, batch: 30, loss: 0.5461129546165466\n",
      "epoch: 8, batch: 31, loss: 0.5679022669792175\n",
      "epoch: 8, batch: 32, loss: 0.6358591914176941\n",
      "epoch: 8, batch: 33, loss: 0.5362528562545776\n",
      "epoch: 8, batch: 34, loss: 0.3004297614097595\n",
      "epoch: 8, batch: 35, loss: 0.8910796642303467\n",
      "epoch: 8, batch: 36, loss: 0.9206794500350952\n",
      "epoch: 8, batch: 37, loss: 0.6907144784927368\n",
      "epoch: 8, batch: 38, loss: 0.5176613926887512\n",
      "epoch: 8, batch: 39, loss: 0.44052305817604065\n",
      "epoch: 8, batch: 40, loss: 0.48826485872268677\n",
      "epoch: 8, batch: 41, loss: 0.3517594039440155\n",
      "epoch: 8, batch: 42, loss: 0.3885343372821808\n",
      "epoch: 8, batch: 43, loss: 0.5451515316963196\n",
      "epoch: 8, batch: 44, loss: 0.6489628553390503\n",
      "epoch: 8, batch: 45, loss: 0.41805335879325867\n",
      "epoch: 8, batch: 46, loss: 0.4707193970680237\n",
      "epoch: 8, batch: 47, loss: 0.5323630571365356\n",
      "epoch: 8, batch: 48, loss: 0.716647744178772\n",
      "epoch: 8, batch: 49, loss: 0.537776529788971\n",
      "epoch: 8, batch: 50, loss: 0.6072301268577576\n",
      "epoch: 8, batch: 51, loss: 0.4914107918739319\n",
      "epoch: 8, batch: 52, loss: 0.507264256477356\n",
      "epoch: 8, batch: 53, loss: 0.6371439695358276\n",
      "epoch: 8, batch: 54, loss: 0.6488443613052368\n",
      "epoch: 8, batch: 55, loss: 0.6775320172309875\n",
      "epoch: 8, batch: 56, loss: 0.3851403295993805\n",
      "epoch: 8, batch: 57, loss: 0.7278726100921631\n",
      "epoch: 8, batch: 58, loss: 0.5080708861351013\n",
      "epoch: 8, batch: 59, loss: 0.6045850515365601\n",
      "epoch: 8, batch: 60, loss: 0.6066955327987671\n",
      "epoch: 8, batch: 61, loss: 0.5480086803436279\n",
      "epoch: 8, batch: 62, loss: 0.3985787332057953\n",
      "epoch: 8, batch: 63, loss: 0.49831491708755493\n",
      "epoch: 8, batch: 64, loss: 0.5116965770721436\n",
      "epoch: 8, batch: 65, loss: 0.36025217175483704\n",
      "epoch: 8, batch: 66, loss: 0.44659894704818726\n",
      "epoch: 8, batch: 67, loss: 0.5289692878723145\n",
      "epoch: 8, batch: 68, loss: 0.6485739946365356\n",
      "epoch: 8, batch: 69, loss: 0.5404201149940491\n",
      "epoch: 8, batch: 70, loss: 0.32213065028190613\n",
      "epoch: 8, batch: 71, loss: 0.6697431802749634\n",
      "epoch: 8, batch: 72, loss: 0.4037477672100067\n",
      "epoch: 8, batch: 73, loss: 0.398041307926178\n",
      "epoch: 8, batch: 74, loss: 0.7727677822113037\n",
      "epoch: 8, batch: 75, loss: 0.4659581184387207\n",
      "epoch: 8, batch: 76, loss: 0.5524460077285767\n",
      "epoch: 8, batch: 77, loss: 0.41118621826171875\n",
      "epoch: 8, batch: 78, loss: 0.5830750465393066\n",
      "epoch: 8, batch: 79, loss: 0.5790806412696838\n",
      "epoch: 8, batch: 80, loss: 0.5964686274528503\n",
      "epoch: 8, batch: 81, loss: 0.38161125779151917\n",
      "epoch: 8, batch: 82, loss: 0.4857454299926758\n",
      "epoch: 8, batch: 83, loss: 0.40684202313423157\n",
      "epoch: 8, batch: 84, loss: 0.6442235112190247\n",
      "epoch: 8, batch: 85, loss: 0.6183138489723206\n",
      "epoch: 8, batch: 86, loss: 0.7973884344100952\n",
      "epoch: 8, batch: 87, loss: 0.4555133581161499\n",
      "epoch: 8, batch: 88, loss: 0.7684065699577332\n",
      "epoch: 8, batch: 89, loss: 0.40681135654449463\n",
      "epoch: 8, batch: 90, loss: 0.41105547547340393\n",
      "epoch: 8, batch: 91, loss: 0.6124290823936462\n",
      "epoch: 8, batch: 92, loss: 0.3350711464881897\n",
      "epoch: 8, batch: 93, loss: 0.4044249951839447\n",
      "epoch: 8, batch: 94, loss: 0.8280507922172546\n",
      "epoch: 8, batch: 95, loss: 0.6377860903739929\n",
      "epoch: 8, batch: 96, loss: 0.4110107719898224\n",
      "epoch: 8, batch: 97, loss: 0.44806602597236633\n",
      "epoch: 8, batch: 98, loss: 0.33238157629966736\n",
      "epoch: 8, batch: 99, loss: 0.4640507698059082\n",
      "epoch: 8, batch: 100, loss: 0.44469836354255676\n",
      "epoch: 8, batch: 101, loss: 0.34121519327163696\n",
      "epoch: 8, batch: 102, loss: 0.4237617552280426\n",
      "epoch: 8, batch: 103, loss: 0.3653586804866791\n",
      "epoch: 8, batch: 104, loss: 0.3393797278404236\n",
      "epoch: 8, batch: 105, loss: 0.6074441075325012\n",
      "epoch: 8, batch: 106, loss: 0.5023456811904907\n",
      "epoch: 8, batch: 107, loss: 0.6806458234786987\n",
      "epoch: 8, batch: 108, loss: 0.6921945214271545\n",
      "epoch: 8, batch: 109, loss: 0.6220430731773376\n",
      "epoch: 8, batch: 110, loss: 0.43845227360725403\n",
      "epoch: 8, batch: 111, loss: 0.5922499895095825\n",
      "epoch: 8, batch: 112, loss: 0.4979833960533142\n",
      "epoch: 8, batch: 113, loss: 0.4349762201309204\n",
      "epoch: 8, batch: 114, loss: 0.3182432949542999\n",
      "epoch: 8, batch: 115, loss: 0.3826327621936798\n",
      "epoch: 8, batch: 116, loss: 0.46010494232177734\n",
      "epoch: 8, batch: 117, loss: 0.27027392387390137\n",
      "epoch: 8, batch: 118, loss: 0.4886060655117035\n",
      "epoch: 8, batch: 119, loss: 0.5921814441680908\n",
      "epoch: 8, batch: 120, loss: 0.7345502376556396\n",
      "epoch: 8, batch: 121, loss: 0.32921040058135986\n",
      "epoch: 8, batch: 122, loss: 0.5380992889404297\n",
      "epoch: 8, batch: 123, loss: 0.47841566801071167\n",
      "epoch: 8, batch: 124, loss: 0.46583136916160583\n",
      "epoch: 8, batch: 125, loss: 0.3687630891799927\n",
      "epoch: 8, batch: 126, loss: 0.4999590516090393\n",
      "epoch: 8, batch: 127, loss: 0.48281407356262207\n",
      "epoch: 8, batch: 128, loss: 0.3462705910205841\n",
      "epoch: 8, batch: 129, loss: 0.44966450333595276\n",
      "epoch: 8, batch: 130, loss: 0.5135422348976135\n",
      "epoch: 8, batch: 131, loss: 0.6564066410064697\n",
      "epoch: 8, batch: 132, loss: 0.5039160847663879\n",
      "epoch: 8, batch: 133, loss: 0.5331131815910339\n",
      "epoch: 8, batch: 134, loss: 0.5995657444000244\n",
      "epoch: 8, batch: 135, loss: 0.8362531065940857\n",
      "epoch: 8, batch: 136, loss: 0.31584593653678894\n",
      "epoch: 8, batch: 137, loss: 0.4979618191719055\n",
      "epoch: 8, batch: 138, loss: 0.5948423147201538\n",
      "epoch: 8, batch: 139, loss: 0.44419756531715393\n",
      "epoch: 8, batch: 140, loss: 0.4431075155735016\n",
      "epoch: 8, batch: 141, loss: 0.6069930195808411\n",
      "epoch: 8, batch: 142, loss: 0.2189275175333023\n",
      "epoch: 8, batch: 143, loss: 0.4923470616340637\n",
      "epoch: 8, batch: 144, loss: 0.5385960936546326\n",
      "epoch: 8, batch: 145, loss: 0.5701019167900085\n",
      "epoch: 8, batch: 146, loss: 0.3980685770511627\n",
      "epoch: 8, batch: 147, loss: 0.6760866641998291\n",
      "epoch: 8, batch: 148, loss: 0.4546070396900177\n",
      "epoch: 8, batch: 149, loss: 0.3440357744693756\n",
      "epoch: 8, batch: 150, loss: 0.4977664649486542\n",
      "epoch: 8, batch: 151, loss: 0.3965778052806854\n",
      "epoch: 8, batch: 152, loss: 0.6167833209037781\n",
      "epoch: 8, batch: 153, loss: 0.43363308906555176\n",
      "epoch: 8, batch: 154, loss: 0.4760887026786804\n",
      "epoch: 8, batch: 155, loss: 0.6529038548469543\n",
      "epoch: 8, batch: 156, loss: 0.4873693287372589\n",
      "epoch: 8, batch: 157, loss: 0.4294627010822296\n",
      "epoch: 8, batch: 158, loss: 0.6614288091659546\n",
      "epoch: 8, batch: 159, loss: 0.3848843276500702\n",
      "epoch: 8, batch: 160, loss: 0.6100560426712036\n",
      "epoch: 8, batch: 161, loss: 0.6130362153053284\n",
      "epoch: 8, batch: 162, loss: 0.40102419257164\n",
      "epoch: 8, batch: 163, loss: 0.4739738404750824\n",
      "epoch: 8, batch: 164, loss: 0.45945537090301514\n",
      "epoch: 8, batch: 165, loss: 0.3040100038051605\n",
      "epoch: 8, batch: 166, loss: 0.37283995747566223\n",
      "epoch: 8, batch: 167, loss: 0.40212422609329224\n",
      "epoch: 8, batch: 168, loss: 0.6634812355041504\n",
      "epoch: 8, batch: 169, loss: 0.41733306646347046\n",
      "epoch: 8, batch: 170, loss: 0.47799763083457947\n",
      "epoch: 8, batch: 171, loss: 0.5608105063438416\n",
      "epoch: 8, batch: 172, loss: 0.3317473232746124\n",
      "epoch: 8, batch: 173, loss: 0.5546978712081909\n",
      "epoch: 8, batch: 174, loss: 0.5615251660346985\n",
      "epoch: 8, batch: 175, loss: 0.3976568877696991\n",
      "epoch: 8, batch: 176, loss: 0.3860432505607605\n",
      "epoch: 8, batch: 177, loss: 0.44375815987586975\n",
      "epoch: 8, batch: 178, loss: 0.68865567445755\n",
      "epoch: 8, batch: 179, loss: 0.3827577233314514\n",
      "epoch: 8, batch: 180, loss: 0.5176097750663757\n",
      "epoch: 8, batch: 181, loss: 0.630841851234436\n",
      "epoch: 8, batch: 182, loss: 0.3268413543701172\n",
      "epoch: 8, batch: 183, loss: 0.41747310757637024\n",
      "epoch: 8, batch: 184, loss: 0.5390341281890869\n",
      "epoch: 8, batch: 185, loss: 0.4298818111419678\n",
      "epoch: 8, batch: 186, loss: 0.49995532631874084\n",
      "epoch: 8, batch: 187, loss: 0.44094473123550415\n",
      "epoch: 8, batch: 188, loss: 0.5809071660041809\n",
      "epoch: 8, batch: 189, loss: 0.6527156829833984\n",
      "epoch: 8, batch: 190, loss: 0.5012014508247375\n",
      "epoch: 8, batch: 191, loss: 0.5267459750175476\n",
      "epoch: 8, batch: 192, loss: 0.5305300354957581\n",
      "epoch: 8, batch: 193, loss: 0.5665135383605957\n",
      "epoch: 8, batch: 194, loss: 0.549977719783783\n",
      "epoch: 8, batch: 195, loss: 0.8065720796585083\n",
      "epoch: 8, batch: 196, loss: 0.36340880393981934\n",
      "epoch: 8, batch: 197, loss: 0.43030601739883423\n",
      "epoch: 8, batch: 198, loss: 0.39548251032829285\n",
      "epoch: 8, batch: 199, loss: 0.4097098112106323\n",
      "epoch: 8, batch: 200, loss: 0.5441421270370483\n",
      "epoch: 8, batch: 201, loss: 0.419699490070343\n",
      "epoch: 8, batch: 202, loss: 0.45555612444877625\n",
      "epoch: 8, batch: 203, loss: 0.6601833701133728\n",
      "epoch: 8, batch: 204, loss: 0.47885119915008545\n",
      "epoch: 8, batch: 205, loss: 0.5728641152381897\n",
      "epoch: 8, batch: 206, loss: 0.5595822334289551\n",
      "epoch: 8, batch: 207, loss: 0.3562869727611542\n",
      "epoch: 8, batch: 208, loss: 0.38157743215560913\n",
      "epoch: 8, batch: 209, loss: 0.5542851686477661\n",
      "epoch: 8, batch: 210, loss: 0.39674657583236694\n",
      "epoch: 8, batch: 211, loss: 0.9049063920974731\n",
      "epoch: 8, batch: 212, loss: 0.5870966911315918\n",
      "epoch: 8, batch: 213, loss: 0.8208947777748108\n",
      "epoch: 8, batch: 214, loss: 0.3419758081436157\n",
      "epoch: 8, batch: 215, loss: 0.6775982975959778\n",
      "epoch: 8, batch: 216, loss: 0.43002262711524963\n",
      "epoch: 8, batch: 217, loss: 0.6024010181427002\n",
      "epoch: 8, batch: 218, loss: 0.5553497076034546\n",
      "epoch: 8, batch: 219, loss: 0.4493281841278076\n",
      "epoch: 8, batch: 220, loss: 0.5185868144035339\n",
      "epoch: 8, batch: 221, loss: 0.4461447596549988\n",
      "epoch: 8, batch: 222, loss: 0.6036222577095032\n",
      "epoch: 8, batch: 223, loss: 0.5386983752250671\n",
      "epoch: 8, batch: 224, loss: 0.4267924427986145\n",
      "epoch: 8, batch: 225, loss: 0.5406814217567444\n",
      "epoch: 8, batch: 226, loss: 0.3939701318740845\n",
      "epoch: 8, batch: 227, loss: 0.3563300669193268\n",
      "epoch: 8, batch: 228, loss: 0.6000046730041504\n",
      "epoch: 8, batch: 229, loss: 0.48637518286705017\n",
      "epoch: 8, batch: 230, loss: 0.20950224995613098\n",
      "epoch: 8, batch: 231, loss: 0.4624829888343811\n",
      "epoch: 8, batch: 232, loss: 0.3749281167984009\n",
      "epoch: 8, batch: 233, loss: 0.7233321666717529\n",
      "epoch: 8, batch: 234, loss: 0.35710299015045166\n",
      "epoch: 8, batch: 235, loss: 0.5255500078201294\n",
      "epoch: 8, batch: 236, loss: 0.40900328755378723\n",
      "epoch: 8, batch: 237, loss: 0.2933359146118164\n",
      "epoch: 8, batch: 238, loss: 0.5934356451034546\n",
      "epoch: 8, batch: 239, loss: 0.39739498496055603\n",
      "epoch: 8, batch: 240, loss: 0.7753677368164062\n",
      "epoch: 8, batch: 241, loss: 0.6348248720169067\n",
      "epoch: 8, batch: 242, loss: 0.521293580532074\n",
      "epoch: 8, batch: 243, loss: 0.42262229323387146\n",
      "epoch: 8, batch: 244, loss: 0.5201069712638855\n",
      "epoch: 8, batch: 245, loss: 0.497362345457077\n",
      "epoch: 8, batch: 246, loss: 0.46409741044044495\n",
      "epoch: 8, batch: 247, loss: 0.610676646232605\n",
      "epoch: 8, batch: 248, loss: 0.6889064908027649\n",
      "epoch: 8, batch: 249, loss: 0.5562416911125183\n",
      "epoch: 8, batch: 250, loss: 0.5614438652992249\n",
      "epoch: 8, batch: 251, loss: 0.39486998319625854\n",
      "epoch: 8, batch: 252, loss: 0.6827104687690735\n",
      "epoch: 8, batch: 253, loss: 0.47313857078552246\n",
      "epoch: 8, batch: 254, loss: 0.3812110126018524\n",
      "epoch: 8, batch: 255, loss: 0.506118655204773\n",
      "epoch: 8, batch: 256, loss: 0.5242430567741394\n",
      "epoch: 8, batch: 257, loss: 0.3804079294204712\n",
      "epoch: 8, batch: 258, loss: 0.3989947438240051\n",
      "epoch: 8, batch: 259, loss: 0.47249898314476013\n",
      "epoch: 8, batch: 260, loss: 0.5383712649345398\n",
      "epoch: 8, batch: 261, loss: 0.3425377309322357\n",
      "epoch: 8, batch: 262, loss: 0.6000306606292725\n",
      "epoch: 8, batch: 263, loss: 0.39387261867523193\n",
      "epoch: 8, batch: 264, loss: 0.6023441553115845\n",
      "epoch: 8, batch: 265, loss: 0.49101439118385315\n",
      "epoch: 8, batch: 266, loss: 1.1453406810760498\n",
      "epoch: 8, batch: 267, loss: 0.46356746554374695\n",
      "epoch: 8, batch: 268, loss: 0.581439733505249\n",
      "epoch: 8, batch: 269, loss: 0.35378068685531616\n",
      "epoch: 8, batch: 270, loss: 0.419817715883255\n",
      "epoch: 8, batch: 271, loss: 0.47165897488594055\n",
      "epoch: 8, batch: 272, loss: 0.3866644501686096\n",
      "epoch: 8, batch: 273, loss: 0.35246026515960693\n",
      "epoch: 8, batch: 274, loss: 0.4398106336593628\n",
      "epoch: 8, batch: 275, loss: 0.5117828845977783\n",
      "epoch: 8, batch: 276, loss: 0.4356630742549896\n",
      "epoch: 8, batch: 277, loss: 0.4533435106277466\n",
      "epoch: 8, batch: 278, loss: 0.2923438549041748\n",
      "epoch: 8, batch: 279, loss: 0.7454279661178589\n",
      "epoch: 8, batch: 280, loss: 0.3945353031158447\n",
      "epoch: 8, batch: 281, loss: 0.37345537543296814\n",
      "epoch: 8, batch: 282, loss: 0.5584125518798828\n",
      "epoch: 8, batch: 283, loss: 0.5873841643333435\n",
      "epoch: 8, batch: 284, loss: 0.5819505453109741\n",
      "epoch: 8, batch: 285, loss: 0.451282799243927\n",
      "epoch: 8, batch: 286, loss: 0.5100165009498596\n",
      "epoch: 8, batch: 287, loss: 0.6419779658317566\n",
      "epoch: 8, batch: 288, loss: 0.4327158033847809\n",
      "epoch: 8, batch: 289, loss: 0.39573022723197937\n",
      "epoch: 8, batch: 290, loss: 0.4084373116493225\n",
      "epoch: 8, batch: 291, loss: 0.4101237952709198\n",
      "epoch: 8, batch: 292, loss: 0.6233980655670166\n",
      "epoch: 8, batch: 293, loss: 0.383796364068985\n",
      "epoch: 8, batch: 294, loss: 0.5311004519462585\n",
      "epoch: 8, batch: 295, loss: 0.4493713676929474\n",
      "epoch: 8, batch: 296, loss: 0.41507264971733093\n",
      "epoch: 8, batch: 297, loss: 0.49111267924308777\n",
      "epoch: 8, batch: 298, loss: 0.37825334072113037\n",
      "epoch: 8, batch: 299, loss: 0.34747958183288574\n",
      "epoch: 8, batch: 300, loss: 0.575833797454834\n",
      "epoch: 8, batch: 301, loss: 0.398131400346756\n",
      "epoch: 8, batch: 302, loss: 0.29455357789993286\n",
      "epoch: 8, batch: 303, loss: 0.716481626033783\n",
      "epoch: 8, batch: 304, loss: 0.4571869373321533\n",
      "epoch: 8, batch: 305, loss: 0.5026899576187134\n",
      "epoch: 8, batch: 306, loss: 0.5139347314834595\n",
      "epoch: 8, batch: 307, loss: 0.4104136824607849\n",
      "epoch: 8, batch: 308, loss: 0.5233373641967773\n",
      "epoch: 8, batch: 309, loss: 0.4896604120731354\n",
      "epoch: 8, batch: 310, loss: 0.44540637731552124\n",
      "epoch: 8, batch: 311, loss: 0.29607871174812317\n",
      "epoch: 8, batch: 312, loss: 0.5396593809127808\n",
      "epoch: 8, batch: 313, loss: 0.5071618556976318\n",
      "epoch: 8, batch: 314, loss: 0.5737048387527466\n",
      "epoch: 8, batch: 315, loss: 0.6650070548057556\n",
      "epoch: 8, batch: 316, loss: 0.5475541949272156\n",
      "epoch: 8, batch: 317, loss: 0.4352239668369293\n",
      "epoch: 8, batch: 318, loss: 0.4007358253002167\n",
      "epoch: 8, batch: 319, loss: 0.48979800939559937\n",
      "epoch: 8, batch: 320, loss: 0.42468592524528503\n",
      "epoch: 8, batch: 321, loss: 0.551308274269104\n",
      "epoch: 8, batch: 322, loss: 0.6613495945930481\n",
      "epoch: 8, batch: 323, loss: 0.32409656047821045\n",
      "epoch: 8, batch: 324, loss: 0.37739092111587524\n",
      "epoch: 8, batch: 325, loss: 0.6138504147529602\n",
      "epoch: 8, batch: 326, loss: 0.43116310238838196\n",
      "epoch: 8, batch: 327, loss: 0.3356102406978607\n",
      "epoch: 8, batch: 328, loss: 0.68342524766922\n",
      "epoch: 8, batch: 329, loss: 0.5753554105758667\n",
      "epoch: 8, batch: 330, loss: 0.5400910377502441\n",
      "epoch: 8, batch: 331, loss: 0.49945592880249023\n",
      "epoch: 8, batch: 332, loss: 0.5366753935813904\n",
      "epoch: 8, batch: 333, loss: 0.3640359342098236\n",
      "epoch: 8, batch: 334, loss: 0.44838473200798035\n",
      "epoch: 8, batch: 335, loss: 0.6525068283081055\n",
      "epoch: 8, batch: 336, loss: 0.7099816799163818\n",
      "epoch: 8, batch: 337, loss: 0.5560004115104675\n",
      "epoch: 8, batch: 338, loss: 0.5179377794265747\n",
      "epoch: 8, batch: 339, loss: 0.3602157235145569\n",
      "epoch: 8, batch: 340, loss: 0.6859741806983948\n",
      "epoch: 8, batch: 341, loss: 0.6152400374412537\n",
      "epoch: 8, batch: 342, loss: 0.3319332003593445\n",
      "epoch: 8, batch: 343, loss: 0.47780370712280273\n",
      "epoch: 8, batch: 344, loss: 0.42371898889541626\n",
      "epoch: 8, batch: 345, loss: 0.4448910355567932\n",
      "epoch: 8, batch: 346, loss: 0.4536612331867218\n",
      "epoch: 8, batch: 347, loss: 0.5614613890647888\n",
      "epoch: 8, batch: 348, loss: 0.8184185028076172\n",
      "epoch: 8, batch: 349, loss: 0.6154311895370483\n",
      "epoch: 8, batch: 350, loss: 0.41966310143470764\n",
      "epoch: 8, batch: 351, loss: 0.3542731702327728\n",
      "epoch: 8, batch: 352, loss: 0.39453089237213135\n",
      "epoch: 8, batch: 353, loss: 0.3277200758457184\n",
      "epoch: 8, batch: 354, loss: 0.9069794416427612\n",
      "epoch: 8, batch: 355, loss: 0.5445840954780579\n",
      "epoch: 8, batch: 356, loss: 0.5223408937454224\n",
      "epoch: 8, batch: 357, loss: 0.6401791572570801\n",
      "epoch: 8, batch: 358, loss: 0.6254859566688538\n",
      "epoch: 8, batch: 359, loss: 0.9166318774223328\n",
      "epoch: 8, batch: 360, loss: 0.4703550636768341\n",
      "epoch: 8, batch: 361, loss: 0.7613599896430969\n",
      "epoch: 8, batch: 362, loss: 0.5397202372550964\n",
      "epoch: 8, batch: 363, loss: 0.37015026807785034\n",
      "epoch: 8, batch: 364, loss: 0.5656898617744446\n",
      "epoch: 8, batch: 365, loss: 0.426472932100296\n",
      "epoch: 8, batch: 366, loss: 0.3580241799354553\n",
      "epoch: 8, batch: 367, loss: 0.46916624903678894\n",
      "epoch: 8, batch: 368, loss: 0.6527083516120911\n",
      "epoch: 8, batch: 369, loss: 0.5132642984390259\n",
      "epoch: 8, batch: 370, loss: 0.2534390985965729\n",
      "epoch: 8, batch: 371, loss: 0.43598321080207825\n",
      "epoch: 8, batch: 372, loss: 0.6055480241775513\n",
      "epoch: 8, batch: 373, loss: 0.6624763011932373\n",
      "epoch: 8, batch: 374, loss: 0.31091418862342834\n",
      "epoch: 8, batch: 375, loss: 0.5020759105682373\n",
      "epoch: 8, batch: 376, loss: 0.41384485363960266\n",
      "epoch: 8, batch: 377, loss: 0.5460041165351868\n",
      "epoch: 8, batch: 378, loss: 0.5973344445228577\n",
      "epoch: 8, batch: 379, loss: 0.5099273324012756\n",
      "epoch: 8, batch: 380, loss: 0.40585076808929443\n",
      "epoch: 8, batch: 381, loss: 0.5300384759902954\n",
      "epoch: 8, batch: 382, loss: 0.599746823310852\n",
      "epoch: 8, batch: 383, loss: 0.3052237331867218\n",
      "epoch: 8, batch: 384, loss: 0.641251266002655\n",
      "epoch: 8, batch: 385, loss: 0.5451894998550415\n",
      "epoch: 8, batch: 386, loss: 0.39766451716423035\n",
      "epoch: 8, batch: 387, loss: 0.48396947979927063\n",
      "epoch: 8, batch: 388, loss: 0.5650395154953003\n",
      "epoch: 8, batch: 389, loss: 0.598685085773468\n",
      "epoch: 8, batch: 390, loss: 0.3720197379589081\n",
      "epoch: 8, batch: 391, loss: 0.36129480600357056\n",
      "epoch: 8, batch: 392, loss: 0.5328478813171387\n",
      "epoch: 8, batch: 393, loss: 0.31467947363853455\n",
      "epoch: 8, batch: 394, loss: 0.43340855836868286\n",
      "epoch: 8, batch: 395, loss: 0.33234938979148865\n",
      "epoch: 8, batch: 396, loss: 0.33589160442352295\n",
      "epoch: 8, batch: 397, loss: 0.3049647808074951\n",
      "epoch: 8, batch: 398, loss: 0.5481902956962585\n",
      "epoch: 8, batch: 399, loss: 0.4009658694267273\n",
      "epoch: 8, batch: 400, loss: 0.3511493504047394\n",
      "epoch: 8, batch: 401, loss: 0.5465142130851746\n",
      "epoch: 8, batch: 402, loss: 0.5941930413246155\n",
      "epoch: 8, batch: 403, loss: 0.8979140520095825\n",
      "epoch: 8, batch: 404, loss: 0.31784626841545105\n",
      "epoch: 8, batch: 405, loss: 0.43938958644866943\n",
      "epoch: 8, batch: 406, loss: 0.5767934322357178\n",
      "epoch: 8, batch: 407, loss: 0.482204794883728\n",
      "epoch: 8, batch: 408, loss: 0.42029228806495667\n",
      "epoch: 8, batch: 409, loss: 0.5283060669898987\n",
      "epoch: 8, batch: 410, loss: 0.8217955231666565\n",
      "epoch: 8, batch: 411, loss: 0.6525290608406067\n",
      "epoch: 8, batch: 412, loss: 0.5920266509056091\n",
      "epoch: 8, batch: 413, loss: 0.6720842719078064\n",
      "epoch: 8, batch: 414, loss: 0.40909630060195923\n",
      "epoch: 8, batch: 415, loss: 0.5473546385765076\n",
      "epoch: 8, batch: 416, loss: 0.5906205773353577\n",
      "epoch: 8, batch: 417, loss: 0.478114515542984\n",
      "epoch: 8, batch: 418, loss: 0.5109751224517822\n",
      "epoch: 8, batch: 419, loss: 0.429644376039505\n",
      "epoch: 8, batch: 420, loss: 0.4439338743686676\n",
      "epoch: 8, batch: 421, loss: 0.40236085653305054\n",
      "epoch: 8, batch: 422, loss: 0.3855491578578949\n",
      "epoch: 8, batch: 423, loss: 0.5763202905654907\n",
      "epoch: 8, batch: 424, loss: 0.2493164986371994\n",
      "epoch: 8, batch: 425, loss: 0.8418633341789246\n",
      "epoch: 8, batch: 426, loss: 0.5982372164726257\n",
      "epoch: 8, batch: 427, loss: 0.4523685574531555\n",
      "epoch: 8, batch: 428, loss: 0.331264853477478\n",
      "epoch: 8, batch: 429, loss: 0.5765634179115295\n",
      "epoch: 8, batch: 430, loss: 0.6042892932891846\n",
      "epoch: 8, batch: 431, loss: 0.539495587348938\n",
      "epoch: 8, batch: 432, loss: 0.42949923872947693\n",
      "epoch: 8, batch: 433, loss: 0.37384918332099915\n",
      "epoch: 8, batch: 434, loss: 0.361777663230896\n",
      "epoch: 8, batch: 435, loss: 0.3881876468658447\n",
      "epoch: 8, batch: 436, loss: 0.5936528444290161\n",
      "epoch: 8, batch: 437, loss: 0.41057392954826355\n",
      "epoch: 8, batch: 438, loss: 0.5143533945083618\n",
      "epoch: 8, batch: 439, loss: 0.5809500813484192\n",
      "epoch: 8, batch: 440, loss: 0.5585253834724426\n",
      "epoch: 8, batch: 441, loss: 0.5117717981338501\n",
      "epoch: 8, batch: 442, loss: 0.717851996421814\n",
      "epoch: 8, batch: 443, loss: 0.3412601947784424\n",
      "epoch: 8, batch: 444, loss: 0.7031187415122986\n",
      "epoch: 8, batch: 445, loss: 0.34206029772758484\n",
      "epoch: 8, batch: 446, loss: 0.3583845794200897\n",
      "epoch: 8, batch: 447, loss: 0.5504201650619507\n",
      "epoch: 8, batch: 448, loss: 0.23744097352027893\n",
      "epoch: 8, batch: 449, loss: 0.7433421611785889\n",
      "epoch: 8, batch: 450, loss: 0.5058262348175049\n",
      "epoch: 8, batch: 451, loss: 0.4596744775772095\n",
      "epoch: 8, batch: 452, loss: 0.5198814272880554\n",
      "epoch: 8, batch: 453, loss: 0.2759703993797302\n",
      "epoch: 8, batch: 454, loss: 0.26573097705841064\n",
      "epoch: 8, batch: 455, loss: 0.39375296235084534\n",
      "epoch: 8, batch: 456, loss: 0.41282305121421814\n",
      "epoch: 8, batch: 457, loss: 0.36784565448760986\n",
      "epoch: 8, batch: 458, loss: 0.5043829679489136\n",
      "epoch: 8, batch: 459, loss: 0.6610835790634155\n",
      "epoch: 8, batch: 460, loss: 0.43725302815437317\n",
      "epoch: 8, batch: 461, loss: 0.5031948685646057\n",
      "epoch: 8, batch: 462, loss: 0.30802661180496216\n",
      "epoch: 8, batch: 463, loss: 0.5304644703865051\n",
      "epoch: 8, batch: 464, loss: 0.4910166561603546\n",
      "epoch: 8, batch: 465, loss: 0.48968759179115295\n",
      "epoch: 8, batch: 466, loss: 0.5290759205818176\n",
      "epoch: 8, batch: 467, loss: 0.40332475304603577\n",
      "epoch: 8, batch: 468, loss: 0.4267048239707947\n",
      "epoch: 8, batch: 469, loss: 0.5016824007034302\n",
      "epoch: 8, batch: 470, loss: 0.6410672664642334\n",
      "epoch: 8, batch: 471, loss: 0.6272618174552917\n",
      "epoch: 8, batch: 472, loss: 0.4986652433872223\n",
      "epoch: 8, batch: 473, loss: 0.2520327568054199\n",
      "epoch: 8, batch: 474, loss: 0.48399627208709717\n",
      "epoch: 8, batch: 475, loss: 0.2793084681034088\n",
      "epoch: 8, batch: 476, loss: 0.45437091588974\n",
      "epoch: 8, batch: 477, loss: 0.5943066477775574\n",
      "epoch: 8, batch: 478, loss: 0.3452993929386139\n",
      "epoch: 8, batch: 479, loss: 0.4766257703304291\n",
      "epoch: 8, batch: 480, loss: 0.449228972196579\n",
      "epoch: 8, batch: 481, loss: 0.7249670624732971\n",
      "epoch: 8, batch: 482, loss: 0.7784432172775269\n",
      "epoch: 8, batch: 483, loss: 0.4051482081413269\n",
      "epoch: 8, batch: 484, loss: 0.5860592126846313\n",
      "epoch: 8, batch: 485, loss: 0.4199930429458618\n",
      "epoch: 8, batch: 486, loss: 0.3497640788555145\n",
      "epoch: 8, batch: 487, loss: 0.4196951389312744\n",
      "epoch: 8, batch: 488, loss: 0.5841406583786011\n",
      "epoch: 8, batch: 489, loss: 0.6577610969543457\n",
      "epoch: 8, batch: 490, loss: 0.41602176427841187\n",
      "epoch: 8, batch: 491, loss: 0.2514044940471649\n",
      "epoch: 8, batch: 492, loss: 0.39118656516075134\n",
      "epoch: 8, batch: 493, loss: 0.4118765592575073\n",
      "epoch: 8, batch: 494, loss: 0.6200077533721924\n",
      "epoch: 8, batch: 495, loss: 0.34056204557418823\n",
      "epoch: 8, batch: 496, loss: 0.3793443739414215\n",
      "epoch: 8, batch: 497, loss: 0.3015422523021698\n",
      "epoch: 8, batch: 498, loss: 0.6624988317489624\n",
      "epoch: 8, batch: 499, loss: 0.2840898334980011\n",
      "epoch: 8, batch: 500, loss: 0.701362133026123\n",
      "epoch: 8, batch: 501, loss: 0.5990228056907654\n",
      "epoch: 8, batch: 502, loss: 0.38722899556159973\n",
      "epoch: 8, batch: 503, loss: 0.7289340496063232\n",
      "epoch: 8, batch: 504, loss: 0.3900482952594757\n",
      "epoch: 8, batch: 505, loss: 0.5634989738464355\n",
      "epoch: 8, batch: 506, loss: 0.4959169328212738\n",
      "epoch: 8, batch: 507, loss: 0.4282955527305603\n",
      "epoch: 8, batch: 508, loss: 0.27607014775276184\n",
      "epoch: 8, batch: 509, loss: 0.492537260055542\n",
      "epoch: 8, batch: 510, loss: 0.2768687605857849\n",
      "epoch: 8, batch: 511, loss: 0.45609867572784424\n",
      "epoch: 8, batch: 512, loss: 0.3065231740474701\n",
      "epoch: 8, batch: 513, loss: 0.7178700566291809\n",
      "epoch: 8, batch: 514, loss: 0.3254198729991913\n",
      "epoch: 8, batch: 515, loss: 0.4067816138267517\n",
      "epoch: 8, batch: 516, loss: 0.46274763345718384\n",
      "epoch: 8, batch: 517, loss: 0.3664695620536804\n",
      "epoch: 8, batch: 518, loss: 0.4643748104572296\n",
      "epoch: 8, batch: 519, loss: 0.334386944770813\n",
      "epoch: 8, batch: 520, loss: 0.3547915816307068\n",
      "epoch: 8, batch: 521, loss: 0.6977121829986572\n",
      "epoch: 8, batch: 522, loss: 0.5601038336753845\n",
      "epoch: 8, batch: 523, loss: 0.34809648990631104\n",
      "epoch: 8, batch: 524, loss: 0.3285333514213562\n",
      "epoch: 8, batch: 525, loss: 0.6275165677070618\n",
      "epoch: 8, batch: 526, loss: 0.759638786315918\n",
      "epoch: 8, batch: 527, loss: 0.3644910454750061\n",
      "epoch: 8, batch: 528, loss: 0.6343163847923279\n",
      "epoch: 8, batch: 529, loss: 0.3091364800930023\n",
      "epoch: 8, batch: 530, loss: 0.5334872007369995\n",
      "epoch: 8, batch: 531, loss: 0.41218751668930054\n",
      "epoch: 8, batch: 532, loss: 0.44299057126045227\n",
      "epoch: 8, batch: 533, loss: 0.41888168454170227\n",
      "epoch: 8, batch: 534, loss: 0.3843754231929779\n",
      "epoch: 8, batch: 535, loss: 0.3916192650794983\n",
      "epoch: 8, batch: 536, loss: 0.6202688813209534\n",
      "epoch: 8, batch: 537, loss: 0.4647725820541382\n",
      "epoch: 8, batch: 538, loss: 0.45664671063423157\n",
      "epoch: 8, batch: 539, loss: 0.6047202348709106\n",
      "epoch: 8, batch: 540, loss: 0.5362455248832703\n",
      "epoch: 8, batch: 541, loss: 0.28331127762794495\n",
      "epoch: 8, batch: 542, loss: 0.520293116569519\n",
      "epoch: 8, batch: 543, loss: 0.5681778788566589\n",
      "epoch: 8, batch: 544, loss: 0.4105771481990814\n",
      "epoch: 8, batch: 545, loss: 0.8234900832176208\n",
      "epoch: 8, batch: 546, loss: 0.5628567337989807\n",
      "epoch: 8, batch: 547, loss: 0.3722105622291565\n",
      "epoch: 8, batch: 548, loss: 0.40834489464759827\n",
      "epoch: 8, batch: 549, loss: 0.5906950235366821\n",
      "epoch: 8, batch: 550, loss: 0.3799310624599457\n",
      "epoch: 8, batch: 551, loss: 0.255914568901062\n",
      "epoch: 8, batch: 552, loss: 0.3553987443447113\n",
      "epoch: 8, batch: 553, loss: 0.6248074769973755\n",
      "epoch: 8, batch: 554, loss: 0.8806827664375305\n",
      "epoch: 8, batch: 555, loss: 0.5336431264877319\n",
      "epoch: 8, batch: 556, loss: 0.38623759150505066\n",
      "epoch: 8, batch: 557, loss: 0.3981488347053528\n",
      "epoch: 8, batch: 558, loss: 0.29074838757514954\n",
      "epoch: 8, batch: 559, loss: 0.5975717306137085\n",
      "epoch: 8, batch: 560, loss: 0.5746749639511108\n",
      "epoch: 8, batch: 561, loss: 0.6235663890838623\n",
      "epoch: 8, batch: 562, loss: 0.8033626079559326\n",
      "epoch: 8, batch: 563, loss: 0.5643717646598816\n",
      "epoch: 8, batch: 564, loss: 0.5436537265777588\n",
      "epoch: 8, batch: 565, loss: 0.43081432580947876\n",
      "epoch: 8, batch: 566, loss: 0.5065414905548096\n",
      "epoch: 8, batch: 567, loss: 0.6204555034637451\n",
      "epoch: 8, batch: 568, loss: 0.34317082166671753\n",
      "epoch: 8, batch: 569, loss: 0.7594125866889954\n",
      "epoch: 8, batch: 570, loss: 0.29548922181129456\n",
      "epoch: 8, batch: 571, loss: 0.52834552526474\n",
      "epoch: 8, batch: 572, loss: 0.6116592288017273\n",
      "epoch: 8, batch: 573, loss: 0.5200381278991699\n",
      "epoch: 8, batch: 574, loss: 0.464269757270813\n",
      "epoch: 8, batch: 575, loss: 0.47898930311203003\n",
      "epoch: 8, batch: 576, loss: 0.3827340602874756\n",
      "epoch: 8, batch: 577, loss: 0.4580414891242981\n",
      "epoch: 8, batch: 578, loss: 0.4042324423789978\n",
      "epoch: 8, batch: 579, loss: 0.5059148669242859\n",
      "epoch: 8, batch: 580, loss: 0.3529394865036011\n",
      "epoch: 8, batch: 581, loss: 0.3649888336658478\n",
      "epoch: 8, batch: 582, loss: 0.6732908487319946\n",
      "epoch: 8, batch: 583, loss: 0.5329167246818542\n",
      "epoch: 8, batch: 584, loss: 0.4593615233898163\n",
      "epoch: 8, batch: 585, loss: 0.4831172823905945\n",
      "epoch: 8, batch: 586, loss: 0.7308048009872437\n",
      "epoch: 8, batch: 587, loss: 0.5753104090690613\n",
      "epoch: 8, batch: 588, loss: 0.3950117528438568\n",
      "epoch: 8, batch: 589, loss: 0.4603099226951599\n",
      "epoch: 8, batch: 590, loss: 0.6052927374839783\n",
      "epoch: 8, batch: 591, loss: 0.4527584910392761\n",
      "epoch: 8, batch: 592, loss: 0.4937210977077484\n",
      "epoch: 8, batch: 593, loss: 0.6217892169952393\n",
      "epoch: 8, batch: 594, loss: 0.64942866563797\n",
      "epoch: 8, batch: 595, loss: 0.5380889773368835\n",
      "epoch: 8, batch: 596, loss: 0.40575194358825684\n",
      "epoch: 8, batch: 597, loss: 0.616051197052002\n",
      "epoch: 8, batch: 598, loss: 0.5193482041358948\n",
      "epoch: 8, batch: 599, loss: 0.46027135848999023\n",
      "epoch: 8, batch: 600, loss: 0.21485525369644165\n",
      "epoch: 8, batch: 601, loss: 0.5254691243171692\n",
      "epoch: 8, batch: 602, loss: 0.22724662721157074\n",
      "epoch: 8, batch: 603, loss: 0.364338755607605\n",
      "epoch: 8, batch: 604, loss: 0.717519998550415\n",
      "epoch: 8, batch: 605, loss: 0.5396716594696045\n",
      "epoch: 8, batch: 606, loss: 0.5261909365653992\n",
      "epoch: 8, batch: 607, loss: 0.5485143661499023\n",
      "epoch: 8, batch: 608, loss: 0.42588359117507935\n",
      "epoch: 8, batch: 609, loss: 0.3312916159629822\n",
      "epoch: 8, batch: 610, loss: 0.7050419449806213\n",
      "epoch: 8, batch: 611, loss: 0.33937209844589233\n",
      "epoch: 8, batch: 612, loss: 0.5477584600448608\n",
      "epoch: 8, batch: 613, loss: 0.5930945873260498\n",
      "epoch: 8, batch: 614, loss: 0.3151302933692932\n",
      "epoch: 8, batch: 615, loss: 0.5159121155738831\n",
      "epoch: 8, batch: 616, loss: 0.4656884968280792\n",
      "epoch: 8, batch: 617, loss: 0.3362092077732086\n",
      "epoch: 8, batch: 618, loss: 0.3494349718093872\n",
      "epoch: 8, batch: 619, loss: 0.42100438475608826\n",
      "epoch: 8, batch: 620, loss: 0.531920850276947\n",
      "epoch: 8, batch: 621, loss: 0.3714521527290344\n",
      "epoch: 8, batch: 622, loss: 0.5303640961647034\n",
      "epoch: 8, batch: 623, loss: 0.602895975112915\n",
      "epoch: 8, batch: 624, loss: 0.3378652036190033\n",
      "epoch: 8, batch: 625, loss: 0.4455788731575012\n",
      "epoch: 8, batch: 626, loss: 0.33186250925064087\n",
      "epoch: 8, batch: 627, loss: 0.5616952180862427\n",
      "epoch: 8, batch: 628, loss: 0.4856218695640564\n",
      "epoch: 8, batch: 629, loss: 0.44165632128715515\n",
      "epoch: 8, batch: 630, loss: 0.504005491733551\n",
      "epoch: 8, batch: 631, loss: 0.4142860472202301\n",
      "epoch: 8, batch: 632, loss: 0.5214759111404419\n",
      "epoch: 8, batch: 633, loss: 0.9468997716903687\n",
      "epoch: 8, batch: 634, loss: 0.45765507221221924\n",
      "epoch: 8, batch: 635, loss: 0.40700799226760864\n",
      "epoch: 8, batch: 636, loss: 0.6570528149604797\n",
      "epoch: 8, batch: 637, loss: 0.7031482458114624\n",
      "epoch: 8, batch: 638, loss: 0.37032416462898254\n",
      "epoch: 8, batch: 639, loss: 0.5164262652397156\n",
      "epoch: 8, batch: 640, loss: 0.40966150164604187\n",
      "epoch: 8, batch: 641, loss: 0.28167662024497986\n",
      "epoch: 8, batch: 642, loss: 0.36050161719322205\n",
      "epoch: 8, batch: 643, loss: 0.5652743577957153\n",
      "epoch: 8, batch: 644, loss: 0.5893633365631104\n",
      "epoch: 8, batch: 645, loss: 0.4618387222290039\n",
      "epoch: 8, batch: 646, loss: 0.6238522529602051\n",
      "epoch: 8, batch: 647, loss: 0.44953081011772156\n",
      "epoch: 8, batch: 648, loss: 0.30099692940711975\n",
      "epoch: 8, batch: 649, loss: 0.828974187374115\n",
      "epoch: 8, batch: 650, loss: 0.5372070074081421\n",
      "epoch: 8, batch: 651, loss: 0.5774332880973816\n",
      "epoch: 8, batch: 652, loss: 0.5818071961402893\n",
      "epoch: 8, batch: 653, loss: 0.4610093832015991\n",
      "epoch: 8, batch: 654, loss: 0.5165099501609802\n",
      "epoch: 8, batch: 655, loss: 0.5634837746620178\n",
      "epoch: 8, batch: 656, loss: 0.3705662190914154\n",
      "epoch: 8, batch: 657, loss: 0.40841323137283325\n",
      "epoch: 8, batch: 658, loss: 0.6035370230674744\n",
      "epoch: 8, batch: 659, loss: 0.4691619277000427\n",
      "epoch: 8, batch: 660, loss: 0.46105051040649414\n",
      "epoch: 8, batch: 661, loss: 0.35901257395744324\n",
      "epoch: 8, batch: 662, loss: 0.4210973381996155\n",
      "epoch: 8, batch: 663, loss: 0.3361324965953827\n",
      "epoch: 8, batch: 664, loss: 0.44611066579818726\n",
      "epoch: 8, batch: 665, loss: 0.30370551347732544\n",
      "epoch: 8, batch: 666, loss: 0.7504145503044128\n",
      "epoch: 8, batch: 667, loss: 0.23799115419387817\n",
      "epoch: 8, batch: 668, loss: 0.2759639620780945\n",
      "epoch: 8, batch: 669, loss: 0.49328213930130005\n",
      "epoch: 8, batch: 670, loss: 0.4206642508506775\n",
      "epoch: 8, batch: 671, loss: 0.5561786890029907\n",
      "epoch: 8, batch: 672, loss: 0.6082432866096497\n",
      "epoch: 8, batch: 673, loss: 0.5305962562561035\n",
      "epoch: 8, batch: 674, loss: 0.6730815172195435\n",
      "epoch: 8, batch: 675, loss: 0.3558503985404968\n",
      "epoch: 8, batch: 676, loss: 0.3240934908390045\n",
      "epoch: 8, batch: 677, loss: 0.5720579028129578\n",
      "epoch: 8, batch: 678, loss: 0.5031480193138123\n",
      "epoch: 8, batch: 679, loss: 0.5296635627746582\n",
      "epoch: 8, batch: 680, loss: 0.48902562260627747\n",
      "epoch: 8, batch: 681, loss: 0.33737707138061523\n",
      "epoch: 8, batch: 682, loss: 0.6064848899841309\n",
      "epoch: 8, batch: 683, loss: 0.6546052098274231\n",
      "epoch: 8, batch: 684, loss: 0.3561986982822418\n",
      "epoch: 8, batch: 685, loss: 0.4191499948501587\n",
      "epoch: 8, batch: 686, loss: 0.3495582342147827\n",
      "epoch: 8, batch: 687, loss: 0.7667600512504578\n",
      "epoch: 8, batch: 688, loss: 0.24460963904857635\n",
      "epoch: 8, batch: 689, loss: 0.571067750453949\n",
      "epoch: 8, batch: 690, loss: 0.5933728814125061\n",
      "epoch: 8, batch: 691, loss: 0.4245198965072632\n",
      "epoch: 8, batch: 692, loss: 0.571504533290863\n",
      "epoch: 8, batch: 693, loss: 0.5780389308929443\n",
      "epoch: 8, batch: 694, loss: 0.6801584959030151\n",
      "epoch: 8, batch: 695, loss: 0.5585453510284424\n",
      "epoch: 8, batch: 696, loss: 0.7209120988845825\n",
      "epoch: 8, batch: 697, loss: 0.5321879386901855\n",
      "epoch: 8, batch: 698, loss: 0.6642144322395325\n",
      "epoch: 8, batch: 699, loss: 0.6175504922866821\n",
      "epoch: 8, batch: 700, loss: 0.5813185572624207\n",
      "epoch: 8, batch: 701, loss: 0.48358047008514404\n",
      "epoch: 8, batch: 702, loss: 0.5577747225761414\n",
      "epoch: 8, batch: 703, loss: 0.5112972259521484\n",
      "epoch: 8, batch: 704, loss: 0.3833331763744354\n",
      "epoch: 8, batch: 705, loss: 0.39319920539855957\n",
      "epoch: 8, batch: 706, loss: 0.6103572845458984\n",
      "epoch: 8, batch: 707, loss: 0.4504624903202057\n",
      "epoch: 8, batch: 708, loss: 0.4308733344078064\n",
      "epoch: 8, batch: 709, loss: 0.4364357590675354\n",
      "epoch: 8, batch: 710, loss: 0.5248299241065979\n",
      "epoch: 8, batch: 711, loss: 0.512338399887085\n",
      "epoch: 8, batch: 712, loss: 0.47422415018081665\n",
      "epoch: 8, batch: 713, loss: 0.3952468931674957\n",
      "epoch: 8, batch: 714, loss: 0.6395100951194763\n",
      "epoch: 8, batch: 715, loss: 0.4456556737422943\n",
      "epoch: 8, batch: 716, loss: 0.4975122809410095\n",
      "epoch: 8, batch: 717, loss: 0.4200150668621063\n",
      "epoch: 8, batch: 718, loss: 0.42872899770736694\n",
      "epoch: 8, batch: 719, loss: 0.35957324504852295\n",
      "epoch: 8, batch: 720, loss: 0.5047601461410522\n",
      "epoch: 8, batch: 721, loss: 0.7325522303581238\n",
      "epoch: 8, batch: 722, loss: 0.4406711757183075\n",
      "epoch: 8, batch: 723, loss: 0.3767516016960144\n",
      "epoch: 8, batch: 724, loss: 0.4250279664993286\n",
      "epoch: 8, batch: 725, loss: 0.5455557703971863\n",
      "epoch: 8, batch: 726, loss: 0.4216935336589813\n",
      "epoch: 8, batch: 727, loss: 0.7642154097557068\n",
      "epoch: 8, batch: 728, loss: 0.2962278425693512\n",
      "epoch: 8, batch: 729, loss: 0.4377616345882416\n",
      "epoch: 8, batch: 730, loss: 0.7614080309867859\n",
      "epoch: 8, batch: 731, loss: 0.48266875743865967\n",
      "epoch: 8, batch: 732, loss: 0.3700951337814331\n",
      "epoch: 8, batch: 733, loss: 0.637149453163147\n",
      "epoch: 8, batch: 734, loss: 0.5974199175834656\n",
      "epoch: 8, batch: 735, loss: 0.5032429695129395\n",
      "epoch: 8, batch: 736, loss: 0.40360185503959656\n",
      "epoch: 8, batch: 737, loss: 0.4333868622779846\n",
      "epoch: 8, batch: 738, loss: 0.36836427450180054\n",
      "epoch: 8, batch: 739, loss: 0.22918778657913208\n",
      "epoch: 8, batch: 740, loss: 0.49969738721847534\n",
      "epoch: 8, batch: 741, loss: 0.35778453946113586\n",
      "epoch: 8, batch: 742, loss: 0.5868258476257324\n",
      "epoch: 8, batch: 743, loss: 0.7430418133735657\n",
      "epoch: 8, batch: 744, loss: 0.6068366169929504\n",
      "epoch: 8, batch: 745, loss: 0.41364505887031555\n",
      "epoch: 8, batch: 746, loss: 0.44674229621887207\n",
      "epoch: 8, batch: 747, loss: 0.6820253133773804\n",
      "epoch: 8, batch: 748, loss: 0.6225814819335938\n",
      "epoch: 8, batch: 749, loss: 0.47903144359588623\n",
      "epoch: 8, batch: 750, loss: 0.5269967913627625\n",
      "epoch: 8, batch: 751, loss: 0.4303306043148041\n",
      "epoch: 8, batch: 752, loss: 0.40928027033805847\n",
      "epoch: 8, batch: 753, loss: 0.3674491345882416\n",
      "epoch: 8, batch: 754, loss: 0.42021647095680237\n",
      "epoch: 8, batch: 755, loss: 0.6062371730804443\n",
      "epoch: 8, batch: 756, loss: 0.3994825482368469\n",
      "epoch: 8, batch: 757, loss: 0.43486565351486206\n",
      "epoch: 8, batch: 758, loss: 0.3573666512966156\n",
      "epoch: 8, batch: 759, loss: 0.46256157755851746\n",
      "epoch: 8, batch: 760, loss: 0.46821537613868713\n",
      "epoch: 8, batch: 761, loss: 0.4912887215614319\n",
      "epoch: 8, batch: 762, loss: 0.5574576258659363\n",
      "epoch: 8, batch: 763, loss: 0.453426331281662\n",
      "epoch: 8, batch: 764, loss: 0.4486778974533081\n",
      "epoch: 8, batch: 765, loss: 0.5766830444335938\n",
      "epoch: 8, batch: 766, loss: 0.4045564830303192\n",
      "epoch: 8, batch: 767, loss: 0.609223484992981\n",
      "epoch: 8, batch: 768, loss: 0.432646244764328\n",
      "epoch: 8, batch: 769, loss: 0.4182007610797882\n",
      "epoch: 8, batch: 770, loss: 0.5159180164337158\n",
      "epoch: 8, batch: 771, loss: 0.8027678728103638\n",
      "epoch: 8, batch: 772, loss: 0.6818152070045471\n",
      "epoch: 8, batch: 773, loss: 0.5041319727897644\n",
      "epoch: 8, batch: 774, loss: 0.3286094665527344\n",
      "epoch: 8, batch: 775, loss: 0.5012544393539429\n",
      "epoch: 8, batch: 776, loss: 0.48600807785987854\n",
      "epoch: 8, batch: 777, loss: 0.29472586512565613\n",
      "epoch: 8, batch: 778, loss: 0.5195297598838806\n",
      "epoch: 8, batch: 779, loss: 0.5029953122138977\n",
      "epoch: 8, batch: 780, loss: 0.5574542284011841\n",
      "epoch: 8, batch: 781, loss: 0.3109361529350281\n",
      "epoch: 8, batch: 782, loss: 0.6845264434814453\n",
      "epoch: 8, batch: 783, loss: 0.411311537027359\n",
      "epoch: 8, batch: 784, loss: 0.22801174223423004\n",
      "epoch: 8, batch: 785, loss: 0.38878148794174194\n",
      "epoch: 8, batch: 786, loss: 0.4088912904262543\n",
      "epoch: 8, batch: 787, loss: 0.2715994715690613\n",
      "epoch: 8, batch: 788, loss: 0.40946924686431885\n",
      "epoch: 8, batch: 789, loss: 0.5819406509399414\n",
      "epoch: 8, batch: 790, loss: 0.4087836742401123\n",
      "epoch: 8, batch: 791, loss: 0.40620797872543335\n",
      "epoch: 8, batch: 792, loss: 0.38953280448913574\n",
      "epoch: 8, batch: 793, loss: 0.45034295320510864\n",
      "epoch: 8, batch: 794, loss: 0.4950277805328369\n",
      "epoch: 8, batch: 795, loss: 0.6611298322677612\n",
      "epoch: 8, batch: 796, loss: 0.40855276584625244\n",
      "epoch: 8, batch: 797, loss: 0.4601549506187439\n",
      "epoch: 8, batch: 798, loss: 0.2880173921585083\n",
      "epoch: 8, batch: 799, loss: 0.5170217156410217\n",
      "epoch: 8, batch: 800, loss: 0.38472890853881836\n",
      "epoch: 8, batch: 801, loss: 0.5629866719245911\n",
      "epoch: 8, batch: 802, loss: 0.5738427639007568\n",
      "epoch: 8, batch: 803, loss: 0.3461567759513855\n",
      "epoch: 8, batch: 804, loss: 0.3252657353878021\n",
      "epoch: 8, batch: 805, loss: 0.5600206851959229\n",
      "epoch: 8, batch: 806, loss: 0.46790775656700134\n",
      "epoch: 8, batch: 807, loss: 0.47837427258491516\n",
      "epoch: 8, batch: 808, loss: 0.47579261660575867\n",
      "epoch: 8, batch: 809, loss: 0.4377710521221161\n",
      "epoch: 8, batch: 810, loss: 0.6139950156211853\n",
      "epoch: 8, batch: 811, loss: 0.5075041055679321\n",
      "epoch: 8, batch: 812, loss: 0.7737292647361755\n",
      "epoch: 8, batch: 813, loss: 0.39333459734916687\n",
      "epoch: 8, batch: 814, loss: 0.43351319432258606\n",
      "epoch: 8, batch: 815, loss: 0.2573665976524353\n",
      "epoch: 8, batch: 816, loss: 0.524937093257904\n",
      "epoch: 8, batch: 817, loss: 0.388439416885376\n",
      "epoch: 8, batch: 818, loss: 0.3979116678237915\n",
      "epoch: 8, batch: 819, loss: 0.5289348363876343\n",
      "epoch: 8, batch: 820, loss: 0.8915417194366455\n",
      "epoch: 8, batch: 821, loss: 0.6870923638343811\n",
      "epoch: 8, batch: 822, loss: 0.5740041732788086\n",
      "epoch: 8, batch: 823, loss: 0.5020496845245361\n",
      "epoch: 8, batch: 824, loss: 0.6583465933799744\n",
      "epoch: 8, batch: 825, loss: 0.7048234343528748\n",
      "epoch: 8, batch: 826, loss: 0.33698591589927673\n",
      "epoch: 8, batch: 827, loss: 0.5132283568382263\n",
      "epoch: 8, batch: 828, loss: 0.22917431592941284\n",
      "epoch: 8, batch: 829, loss: 0.616456925868988\n",
      "epoch: 8, batch: 830, loss: 0.49496763944625854\n",
      "epoch: 8, batch: 831, loss: 0.5067448019981384\n",
      "epoch: 8, batch: 832, loss: 0.6858403086662292\n",
      "epoch: 8, batch: 833, loss: 0.3714968264102936\n",
      "epoch: 8, batch: 834, loss: 0.53738933801651\n",
      "epoch: 8, batch: 835, loss: 0.514854907989502\n",
      "epoch: 8, batch: 836, loss: 0.319864422082901\n",
      "epoch: 8, batch: 837, loss: 0.43164291977882385\n",
      "epoch: 8, batch: 838, loss: 0.49217191338539124\n",
      "epoch: 8, batch: 839, loss: 0.23878976702690125\n",
      "epoch: 8, batch: 840, loss: 0.3930319845676422\n",
      "epoch: 8, batch: 841, loss: 0.7867512702941895\n",
      "epoch: 8, batch: 842, loss: 0.7915866374969482\n",
      "epoch: 8, batch: 843, loss: 0.34207239747047424\n",
      "epoch: 8, batch: 844, loss: 0.4639768600463867\n",
      "epoch: 8, batch: 845, loss: 0.3154379427433014\n",
      "epoch: 8, batch: 846, loss: 0.42559581995010376\n",
      "epoch: 8, batch: 847, loss: 0.5049976110458374\n",
      "epoch: 8, batch: 848, loss: 0.5557345747947693\n",
      "epoch: 8, batch: 849, loss: 0.7718675136566162\n",
      "epoch: 8, batch: 850, loss: 0.4289962947368622\n",
      "epoch: 8, batch: 851, loss: 0.5379936695098877\n",
      "epoch: 8, batch: 852, loss: 0.47429513931274414\n",
      "epoch: 8, batch: 853, loss: 0.5726230144500732\n",
      "epoch: 8, batch: 854, loss: 0.320488840341568\n",
      "epoch: 8, batch: 855, loss: 0.6226599812507629\n",
      "epoch: 8, batch: 856, loss: 0.36801281571388245\n",
      "epoch: 8, batch: 857, loss: 0.32110074162483215\n",
      "epoch: 8, batch: 858, loss: 0.4886291027069092\n",
      "epoch: 8, batch: 859, loss: 0.5582269430160522\n",
      "epoch: 8, batch: 860, loss: 0.2305096834897995\n",
      "epoch: 8, batch: 861, loss: 0.690667450428009\n",
      "epoch: 8, batch: 862, loss: 0.42766550183296204\n",
      "epoch: 8, batch: 863, loss: 0.4482424259185791\n",
      "epoch: 8, batch: 864, loss: 0.46326735615730286\n",
      "epoch: 8, batch: 865, loss: 0.6158115863800049\n",
      "epoch: 8, batch: 866, loss: 0.47498250007629395\n",
      "epoch: 8, batch: 867, loss: 0.7595827579498291\n",
      "epoch: 8, batch: 868, loss: 0.4053756892681122\n",
      "epoch: 8, batch: 869, loss: 0.3807384669780731\n",
      "epoch: 8, batch: 870, loss: 0.42031049728393555\n",
      "epoch: 8, batch: 871, loss: 0.4520523250102997\n",
      "epoch: 8, batch: 872, loss: 0.36489295959472656\n",
      "epoch: 8, batch: 873, loss: 0.4457593560218811\n",
      "epoch: 8, batch: 874, loss: 0.6693926453590393\n",
      "epoch: 8, batch: 875, loss: 0.5274252891540527\n",
      "epoch: 8, batch: 876, loss: 0.41854894161224365\n",
      "epoch: 8, batch: 877, loss: 0.3808079957962036\n",
      "epoch: 8, batch: 878, loss: 0.564098596572876\n",
      "epoch: 8, batch: 879, loss: 0.561779797077179\n",
      "epoch: 8, batch: 880, loss: 0.513508677482605\n",
      "epoch: 8, batch: 881, loss: 0.6411246061325073\n",
      "epoch: 8, batch: 882, loss: 0.33576542139053345\n",
      "epoch: 8, batch: 883, loss: 0.3330269157886505\n",
      "epoch: 8, batch: 884, loss: 0.6283488869667053\n",
      "epoch: 8, batch: 885, loss: 0.4379855990409851\n",
      "epoch: 8, batch: 886, loss: 0.28570082783699036\n",
      "epoch: 8, batch: 887, loss: 0.33721452951431274\n",
      "epoch: 8, batch: 888, loss: 0.7933101654052734\n",
      "epoch: 8, batch: 889, loss: 0.49598297476768494\n",
      "epoch: 8, batch: 890, loss: 0.5175668597221375\n",
      "epoch: 8, batch: 891, loss: 0.4532127380371094\n",
      "epoch: 8, batch: 892, loss: 0.3138875961303711\n",
      "epoch: 8, batch: 893, loss: 0.6024197340011597\n",
      "epoch: 8, batch: 894, loss: 0.3639622926712036\n",
      "epoch: 8, batch: 895, loss: 0.43118250370025635\n",
      "epoch: 8, batch: 896, loss: 0.7425336241722107\n",
      "epoch: 8, batch: 897, loss: 0.9024957418441772\n",
      "epoch: 8, batch: 898, loss: 0.3361445367336273\n",
      "epoch: 8, batch: 899, loss: 0.5093145370483398\n",
      "epoch: 8, batch: 900, loss: 0.5095896124839783\n",
      "epoch: 8, batch: 901, loss: 0.7976471781730652\n",
      "epoch: 8, batch: 902, loss: 0.41101524233818054\n",
      "epoch: 8, batch: 903, loss: 0.49421727657318115\n",
      "epoch: 8, batch: 904, loss: 0.46999338269233704\n",
      "epoch: 8, batch: 905, loss: 0.36218729615211487\n",
      "epoch: 8, batch: 906, loss: 0.8471869230270386\n",
      "epoch: 8, batch: 907, loss: 0.6360504031181335\n",
      "epoch: 8, batch: 908, loss: 0.43970978260040283\n",
      "epoch: 8, batch: 909, loss: 0.6104129552841187\n",
      "epoch: 8, batch: 910, loss: 0.5500223636627197\n",
      "epoch: 8, batch: 911, loss: 0.5557282567024231\n",
      "epoch: 8, batch: 912, loss: 0.479570209980011\n",
      "epoch: 8, batch: 913, loss: 0.47335970401763916\n",
      "epoch: 8, batch: 914, loss: 0.33201029896736145\n",
      "epoch: 8, batch: 915, loss: 0.6956633925437927\n",
      "epoch: 8, batch: 916, loss: 0.3631260097026825\n",
      "epoch: 8, batch: 917, loss: 0.27505871653556824\n",
      "epoch: 8, batch: 918, loss: 0.25070399045944214\n",
      "epoch: 8, batch: 919, loss: 0.4579388201236725\n",
      "epoch: 8, batch: 920, loss: 0.6198328137397766\n",
      "epoch: 8, batch: 921, loss: 0.4173281490802765\n",
      "epoch: 8, batch: 922, loss: 0.4713563024997711\n",
      "epoch: 8, batch: 923, loss: 0.6393059492111206\n",
      "epoch: 8, batch: 924, loss: 0.5195411443710327\n",
      "epoch: 8, batch: 925, loss: 0.47494757175445557\n",
      "epoch: 8, batch: 926, loss: 0.5737841129302979\n",
      "epoch: 8, batch: 927, loss: 0.5778884291648865\n",
      "epoch: 8, batch: 928, loss: 0.34021425247192383\n",
      "epoch: 8, batch: 929, loss: 0.29993101954460144\n",
      "epoch: 8, batch: 930, loss: 0.4716443121433258\n",
      "epoch: 8, batch: 931, loss: 0.3606770932674408\n",
      "epoch: 8, batch: 932, loss: 0.4880848526954651\n",
      "epoch: 8, batch: 933, loss: 0.5062045454978943\n",
      "epoch: 8, batch: 934, loss: 0.3290715515613556\n",
      "epoch: 8, batch: 935, loss: 0.9802566170692444\n",
      "epoch: 8, batch: 936, loss: 0.4197292625904083\n",
      "epoch: 8, batch: 937, loss: 0.610215961933136\n",
      "epoch: 8, batch: 938, loss: 0.33319413661956787\n",
      "epoch: 8, batch: 939, loss: 0.5918991565704346\n",
      "epoch: 8, batch: 940, loss: 0.3565874695777893\n",
      "epoch: 8, batch: 941, loss: 0.4966464042663574\n",
      "epoch: 8, batch: 942, loss: 0.30855679512023926\n",
      "epoch: 8, batch: 943, loss: 0.4154354929924011\n",
      "epoch: 8, batch: 944, loss: 0.5942408442497253\n",
      "epoch: 8, batch: 945, loss: 0.5298248529434204\n",
      "epoch: 8, batch: 946, loss: 0.4092039465904236\n",
      "epoch: 8, batch: 947, loss: 0.4477594792842865\n",
      "epoch: 8, batch: 948, loss: 0.42147696018218994\n",
      "epoch: 8, batch: 949, loss: 0.42741715908050537\n",
      "epoch: 8, batch: 950, loss: 0.5874536037445068\n",
      "epoch: 8, batch: 951, loss: 0.282348096370697\n",
      "epoch: 8, batch: 952, loss: 0.39823582768440247\n",
      "epoch: 8, batch: 953, loss: 1.0276292562484741\n",
      "epoch: 8, batch: 954, loss: 0.5922641754150391\n",
      "epoch: 8, batch: 955, loss: 0.2663300037384033\n",
      "epoch: 8, batch: 956, loss: 0.5418199896812439\n",
      "epoch: 8, batch: 957, loss: 0.6970701217651367\n",
      "epoch: 8, batch: 958, loss: 0.5211726427078247\n",
      "epoch: 8, batch: 959, loss: 0.39783617854118347\n",
      "epoch: 8, batch: 960, loss: 0.4390068054199219\n",
      "epoch: 8, batch: 961, loss: 0.7045442461967468\n",
      "epoch: 8, batch: 962, loss: 0.5650398135185242\n",
      "epoch: 8, batch: 963, loss: 0.4540864825248718\n",
      "epoch: 8, batch: 964, loss: 0.48850017786026\n",
      "epoch: 8, batch: 965, loss: 0.25342321395874023\n",
      "epoch: 8, batch: 966, loss: 0.6480543613433838\n",
      "epoch: 8, batch: 967, loss: 0.3890618681907654\n",
      "epoch: 8, batch: 968, loss: 0.33849865198135376\n",
      "epoch: 8, batch: 969, loss: 0.35753384232521057\n",
      "epoch: 8, batch: 970, loss: 0.6796759963035583\n",
      "epoch: 8, batch: 971, loss: 0.5377439260482788\n",
      "epoch: 8, batch: 972, loss: 0.6933391690254211\n",
      "epoch: 8, batch: 973, loss: 0.32294124364852905\n",
      "epoch: 8, batch: 974, loss: 0.5182157754898071\n",
      "epoch: 8, batch: 975, loss: 0.5224411487579346\n",
      "epoch: 8, batch: 976, loss: 0.4551086127758026\n",
      "epoch: 8, batch: 977, loss: 0.43558359146118164\n",
      "epoch: 8, batch: 978, loss: 0.47157910466194153\n",
      "epoch: 8, batch: 979, loss: 0.3087824285030365\n",
      "epoch: 8, batch: 980, loss: 0.4769060015678406\n",
      "epoch: 8, batch: 981, loss: 0.5617236495018005\n",
      "epoch: 8, batch: 982, loss: 0.5564911365509033\n",
      "epoch: 8, batch: 983, loss: 0.5258228778839111\n",
      "epoch: 8, batch: 984, loss: 0.45003995299339294\n",
      "epoch: 8, batch: 985, loss: 0.3050684630870819\n",
      "epoch: 8, batch: 986, loss: 0.23194248974323273\n",
      "epoch: 8, batch: 987, loss: 0.5300798416137695\n",
      "epoch: 8, batch: 988, loss: 0.6747321486473083\n",
      "epoch: 8, batch: 989, loss: 0.6476731300354004\n",
      "epoch: 8, batch: 990, loss: 0.34655630588531494\n",
      "epoch: 8, batch: 991, loss: 0.3996724784374237\n",
      "epoch: 8, batch: 992, loss: 0.3249629735946655\n",
      "epoch: 8, batch: 993, loss: 0.3964248299598694\n",
      "epoch: 8, batch: 994, loss: 0.6633393168449402\n",
      "epoch: 8, batch: 995, loss: 0.2103286236524582\n",
      "epoch: 8, batch: 996, loss: 0.45226243138313293\n",
      "epoch: 8, batch: 997, loss: 0.3436117172241211\n",
      "epoch: 8, batch: 998, loss: 0.5986455678939819\n",
      "epoch: 8, batch: 999, loss: 0.6318883299827576\n",
      "epoch: 8, batch: 1000, loss: 0.2479093372821808\n",
      "epoch: 8, batch: 1001, loss: 0.6070287823677063\n",
      "epoch: 8, batch: 1002, loss: 0.611526608467102\n",
      "epoch: 8, batch: 1003, loss: 0.2658410966396332\n",
      "epoch: 8, batch: 1004, loss: 0.633573591709137\n",
      "epoch: 8, batch: 1005, loss: 0.5923959016799927\n",
      "epoch: 8, batch: 1006, loss: 0.44967368245124817\n",
      "epoch: 8, batch: 1007, loss: 0.532915472984314\n",
      "epoch: 8, batch: 1008, loss: 0.45098569989204407\n",
      "epoch: 8, batch: 1009, loss: 0.5341480374336243\n",
      "epoch: 8, batch: 1010, loss: 0.5474238991737366\n",
      "epoch: 8, batch: 1011, loss: 0.37551164627075195\n",
      "epoch: 8, batch: 1012, loss: 0.6807857751846313\n",
      "epoch: 8, batch: 1013, loss: 0.4158448874950409\n",
      "epoch: 8, batch: 1014, loss: 0.26739001274108887\n",
      "epoch: 8, batch: 1015, loss: 0.3538168966770172\n",
      "epoch: 8, batch: 1016, loss: 0.5631633400917053\n",
      "epoch: 8, batch: 1017, loss: 0.3408602774143219\n",
      "epoch: 8, batch: 1018, loss: 0.36387377977371216\n",
      "epoch: 8, batch: 1019, loss: 0.5029708743095398\n",
      "epoch: 8, batch: 1020, loss: 0.55825275182724\n",
      "epoch: 8, batch: 1021, loss: 0.4214059114456177\n",
      "epoch: 8, batch: 1022, loss: 0.48021167516708374\n",
      "epoch: 8, batch: 1023, loss: 0.3433751165866852\n",
      "epoch: 8, batch: 1024, loss: 0.3158845603466034\n",
      "epoch: 8, batch: 1025, loss: 0.8230579495429993\n",
      "epoch: 8, batch: 1026, loss: 0.2715735137462616\n",
      "epoch: 8, batch: 1027, loss: 0.6326172351837158\n",
      "epoch: 8, batch: 1028, loss: 0.5274270176887512\n",
      "epoch: 8, batch: 1029, loss: 0.6411750912666321\n",
      "epoch: 8, batch: 1030, loss: 0.4522860646247864\n",
      "epoch: 8, batch: 1031, loss: 0.32036638259887695\n",
      "epoch: 8, batch: 1032, loss: 0.2979547679424286\n",
      "epoch: 8, batch: 1033, loss: 0.6034608483314514\n",
      "epoch: 8, batch: 1034, loss: 0.5310789942741394\n",
      "epoch: 8, batch: 1035, loss: 0.48688873648643494\n",
      "epoch: 8, batch: 1036, loss: 0.6530715227127075\n",
      "epoch: 8, batch: 1037, loss: 0.3541817367076874\n",
      "epoch: 8, batch: 1038, loss: 0.5840612053871155\n",
      "epoch: 8, batch: 1039, loss: 0.4438938498497009\n",
      "epoch: 8, batch: 1040, loss: 0.5661199688911438\n",
      "epoch: 8, batch: 1041, loss: 0.4229012131690979\n",
      "epoch: 8, batch: 1042, loss: 0.4523147642612457\n",
      "epoch: 8, batch: 1043, loss: 0.322316437959671\n",
      "epoch: 8, batch: 1044, loss: 0.5063192248344421\n",
      "epoch: 8, batch: 1045, loss: 0.3092053532600403\n",
      "epoch: 8, batch: 1046, loss: 0.34228628873825073\n",
      "epoch: 8, batch: 1047, loss: 0.5197588205337524\n",
      "epoch: 8, batch: 1048, loss: 0.3884076774120331\n",
      "epoch: 8, batch: 1049, loss: 0.34738802909851074\n",
      "epoch: 8, batch: 1050, loss: 0.34181922674179077\n",
      "epoch: 8, batch: 1051, loss: 0.462116003036499\n",
      "epoch: 8, batch: 1052, loss: 0.6630694270133972\n",
      "epoch: 8, batch: 1053, loss: 0.681717038154602\n",
      "epoch: 8, batch: 1054, loss: 0.32084181904792786\n",
      "epoch: 8, batch: 1055, loss: 0.24352245032787323\n",
      "epoch: 8, batch: 1056, loss: 0.5980449318885803\n",
      "epoch: 8, batch: 1057, loss: 0.5789828300476074\n",
      "epoch: 8, batch: 1058, loss: 0.42193982005119324\n",
      "epoch: 8, batch: 1059, loss: 0.304121732711792\n",
      "epoch: 8, batch: 1060, loss: 0.6142837405204773\n",
      "epoch: 8, batch: 1061, loss: 0.2896328568458557\n",
      "epoch: 8, batch: 1062, loss: 0.4905931055545807\n",
      "epoch: 8, batch: 1063, loss: 0.31820470094680786\n",
      "epoch: 8, batch: 1064, loss: 0.19685621559619904\n",
      "epoch: 8, batch: 1065, loss: 0.563092827796936\n",
      "epoch: 8, batch: 1066, loss: 0.5378394722938538\n",
      "epoch: 8, batch: 1067, loss: 0.2928777039051056\n",
      "epoch: 8, batch: 1068, loss: 0.30990567803382874\n",
      "epoch: 8, batch: 1069, loss: 0.6873661875724792\n",
      "epoch: 8, batch: 1070, loss: 0.662628710269928\n",
      "epoch: 8, batch: 1071, loss: 0.3216312825679779\n",
      "epoch: 8, batch: 1072, loss: 0.4972946345806122\n",
      "epoch: 8, batch: 1073, loss: 0.4516447186470032\n",
      "epoch: 8, batch: 1074, loss: 0.655240535736084\n",
      "epoch: 8, batch: 1075, loss: 0.21991784870624542\n",
      "epoch: 8, batch: 1076, loss: 0.38636714220046997\n",
      "epoch: 8, batch: 1077, loss: 0.456281840801239\n",
      "epoch: 8, batch: 1078, loss: 0.44519221782684326\n",
      "epoch: 8, batch: 1079, loss: 0.39180701971054077\n",
      "epoch: 8, batch: 1080, loss: 0.6037657856941223\n",
      "epoch: 8, batch: 1081, loss: 0.46022501587867737\n",
      "epoch: 8, batch: 1082, loss: 0.7261639833450317\n",
      "epoch: 8, batch: 1083, loss: 0.2511236369609833\n",
      "epoch: 8, batch: 1084, loss: 0.4139545261859894\n",
      "epoch: 8, batch: 1085, loss: 0.33160996437072754\n",
      "epoch: 8, batch: 1086, loss: 0.45230603218078613\n",
      "epoch: 8, batch: 1087, loss: 0.6130720376968384\n",
      "epoch: 8, batch: 1088, loss: 0.3554159104824066\n",
      "epoch: 8, batch: 1089, loss: 0.350264310836792\n",
      "epoch: 8, batch: 1090, loss: 0.30972474813461304\n",
      "epoch: 8, batch: 1091, loss: 0.39633285999298096\n",
      "epoch: 8, batch: 1092, loss: 0.4192156195640564\n",
      "epoch: 8, batch: 1093, loss: 0.6354976892471313\n",
      "epoch: 8, batch: 1094, loss: 0.26408663392066956\n",
      "epoch: 8, batch: 1095, loss: 0.5343301296234131\n",
      "epoch: 8, batch: 1096, loss: 0.4199643135070801\n",
      "epoch: 8, batch: 1097, loss: 0.46272045373916626\n",
      "epoch: 8, batch: 1098, loss: 0.525944709777832\n",
      "epoch: 8, batch: 1099, loss: 0.5048608779907227\n",
      "epoch: 8, batch: 1100, loss: 0.29883018136024475\n",
      "epoch: 8, batch: 1101, loss: 0.5319706201553345\n",
      "epoch: 8, batch: 1102, loss: 0.46028420329093933\n",
      "epoch: 8, batch: 1103, loss: 0.6807697415351868\n",
      "epoch: 8, batch: 1104, loss: 0.8889502286911011\n",
      "epoch: 8, batch: 1105, loss: 0.49484124779701233\n",
      "epoch: 8, batch: 1106, loss: 0.5084614753723145\n",
      "epoch: 8, batch: 1107, loss: 0.6362051963806152\n",
      "epoch: 8, batch: 1108, loss: 0.4286356270313263\n",
      "epoch: 8, batch: 1109, loss: 0.651762843132019\n",
      "epoch: 8, batch: 1110, loss: 0.41110163927078247\n",
      "epoch: 8, batch: 1111, loss: 0.6935591697692871\n",
      "epoch: 8, batch: 1112, loss: 0.5247112512588501\n",
      "epoch: 8, batch: 1113, loss: 0.3839017152786255\n",
      "epoch: 8, batch: 1114, loss: 0.32802313566207886\n",
      "epoch: 8, batch: 1115, loss: 0.39938658475875854\n",
      "epoch: 8, batch: 1116, loss: 0.6200962662696838\n",
      "epoch: 8, batch: 1117, loss: 0.8897954225540161\n",
      "epoch: 8, batch: 1118, loss: 0.4740239381790161\n",
      "epoch: 8, batch: 1119, loss: 0.4309806525707245\n",
      "epoch: 8, batch: 1120, loss: 0.2734334468841553\n",
      "epoch: 8, batch: 1121, loss: 0.44906848669052124\n",
      "epoch: 8, batch: 1122, loss: 0.5919376015663147\n",
      "epoch: 8, batch: 1123, loss: 0.5294399261474609\n",
      "epoch: 8, batch: 1124, loss: 0.5741797089576721\n",
      "epoch: 8, batch: 1125, loss: 0.4336748719215393\n",
      "epoch: 8, batch: 1126, loss: 0.5144349932670593\n",
      "epoch: 8, batch: 1127, loss: 0.41621118783950806\n",
      "epoch: 8, batch: 1128, loss: 0.6410443186759949\n",
      "epoch: 8, batch: 1129, loss: 0.3527706265449524\n",
      "epoch: 8, batch: 1130, loss: 0.5809401869773865\n",
      "epoch: 8, batch: 1131, loss: 0.4215461015701294\n",
      "epoch: 8, batch: 1132, loss: 0.38652923703193665\n",
      "epoch: 8, batch: 1133, loss: 0.5066463351249695\n",
      "epoch: 8, batch: 1134, loss: 0.8659170269966125\n",
      "epoch: 8, batch: 1135, loss: 0.5545994639396667\n",
      "epoch: 8, batch: 1136, loss: 0.633503794670105\n",
      "epoch: 8, batch: 1137, loss: 0.49674034118652344\n",
      "epoch: 8, batch: 1138, loss: 0.3972083628177643\n",
      "epoch: 8, batch: 1139, loss: 0.3834591507911682\n",
      "epoch: 8, batch: 1140, loss: 0.4598589241504669\n",
      "epoch: 8, batch: 1141, loss: 0.2676961421966553\n",
      "epoch: 8, batch: 1142, loss: 0.49897435307502747\n",
      "epoch: 8, batch: 1143, loss: 0.6207000613212585\n",
      "epoch: 8, batch: 1144, loss: 0.4188000559806824\n",
      "epoch: 8, batch: 1145, loss: 0.8774157762527466\n",
      "epoch: 8, batch: 1146, loss: 0.643528938293457\n",
      "epoch: 8, batch: 1147, loss: 0.6301771998405457\n",
      "epoch: 8, batch: 1148, loss: 0.5918904542922974\n",
      "epoch: 8, batch: 1149, loss: 0.48137304186820984\n",
      "epoch: 8, batch: 1150, loss: 0.5869990587234497\n",
      "epoch: 8, batch: 1151, loss: 0.4547558128833771\n",
      "epoch: 8, batch: 1152, loss: 0.49527204036712646\n",
      "epoch: 8, batch: 1153, loss: 0.6189370155334473\n",
      "epoch: 8, batch: 1154, loss: 0.28281861543655396\n",
      "epoch: 8, batch: 1155, loss: 0.43660956621170044\n",
      "epoch: 8, batch: 1156, loss: 0.2549031376838684\n",
      "epoch: 8, batch: 1157, loss: 0.3093715012073517\n",
      "epoch: 8, batch: 1158, loss: 0.4747447371482849\n",
      "epoch: 8, batch: 1159, loss: 0.46757328510284424\n",
      "epoch: 8, batch: 1160, loss: 0.34859731793403625\n",
      "epoch: 8, batch: 1161, loss: 0.5412876605987549\n",
      "epoch: 8, batch: 1162, loss: 0.30373603105545044\n",
      "epoch: 8, batch: 1163, loss: 0.3034326434135437\n",
      "epoch: 8, batch: 1164, loss: 0.5268446207046509\n",
      "epoch: 8, batch: 1165, loss: 0.4228004515171051\n",
      "epoch: 8, batch: 1166, loss: 0.5286779999732971\n",
      "epoch: 8, batch: 1167, loss: 0.5285093784332275\n",
      "epoch: 8, batch: 1168, loss: 0.3868902623653412\n",
      "epoch: 8, batch: 1169, loss: 0.33121371269226074\n",
      "epoch: 8, batch: 1170, loss: 0.49928581714630127\n",
      "epoch: 8, batch: 1171, loss: 0.6562674045562744\n",
      "epoch: 8, batch: 1172, loss: 0.30170324444770813\n",
      "epoch: 8, batch: 1173, loss: 0.309397429227829\n",
      "epoch: 8, batch: 1174, loss: 0.5607514381408691\n",
      "epoch: 8, batch: 1175, loss: 0.18223105370998383\n",
      "epoch: 8, batch: 1176, loss: 0.2870919406414032\n",
      "epoch: 8, batch: 1177, loss: 0.550396740436554\n",
      "epoch: 8, batch: 1178, loss: 0.34710580110549927\n",
      "epoch: 8, batch: 1179, loss: 0.5980291366577148\n",
      "epoch: 8, batch: 1180, loss: 0.5511442422866821\n",
      "epoch: 8, batch: 1181, loss: 0.23190449178218842\n",
      "epoch: 8, batch: 1182, loss: 0.5136892795562744\n",
      "epoch: 8, batch: 1183, loss: 0.4665805995464325\n",
      "epoch: 8, batch: 1184, loss: 0.7383247017860413\n",
      "epoch: 8, batch: 1185, loss: 0.7341028451919556\n",
      "epoch: 8, batch: 1186, loss: 0.33774635195732117\n",
      "epoch: 8, batch: 1187, loss: 0.29560455679893494\n",
      "epoch: 8, batch: 1188, loss: 0.5241968035697937\n",
      "epoch: 8, batch: 1189, loss: 0.377579003572464\n",
      "epoch: 8, batch: 1190, loss: 0.43627408146858215\n",
      "epoch: 8, batch: 1191, loss: 0.6776633858680725\n",
      "epoch: 8, batch: 1192, loss: 0.7195332050323486\n",
      "epoch: 8, batch: 1193, loss: 0.4456387460231781\n",
      "epoch: 8, batch: 1194, loss: 0.5774539113044739\n",
      "epoch: 8, batch: 1195, loss: 0.4126850366592407\n",
      "epoch: 8, batch: 1196, loss: 0.4177287817001343\n",
      "epoch: 8, batch: 1197, loss: 0.5313181281089783\n",
      "epoch: 8, batch: 1198, loss: 0.3914004862308502\n",
      "epoch: 8, batch: 1199, loss: 0.6153164505958557\n",
      "epoch: 8, batch: 1200, loss: 0.48639094829559326\n",
      "epoch: 8, batch: 1201, loss: 0.39787063002586365\n",
      "epoch: 8, batch: 1202, loss: 0.5263733267784119\n",
      "epoch: 8, batch: 1203, loss: 0.32951316237449646\n",
      "epoch: 8, batch: 1204, loss: 0.3814312219619751\n",
      "epoch: 8, batch: 1205, loss: 0.417747437953949\n",
      "epoch: 8, batch: 1206, loss: 0.4618748724460602\n",
      "epoch: 8, batch: 1207, loss: 0.4603111147880554\n",
      "epoch: 8, batch: 1208, loss: 0.6320239305496216\n",
      "epoch: 8, batch: 1209, loss: 0.5753443241119385\n",
      "epoch: 8, batch: 1210, loss: 0.5042054653167725\n",
      "epoch: 8, batch: 1211, loss: 0.4055236577987671\n",
      "epoch: 8, batch: 1212, loss: 0.4267245829105377\n",
      "epoch: 8, batch: 1213, loss: 0.6403098702430725\n",
      "epoch: 8, batch: 1214, loss: 0.5236917734146118\n",
      "epoch: 8, batch: 1215, loss: 0.3636813163757324\n",
      "epoch: 8, batch: 1216, loss: 0.6202242374420166\n",
      "epoch: 8, batch: 1217, loss: 0.3933434784412384\n",
      "epoch: 8, batch: 1218, loss: 1.0301250219345093\n",
      "epoch: 8, batch: 1219, loss: 1.0108648538589478\n",
      "epoch: 8, batch: 1220, loss: 0.5650444030761719\n",
      "epoch: 8, batch: 1221, loss: 0.36967119574546814\n",
      "epoch: 8, batch: 1222, loss: 0.48342639207839966\n",
      "epoch: 8, batch: 1223, loss: 0.5323611497879028\n",
      "epoch: 8, batch: 1224, loss: 0.3329891562461853\n",
      "epoch: 8, batch: 1225, loss: 0.37321171164512634\n",
      "epoch: 8, batch: 1226, loss: 0.4486706554889679\n",
      "epoch: 8, batch: 1227, loss: 0.3633406162261963\n",
      "epoch: 8, batch: 1228, loss: 0.3517455458641052\n",
      "epoch: 8, batch: 1229, loss: 0.6444011926651001\n",
      "epoch: 8, batch: 1230, loss: 0.5441398620605469\n",
      "epoch: 8, batch: 1231, loss: 0.4495021402835846\n",
      "epoch: 8, batch: 1232, loss: 0.7429977059364319\n",
      "epoch: 8, batch: 1233, loss: 0.46713364124298096\n",
      "epoch: 8, batch: 1234, loss: 0.43120378255844116\n",
      "epoch: 8, batch: 1235, loss: 0.3879089057445526\n",
      "epoch: 8, batch: 1236, loss: 0.47709742188453674\n",
      "epoch: 8, batch: 1237, loss: 0.5346387028694153\n",
      "epoch: 8, batch: 1238, loss: 0.28787627816200256\n",
      "epoch: 8, batch: 1239, loss: 0.2982015311717987\n",
      "epoch: 8, batch: 1240, loss: 0.4460054934024811\n",
      "epoch: 8, batch: 1241, loss: 0.5911667943000793\n",
      "epoch: 8, batch: 1242, loss: 0.6535658240318298\n",
      "epoch: 8, batch: 1243, loss: 0.22500357031822205\n",
      "epoch: 8, batch: 1244, loss: 0.46641090512275696\n",
      "epoch: 8, batch: 1245, loss: 0.21925844252109528\n",
      "epoch: 8, batch: 1246, loss: 0.7707667350769043\n",
      "epoch: 8, batch: 1247, loss: 0.41078299283981323\n",
      "epoch: 8, batch: 1248, loss: 0.27713534235954285\n",
      "epoch: 8, batch: 1249, loss: 0.34987252950668335\n",
      "epoch: 8, batch: 1250, loss: 0.3488726019859314\n",
      "epoch: 8, batch: 1251, loss: 0.41273269057273865\n",
      "epoch: 8, batch: 1252, loss: 0.49742555618286133\n",
      "epoch: 8, batch: 1253, loss: 0.3315001428127289\n",
      "epoch: 8, batch: 1254, loss: 0.41036170721054077\n",
      "epoch: 8, batch: 1255, loss: 0.726684033870697\n",
      "epoch: 8, batch: 1256, loss: 0.4128406047821045\n",
      "epoch: 8, batch: 1257, loss: 0.4177994728088379\n",
      "epoch: 8, batch: 1258, loss: 0.32519832253456116\n",
      "epoch: 8, batch: 1259, loss: 0.49382081627845764\n",
      "epoch: 8, batch: 1260, loss: 0.463413804769516\n",
      "epoch: 8, batch: 1261, loss: 0.4230223596096039\n",
      "epoch: 8, batch: 1262, loss: 0.3311947286128998\n",
      "epoch: 8, batch: 1263, loss: 0.5338982939720154\n",
      "epoch: 8, batch: 1264, loss: 0.48946666717529297\n",
      "epoch: 8, batch: 1265, loss: 0.8026395440101624\n",
      "epoch: 8, batch: 1266, loss: 0.29466086626052856\n",
      "epoch: 8, batch: 1267, loss: 0.33809584379196167\n",
      "epoch: 8, batch: 1268, loss: 0.5354325175285339\n",
      "epoch: 8, batch: 1269, loss: 0.363787442445755\n",
      "epoch: 8, batch: 1270, loss: 0.42334476113319397\n",
      "epoch: 8, batch: 1271, loss: 0.5635184645652771\n",
      "epoch: 8, batch: 1272, loss: 0.3595168888568878\n",
      "epoch: 8, batch: 1273, loss: 0.5864441394805908\n",
      "epoch: 8, batch: 1274, loss: 0.31466609239578247\n",
      "epoch: 8, batch: 1275, loss: 0.48704594373703003\n",
      "epoch: 8, batch: 1276, loss: 0.7612841129302979\n",
      "epoch: 8, batch: 1277, loss: 0.42086440324783325\n",
      "epoch: 8, batch: 1278, loss: 0.47157129645347595\n",
      "epoch: 8, batch: 1279, loss: 0.5704284906387329\n",
      "epoch: 8, batch: 1280, loss: 0.4091026484966278\n",
      "epoch: 8, batch: 1281, loss: 0.5193476676940918\n",
      "epoch: 8, batch: 1282, loss: 0.46073174476623535\n",
      "epoch: 8, batch: 1283, loss: 0.39062145352363586\n",
      "epoch: 8, batch: 1284, loss: 0.4164566695690155\n",
      "epoch: 8, batch: 1285, loss: 0.5593349933624268\n",
      "epoch: 8, batch: 1286, loss: 0.4900533854961395\n",
      "epoch: 8, batch: 1287, loss: 0.46843716502189636\n",
      "epoch: 8, batch: 1288, loss: 0.6093569397926331\n",
      "epoch: 8, batch: 1289, loss: 0.22980815172195435\n",
      "epoch: 8, batch: 1290, loss: 0.5013285279273987\n",
      "epoch: 8, batch: 1291, loss: 0.4084485173225403\n",
      "epoch: 8, batch: 1292, loss: 0.3650137484073639\n",
      "epoch: 8, batch: 1293, loss: 0.3608276844024658\n",
      "epoch: 8, batch: 1294, loss: 0.4802470803260803\n",
      "epoch: 8, batch: 1295, loss: 0.6596675515174866\n",
      "epoch: 8, batch: 1296, loss: 0.47038450837135315\n",
      "epoch: 8, batch: 1297, loss: 0.3991217017173767\n",
      "epoch: 8, batch: 1298, loss: 0.36123713850975037\n",
      "epoch: 8, batch: 1299, loss: 0.2452644258737564\n",
      "epoch: 8, batch: 1300, loss: 0.30716001987457275\n",
      "epoch: 8, batch: 1301, loss: 0.5542555451393127\n",
      "epoch: 8, batch: 1302, loss: 0.3111780285835266\n",
      "epoch: 8, batch: 1303, loss: 0.288943886756897\n",
      "epoch: 8, batch: 1304, loss: 0.48057663440704346\n",
      "epoch: 8, batch: 1305, loss: 0.30827635526657104\n",
      "epoch: 8, batch: 1306, loss: 0.4057449400424957\n",
      "epoch: 8, batch: 1307, loss: 0.370606392621994\n",
      "epoch: 8, batch: 1308, loss: 0.5687627792358398\n",
      "epoch: 8, batch: 1309, loss: 0.4094245135784149\n",
      "epoch: 8, batch: 1310, loss: 0.6589077711105347\n",
      "epoch: 8, batch: 1311, loss: 0.3631468713283539\n",
      "epoch: 8, batch: 1312, loss: 0.3264622092247009\n",
      "epoch: 8, batch: 1313, loss: 0.5283986330032349\n",
      "epoch: 8, batch: 1314, loss: 0.2913797199726105\n",
      "epoch: 8, batch: 1315, loss: 0.4685731530189514\n",
      "epoch: 8, batch: 1316, loss: 0.506672203540802\n",
      "epoch: 8, batch: 1317, loss: 0.5159609317779541\n",
      "epoch: 8, batch: 1318, loss: 0.614865243434906\n",
      "epoch: 8, batch: 1319, loss: 0.5431656837463379\n",
      "epoch: 8, batch: 1320, loss: 0.4127568006515503\n",
      "epoch: 8, batch: 1321, loss: 0.4209134876728058\n",
      "epoch: 8, batch: 1322, loss: 0.3244931697845459\n",
      "epoch: 8, batch: 1323, loss: 0.3049285411834717\n",
      "epoch: 8, batch: 1324, loss: 0.5524850487709045\n",
      "epoch: 8, batch: 1325, loss: 0.5038559436798096\n",
      "epoch: 8, batch: 1326, loss: 0.4435639977455139\n",
      "epoch: 8, batch: 1327, loss: 0.49627748131752014\n",
      "epoch: 8, batch: 1328, loss: 0.31987735629081726\n",
      "epoch: 8, batch: 1329, loss: 0.4109684228897095\n",
      "epoch: 8, batch: 1330, loss: 0.5339633226394653\n",
      "epoch: 8, batch: 1331, loss: 0.38692161440849304\n",
      "epoch: 8, batch: 1332, loss: 0.40643227100372314\n",
      "epoch: 8, batch: 1333, loss: 0.4907037019729614\n",
      "epoch: 8, batch: 1334, loss: 0.17339013516902924\n",
      "epoch: 8, batch: 1335, loss: 0.2991558611392975\n",
      "epoch: 8, batch: 1336, loss: 0.5347524285316467\n",
      "epoch: 8, batch: 1337, loss: 0.48660072684288025\n",
      "epoch: 8, batch: 1338, loss: 0.4182199239730835\n",
      "epoch: 8, batch: 1339, loss: 0.29159238934516907\n",
      "epoch: 8, batch: 1340, loss: 0.41419512033462524\n",
      "epoch: 8, batch: 1341, loss: 0.4652961790561676\n",
      "epoch: 8, batch: 1342, loss: 0.3112604320049286\n",
      "epoch: 8, batch: 1343, loss: 0.4365774691104889\n",
      "epoch: 8, batch: 1344, loss: 0.5317782759666443\n",
      "epoch: 8, batch: 1345, loss: 0.5061681866645813\n",
      "epoch: 8, batch: 1346, loss: 0.41652053594589233\n",
      "epoch: 8, batch: 1347, loss: 0.4047529697418213\n",
      "epoch: 8, batch: 1348, loss: 0.5080034732818604\n",
      "epoch: 8, batch: 1349, loss: 0.26469317078590393\n",
      "epoch: 8, batch: 1350, loss: 0.26113927364349365\n",
      "epoch: 8, batch: 1351, loss: 0.654584527015686\n",
      "epoch: 8, batch: 1352, loss: 0.5425577163696289\n",
      "epoch: 8, batch: 1353, loss: 0.2137666940689087\n",
      "epoch: 8, batch: 1354, loss: 0.5576763153076172\n",
      "epoch: 8, batch: 1355, loss: 0.3250125050544739\n",
      "epoch: 8, batch: 1356, loss: 0.6466180682182312\n",
      "epoch: 8, batch: 1357, loss: 0.25609567761421204\n",
      "epoch: 8, batch: 1358, loss: 0.3662129342556\n",
      "epoch: 8, batch: 1359, loss: 0.4885700047016144\n",
      "epoch: 8, batch: 1360, loss: 0.2832788825035095\n",
      "epoch: 8, batch: 1361, loss: 0.36400750279426575\n",
      "epoch: 8, batch: 1362, loss: 0.5977540016174316\n",
      "epoch: 8, batch: 1363, loss: 0.2882634997367859\n",
      "epoch: 8, batch: 1364, loss: 0.4332066476345062\n",
      "epoch: 8, batch: 1365, loss: 0.7306880354881287\n",
      "epoch: 8, batch: 1366, loss: 0.4489559233188629\n",
      "epoch: 8, batch: 1367, loss: 0.5449070334434509\n",
      "epoch: 8, batch: 1368, loss: 0.4147568941116333\n",
      "epoch: 8, batch: 1369, loss: 0.35305821895599365\n",
      "epoch: 8, batch: 1370, loss: 0.4774145185947418\n",
      "epoch: 8, batch: 1371, loss: 0.5334087014198303\n",
      "epoch: 8, batch: 1372, loss: 0.549720048904419\n",
      "epoch: 8, batch: 1373, loss: 0.20945268869400024\n",
      "epoch: 8, batch: 1374, loss: 0.691192626953125\n",
      "epoch: 8, batch: 1375, loss: 0.3734937608242035\n",
      "epoch: 8, batch: 1376, loss: 0.41669490933418274\n",
      "epoch: 8, batch: 1377, loss: 0.4790555238723755\n",
      "epoch: 8, batch: 1378, loss: 0.3115052580833435\n",
      "epoch: 8, batch: 1379, loss: 0.5482564568519592\n",
      "epoch: 8, batch: 1380, loss: 0.3016885817050934\n",
      "epoch: 8, batch: 1381, loss: 0.6517930030822754\n",
      "epoch: 8, batch: 1382, loss: 0.670336127281189\n",
      "epoch: 8, batch: 1383, loss: 0.5609294176101685\n",
      "epoch: 8, batch: 1384, loss: 0.3088527023792267\n",
      "epoch: 8, batch: 1385, loss: 0.5726177096366882\n",
      "epoch: 8, batch: 1386, loss: 0.7566213607788086\n",
      "epoch: 8, batch: 1387, loss: 0.4585127830505371\n",
      "epoch: 8, batch: 1388, loss: 0.46975067257881165\n",
      "epoch: 8, batch: 1389, loss: 0.6294593214988708\n",
      "epoch: 8, batch: 1390, loss: 0.9199979305267334\n",
      "epoch: 8, batch: 1391, loss: 0.3707559406757355\n",
      "epoch: 8, batch: 1392, loss: 0.7366100549697876\n",
      "epoch: 8, batch: 1393, loss: 0.316682904958725\n",
      "epoch: 8, batch: 1394, loss: 0.46840083599090576\n",
      "epoch: 8, batch: 1395, loss: 0.46864601969718933\n",
      "epoch: 8, batch: 1396, loss: 0.3827822804450989\n",
      "epoch: 8, batch: 1397, loss: 0.38483723998069763\n",
      "epoch: 8, batch: 1398, loss: 0.4098578095436096\n",
      "epoch: 8, batch: 1399, loss: 0.7580369710922241\n",
      "epoch: 8, batch: 1400, loss: 0.48023921251296997\n",
      "epoch: 8, batch: 1401, loss: 0.521982729434967\n",
      "epoch: 8, batch: 1402, loss: 0.33938249945640564\n",
      "epoch: 8, batch: 1403, loss: 0.4157498776912689\n",
      "epoch: 8, batch: 1404, loss: 0.46007925271987915\n",
      "epoch: 8, batch: 1405, loss: 0.2854934632778168\n",
      "epoch: 8, batch: 1406, loss: 0.420808345079422\n",
      "epoch: 8, batch: 1407, loss: 0.531007707118988\n",
      "epoch: 8, batch: 1408, loss: 0.534800112247467\n",
      "epoch: 8, batch: 1409, loss: 0.8112954497337341\n",
      "epoch: 8, batch: 1410, loss: 0.8675017356872559\n",
      "epoch: 8, batch: 1411, loss: 0.4846529960632324\n",
      "epoch: 8, batch: 1412, loss: 0.2529962360858917\n",
      "epoch: 8, batch: 1413, loss: 0.720333456993103\n",
      "epoch: 8, batch: 1414, loss: 0.3567005395889282\n",
      "epoch: 8, batch: 1415, loss: 0.28960055112838745\n",
      "epoch: 8, batch: 1416, loss: 0.6084983348846436\n",
      "epoch: 8, batch: 1417, loss: 0.28284063935279846\n",
      "epoch: 8, batch: 1418, loss: 0.6197629570960999\n",
      "epoch: 8, batch: 1419, loss: 0.3420940935611725\n",
      "epoch: 8, batch: 1420, loss: 0.6035277843475342\n",
      "epoch: 8, batch: 1421, loss: 0.35086584091186523\n",
      "epoch: 8, batch: 1422, loss: 0.37374716997146606\n",
      "epoch: 8, batch: 1423, loss: 0.43399593234062195\n",
      "epoch: 8, batch: 1424, loss: 0.27065935730934143\n",
      "epoch: 8, batch: 1425, loss: 0.42736202478408813\n",
      "epoch: 8, batch: 1426, loss: 0.44987475872039795\n",
      "epoch: 8, batch: 1427, loss: 0.5202902555465698\n",
      "epoch: 8, batch: 1428, loss: 0.48258307576179504\n",
      "epoch: 8, batch: 1429, loss: 0.5676352381706238\n",
      "epoch: 8, batch: 1430, loss: 0.49892303347587585\n",
      "epoch: 8, batch: 1431, loss: 0.4605807662010193\n",
      "epoch: 8, batch: 1432, loss: 0.6335793733596802\n",
      "epoch: 8, batch: 1433, loss: 0.6330935955047607\n",
      "epoch: 8, batch: 1434, loss: 0.6043182015419006\n",
      "epoch: 8, batch: 1435, loss: 0.5559554100036621\n",
      "epoch: 8, batch: 1436, loss: 0.46074023842811584\n",
      "epoch: 8, batch: 1437, loss: 0.2715674340724945\n",
      "epoch: 8, batch: 1438, loss: 0.6159707903862\n",
      "epoch: 8, batch: 1439, loss: 0.5771142244338989\n",
      "epoch: 8, batch: 1440, loss: 0.32152679562568665\n",
      "epoch: 8, batch: 1441, loss: 0.49877405166625977\n",
      "epoch: 8, batch: 1442, loss: 0.7297434210777283\n",
      "epoch: 8, batch: 1443, loss: 0.7869980931282043\n",
      "epoch: 8, batch: 1444, loss: 0.27055203914642334\n",
      "epoch: 8, batch: 1445, loss: 0.5818546414375305\n",
      "epoch: 8, batch: 1446, loss: 0.46098601818084717\n",
      "epoch: 8, batch: 1447, loss: 0.1923174113035202\n",
      "epoch: 8, batch: 1448, loss: 0.2180774211883545\n",
      "epoch: 8, batch: 1449, loss: 0.4644404351711273\n",
      "epoch: 8, batch: 1450, loss: 0.5706431865692139\n",
      "epoch: 8, batch: 1451, loss: 0.6395021080970764\n",
      "epoch: 8, batch: 1452, loss: 0.5863478779792786\n",
      "epoch: 8, batch: 1453, loss: 0.3161850571632385\n",
      "epoch: 8, batch: 1454, loss: 0.39114388823509216\n",
      "epoch: 8, batch: 1455, loss: 0.4692227840423584\n",
      "epoch: 8, batch: 1456, loss: 0.633816659450531\n",
      "epoch: 8, batch: 1457, loss: 0.5269719362258911\n",
      "epoch: 8, batch: 1458, loss: 0.3297792971134186\n",
      "epoch: 8, batch: 1459, loss: 0.4082735776901245\n",
      "epoch: 8, batch: 1460, loss: 0.6438724994659424\n",
      "epoch: 8, batch: 1461, loss: 0.5405818819999695\n",
      "epoch: 8, batch: 1462, loss: 0.28820857405662537\n",
      "epoch: 8, batch: 1463, loss: 0.6212930679321289\n",
      "epoch: 8, batch: 1464, loss: 0.2615581750869751\n",
      "epoch: 8, batch: 1465, loss: 0.2622784972190857\n",
      "epoch: 8, batch: 1466, loss: 0.35364675521850586\n",
      "epoch: 8, batch: 1467, loss: 0.3527008593082428\n",
      "epoch: 8, batch: 1468, loss: 0.4234625995159149\n",
      "epoch: 8, batch: 1469, loss: 0.34823599457740784\n",
      "epoch: 8, batch: 1470, loss: 0.39492273330688477\n",
      "epoch: 8, batch: 1471, loss: 0.28239360451698303\n",
      "epoch: 8, batch: 1472, loss: 0.5393112897872925\n",
      "epoch: 8, batch: 1473, loss: 0.455837607383728\n",
      "epoch: 8, batch: 1474, loss: 0.6236034035682678\n",
      "epoch: 8, batch: 1475, loss: 0.316510945558548\n",
      "epoch: 8, batch: 1476, loss: 0.30602654814720154\n",
      "epoch: 8, batch: 1477, loss: 0.3406384289264679\n",
      "epoch: 8, batch: 1478, loss: 0.44136905670166016\n",
      "epoch: 8, batch: 1479, loss: 0.7783337831497192\n",
      "epoch: 8, batch: 1480, loss: 0.36945199966430664\n",
      "epoch: 8, batch: 1481, loss: 0.3900336027145386\n",
      "epoch: 8, batch: 1482, loss: 0.3435339629650116\n",
      "epoch: 8, batch: 1483, loss: 0.4390590488910675\n",
      "epoch: 8, batch: 1484, loss: 0.7502784132957458\n",
      "epoch: 8, batch: 1485, loss: 0.4545528292655945\n",
      "epoch: 8, batch: 1486, loss: 0.31651973724365234\n",
      "epoch: 8, batch: 1487, loss: 0.461843341588974\n",
      "epoch: 8, batch: 1488, loss: 0.4233020544052124\n",
      "epoch: 8, batch: 1489, loss: 0.46226879954338074\n",
      "epoch: 8, batch: 1490, loss: 0.5810745358467102\n",
      "epoch: 8, batch: 1491, loss: 0.5215622782707214\n",
      "epoch: 8, batch: 1492, loss: 0.22043602168560028\n",
      "epoch: 8, batch: 1493, loss: 0.34828850626945496\n",
      "epoch: 8, batch: 1494, loss: 0.6130886077880859\n",
      "epoch: 8, batch: 1495, loss: 0.3606717586517334\n",
      "epoch: 8, batch: 1496, loss: 0.5317656397819519\n",
      "epoch: 8, batch: 1497, loss: 0.2957456409931183\n",
      "epoch: 8, batch: 1498, loss: 0.5588811039924622\n",
      "epoch: 8, batch: 1499, loss: 0.488992303609848\n",
      "epoch: 8, batch: 1500, loss: 0.4577074348926544\n",
      "epoch: 8, batch: 1501, loss: 0.3727342188358307\n",
      "epoch: 8, batch: 1502, loss: 0.49400919675827026\n",
      "epoch: 8, batch: 1503, loss: 0.49510520696640015\n",
      "epoch: 8, batch: 1504, loss: 0.4871442914009094\n",
      "epoch: 8, batch: 1505, loss: 0.7176668643951416\n",
      "epoch: 8, batch: 1506, loss: 0.42048969864845276\n",
      "epoch: 8, batch: 1507, loss: 0.5333756804466248\n",
      "epoch: 8, batch: 1508, loss: 0.45616063475608826\n",
      "epoch: 8, batch: 1509, loss: 0.4811083674430847\n",
      "epoch: 8, batch: 1510, loss: 0.3889857530593872\n",
      "epoch: 8, batch: 1511, loss: 0.6696762442588806\n",
      "epoch: 8, batch: 1512, loss: 0.5177364349365234\n",
      "epoch: 8, batch: 1513, loss: 0.40167924761772156\n",
      "epoch: 8, batch: 1514, loss: 0.45773282647132874\n",
      "epoch: 8, batch: 1515, loss: 0.3522321283817291\n",
      "epoch: 8, batch: 1516, loss: 0.6185799837112427\n",
      "epoch: 8, batch: 1517, loss: 0.9158720374107361\n",
      "epoch: 8, batch: 1518, loss: 0.2798686921596527\n",
      "epoch: 8, batch: 1519, loss: 0.41762015223503113\n",
      "epoch: 8, batch: 1520, loss: 0.5052345991134644\n",
      "epoch: 8, batch: 1521, loss: 0.5358083248138428\n",
      "epoch: 8, batch: 1522, loss: 0.539171040058136\n",
      "epoch: 8, batch: 1523, loss: 0.33275070786476135\n",
      "epoch: 8, batch: 1524, loss: 0.3254951536655426\n",
      "epoch: 8, batch: 1525, loss: 0.48450347781181335\n",
      "epoch: 8, batch: 1526, loss: 0.2532949447631836\n",
      "epoch: 8, batch: 1527, loss: 0.5238834619522095\n",
      "epoch: 8, batch: 1528, loss: 0.6038524508476257\n",
      "epoch: 8, batch: 1529, loss: 0.38373270630836487\n",
      "epoch: 8, batch: 1530, loss: 0.6794840097427368\n",
      "epoch: 8, batch: 1531, loss: 0.5265019536018372\n",
      "epoch: 8, batch: 1532, loss: 0.5287107825279236\n",
      "epoch: 8, batch: 1533, loss: 0.783976674079895\n",
      "epoch: 8, batch: 1534, loss: 0.4804343283176422\n",
      "epoch: 8, batch: 1535, loss: 0.34221887588500977\n",
      "epoch: 8, batch: 1536, loss: 0.4979475438594818\n",
      "epoch: 8, batch: 1537, loss: 0.4303832948207855\n",
      "epoch: 8, batch: 1538, loss: 0.6642534732818604\n",
      "epoch: 8, batch: 1539, loss: 0.3987671434879303\n",
      "epoch: 8, batch: 1540, loss: 0.2624383270740509\n",
      "epoch: 8, batch: 1541, loss: 0.43316391110420227\n",
      "epoch: 8, batch: 1542, loss: 0.28975406289100647\n",
      "epoch: 8, batch: 1543, loss: 0.2540891766548157\n",
      "epoch: 8, batch: 1544, loss: 0.477586567401886\n",
      "epoch: 8, batch: 1545, loss: 0.43436238169670105\n",
      "epoch: 8, batch: 1546, loss: 0.38634639978408813\n",
      "epoch: 8, batch: 1547, loss: 0.44279664754867554\n",
      "epoch: 8, batch: 1548, loss: 0.4059084355831146\n",
      "epoch: 8, batch: 1549, loss: 0.28460630774497986\n",
      "epoch: 8, batch: 1550, loss: 0.43170076608657837\n",
      "epoch: 8, batch: 1551, loss: 0.5712175965309143\n",
      "epoch: 8, batch: 1552, loss: 0.6960967779159546\n",
      "epoch: 8, batch: 1553, loss: 0.4019097685813904\n",
      "epoch: 8, batch: 1554, loss: 0.3180249035358429\n",
      "epoch: 8, batch: 1555, loss: 0.4290459454059601\n",
      "epoch: 8, batch: 1556, loss: 0.42036008834838867\n",
      "epoch: 8, batch: 1557, loss: 0.5310859680175781\n",
      "epoch: 8, batch: 1558, loss: 0.48694682121276855\n",
      "epoch: 8, batch: 1559, loss: 0.3743593692779541\n",
      "epoch: 8, batch: 1560, loss: 0.5094528794288635\n",
      "epoch: 8, batch: 1561, loss: 0.501089870929718\n",
      "epoch: 8, batch: 1562, loss: 0.40206775069236755\n",
      "epoch: 8, batch: 1563, loss: 0.43264147639274597\n",
      "epoch: 8, batch: 1564, loss: 0.37352895736694336\n",
      "epoch: 8, batch: 1565, loss: 0.4236559271812439\n",
      "epoch: 8, batch: 1566, loss: 0.23863117396831512\n",
      "epoch: 8, batch: 1567, loss: 0.42913684248924255\n",
      "epoch: 8, batch: 1568, loss: 0.5443320274353027\n",
      "epoch: 8, batch: 1569, loss: 0.3470824360847473\n",
      "epoch: 8, batch: 1570, loss: 0.7559043169021606\n",
      "epoch: 8, batch: 1571, loss: 0.6030635237693787\n",
      "epoch: 8, batch: 1572, loss: 0.3129042088985443\n",
      "epoch: 8, batch: 1573, loss: 0.4084456264972687\n",
      "epoch: 8, batch: 1574, loss: 0.2418653964996338\n",
      "epoch: 8, batch: 1575, loss: 0.4517596662044525\n",
      "epoch: 8, batch: 1576, loss: 0.7452399134635925\n",
      "epoch: 8, batch: 1577, loss: 0.3927037715911865\n",
      "epoch: 8, batch: 1578, loss: 0.5079188346862793\n",
      "epoch: 8, batch: 1579, loss: 0.5600904822349548\n",
      "epoch: 8, batch: 1580, loss: 0.39919281005859375\n",
      "epoch: 8, batch: 1581, loss: 0.6486857533454895\n",
      "epoch: 8, batch: 1582, loss: 0.3272719383239746\n",
      "epoch: 8, batch: 1583, loss: 0.6288906335830688\n",
      "epoch: 8, batch: 1584, loss: 0.496071457862854\n",
      "epoch: 8, batch: 1585, loss: 0.5107309818267822\n",
      "epoch: 8, batch: 1586, loss: 0.571663498878479\n",
      "epoch: 8, batch: 1587, loss: 0.4818354547023773\n",
      "epoch: 8, batch: 1588, loss: 0.6042404174804688\n",
      "epoch: 8, batch: 1589, loss: 0.3972700834274292\n",
      "epoch: 8, batch: 1590, loss: 0.38242506980895996\n",
      "epoch: 8, batch: 1591, loss: 0.2579658031463623\n",
      "epoch: 8, batch: 1592, loss: 0.6529204249382019\n",
      "epoch: 8, batch: 1593, loss: 0.6094794273376465\n",
      "epoch: 8, batch: 1594, loss: 0.4707782566547394\n",
      "epoch: 8, batch: 1595, loss: 0.4931972324848175\n",
      "epoch: 8, batch: 1596, loss: 0.34365227818489075\n",
      "epoch: 8, batch: 1597, loss: 0.28714483976364136\n",
      "epoch: 8, batch: 1598, loss: 0.3739667236804962\n",
      "epoch: 8, batch: 1599, loss: 0.6653186678886414\n",
      "epoch: 8, batch: 1600, loss: 0.39572980999946594\n",
      "epoch: 8, batch: 1601, loss: 0.4519222676753998\n",
      "epoch: 8, batch: 1602, loss: 0.270857572555542\n",
      "epoch: 8, batch: 1603, loss: 0.522113025188446\n",
      "epoch: 8, batch: 1604, loss: 0.5557083487510681\n",
      "epoch: 8, batch: 1605, loss: 0.46060436964035034\n",
      "epoch: 8, batch: 1606, loss: 0.5488581657409668\n",
      "epoch: 8, batch: 1607, loss: 0.5936864614486694\n",
      "epoch: 8, batch: 1608, loss: 0.4641885459423065\n",
      "epoch: 8, batch: 1609, loss: 0.5257989764213562\n",
      "epoch: 8, batch: 1610, loss: 0.5804793834686279\n",
      "epoch: 8, batch: 1611, loss: 0.6094091534614563\n",
      "epoch: 8, batch: 1612, loss: 0.4099317789077759\n",
      "epoch: 8, batch: 1613, loss: 0.4158554971218109\n",
      "epoch: 8, batch: 1614, loss: 0.2716573178768158\n",
      "epoch: 8, batch: 1615, loss: 0.4045396149158478\n",
      "epoch: 8, batch: 1616, loss: 0.5538456439971924\n",
      "epoch: 8, batch: 1617, loss: 0.5863103866577148\n",
      "epoch: 8, batch: 1618, loss: 0.3917509913444519\n",
      "epoch: 8, batch: 1619, loss: 0.3117181062698364\n",
      "epoch: 8, batch: 1620, loss: 0.3222897946834564\n",
      "epoch: 8, batch: 1621, loss: 0.6391118764877319\n",
      "epoch: 8, batch: 1622, loss: 0.2952357232570648\n",
      "epoch: 8, batch: 1623, loss: 0.3336288332939148\n",
      "epoch: 8, batch: 1624, loss: 0.504220724105835\n",
      "epoch: 8, batch: 1625, loss: 0.3900946378707886\n",
      "epoch: 8, batch: 1626, loss: 0.5734732151031494\n",
      "epoch: 8, batch: 1627, loss: 0.38729074597358704\n",
      "epoch: 8, batch: 1628, loss: 0.38817235827445984\n",
      "epoch: 8, batch: 1629, loss: 0.6029098629951477\n",
      "epoch: 8, batch: 1630, loss: 0.39499062299728394\n",
      "epoch: 8, batch: 1631, loss: 0.3848032057285309\n",
      "epoch: 8, batch: 1632, loss: 0.5035524368286133\n",
      "epoch: 8, batch: 1633, loss: 0.6578838229179382\n",
      "epoch: 8, batch: 1634, loss: 0.3815244734287262\n",
      "epoch: 8, batch: 1635, loss: 0.4173137843608856\n",
      "epoch: 8, batch: 1636, loss: 0.5190783143043518\n",
      "epoch: 8, batch: 1637, loss: 0.4532925486564636\n",
      "epoch: 8, batch: 1638, loss: 0.4974619448184967\n",
      "epoch: 8, batch: 1639, loss: 0.3231751620769501\n",
      "epoch: 8, batch: 1640, loss: 0.35058873891830444\n",
      "epoch: 8, batch: 1641, loss: 0.32760128378868103\n",
      "epoch: 8, batch: 1642, loss: 0.3278684914112091\n",
      "epoch: 8, batch: 1643, loss: 0.45984214544296265\n",
      "epoch: 8, batch: 1644, loss: 0.49477648735046387\n",
      "epoch: 8, batch: 1645, loss: 0.252300888299942\n",
      "epoch: 8, batch: 1646, loss: 0.410437673330307\n",
      "epoch: 8, batch: 1647, loss: 0.3706757724285126\n",
      "epoch: 8, batch: 1648, loss: 0.35252833366394043\n",
      "epoch: 8, batch: 1649, loss: 0.28731364011764526\n",
      "epoch: 8, batch: 1650, loss: 0.45052993297576904\n",
      "epoch: 8, batch: 1651, loss: 0.5055868625640869\n",
      "epoch: 8, batch: 1652, loss: 0.7191345691680908\n",
      "epoch: 8, batch: 1653, loss: 0.3351981043815613\n",
      "epoch: 8, batch: 1654, loss: 0.36054855585098267\n",
      "epoch: 8, batch: 1655, loss: 0.30211472511291504\n",
      "epoch: 8, batch: 1656, loss: 0.41064101457595825\n",
      "epoch: 8, batch: 1657, loss: 0.6402310132980347\n",
      "epoch: 8, batch: 1658, loss: 0.3458114266395569\n",
      "epoch: 8, batch: 1659, loss: 0.5332936644554138\n",
      "epoch: 8, batch: 1660, loss: 0.30724823474884033\n",
      "epoch: 8, batch: 1661, loss: 0.24703428149223328\n",
      "epoch: 8, batch: 1662, loss: 0.500637948513031\n",
      "epoch: 8, batch: 1663, loss: 0.5630760788917542\n",
      "epoch: 8, batch: 1664, loss: 0.38975006341934204\n",
      "epoch: 8, batch: 1665, loss: 0.6371480822563171\n",
      "epoch: 8, batch: 1666, loss: 0.5872014760971069\n",
      "epoch: 8, batch: 1667, loss: 0.43380874395370483\n",
      "epoch: 8, batch: 1668, loss: 0.7659085392951965\n",
      "epoch: 8, batch: 1669, loss: 0.49880605936050415\n",
      "epoch: 8, batch: 1670, loss: 0.5115379095077515\n",
      "epoch: 8, batch: 1671, loss: 0.3548088073730469\n",
      "epoch: 8, batch: 1672, loss: 0.6458200216293335\n",
      "epoch: 8, batch: 1673, loss: 0.27912938594818115\n",
      "epoch: 8, batch: 1674, loss: 0.8660854697227478\n",
      "epoch: 8, batch: 1675, loss: 0.2574499845504761\n",
      "epoch: 8, batch: 1676, loss: 0.685539186000824\n",
      "epoch: 8, batch: 1677, loss: 0.46690940856933594\n",
      "epoch: 8, batch: 1678, loss: 0.5958659052848816\n",
      "epoch: 8, batch: 1679, loss: 0.3399509787559509\n",
      "epoch: 8, batch: 1680, loss: 0.44598281383514404\n",
      "epoch: 8, batch: 1681, loss: 0.29392343759536743\n",
      "epoch: 8, batch: 1682, loss: 0.5449304580688477\n",
      "epoch: 8, batch: 1683, loss: 0.5905629992485046\n",
      "epoch: 8, batch: 1684, loss: 0.2119453102350235\n",
      "epoch: 8, batch: 1685, loss: 0.7214678525924683\n",
      "epoch: 8, batch: 1686, loss: 0.5124402642250061\n",
      "epoch: 8, batch: 1687, loss: 0.29634225368499756\n",
      "epoch: 8, batch: 1688, loss: 0.6623581647872925\n",
      "epoch: 8, batch: 1689, loss: 0.4046802818775177\n",
      "epoch: 8, batch: 1690, loss: 0.5788276791572571\n",
      "epoch: 8, batch: 1691, loss: 0.6914770007133484\n",
      "epoch: 8, batch: 1692, loss: 0.33822154998779297\n",
      "epoch: 8, batch: 1693, loss: 0.3105878531932831\n",
      "epoch: 8, batch: 1694, loss: 0.25390270352363586\n",
      "epoch: 8, batch: 1695, loss: 0.3705446124076843\n",
      "epoch: 8, batch: 1696, loss: 0.30876851081848145\n",
      "epoch: 8, batch: 1697, loss: 0.32703614234924316\n",
      "epoch: 8, batch: 1698, loss: 0.2129550725221634\n",
      "epoch: 8, batch: 1699, loss: 0.4597161114215851\n",
      "epoch: 8, batch: 1700, loss: 0.8219955563545227\n",
      "epoch: 8, batch: 1701, loss: 0.67595374584198\n",
      "epoch: 8, batch: 1702, loss: 0.39154136180877686\n",
      "epoch: 8, batch: 1703, loss: 0.5067576766014099\n",
      "epoch: 8, batch: 1704, loss: 0.42257094383239746\n",
      "epoch: 8, batch: 1705, loss: 0.5120857954025269\n",
      "epoch: 8, batch: 1706, loss: 0.32794830203056335\n",
      "epoch: 8, batch: 1707, loss: 0.44077634811401367\n",
      "epoch: 8, batch: 1708, loss: 0.5729609131813049\n",
      "epoch: 8, batch: 1709, loss: 0.38218680024147034\n",
      "epoch: 8, batch: 1710, loss: 0.5468688607215881\n",
      "epoch: 8, batch: 1711, loss: 0.4002474844455719\n",
      "epoch: 8, batch: 1712, loss: 0.4878064692020416\n",
      "epoch: 8, batch: 1713, loss: 0.4653378427028656\n",
      "epoch: 8, batch: 1714, loss: 0.6556745171546936\n",
      "epoch: 8, batch: 1715, loss: 0.3186606764793396\n",
      "epoch: 8, batch: 1716, loss: 0.33758091926574707\n",
      "epoch: 8, batch: 1717, loss: 0.5012774467468262\n",
      "epoch: 8, batch: 1718, loss: 0.5188742876052856\n",
      "epoch: 8, batch: 1719, loss: 0.42093098163604736\n",
      "epoch: 8, batch: 1720, loss: 0.5306863784790039\n",
      "epoch: 8, batch: 1721, loss: 0.3184707760810852\n",
      "epoch: 8, batch: 1722, loss: 0.48029693961143494\n",
      "epoch: 8, batch: 1723, loss: 0.434135764837265\n",
      "epoch: 8, batch: 1724, loss: 0.35670214891433716\n",
      "epoch: 8, batch: 1725, loss: 0.8117439150810242\n",
      "epoch: 8, batch: 1726, loss: 0.4908961355686188\n",
      "epoch: 8, batch: 1727, loss: 0.3210582137107849\n",
      "epoch: 8, batch: 1728, loss: 0.6085390448570251\n",
      "epoch: 8, batch: 1729, loss: 0.497916579246521\n",
      "epoch: 8, batch: 1730, loss: 0.39139658212661743\n",
      "epoch: 8, batch: 1731, loss: 0.6532641649246216\n",
      "epoch: 8, batch: 1732, loss: 0.40360817313194275\n",
      "epoch: 8, batch: 1733, loss: 0.7553870677947998\n",
      "epoch: 8, batch: 1734, loss: 0.22041480243206024\n",
      "epoch: 8, batch: 1735, loss: 0.4915015995502472\n",
      "epoch: 8, batch: 1736, loss: 0.5186935663223267\n",
      "epoch: 8, batch: 1737, loss: 0.5012144446372986\n",
      "epoch: 8, batch: 1738, loss: 0.5649449825286865\n",
      "epoch: 8, batch: 1739, loss: 0.2482510507106781\n",
      "epoch: 8, batch: 1740, loss: 0.4517563283443451\n",
      "epoch: 8, batch: 1741, loss: 0.44101738929748535\n",
      "epoch: 8, batch: 1742, loss: 0.37529367208480835\n",
      "epoch: 8, batch: 1743, loss: 0.5547824501991272\n",
      "epoch: 8, batch: 1744, loss: 0.3997704088687897\n",
      "epoch: 8, batch: 1745, loss: 0.8151194453239441\n",
      "epoch: 8, batch: 1746, loss: 0.4023195207118988\n",
      "epoch: 8, batch: 1747, loss: 0.6720401048660278\n",
      "epoch: 8, batch: 1748, loss: 0.43168601393699646\n",
      "epoch: 8, batch: 1749, loss: 0.43221837282180786\n",
      "epoch: 8, batch: 1750, loss: 0.5903697609901428\n",
      "epoch: 8, batch: 1751, loss: 0.40472742915153503\n",
      "epoch: 8, batch: 1752, loss: 0.513577401638031\n",
      "epoch: 8, batch: 1753, loss: 0.5822911262512207\n",
      "epoch: 8, batch: 1754, loss: 0.3079450726509094\n",
      "epoch: 8, batch: 1755, loss: 0.579901397228241\n",
      "epoch: 8, batch: 1756, loss: 0.7378959059715271\n",
      "epoch: 8, batch: 1757, loss: 0.22145353257656097\n",
      "epoch: 8, batch: 1758, loss: 0.39460474252700806\n",
      "epoch: 8, batch: 1759, loss: 0.3561284840106964\n",
      "epoch: 8, batch: 1760, loss: 0.34472519159317017\n",
      "epoch: 8, batch: 1761, loss: 0.3413515090942383\n",
      "epoch: 8, batch: 1762, loss: 0.33780694007873535\n",
      "epoch: 8, batch: 1763, loss: 0.31472429633140564\n",
      "epoch: 8, batch: 1764, loss: 0.386540025472641\n",
      "epoch: 8, batch: 1765, loss: 0.8191256523132324\n",
      "epoch: 8, batch: 1766, loss: 0.3223903179168701\n",
      "epoch: 8, batch: 1767, loss: 0.308793306350708\n",
      "epoch: 8, batch: 1768, loss: 0.5066473484039307\n",
      "epoch: 8, batch: 1769, loss: 0.24710257351398468\n",
      "epoch: 8, batch: 1770, loss: 0.36883947253227234\n",
      "epoch: 8, batch: 1771, loss: 0.5260830521583557\n",
      "epoch: 8, batch: 1772, loss: 0.2725750207901001\n",
      "epoch: 8, batch: 1773, loss: 0.3314673602581024\n",
      "epoch: 8, batch: 1774, loss: 0.49474823474884033\n",
      "epoch: 8, batch: 1775, loss: 0.4510648250579834\n",
      "epoch: 8, batch: 1776, loss: 0.322589635848999\n",
      "epoch: 8, batch: 1777, loss: 0.35810598731040955\n",
      "epoch: 8, batch: 1778, loss: 0.5857260227203369\n",
      "epoch: 8, batch: 1779, loss: 0.5300464630126953\n",
      "epoch: 8, batch: 1780, loss: 0.31224459409713745\n",
      "epoch: 8, batch: 1781, loss: 0.6114765405654907\n",
      "epoch: 8, batch: 1782, loss: 0.6005024313926697\n",
      "epoch: 8, batch: 1783, loss: 0.46626409888267517\n",
      "epoch: 8, batch: 1784, loss: 0.5226292610168457\n",
      "epoch: 8, batch: 1785, loss: 0.3069629371166229\n",
      "epoch: 8, batch: 1786, loss: 0.3994877338409424\n",
      "epoch: 8, batch: 1787, loss: 0.39603421092033386\n",
      "epoch: 8, batch: 1788, loss: 0.5594019293785095\n",
      "epoch: 8, batch: 1789, loss: 0.33573007583618164\n",
      "epoch: 8, batch: 1790, loss: 0.4745027720928192\n",
      "epoch: 8, batch: 1791, loss: 0.4723511040210724\n",
      "epoch: 8, batch: 1792, loss: 0.26849737763404846\n",
      "epoch: 8, batch: 1793, loss: 0.5401085615158081\n",
      "epoch: 8, batch: 1794, loss: 0.36147233843803406\n",
      "epoch: 8, batch: 1795, loss: 0.3284912705421448\n",
      "epoch: 8, batch: 1796, loss: 0.48366227746009827\n",
      "epoch: 8, batch: 1797, loss: 0.5454199910163879\n",
      "epoch: 8, batch: 1798, loss: 0.4594407379627228\n",
      "epoch: 8, batch: 1799, loss: 0.5014575123786926\n",
      "epoch: 8, batch: 1800, loss: 0.5596068501472473\n",
      "epoch: 8, batch: 1801, loss: 0.5666290521621704\n",
      "epoch: 8, batch: 1802, loss: 0.450766921043396\n",
      "epoch: 8, batch: 1803, loss: 0.6369826793670654\n",
      "epoch: 8, batch: 1804, loss: 0.33546704053878784\n",
      "epoch: 8, batch: 1805, loss: 0.3368906080722809\n",
      "epoch: 8, batch: 1806, loss: 0.6960672736167908\n",
      "epoch: 8, batch: 1807, loss: 0.41301730275154114\n",
      "epoch: 8, batch: 1808, loss: 0.507784366607666\n",
      "epoch: 8, batch: 1809, loss: 0.6665598750114441\n",
      "epoch: 8, batch: 1810, loss: 0.7452275156974792\n",
      "epoch: 8, batch: 1811, loss: 0.5477316379547119\n",
      "epoch: 8, batch: 1812, loss: 0.5248392224311829\n",
      "epoch: 8, batch: 1813, loss: 0.35922324657440186\n",
      "epoch: 8, batch: 1814, loss: 0.33736148476600647\n",
      "epoch: 8, batch: 1815, loss: 0.48957517743110657\n",
      "epoch: 8, batch: 1816, loss: 0.7367326021194458\n",
      "epoch: 8, batch: 1817, loss: 0.5614722371101379\n",
      "epoch: 8, batch: 1818, loss: 0.4202442765235901\n",
      "epoch: 8, batch: 1819, loss: 0.9086682200431824\n",
      "epoch: 8, batch: 1820, loss: 0.5874219536781311\n",
      "epoch: 8, batch: 1821, loss: 0.44535890221595764\n",
      "epoch: 8, batch: 1822, loss: 0.24044767022132874\n",
      "epoch: 8, batch: 1823, loss: 0.4037832021713257\n",
      "epoch: 8, batch: 1824, loss: 0.38009682297706604\n",
      "epoch: 8, batch: 1825, loss: 0.5541590452194214\n",
      "epoch: 8, batch: 1826, loss: 1.0531519651412964\n",
      "epoch: 8, batch: 1827, loss: 0.2824069559574127\n",
      "epoch: 8, batch: 1828, loss: 0.5404159426689148\n",
      "epoch: 8, batch: 1829, loss: 0.23970621824264526\n",
      "epoch: 8, batch: 1830, loss: 0.4026951491832733\n",
      "epoch: 8, batch: 1831, loss: 0.671351432800293\n",
      "epoch: 8, batch: 1832, loss: 0.5125657320022583\n",
      "epoch: 8, batch: 1833, loss: 0.6231147050857544\n",
      "epoch: 8, batch: 1834, loss: 0.5164223313331604\n",
      "epoch: 8, batch: 1835, loss: 0.3922024667263031\n",
      "epoch: 8, batch: 1836, loss: 0.34533122181892395\n",
      "epoch: 8, batch: 1837, loss: 0.7005937099456787\n",
      "epoch: 8, batch: 1838, loss: 0.4610083997249603\n",
      "epoch: 8, batch: 1839, loss: 0.5921738743782043\n",
      "epoch: 8, batch: 1840, loss: 0.4688423275947571\n",
      "epoch: 8, batch: 1841, loss: 0.47442957758903503\n",
      "epoch: 8, batch: 1842, loss: 0.5639374852180481\n",
      "epoch: 8, batch: 1843, loss: 0.6026387810707092\n",
      "epoch: 8, batch: 1844, loss: 0.6096078157424927\n",
      "epoch: 8, batch: 1845, loss: 0.4091138243675232\n",
      "epoch: 8, batch: 1846, loss: 0.4308328926563263\n",
      "epoch: 8, batch: 1847, loss: 0.402784138917923\n",
      "epoch: 8, batch: 1848, loss: 0.4426717162132263\n",
      "epoch: 8, batch: 1849, loss: 0.7679821252822876\n",
      "epoch: 8, batch: 1850, loss: 0.3053039014339447\n",
      "epoch: 8, batch: 1851, loss: 0.6017295718193054\n",
      "epoch: 8, batch: 1852, loss: 0.5067212581634521\n",
      "epoch: 8, batch: 1853, loss: 0.44878214597702026\n",
      "epoch: 8, batch: 1854, loss: 0.4008745551109314\n",
      "epoch: 8, batch: 1855, loss: 0.29087069630622864\n",
      "epoch: 8, batch: 1856, loss: 0.4784030020236969\n",
      "epoch: 8, batch: 1857, loss: 0.3943674564361572\n",
      "epoch: 8, batch: 1858, loss: 0.28904202580451965\n",
      "epoch: 8, batch: 1859, loss: 0.37756943702697754\n",
      "epoch: 8, batch: 1860, loss: 0.3723560571670532\n",
      "epoch: 8, batch: 1861, loss: 0.38542333245277405\n",
      "epoch: 8, batch: 1862, loss: 0.4722880423069\n",
      "epoch: 8, batch: 1863, loss: 0.2917053699493408\n",
      "epoch: 8, batch: 1864, loss: 0.5406796932220459\n",
      "epoch: 8, batch: 1865, loss: 0.47781509160995483\n",
      "epoch: 8, batch: 1866, loss: 0.7305633425712585\n",
      "epoch: 8, batch: 1867, loss: 0.5296088457107544\n",
      "epoch: 8, batch: 1868, loss: 0.4144277572631836\n",
      "epoch: 8, batch: 1869, loss: 0.36657774448394775\n",
      "epoch: 8, batch: 1870, loss: 0.4544089734554291\n",
      "epoch: 8, batch: 1871, loss: 0.36108195781707764\n",
      "epoch: 8, batch: 1872, loss: 0.16671065986156464\n",
      "epoch: 8, batch: 1873, loss: 0.4114435315132141\n",
      "epoch: 8, batch: 1874, loss: 0.43357378244400024\n",
      "epoch: 9, batch: 0, loss: 0.4833441972732544\n",
      "epoch: 9, batch: 1, loss: 0.28986042737960815\n",
      "epoch: 9, batch: 2, loss: 0.4684191942214966\n",
      "epoch: 9, batch: 3, loss: 0.3898189067840576\n",
      "epoch: 9, batch: 4, loss: 0.4812997579574585\n",
      "epoch: 9, batch: 5, loss: 0.512954592704773\n",
      "epoch: 9, batch: 6, loss: 0.3277161419391632\n",
      "epoch: 9, batch: 7, loss: 0.5516456961631775\n",
      "epoch: 9, batch: 8, loss: 0.6010373830795288\n",
      "epoch: 9, batch: 9, loss: 0.4433967173099518\n",
      "epoch: 9, batch: 10, loss: 0.24453143775463104\n",
      "epoch: 9, batch: 11, loss: 0.21095609664916992\n",
      "epoch: 9, batch: 12, loss: 0.5675202012062073\n",
      "epoch: 9, batch: 13, loss: 0.5567845106124878\n",
      "epoch: 9, batch: 14, loss: 0.7300860285758972\n",
      "epoch: 9, batch: 15, loss: 0.46371328830718994\n",
      "epoch: 9, batch: 16, loss: 0.5278850793838501\n",
      "epoch: 9, batch: 17, loss: 0.3566695749759674\n",
      "epoch: 9, batch: 18, loss: 0.3341149389743805\n",
      "epoch: 9, batch: 19, loss: 0.2670397162437439\n",
      "epoch: 9, batch: 20, loss: 0.6107582449913025\n",
      "epoch: 9, batch: 21, loss: 0.18030479550361633\n",
      "epoch: 9, batch: 22, loss: 0.46672362089157104\n",
      "epoch: 9, batch: 23, loss: 0.4042563736438751\n",
      "epoch: 9, batch: 24, loss: 0.4544095993041992\n",
      "epoch: 9, batch: 25, loss: 0.43205901980400085\n",
      "epoch: 9, batch: 26, loss: 0.32867881655693054\n",
      "epoch: 9, batch: 27, loss: 0.39230552315711975\n",
      "epoch: 9, batch: 28, loss: 0.37342551350593567\n",
      "epoch: 9, batch: 29, loss: 0.256352961063385\n",
      "epoch: 9, batch: 30, loss: 0.3885471522808075\n",
      "epoch: 9, batch: 31, loss: 0.4763665199279785\n",
      "epoch: 9, batch: 32, loss: 0.40748417377471924\n",
      "epoch: 9, batch: 33, loss: 0.410933256149292\n",
      "epoch: 9, batch: 34, loss: 0.3527694344520569\n",
      "epoch: 9, batch: 35, loss: 0.47797831892967224\n",
      "epoch: 9, batch: 36, loss: 0.4592955410480499\n",
      "epoch: 9, batch: 37, loss: 0.6356627941131592\n",
      "epoch: 9, batch: 38, loss: 0.5130239129066467\n",
      "epoch: 9, batch: 39, loss: 0.1917138248682022\n",
      "epoch: 9, batch: 40, loss: 0.6207259297370911\n",
      "epoch: 9, batch: 41, loss: 0.3654711842536926\n",
      "epoch: 9, batch: 42, loss: 0.6594095230102539\n",
      "epoch: 9, batch: 43, loss: 0.36742103099823\n",
      "epoch: 9, batch: 44, loss: 0.4868369996547699\n",
      "epoch: 9, batch: 45, loss: 0.2850881814956665\n",
      "epoch: 9, batch: 46, loss: 0.5226025581359863\n",
      "epoch: 9, batch: 47, loss: 0.5772565603256226\n",
      "epoch: 9, batch: 48, loss: 0.6297259330749512\n",
      "epoch: 9, batch: 49, loss: 0.4755444824695587\n",
      "epoch: 9, batch: 50, loss: 0.8308963775634766\n",
      "epoch: 9, batch: 51, loss: 0.472773015499115\n",
      "epoch: 9, batch: 52, loss: 0.5364653468132019\n",
      "epoch: 9, batch: 53, loss: 0.6539978981018066\n",
      "epoch: 9, batch: 54, loss: 0.7119932174682617\n",
      "epoch: 9, batch: 55, loss: 0.483465313911438\n",
      "epoch: 9, batch: 56, loss: 0.38947468996047974\n",
      "epoch: 9, batch: 57, loss: 0.3936672508716583\n",
      "epoch: 9, batch: 58, loss: 0.3913007080554962\n",
      "epoch: 9, batch: 59, loss: 0.4060126841068268\n",
      "epoch: 9, batch: 60, loss: 0.2724289000034332\n",
      "epoch: 9, batch: 61, loss: 0.4154106378555298\n",
      "epoch: 9, batch: 62, loss: 0.34676042199134827\n",
      "epoch: 9, batch: 63, loss: 0.26430508494377136\n",
      "epoch: 9, batch: 64, loss: 0.6038020253181458\n",
      "epoch: 9, batch: 65, loss: 0.41554227471351624\n",
      "epoch: 9, batch: 66, loss: 0.3444787859916687\n",
      "epoch: 9, batch: 67, loss: 0.2739240527153015\n",
      "epoch: 9, batch: 68, loss: 0.4411754608154297\n",
      "epoch: 9, batch: 69, loss: 0.6369744539260864\n",
      "epoch: 9, batch: 70, loss: 0.48665177822113037\n",
      "epoch: 9, batch: 71, loss: 0.49001544713974\n",
      "epoch: 9, batch: 72, loss: 0.5372363328933716\n",
      "epoch: 9, batch: 73, loss: 0.22133949398994446\n",
      "epoch: 9, batch: 74, loss: 0.4106658101081848\n",
      "epoch: 9, batch: 75, loss: 0.5260956287384033\n",
      "epoch: 9, batch: 76, loss: 0.2981540560722351\n",
      "epoch: 9, batch: 77, loss: 0.3891932964324951\n",
      "epoch: 9, batch: 78, loss: 0.22873643040657043\n",
      "epoch: 9, batch: 79, loss: 0.5114622712135315\n",
      "epoch: 9, batch: 80, loss: 0.5241966247558594\n",
      "epoch: 9, batch: 81, loss: 0.6180279850959778\n",
      "epoch: 9, batch: 82, loss: 0.450852632522583\n",
      "epoch: 9, batch: 83, loss: 0.6533159017562866\n",
      "epoch: 9, batch: 84, loss: 0.5685933828353882\n",
      "epoch: 9, batch: 85, loss: 0.33514511585235596\n",
      "epoch: 9, batch: 86, loss: 0.41522017121315\n",
      "epoch: 9, batch: 87, loss: 0.28982290625572205\n",
      "epoch: 9, batch: 88, loss: 0.4739682674407959\n",
      "epoch: 9, batch: 89, loss: 0.7313277721405029\n",
      "epoch: 9, batch: 90, loss: 0.6191220879554749\n",
      "epoch: 9, batch: 91, loss: 0.46584537625312805\n",
      "epoch: 9, batch: 92, loss: 0.41209661960601807\n",
      "epoch: 9, batch: 93, loss: 0.26681429147720337\n",
      "epoch: 9, batch: 94, loss: 0.4968026578426361\n",
      "epoch: 9, batch: 95, loss: 0.5833497047424316\n",
      "epoch: 9, batch: 96, loss: 0.3142849802970886\n",
      "epoch: 9, batch: 97, loss: 0.26730552315711975\n",
      "epoch: 9, batch: 98, loss: 0.6477664709091187\n",
      "epoch: 9, batch: 99, loss: 0.333140105009079\n",
      "epoch: 9, batch: 100, loss: 0.6245316863059998\n",
      "epoch: 9, batch: 101, loss: 0.46790611743927\n",
      "epoch: 9, batch: 102, loss: 0.4228067994117737\n",
      "epoch: 9, batch: 103, loss: 0.3106411099433899\n",
      "epoch: 9, batch: 104, loss: 0.49911022186279297\n",
      "epoch: 9, batch: 105, loss: 0.3414810001850128\n",
      "epoch: 9, batch: 106, loss: 0.676254391670227\n",
      "epoch: 9, batch: 107, loss: 0.7771052122116089\n",
      "epoch: 9, batch: 108, loss: 0.4293699562549591\n",
      "epoch: 9, batch: 109, loss: 0.43766531348228455\n",
      "epoch: 9, batch: 110, loss: 0.7118789553642273\n",
      "epoch: 9, batch: 111, loss: 0.4049014449119568\n",
      "epoch: 9, batch: 112, loss: 0.44049760699272156\n",
      "epoch: 9, batch: 113, loss: 0.38591697812080383\n",
      "epoch: 9, batch: 114, loss: 0.3256568908691406\n",
      "epoch: 9, batch: 115, loss: 0.37903541326522827\n",
      "epoch: 9, batch: 116, loss: 0.3524310886859894\n",
      "epoch: 9, batch: 117, loss: 0.49779993295669556\n",
      "epoch: 9, batch: 118, loss: 0.8607744574546814\n",
      "epoch: 9, batch: 119, loss: 0.3600236773490906\n",
      "epoch: 9, batch: 120, loss: 0.2833992540836334\n",
      "epoch: 9, batch: 121, loss: 0.49947184324264526\n",
      "epoch: 9, batch: 122, loss: 0.5974307060241699\n",
      "epoch: 9, batch: 123, loss: 0.4430253803730011\n",
      "epoch: 9, batch: 124, loss: 0.5747804641723633\n",
      "epoch: 9, batch: 125, loss: 0.4590929448604584\n",
      "epoch: 9, batch: 126, loss: 0.7143315672874451\n",
      "epoch: 9, batch: 127, loss: 0.35589662194252014\n",
      "epoch: 9, batch: 128, loss: 0.6384164094924927\n",
      "epoch: 9, batch: 129, loss: 0.563027560710907\n",
      "epoch: 9, batch: 130, loss: 0.3970295488834381\n",
      "epoch: 9, batch: 131, loss: 0.4981459081172943\n",
      "epoch: 9, batch: 132, loss: 0.37825363874435425\n",
      "epoch: 9, batch: 133, loss: 0.3382801115512848\n",
      "epoch: 9, batch: 134, loss: 0.34461212158203125\n",
      "epoch: 9, batch: 135, loss: 0.5643319487571716\n",
      "epoch: 9, batch: 136, loss: 0.51402747631073\n",
      "epoch: 9, batch: 137, loss: 0.47204142808914185\n",
      "epoch: 9, batch: 138, loss: 0.722722589969635\n",
      "epoch: 9, batch: 139, loss: 0.399493932723999\n",
      "epoch: 9, batch: 140, loss: 0.26108771562576294\n",
      "epoch: 9, batch: 141, loss: 0.42786097526550293\n",
      "epoch: 9, batch: 142, loss: 0.38422057032585144\n",
      "epoch: 9, batch: 143, loss: 0.6249343752861023\n",
      "epoch: 9, batch: 144, loss: 0.31641852855682373\n",
      "epoch: 9, batch: 145, loss: 0.6187572479248047\n",
      "epoch: 9, batch: 146, loss: 0.2435404658317566\n",
      "epoch: 9, batch: 147, loss: 0.4488925337791443\n",
      "epoch: 9, batch: 148, loss: 0.24902614951133728\n",
      "epoch: 9, batch: 149, loss: 0.42076364159584045\n",
      "epoch: 9, batch: 150, loss: 0.27603447437286377\n",
      "epoch: 9, batch: 151, loss: 0.5261225700378418\n",
      "epoch: 9, batch: 152, loss: 0.4160439968109131\n",
      "epoch: 9, batch: 153, loss: 0.3750397861003876\n",
      "epoch: 9, batch: 154, loss: 0.5391202569007874\n",
      "epoch: 9, batch: 155, loss: 0.42147505283355713\n",
      "epoch: 9, batch: 156, loss: 0.5611686706542969\n",
      "epoch: 9, batch: 157, loss: 0.3462144434452057\n",
      "epoch: 9, batch: 158, loss: 0.5266094207763672\n",
      "epoch: 9, batch: 159, loss: 0.6165055632591248\n",
      "epoch: 9, batch: 160, loss: 0.3690229058265686\n",
      "epoch: 9, batch: 161, loss: 0.42263054847717285\n",
      "epoch: 9, batch: 162, loss: 0.4498967230319977\n",
      "epoch: 9, batch: 163, loss: 0.6953482627868652\n",
      "epoch: 9, batch: 164, loss: 0.38807910680770874\n",
      "epoch: 9, batch: 165, loss: 0.44140586256980896\n",
      "epoch: 9, batch: 166, loss: 0.4523082971572876\n",
      "epoch: 9, batch: 167, loss: 0.3310818374156952\n",
      "epoch: 9, batch: 168, loss: 0.5112183094024658\n",
      "epoch: 9, batch: 169, loss: 0.6187114715576172\n",
      "epoch: 9, batch: 170, loss: 0.41825416684150696\n",
      "epoch: 9, batch: 171, loss: 0.4059150218963623\n",
      "epoch: 9, batch: 172, loss: 0.41713669896125793\n",
      "epoch: 9, batch: 173, loss: 0.38307687640190125\n",
      "epoch: 9, batch: 174, loss: 0.5207030177116394\n",
      "epoch: 9, batch: 175, loss: 0.5872112512588501\n",
      "epoch: 9, batch: 176, loss: 0.6281418204307556\n",
      "epoch: 9, batch: 177, loss: 0.5323339700698853\n",
      "epoch: 9, batch: 178, loss: 0.26629647612571716\n",
      "epoch: 9, batch: 179, loss: 0.44854021072387695\n",
      "epoch: 9, batch: 180, loss: 0.47275882959365845\n",
      "epoch: 9, batch: 181, loss: 0.795312225818634\n",
      "epoch: 9, batch: 182, loss: 0.5841557383537292\n",
      "epoch: 9, batch: 183, loss: 0.6652461290359497\n",
      "epoch: 9, batch: 184, loss: 0.6427658200263977\n",
      "epoch: 9, batch: 185, loss: 0.7382752299308777\n",
      "epoch: 9, batch: 186, loss: 0.5847460627555847\n",
      "epoch: 9, batch: 187, loss: 0.5360995531082153\n",
      "epoch: 9, batch: 188, loss: 0.5052909851074219\n",
      "epoch: 9, batch: 189, loss: 0.45806241035461426\n",
      "epoch: 9, batch: 190, loss: 0.32074007391929626\n",
      "epoch: 9, batch: 191, loss: 0.24911731481552124\n",
      "epoch: 9, batch: 192, loss: 0.18535453081130981\n",
      "epoch: 9, batch: 193, loss: 0.3717774450778961\n",
      "epoch: 9, batch: 194, loss: 0.47248485684394836\n",
      "epoch: 9, batch: 195, loss: 0.6383787989616394\n",
      "epoch: 9, batch: 196, loss: 0.5698508024215698\n",
      "epoch: 9, batch: 197, loss: 0.27023041248321533\n",
      "epoch: 9, batch: 198, loss: 0.6771175861358643\n",
      "epoch: 9, batch: 199, loss: 0.2843170762062073\n",
      "epoch: 9, batch: 200, loss: 0.5614159107208252\n",
      "epoch: 9, batch: 201, loss: 0.6718897819519043\n",
      "epoch: 9, batch: 202, loss: 0.2875330448150635\n",
      "epoch: 9, batch: 203, loss: 1.0031771659851074\n",
      "epoch: 9, batch: 204, loss: 0.8117921352386475\n",
      "epoch: 9, batch: 205, loss: 0.4297363758087158\n",
      "epoch: 9, batch: 206, loss: 0.44269752502441406\n",
      "epoch: 9, batch: 207, loss: 0.46928849816322327\n",
      "epoch: 9, batch: 208, loss: 0.5407742261886597\n",
      "epoch: 9, batch: 209, loss: 0.4703306257724762\n",
      "epoch: 9, batch: 210, loss: 0.5560608506202698\n",
      "epoch: 9, batch: 211, loss: 0.4505651593208313\n",
      "epoch: 9, batch: 212, loss: 0.2249147593975067\n",
      "epoch: 9, batch: 213, loss: 0.6641021966934204\n",
      "epoch: 9, batch: 214, loss: 0.7314193248748779\n",
      "epoch: 9, batch: 215, loss: 0.39792075753211975\n",
      "epoch: 9, batch: 216, loss: 0.5802628993988037\n",
      "epoch: 9, batch: 217, loss: 0.4464702010154724\n",
      "epoch: 9, batch: 218, loss: 0.19359876215457916\n",
      "epoch: 9, batch: 219, loss: 0.3143137991428375\n",
      "epoch: 9, batch: 220, loss: 0.3788166046142578\n",
      "epoch: 9, batch: 221, loss: 0.4447024464607239\n",
      "epoch: 9, batch: 222, loss: 0.9031481146812439\n",
      "epoch: 9, batch: 223, loss: 0.3737756311893463\n",
      "epoch: 9, batch: 224, loss: 0.398838073015213\n",
      "epoch: 9, batch: 225, loss: 0.26810553669929504\n",
      "epoch: 9, batch: 226, loss: 0.27600276470184326\n",
      "epoch: 9, batch: 227, loss: 0.5863672494888306\n",
      "epoch: 9, batch: 228, loss: 0.2946828603744507\n",
      "epoch: 9, batch: 229, loss: 0.5770220160484314\n",
      "epoch: 9, batch: 230, loss: 0.5149115324020386\n",
      "epoch: 9, batch: 231, loss: 0.3326309621334076\n",
      "epoch: 9, batch: 232, loss: 0.5113060474395752\n",
      "epoch: 9, batch: 233, loss: 0.36936044692993164\n",
      "epoch: 9, batch: 234, loss: 0.6052377223968506\n",
      "epoch: 9, batch: 235, loss: 0.5588476657867432\n",
      "epoch: 9, batch: 236, loss: 0.7029350399971008\n",
      "epoch: 9, batch: 237, loss: 0.41340571641921997\n",
      "epoch: 9, batch: 238, loss: 0.37880444526672363\n",
      "epoch: 9, batch: 239, loss: 0.26733604073524475\n",
      "epoch: 9, batch: 240, loss: 0.27562573552131653\n",
      "epoch: 9, batch: 241, loss: 0.3724379539489746\n",
      "epoch: 9, batch: 242, loss: 0.4372076094150543\n",
      "epoch: 9, batch: 243, loss: 0.4078276753425598\n",
      "epoch: 9, batch: 244, loss: 0.4347446858882904\n",
      "epoch: 9, batch: 245, loss: 0.24282272160053253\n",
      "epoch: 9, batch: 246, loss: 0.49392396211624146\n",
      "epoch: 9, batch: 247, loss: 0.4322528839111328\n",
      "epoch: 9, batch: 248, loss: 0.32512223720550537\n",
      "epoch: 9, batch: 249, loss: 0.3503296673297882\n",
      "epoch: 9, batch: 250, loss: 0.5838642716407776\n",
      "epoch: 9, batch: 251, loss: 0.3072626292705536\n",
      "epoch: 9, batch: 252, loss: 0.4888685941696167\n",
      "epoch: 9, batch: 253, loss: 0.31590527296066284\n",
      "epoch: 9, batch: 254, loss: 0.2303611785173416\n",
      "epoch: 9, batch: 255, loss: 0.21632952988147736\n",
      "epoch: 9, batch: 256, loss: 0.4920375943183899\n",
      "epoch: 9, batch: 257, loss: 0.4192044734954834\n",
      "epoch: 9, batch: 258, loss: 0.4844047427177429\n",
      "epoch: 9, batch: 259, loss: 0.32408323884010315\n",
      "epoch: 9, batch: 260, loss: 0.3525782525539398\n",
      "epoch: 9, batch: 261, loss: 0.31820064783096313\n",
      "epoch: 9, batch: 262, loss: 0.5487698316574097\n",
      "epoch: 9, batch: 263, loss: 0.7400636076927185\n",
      "epoch: 9, batch: 264, loss: 0.5707541108131409\n",
      "epoch: 9, batch: 265, loss: 0.22075234353542328\n",
      "epoch: 9, batch: 266, loss: 0.4657937288284302\n",
      "epoch: 9, batch: 267, loss: 0.2919205129146576\n",
      "epoch: 9, batch: 268, loss: 0.5928118824958801\n",
      "epoch: 9, batch: 269, loss: 0.5493199229240417\n",
      "epoch: 9, batch: 270, loss: 0.7323668003082275\n",
      "epoch: 9, batch: 271, loss: 0.48789358139038086\n",
      "epoch: 9, batch: 272, loss: 0.5313689708709717\n",
      "epoch: 9, batch: 273, loss: 0.7493295669555664\n",
      "epoch: 9, batch: 274, loss: 0.3378600776195526\n",
      "epoch: 9, batch: 275, loss: 0.4804457426071167\n",
      "epoch: 9, batch: 276, loss: 0.5203841328620911\n",
      "epoch: 9, batch: 277, loss: 0.3853565752506256\n",
      "epoch: 9, batch: 278, loss: 0.34467047452926636\n",
      "epoch: 9, batch: 279, loss: 0.7987131476402283\n",
      "epoch: 9, batch: 280, loss: 0.31133419275283813\n",
      "epoch: 9, batch: 281, loss: 0.36560311913490295\n",
      "epoch: 9, batch: 282, loss: 0.42767831683158875\n",
      "epoch: 9, batch: 283, loss: 0.394284188747406\n",
      "epoch: 9, batch: 284, loss: 0.6011817455291748\n",
      "epoch: 9, batch: 285, loss: 0.577372670173645\n",
      "epoch: 9, batch: 286, loss: 0.5795755982398987\n",
      "epoch: 9, batch: 287, loss: 0.35708773136138916\n",
      "epoch: 9, batch: 288, loss: 0.41674569249153137\n",
      "epoch: 9, batch: 289, loss: 0.6057414412498474\n",
      "epoch: 9, batch: 290, loss: 0.30752602219581604\n",
      "epoch: 9, batch: 291, loss: 0.6157289147377014\n",
      "epoch: 9, batch: 292, loss: 0.5083420276641846\n",
      "epoch: 9, batch: 293, loss: 0.25565049052238464\n",
      "epoch: 9, batch: 294, loss: 0.4322822093963623\n",
      "epoch: 9, batch: 295, loss: 0.3793291449546814\n",
      "epoch: 9, batch: 296, loss: 0.34725621342658997\n",
      "epoch: 9, batch: 297, loss: 0.4330909252166748\n",
      "epoch: 9, batch: 298, loss: 0.46553850173950195\n",
      "epoch: 9, batch: 299, loss: 0.2128922939300537\n",
      "epoch: 9, batch: 300, loss: 0.3541398048400879\n",
      "epoch: 9, batch: 301, loss: 0.6887693405151367\n",
      "epoch: 9, batch: 302, loss: 0.4520358443260193\n",
      "epoch: 9, batch: 303, loss: 0.40153858065605164\n",
      "epoch: 9, batch: 304, loss: 0.22827643156051636\n",
      "epoch: 9, batch: 305, loss: 0.20583854615688324\n",
      "epoch: 9, batch: 306, loss: 0.4142880141735077\n",
      "epoch: 9, batch: 307, loss: 0.38411226868629456\n",
      "epoch: 9, batch: 308, loss: 0.4875706732273102\n",
      "epoch: 9, batch: 309, loss: 0.591281533241272\n",
      "epoch: 9, batch: 310, loss: 0.5270751118659973\n",
      "epoch: 9, batch: 311, loss: 0.35655397176742554\n",
      "epoch: 9, batch: 312, loss: 0.4725078344345093\n",
      "epoch: 9, batch: 313, loss: 0.5717119574546814\n",
      "epoch: 9, batch: 314, loss: 0.34568890929222107\n",
      "epoch: 9, batch: 315, loss: 0.2788107395172119\n",
      "epoch: 9, batch: 316, loss: 0.3175047039985657\n",
      "epoch: 9, batch: 317, loss: 0.4958159923553467\n",
      "epoch: 9, batch: 318, loss: 0.4412190020084381\n",
      "epoch: 9, batch: 319, loss: 0.3301188051700592\n",
      "epoch: 9, batch: 320, loss: 0.5150092244148254\n",
      "epoch: 9, batch: 321, loss: 0.34443873167037964\n",
      "epoch: 9, batch: 322, loss: 0.6451641917228699\n",
      "epoch: 9, batch: 323, loss: 0.3248198926448822\n",
      "epoch: 9, batch: 324, loss: 0.6232678890228271\n",
      "epoch: 9, batch: 325, loss: 0.7858167290687561\n",
      "epoch: 9, batch: 326, loss: 0.5224021673202515\n",
      "epoch: 9, batch: 327, loss: 0.31035009026527405\n",
      "epoch: 9, batch: 328, loss: 0.3101699650287628\n",
      "epoch: 9, batch: 329, loss: 0.46334829926490784\n",
      "epoch: 9, batch: 330, loss: 0.5215134024620056\n",
      "epoch: 9, batch: 331, loss: 0.42330875992774963\n",
      "epoch: 9, batch: 332, loss: 0.30729028582572937\n",
      "epoch: 9, batch: 333, loss: 0.5652734637260437\n",
      "epoch: 9, batch: 334, loss: 0.3795156180858612\n",
      "epoch: 9, batch: 335, loss: 0.390351265668869\n",
      "epoch: 9, batch: 336, loss: 0.3648831844329834\n",
      "epoch: 9, batch: 337, loss: 0.6213157773017883\n",
      "epoch: 9, batch: 338, loss: 0.5028932094573975\n",
      "epoch: 9, batch: 339, loss: 0.465643048286438\n",
      "epoch: 9, batch: 340, loss: 0.45225706696510315\n",
      "epoch: 9, batch: 341, loss: 0.30360889434814453\n",
      "epoch: 9, batch: 342, loss: 0.6548444628715515\n",
      "epoch: 9, batch: 343, loss: 0.5019137263298035\n",
      "epoch: 9, batch: 344, loss: 0.31338006258010864\n",
      "epoch: 9, batch: 345, loss: 0.31030017137527466\n",
      "epoch: 9, batch: 346, loss: 0.6087659597396851\n",
      "epoch: 9, batch: 347, loss: 0.4503862261772156\n",
      "epoch: 9, batch: 348, loss: 0.48796215653419495\n",
      "epoch: 9, batch: 349, loss: 0.7379273176193237\n",
      "epoch: 9, batch: 350, loss: 0.2614593505859375\n",
      "epoch: 9, batch: 351, loss: 0.635918140411377\n",
      "epoch: 9, batch: 352, loss: 0.3777677118778229\n",
      "epoch: 9, batch: 353, loss: 0.5461539030075073\n",
      "epoch: 9, batch: 354, loss: 0.3373240530490875\n",
      "epoch: 9, batch: 355, loss: 0.3537598252296448\n",
      "epoch: 9, batch: 356, loss: 0.4811512231826782\n",
      "epoch: 9, batch: 357, loss: 0.5779473781585693\n",
      "epoch: 9, batch: 358, loss: 0.3481454849243164\n",
      "epoch: 9, batch: 359, loss: 0.5198488831520081\n",
      "epoch: 9, batch: 360, loss: 0.31499677896499634\n",
      "epoch: 9, batch: 361, loss: 0.5530337691307068\n",
      "epoch: 9, batch: 362, loss: 0.4005996286869049\n",
      "epoch: 9, batch: 363, loss: 0.406114399433136\n",
      "epoch: 9, batch: 364, loss: 0.35001087188720703\n",
      "epoch: 9, batch: 365, loss: 0.3689357340335846\n",
      "epoch: 9, batch: 366, loss: 0.5437370538711548\n",
      "epoch: 9, batch: 367, loss: 0.3572881519794464\n",
      "epoch: 9, batch: 368, loss: 0.3381747305393219\n",
      "epoch: 9, batch: 369, loss: 0.6763267517089844\n",
      "epoch: 9, batch: 370, loss: 0.6256901025772095\n",
      "epoch: 9, batch: 371, loss: 0.6815972924232483\n",
      "epoch: 9, batch: 372, loss: 0.4176487326622009\n",
      "epoch: 9, batch: 373, loss: 0.3780100345611572\n",
      "epoch: 9, batch: 374, loss: 0.42890408635139465\n",
      "epoch: 9, batch: 375, loss: 0.4313972294330597\n",
      "epoch: 9, batch: 376, loss: 0.7923902869224548\n",
      "epoch: 9, batch: 377, loss: 0.5174874067306519\n",
      "epoch: 9, batch: 378, loss: 0.40821540355682373\n",
      "epoch: 9, batch: 379, loss: 0.6254457831382751\n",
      "epoch: 9, batch: 380, loss: 0.41795822978019714\n",
      "epoch: 9, batch: 381, loss: 0.5616163015365601\n",
      "epoch: 9, batch: 382, loss: 0.654941737651825\n",
      "epoch: 9, batch: 383, loss: 0.5516148209571838\n",
      "epoch: 9, batch: 384, loss: 0.30162709951400757\n",
      "epoch: 9, batch: 385, loss: 0.3272830545902252\n",
      "epoch: 9, batch: 386, loss: 0.4280504882335663\n",
      "epoch: 9, batch: 387, loss: 0.45559507608413696\n",
      "epoch: 9, batch: 388, loss: 0.3626391887664795\n",
      "epoch: 9, batch: 389, loss: 0.5216889977455139\n",
      "epoch: 9, batch: 390, loss: 0.4876596927642822\n",
      "epoch: 9, batch: 391, loss: 0.3089844584465027\n",
      "epoch: 9, batch: 392, loss: 0.3409014940261841\n",
      "epoch: 9, batch: 393, loss: 0.4543568193912506\n",
      "epoch: 9, batch: 394, loss: 0.45520249009132385\n",
      "epoch: 9, batch: 395, loss: 0.4819484353065491\n",
      "epoch: 9, batch: 396, loss: 0.5599660873413086\n",
      "epoch: 9, batch: 397, loss: 0.29563242197036743\n",
      "epoch: 9, batch: 398, loss: 0.5638795495033264\n",
      "epoch: 9, batch: 399, loss: 0.6895919442176819\n",
      "epoch: 9, batch: 400, loss: 0.5644605159759521\n",
      "epoch: 9, batch: 401, loss: 0.33019721508026123\n",
      "epoch: 9, batch: 402, loss: 0.3603665232658386\n",
      "epoch: 9, batch: 403, loss: 0.7282789945602417\n",
      "epoch: 9, batch: 404, loss: 0.33732935786247253\n",
      "epoch: 9, batch: 405, loss: 0.40749016404151917\n",
      "epoch: 9, batch: 406, loss: 0.40315327048301697\n",
      "epoch: 9, batch: 407, loss: 0.5909150838851929\n",
      "epoch: 9, batch: 408, loss: 0.7214879393577576\n",
      "epoch: 9, batch: 409, loss: 0.7077608704566956\n",
      "epoch: 9, batch: 410, loss: 0.38113343715667725\n",
      "epoch: 9, batch: 411, loss: 0.322988361120224\n",
      "epoch: 9, batch: 412, loss: 0.44478535652160645\n",
      "epoch: 9, batch: 413, loss: 0.20151856541633606\n",
      "epoch: 9, batch: 414, loss: 0.7247557044029236\n",
      "epoch: 9, batch: 415, loss: 0.4746059775352478\n",
      "epoch: 9, batch: 416, loss: 0.32541006803512573\n",
      "epoch: 9, batch: 417, loss: 0.20152513682842255\n",
      "epoch: 9, batch: 418, loss: 0.5051854252815247\n",
      "epoch: 9, batch: 419, loss: 0.5087664723396301\n",
      "epoch: 9, batch: 420, loss: 0.4882277250289917\n",
      "epoch: 9, batch: 421, loss: 0.7742008566856384\n",
      "epoch: 9, batch: 422, loss: 0.5243847370147705\n",
      "epoch: 9, batch: 423, loss: 0.6637502908706665\n",
      "epoch: 9, batch: 424, loss: 0.5169157981872559\n",
      "epoch: 9, batch: 425, loss: 0.29459676146507263\n",
      "epoch: 9, batch: 426, loss: 0.5275453329086304\n",
      "epoch: 9, batch: 427, loss: 0.3805927038192749\n",
      "epoch: 9, batch: 428, loss: 0.5377777814865112\n",
      "epoch: 9, batch: 429, loss: 0.5637683272361755\n",
      "epoch: 9, batch: 430, loss: 0.7513996958732605\n",
      "epoch: 9, batch: 431, loss: 0.5198293924331665\n",
      "epoch: 9, batch: 432, loss: 0.5461281538009644\n",
      "epoch: 9, batch: 433, loss: 0.704285740852356\n",
      "epoch: 9, batch: 434, loss: 0.36728671193122864\n",
      "epoch: 9, batch: 435, loss: 0.5959810018539429\n",
      "epoch: 9, batch: 436, loss: 0.47697266936302185\n",
      "epoch: 9, batch: 437, loss: 0.4985104501247406\n",
      "epoch: 9, batch: 438, loss: 0.49416661262512207\n",
      "epoch: 9, batch: 439, loss: 0.19030624628067017\n",
      "epoch: 9, batch: 440, loss: 0.5730874538421631\n",
      "epoch: 9, batch: 441, loss: 0.5338286757469177\n",
      "epoch: 9, batch: 442, loss: 0.4315702021121979\n",
      "epoch: 9, batch: 443, loss: 0.26316961646080017\n",
      "epoch: 9, batch: 444, loss: 0.5526391863822937\n",
      "epoch: 9, batch: 445, loss: 0.46471068263053894\n",
      "epoch: 9, batch: 446, loss: 0.6947260499000549\n",
      "epoch: 9, batch: 447, loss: 0.42532870173454285\n",
      "epoch: 9, batch: 448, loss: 0.31697916984558105\n",
      "epoch: 9, batch: 449, loss: 0.454755574464798\n",
      "epoch: 9, batch: 450, loss: 0.32830190658569336\n",
      "epoch: 9, batch: 451, loss: 0.36944833397865295\n",
      "epoch: 9, batch: 452, loss: 0.47011250257492065\n",
      "epoch: 9, batch: 453, loss: 0.17067886888980865\n",
      "epoch: 9, batch: 454, loss: 0.4915054738521576\n",
      "epoch: 9, batch: 455, loss: 0.5160015225410461\n",
      "epoch: 9, batch: 456, loss: 0.32985857129096985\n",
      "epoch: 9, batch: 457, loss: 0.9011770486831665\n",
      "epoch: 9, batch: 458, loss: 0.5332986116409302\n",
      "epoch: 9, batch: 459, loss: 0.5320513844490051\n",
      "epoch: 9, batch: 460, loss: 0.48738351464271545\n",
      "epoch: 9, batch: 461, loss: 0.6409704089164734\n",
      "epoch: 9, batch: 462, loss: 0.5344480872154236\n",
      "epoch: 9, batch: 463, loss: 0.49872076511383057\n",
      "epoch: 9, batch: 464, loss: 0.3526102602481842\n",
      "epoch: 9, batch: 465, loss: 0.3260689377784729\n",
      "epoch: 9, batch: 466, loss: 0.5516508221626282\n",
      "epoch: 9, batch: 467, loss: 0.5324832201004028\n",
      "epoch: 9, batch: 468, loss: 0.5339750051498413\n",
      "epoch: 9, batch: 469, loss: 0.3292878270149231\n",
      "epoch: 9, batch: 470, loss: 0.6986876130104065\n",
      "epoch: 9, batch: 471, loss: 0.5368792414665222\n",
      "epoch: 9, batch: 472, loss: 0.3887358605861664\n",
      "epoch: 9, batch: 473, loss: 0.32718366384506226\n",
      "epoch: 9, batch: 474, loss: 0.37463268637657166\n",
      "epoch: 9, batch: 475, loss: 0.43953293561935425\n",
      "epoch: 9, batch: 476, loss: 0.48173633217811584\n",
      "epoch: 9, batch: 477, loss: 0.41363564133644104\n",
      "epoch: 9, batch: 478, loss: 0.16004587709903717\n",
      "epoch: 9, batch: 479, loss: 0.3978067934513092\n",
      "epoch: 9, batch: 480, loss: 0.4209119379520416\n",
      "epoch: 9, batch: 481, loss: 0.386405348777771\n",
      "epoch: 9, batch: 482, loss: 0.28710535168647766\n",
      "epoch: 9, batch: 483, loss: 0.20774352550506592\n",
      "epoch: 9, batch: 484, loss: 0.5073689818382263\n",
      "epoch: 9, batch: 485, loss: 0.47822439670562744\n",
      "epoch: 9, batch: 486, loss: 0.3335254192352295\n",
      "epoch: 9, batch: 487, loss: 0.3028126358985901\n",
      "epoch: 9, batch: 488, loss: 0.3545401990413666\n",
      "epoch: 9, batch: 489, loss: 0.3576163351535797\n",
      "epoch: 9, batch: 490, loss: 0.6498579382896423\n",
      "epoch: 9, batch: 491, loss: 0.5961111783981323\n",
      "epoch: 9, batch: 492, loss: 0.5266042351722717\n",
      "epoch: 9, batch: 493, loss: 0.2872050106525421\n",
      "epoch: 9, batch: 494, loss: 0.3542962670326233\n",
      "epoch: 9, batch: 495, loss: 0.31073886156082153\n",
      "epoch: 9, batch: 496, loss: 0.3241889774799347\n",
      "epoch: 9, batch: 497, loss: 0.30203720927238464\n",
      "epoch: 9, batch: 498, loss: 0.5382450222969055\n",
      "epoch: 9, batch: 499, loss: 0.2381087839603424\n",
      "epoch: 9, batch: 500, loss: 0.3894020915031433\n",
      "epoch: 9, batch: 501, loss: 0.2880101799964905\n",
      "epoch: 9, batch: 502, loss: 0.6468508243560791\n",
      "epoch: 9, batch: 503, loss: 0.41690847277641296\n",
      "epoch: 9, batch: 504, loss: 0.7740805745124817\n",
      "epoch: 9, batch: 505, loss: 0.34408479928970337\n",
      "epoch: 9, batch: 506, loss: 0.2924596965312958\n",
      "epoch: 9, batch: 507, loss: 0.7464212775230408\n",
      "epoch: 9, batch: 508, loss: 0.37125352025032043\n",
      "epoch: 9, batch: 509, loss: 0.3231809139251709\n",
      "epoch: 9, batch: 510, loss: 0.5358659625053406\n",
      "epoch: 9, batch: 511, loss: 0.435519814491272\n",
      "epoch: 9, batch: 512, loss: 0.4027453064918518\n",
      "epoch: 9, batch: 513, loss: 0.3932550251483917\n",
      "epoch: 9, batch: 514, loss: 0.2527575194835663\n",
      "epoch: 9, batch: 515, loss: 0.4192867577075958\n",
      "epoch: 9, batch: 516, loss: 0.32632288336753845\n",
      "epoch: 9, batch: 517, loss: 0.5298274159431458\n",
      "epoch: 9, batch: 518, loss: 0.37217986583709717\n",
      "epoch: 9, batch: 519, loss: 0.5066553950309753\n",
      "epoch: 9, batch: 520, loss: 0.5426253080368042\n",
      "epoch: 9, batch: 521, loss: 0.3089064061641693\n",
      "epoch: 9, batch: 522, loss: 0.35562512278556824\n",
      "epoch: 9, batch: 523, loss: 0.3183254301548004\n",
      "epoch: 9, batch: 524, loss: 0.6476485133171082\n",
      "epoch: 9, batch: 525, loss: 0.46308013796806335\n",
      "epoch: 9, batch: 526, loss: 0.4049280285835266\n",
      "epoch: 9, batch: 527, loss: 0.5174416899681091\n",
      "epoch: 9, batch: 528, loss: 0.5431473255157471\n",
      "epoch: 9, batch: 529, loss: 0.2423688769340515\n",
      "epoch: 9, batch: 530, loss: 0.5360422134399414\n",
      "epoch: 9, batch: 531, loss: 0.36115026473999023\n",
      "epoch: 9, batch: 532, loss: 0.540891706943512\n",
      "epoch: 9, batch: 533, loss: 0.3332456648349762\n",
      "epoch: 9, batch: 534, loss: 0.7950877547264099\n",
      "epoch: 9, batch: 535, loss: 0.3903965353965759\n",
      "epoch: 9, batch: 536, loss: 0.6668956875801086\n",
      "epoch: 9, batch: 537, loss: 0.22259432077407837\n",
      "epoch: 9, batch: 538, loss: 0.5244852304458618\n",
      "epoch: 9, batch: 539, loss: 0.590598464012146\n",
      "epoch: 9, batch: 540, loss: 0.42014744877815247\n",
      "epoch: 9, batch: 541, loss: 0.4995848536491394\n",
      "epoch: 9, batch: 542, loss: 0.29245641827583313\n",
      "epoch: 9, batch: 543, loss: 0.5047755241394043\n",
      "epoch: 9, batch: 544, loss: 0.7138689160346985\n",
      "epoch: 9, batch: 545, loss: 0.5070604681968689\n",
      "epoch: 9, batch: 546, loss: 0.5501481890678406\n",
      "epoch: 9, batch: 547, loss: 0.42247310280799866\n",
      "epoch: 9, batch: 548, loss: 0.46630364656448364\n",
      "epoch: 9, batch: 549, loss: 0.42889267206192017\n",
      "epoch: 9, batch: 550, loss: 0.4255102574825287\n",
      "epoch: 9, batch: 551, loss: 0.4318438172340393\n",
      "epoch: 9, batch: 552, loss: 0.3278726637363434\n",
      "epoch: 9, batch: 553, loss: 0.33668795228004456\n",
      "epoch: 9, batch: 554, loss: 0.3848884403705597\n",
      "epoch: 9, batch: 555, loss: 0.38986730575561523\n",
      "epoch: 9, batch: 556, loss: 0.6166922450065613\n",
      "epoch: 9, batch: 557, loss: 0.24719206988811493\n",
      "epoch: 9, batch: 558, loss: 0.6585772037506104\n",
      "epoch: 9, batch: 559, loss: 0.5081291794776917\n",
      "epoch: 9, batch: 560, loss: 0.6673438549041748\n",
      "epoch: 9, batch: 561, loss: 0.30707696080207825\n",
      "epoch: 9, batch: 562, loss: 0.6176621317863464\n",
      "epoch: 9, batch: 563, loss: 0.2970224916934967\n",
      "epoch: 9, batch: 564, loss: 0.5223750472068787\n",
      "epoch: 9, batch: 565, loss: 0.7022498846054077\n",
      "epoch: 9, batch: 566, loss: 0.7483054399490356\n",
      "epoch: 9, batch: 567, loss: 0.37055328488349915\n",
      "epoch: 9, batch: 568, loss: 0.25300097465515137\n",
      "epoch: 9, batch: 569, loss: 0.5446650981903076\n",
      "epoch: 9, batch: 570, loss: 0.3733668327331543\n",
      "epoch: 9, batch: 571, loss: 0.3859046697616577\n",
      "epoch: 9, batch: 572, loss: 0.40622735023498535\n",
      "epoch: 9, batch: 573, loss: 0.7604158520698547\n",
      "epoch: 9, batch: 574, loss: 0.4033963680267334\n",
      "epoch: 9, batch: 575, loss: 0.22186976671218872\n",
      "epoch: 9, batch: 576, loss: 0.5867421627044678\n",
      "epoch: 9, batch: 577, loss: 0.31869131326675415\n",
      "epoch: 9, batch: 578, loss: 0.3268730640411377\n",
      "epoch: 9, batch: 579, loss: 0.3468780815601349\n",
      "epoch: 9, batch: 580, loss: 0.3415990471839905\n",
      "epoch: 9, batch: 581, loss: 0.3069421947002411\n",
      "epoch: 9, batch: 582, loss: 0.5916475653648376\n",
      "epoch: 9, batch: 583, loss: 0.3951140344142914\n",
      "epoch: 9, batch: 584, loss: 0.4200856387615204\n",
      "epoch: 9, batch: 585, loss: 0.7282081246376038\n",
      "epoch: 9, batch: 586, loss: 0.33859962224960327\n",
      "epoch: 9, batch: 587, loss: 0.48450976610183716\n",
      "epoch: 9, batch: 588, loss: 0.4516597390174866\n",
      "epoch: 9, batch: 589, loss: 0.5110570788383484\n",
      "epoch: 9, batch: 590, loss: 0.3959183692932129\n",
      "epoch: 9, batch: 591, loss: 0.3550427258014679\n",
      "epoch: 9, batch: 592, loss: 0.49499380588531494\n",
      "epoch: 9, batch: 593, loss: 0.3163515329360962\n",
      "epoch: 9, batch: 594, loss: 0.47877439856529236\n",
      "epoch: 9, batch: 595, loss: 0.604356586933136\n",
      "epoch: 9, batch: 596, loss: 0.3838329017162323\n",
      "epoch: 9, batch: 597, loss: 0.45073989033699036\n",
      "epoch: 9, batch: 598, loss: 0.3663872182369232\n",
      "epoch: 9, batch: 599, loss: 0.2912358045578003\n",
      "epoch: 9, batch: 600, loss: 0.3561652600765228\n",
      "epoch: 9, batch: 601, loss: 0.4484254717826843\n",
      "epoch: 9, batch: 602, loss: 0.4880659580230713\n",
      "epoch: 9, batch: 603, loss: 0.4621274769306183\n",
      "epoch: 9, batch: 604, loss: 0.8300437331199646\n",
      "epoch: 9, batch: 605, loss: 0.532233476638794\n",
      "epoch: 9, batch: 606, loss: 0.43953144550323486\n",
      "epoch: 9, batch: 607, loss: 0.2643990218639374\n",
      "epoch: 9, batch: 608, loss: 0.412130206823349\n",
      "epoch: 9, batch: 609, loss: 0.38408464193344116\n",
      "epoch: 9, batch: 610, loss: 0.5767669677734375\n",
      "epoch: 9, batch: 611, loss: 0.35753726959228516\n",
      "epoch: 9, batch: 612, loss: 0.6343214511871338\n",
      "epoch: 9, batch: 613, loss: 0.417171448469162\n",
      "epoch: 9, batch: 614, loss: 0.3491784334182739\n",
      "epoch: 9, batch: 615, loss: 0.6112543940544128\n",
      "epoch: 9, batch: 616, loss: 0.4162960350513458\n",
      "epoch: 9, batch: 617, loss: 0.41418978571891785\n",
      "epoch: 9, batch: 618, loss: 0.4811273217201233\n",
      "epoch: 9, batch: 619, loss: 0.622718334197998\n",
      "epoch: 9, batch: 620, loss: 0.6065312027931213\n",
      "epoch: 9, batch: 621, loss: 0.35877275466918945\n",
      "epoch: 9, batch: 622, loss: 0.40347984433174133\n",
      "epoch: 9, batch: 623, loss: 0.46791383624076843\n",
      "epoch: 9, batch: 624, loss: 0.4432357847690582\n",
      "epoch: 9, batch: 625, loss: 0.40050843358039856\n",
      "epoch: 9, batch: 626, loss: 0.411573588848114\n",
      "epoch: 9, batch: 627, loss: 0.44788873195648193\n",
      "epoch: 9, batch: 628, loss: 0.52655029296875\n",
      "epoch: 9, batch: 629, loss: 0.237171471118927\n",
      "epoch: 9, batch: 630, loss: 0.39080676436424255\n",
      "epoch: 9, batch: 631, loss: 0.29633891582489014\n",
      "epoch: 9, batch: 632, loss: 0.5249277353286743\n",
      "epoch: 9, batch: 633, loss: 0.6210835576057434\n",
      "epoch: 9, batch: 634, loss: 0.29838669300079346\n",
      "epoch: 9, batch: 635, loss: 0.3373798131942749\n",
      "epoch: 9, batch: 636, loss: 0.788617730140686\n",
      "epoch: 9, batch: 637, loss: 0.27431362867355347\n",
      "epoch: 9, batch: 638, loss: 0.43910524249076843\n",
      "epoch: 9, batch: 639, loss: 0.4760761559009552\n",
      "epoch: 9, batch: 640, loss: 0.7252821922302246\n",
      "epoch: 9, batch: 641, loss: 0.5883013606071472\n",
      "epoch: 9, batch: 642, loss: 0.29554805159568787\n",
      "epoch: 9, batch: 643, loss: 0.40214261412620544\n",
      "epoch: 9, batch: 644, loss: 0.37928342819213867\n",
      "epoch: 9, batch: 645, loss: 0.35531067848205566\n",
      "epoch: 9, batch: 646, loss: 1.001584529876709\n",
      "epoch: 9, batch: 647, loss: 0.539474368095398\n",
      "epoch: 9, batch: 648, loss: 0.23004817962646484\n",
      "epoch: 9, batch: 649, loss: 0.39993226528167725\n",
      "epoch: 9, batch: 650, loss: 0.6698665618896484\n",
      "epoch: 9, batch: 651, loss: 0.2679389417171478\n",
      "epoch: 9, batch: 652, loss: 0.4296829402446747\n",
      "epoch: 9, batch: 653, loss: 0.421522855758667\n",
      "epoch: 9, batch: 654, loss: 0.4524174630641937\n",
      "epoch: 9, batch: 655, loss: 0.2837965190410614\n",
      "epoch: 9, batch: 656, loss: 0.6242756843566895\n",
      "epoch: 9, batch: 657, loss: 0.39847105741500854\n",
      "epoch: 9, batch: 658, loss: 0.45427125692367554\n",
      "epoch: 9, batch: 659, loss: 0.406838595867157\n",
      "epoch: 9, batch: 660, loss: 0.2517794966697693\n",
      "epoch: 9, batch: 661, loss: 0.4373559355735779\n",
      "epoch: 9, batch: 662, loss: 0.38247165083885193\n",
      "epoch: 9, batch: 663, loss: 0.3713834881782532\n",
      "epoch: 9, batch: 664, loss: 0.5416823625564575\n",
      "epoch: 9, batch: 665, loss: 0.3942113220691681\n",
      "epoch: 9, batch: 666, loss: 0.3618723452091217\n",
      "epoch: 9, batch: 667, loss: 0.7864859104156494\n",
      "epoch: 9, batch: 668, loss: 0.3685571551322937\n",
      "epoch: 9, batch: 669, loss: 0.4649643003940582\n",
      "epoch: 9, batch: 670, loss: 0.5269262194633484\n",
      "epoch: 9, batch: 671, loss: 0.5165481567382812\n",
      "epoch: 9, batch: 672, loss: 0.46138229966163635\n",
      "epoch: 9, batch: 673, loss: 0.6320978403091431\n",
      "epoch: 9, batch: 674, loss: 0.3308010995388031\n",
      "epoch: 9, batch: 675, loss: 0.5067430734634399\n",
      "epoch: 9, batch: 676, loss: 0.28773295879364014\n",
      "epoch: 9, batch: 677, loss: 0.5520302653312683\n",
      "epoch: 9, batch: 678, loss: 0.5225268006324768\n",
      "epoch: 9, batch: 679, loss: 0.6994679570198059\n",
      "epoch: 9, batch: 680, loss: 0.5642581582069397\n",
      "epoch: 9, batch: 681, loss: 0.38634422421455383\n",
      "epoch: 9, batch: 682, loss: 0.41352730989456177\n",
      "epoch: 9, batch: 683, loss: 0.6153472661972046\n",
      "epoch: 9, batch: 684, loss: 0.5052915215492249\n",
      "epoch: 9, batch: 685, loss: 0.16173632442951202\n",
      "epoch: 9, batch: 686, loss: 0.3545052111148834\n",
      "epoch: 9, batch: 687, loss: 0.3852224349975586\n",
      "epoch: 9, batch: 688, loss: 0.4033202826976776\n",
      "epoch: 9, batch: 689, loss: 0.4753316640853882\n",
      "epoch: 9, batch: 690, loss: 0.3839741051197052\n",
      "epoch: 9, batch: 691, loss: 0.29363036155700684\n",
      "epoch: 9, batch: 692, loss: 0.30687013268470764\n",
      "epoch: 9, batch: 693, loss: 0.30572569370269775\n",
      "epoch: 9, batch: 694, loss: 0.5157368183135986\n",
      "epoch: 9, batch: 695, loss: 0.40164947509765625\n",
      "epoch: 9, batch: 696, loss: 0.38888418674468994\n",
      "epoch: 9, batch: 697, loss: 0.6412267088890076\n",
      "epoch: 9, batch: 698, loss: 0.3968784809112549\n",
      "epoch: 9, batch: 699, loss: 0.4448848366737366\n",
      "epoch: 9, batch: 700, loss: 0.3728567361831665\n",
      "epoch: 9, batch: 701, loss: 0.48892807960510254\n",
      "epoch: 9, batch: 702, loss: 0.31704065203666687\n",
      "epoch: 9, batch: 703, loss: 0.48331108689308167\n",
      "epoch: 9, batch: 704, loss: 0.7733706831932068\n",
      "epoch: 9, batch: 705, loss: 0.48643577098846436\n",
      "epoch: 9, batch: 706, loss: 0.5682337284088135\n",
      "epoch: 9, batch: 707, loss: 0.454155832529068\n",
      "epoch: 9, batch: 708, loss: 0.39471811056137085\n",
      "epoch: 9, batch: 709, loss: 0.3055577576160431\n",
      "epoch: 9, batch: 710, loss: 0.36632946133613586\n",
      "epoch: 9, batch: 711, loss: 0.4677414894104004\n",
      "epoch: 9, batch: 712, loss: 0.35234788060188293\n",
      "epoch: 9, batch: 713, loss: 0.46189191937446594\n",
      "epoch: 9, batch: 714, loss: 0.46359390020370483\n",
      "epoch: 9, batch: 715, loss: 0.39035022258758545\n",
      "epoch: 9, batch: 716, loss: 0.398591548204422\n",
      "epoch: 9, batch: 717, loss: 0.7777267694473267\n",
      "epoch: 9, batch: 718, loss: 0.3739071488380432\n",
      "epoch: 9, batch: 719, loss: 0.44063955545425415\n",
      "epoch: 9, batch: 720, loss: 0.31736770272254944\n",
      "epoch: 9, batch: 721, loss: 0.7041156888008118\n",
      "epoch: 9, batch: 722, loss: 0.48973098397254944\n",
      "epoch: 9, batch: 723, loss: 0.29120227694511414\n",
      "epoch: 9, batch: 724, loss: 0.3254292607307434\n",
      "epoch: 9, batch: 725, loss: 0.3897705376148224\n",
      "epoch: 9, batch: 726, loss: 0.38813483715057373\n",
      "epoch: 9, batch: 727, loss: 0.2333451807498932\n",
      "epoch: 9, batch: 728, loss: 0.6393464207649231\n",
      "epoch: 9, batch: 729, loss: 0.45180055499076843\n",
      "epoch: 9, batch: 730, loss: 0.32024598121643066\n",
      "epoch: 9, batch: 731, loss: 0.3369739055633545\n",
      "epoch: 9, batch: 732, loss: 0.3132702112197876\n",
      "epoch: 9, batch: 733, loss: 0.24031904339790344\n",
      "epoch: 9, batch: 734, loss: 0.4736475646495819\n",
      "epoch: 9, batch: 735, loss: 0.5886263847351074\n",
      "epoch: 9, batch: 736, loss: 0.3565584719181061\n",
      "epoch: 9, batch: 737, loss: 0.26678693294525146\n",
      "epoch: 9, batch: 738, loss: 0.5439849495887756\n",
      "epoch: 9, batch: 739, loss: 0.4555434584617615\n",
      "epoch: 9, batch: 740, loss: 0.43552619218826294\n",
      "epoch: 9, batch: 741, loss: 0.37862932682037354\n",
      "epoch: 9, batch: 742, loss: 0.3708951473236084\n",
      "epoch: 9, batch: 743, loss: 0.5401046872138977\n",
      "epoch: 9, batch: 744, loss: 0.32992127537727356\n",
      "epoch: 9, batch: 745, loss: 0.4205496311187744\n",
      "epoch: 9, batch: 746, loss: 0.5464953780174255\n",
      "epoch: 9, batch: 747, loss: 0.46672770380973816\n",
      "epoch: 9, batch: 748, loss: 0.3987114429473877\n",
      "epoch: 9, batch: 749, loss: 0.8155268430709839\n",
      "epoch: 9, batch: 750, loss: 0.58683180809021\n",
      "epoch: 9, batch: 751, loss: 0.7422881722450256\n",
      "epoch: 9, batch: 752, loss: 0.47176259756088257\n",
      "epoch: 9, batch: 753, loss: 0.42511245608329773\n",
      "epoch: 9, batch: 754, loss: 0.5301098227500916\n",
      "epoch: 9, batch: 755, loss: 0.284118115901947\n",
      "epoch: 9, batch: 756, loss: 0.4934132695198059\n",
      "epoch: 9, batch: 757, loss: 0.43910443782806396\n",
      "epoch: 9, batch: 758, loss: 0.5470402836799622\n",
      "epoch: 9, batch: 759, loss: 0.5668537616729736\n",
      "epoch: 9, batch: 760, loss: 0.6385907530784607\n",
      "epoch: 9, batch: 761, loss: 0.3818971514701843\n",
      "epoch: 9, batch: 762, loss: 0.29992935061454773\n",
      "epoch: 9, batch: 763, loss: 0.4082234501838684\n",
      "epoch: 9, batch: 764, loss: 0.6352559924125671\n",
      "epoch: 9, batch: 765, loss: 0.6392900943756104\n",
      "epoch: 9, batch: 766, loss: 0.40823251008987427\n",
      "epoch: 9, batch: 767, loss: 0.2907390296459198\n",
      "epoch: 9, batch: 768, loss: 0.6966507434844971\n",
      "epoch: 9, batch: 769, loss: 0.45921167731285095\n",
      "epoch: 9, batch: 770, loss: 0.5497922897338867\n",
      "epoch: 9, batch: 771, loss: 0.39813944697380066\n",
      "epoch: 9, batch: 772, loss: 0.30313390493392944\n",
      "epoch: 9, batch: 773, loss: 0.4253362715244293\n",
      "epoch: 9, batch: 774, loss: 0.41815587878227234\n",
      "epoch: 9, batch: 775, loss: 0.8349299430847168\n",
      "epoch: 9, batch: 776, loss: 0.5434439778327942\n",
      "epoch: 9, batch: 777, loss: 1.0071200132369995\n",
      "epoch: 9, batch: 778, loss: 0.40587741136550903\n",
      "epoch: 9, batch: 779, loss: 0.5959969758987427\n",
      "epoch: 9, batch: 780, loss: 0.4161267876625061\n",
      "epoch: 9, batch: 781, loss: 0.5261728167533875\n",
      "epoch: 9, batch: 782, loss: 0.34224700927734375\n",
      "epoch: 9, batch: 783, loss: 0.7229503393173218\n",
      "epoch: 9, batch: 784, loss: 0.3683980107307434\n",
      "epoch: 9, batch: 785, loss: 0.3109658360481262\n",
      "epoch: 9, batch: 786, loss: 0.564120352268219\n",
      "epoch: 9, batch: 787, loss: 0.46869906783103943\n",
      "epoch: 9, batch: 788, loss: 0.4758772552013397\n",
      "epoch: 9, batch: 789, loss: 0.4379718005657196\n",
      "epoch: 9, batch: 790, loss: 0.3823677897453308\n",
      "epoch: 9, batch: 791, loss: 0.2579187750816345\n",
      "epoch: 9, batch: 792, loss: 0.6457297801971436\n",
      "epoch: 9, batch: 793, loss: 0.4397865831851959\n",
      "epoch: 9, batch: 794, loss: 0.7122908234596252\n",
      "epoch: 9, batch: 795, loss: 0.3237573504447937\n",
      "epoch: 9, batch: 796, loss: 0.29354509711265564\n",
      "epoch: 9, batch: 797, loss: 0.342934787273407\n",
      "epoch: 9, batch: 798, loss: 0.31481027603149414\n",
      "epoch: 9, batch: 799, loss: 0.3807046115398407\n",
      "epoch: 9, batch: 800, loss: 0.3774399161338806\n",
      "epoch: 9, batch: 801, loss: 0.4038010239601135\n",
      "epoch: 9, batch: 802, loss: 0.3590647280216217\n",
      "epoch: 9, batch: 803, loss: 0.46948084235191345\n",
      "epoch: 9, batch: 804, loss: 0.4281318187713623\n",
      "epoch: 9, batch: 805, loss: 0.3731965720653534\n",
      "epoch: 9, batch: 806, loss: 0.6888661980628967\n",
      "epoch: 9, batch: 807, loss: 0.5455662608146667\n",
      "epoch: 9, batch: 808, loss: 0.2926896810531616\n",
      "epoch: 9, batch: 809, loss: 0.8049236536026001\n",
      "epoch: 9, batch: 810, loss: 0.44549691677093506\n",
      "epoch: 9, batch: 811, loss: 0.34080466628074646\n",
      "epoch: 9, batch: 812, loss: 0.5695701837539673\n",
      "epoch: 9, batch: 813, loss: 0.2910914123058319\n",
      "epoch: 9, batch: 814, loss: 0.31128525733947754\n",
      "epoch: 9, batch: 815, loss: 0.6620373725891113\n",
      "epoch: 9, batch: 816, loss: 0.37209177017211914\n",
      "epoch: 9, batch: 817, loss: 0.3353217542171478\n",
      "epoch: 9, batch: 818, loss: 0.6038151979446411\n",
      "epoch: 9, batch: 819, loss: 0.43102338910102844\n",
      "epoch: 9, batch: 820, loss: 0.44017696380615234\n",
      "epoch: 9, batch: 821, loss: 0.45900678634643555\n",
      "epoch: 9, batch: 822, loss: 0.5420475006103516\n",
      "epoch: 9, batch: 823, loss: 0.3117770254611969\n",
      "epoch: 9, batch: 824, loss: 0.26008668541908264\n",
      "epoch: 9, batch: 825, loss: 0.377340167760849\n",
      "epoch: 9, batch: 826, loss: 0.3055709898471832\n",
      "epoch: 9, batch: 827, loss: 0.5732907652854919\n",
      "epoch: 9, batch: 828, loss: 0.3853430151939392\n",
      "epoch: 9, batch: 829, loss: 0.38410136103630066\n",
      "epoch: 9, batch: 830, loss: 0.47876593470573425\n",
      "epoch: 9, batch: 831, loss: 0.636756956577301\n",
      "epoch: 9, batch: 832, loss: 0.5823714733123779\n",
      "epoch: 9, batch: 833, loss: 0.49012959003448486\n",
      "epoch: 9, batch: 834, loss: 0.4716465473175049\n",
      "epoch: 9, batch: 835, loss: 0.45726630091667175\n",
      "epoch: 9, batch: 836, loss: 0.5347529053688049\n",
      "epoch: 9, batch: 837, loss: 0.6296072602272034\n",
      "epoch: 9, batch: 838, loss: 0.5533862709999084\n",
      "epoch: 9, batch: 839, loss: 0.3932824730873108\n",
      "epoch: 9, batch: 840, loss: 0.31694576144218445\n",
      "epoch: 9, batch: 841, loss: 0.32441630959510803\n",
      "epoch: 9, batch: 842, loss: 0.6101027727127075\n",
      "epoch: 9, batch: 843, loss: 0.36066168546676636\n",
      "epoch: 9, batch: 844, loss: 0.33912479877471924\n",
      "epoch: 9, batch: 845, loss: 0.2300354391336441\n",
      "epoch: 9, batch: 846, loss: 0.42829403281211853\n",
      "epoch: 9, batch: 847, loss: 0.5798109173774719\n",
      "epoch: 9, batch: 848, loss: 0.4851486086845398\n",
      "epoch: 9, batch: 849, loss: 0.6623005270957947\n",
      "epoch: 9, batch: 850, loss: 0.4617668390274048\n",
      "epoch: 9, batch: 851, loss: 0.3749600648880005\n",
      "epoch: 9, batch: 852, loss: 0.3775532841682434\n",
      "epoch: 9, batch: 853, loss: 0.39225754141807556\n",
      "epoch: 9, batch: 854, loss: 0.34375402331352234\n",
      "epoch: 9, batch: 855, loss: 0.3959844708442688\n",
      "epoch: 9, batch: 856, loss: 0.6458117365837097\n",
      "epoch: 9, batch: 857, loss: 0.6804690957069397\n",
      "epoch: 9, batch: 858, loss: 0.7706544995307922\n",
      "epoch: 9, batch: 859, loss: 0.5094447135925293\n",
      "epoch: 9, batch: 860, loss: 0.5757133364677429\n",
      "epoch: 9, batch: 861, loss: 0.4827519655227661\n",
      "epoch: 9, batch: 862, loss: 0.8213393092155457\n",
      "epoch: 9, batch: 863, loss: 0.7020193338394165\n",
      "epoch: 9, batch: 864, loss: 0.3720287084579468\n",
      "epoch: 9, batch: 865, loss: 0.3735693097114563\n",
      "epoch: 9, batch: 866, loss: 0.7620741724967957\n",
      "epoch: 9, batch: 867, loss: 0.3922330141067505\n",
      "epoch: 9, batch: 868, loss: 0.27225497364997864\n",
      "epoch: 9, batch: 869, loss: 0.439506471157074\n",
      "epoch: 9, batch: 870, loss: 0.3469904363155365\n",
      "epoch: 9, batch: 871, loss: 0.5135886073112488\n",
      "epoch: 9, batch: 872, loss: 0.7507656812667847\n",
      "epoch: 9, batch: 873, loss: 0.5383253693580627\n",
      "epoch: 9, batch: 874, loss: 0.3825848400592804\n",
      "epoch: 9, batch: 875, loss: 0.2357073426246643\n",
      "epoch: 9, batch: 876, loss: 0.48479533195495605\n",
      "epoch: 9, batch: 877, loss: 0.5696264505386353\n",
      "epoch: 9, batch: 878, loss: 0.4491998553276062\n",
      "epoch: 9, batch: 879, loss: 0.606819748878479\n",
      "epoch: 9, batch: 880, loss: 0.6407181620597839\n",
      "epoch: 9, batch: 881, loss: 0.5282037854194641\n",
      "epoch: 9, batch: 882, loss: 0.42353594303131104\n",
      "epoch: 9, batch: 883, loss: 0.45196741819381714\n",
      "epoch: 9, batch: 884, loss: 0.5021184682846069\n",
      "epoch: 9, batch: 885, loss: 0.5244024395942688\n",
      "epoch: 9, batch: 886, loss: 0.602582573890686\n",
      "epoch: 9, batch: 887, loss: 0.5238760709762573\n",
      "epoch: 9, batch: 888, loss: 0.3006132245063782\n",
      "epoch: 9, batch: 889, loss: 0.3245774805545807\n",
      "epoch: 9, batch: 890, loss: 0.3560275137424469\n",
      "epoch: 9, batch: 891, loss: 0.5312816500663757\n",
      "epoch: 9, batch: 892, loss: 0.5640005469322205\n",
      "epoch: 9, batch: 893, loss: 0.5653167963027954\n",
      "epoch: 9, batch: 894, loss: 0.14963942766189575\n",
      "epoch: 9, batch: 895, loss: 0.27828502655029297\n",
      "epoch: 9, batch: 896, loss: 0.5189278721809387\n",
      "epoch: 9, batch: 897, loss: 0.3944183588027954\n",
      "epoch: 9, batch: 898, loss: 0.5478789806365967\n",
      "epoch: 9, batch: 899, loss: 0.6875526905059814\n",
      "epoch: 9, batch: 900, loss: 0.3470446467399597\n",
      "epoch: 9, batch: 901, loss: 0.326261430978775\n",
      "epoch: 9, batch: 902, loss: 0.3608362078666687\n",
      "epoch: 9, batch: 903, loss: 0.39555883407592773\n",
      "epoch: 9, batch: 904, loss: 0.41957566142082214\n",
      "epoch: 9, batch: 905, loss: 0.3936421573162079\n",
      "epoch: 9, batch: 906, loss: 0.8360655307769775\n",
      "epoch: 9, batch: 907, loss: 0.5273171663284302\n",
      "epoch: 9, batch: 908, loss: 0.40512895584106445\n",
      "epoch: 9, batch: 909, loss: 0.5847113132476807\n",
      "epoch: 9, batch: 910, loss: 0.46229490637779236\n",
      "epoch: 9, batch: 911, loss: 0.3637367784976959\n",
      "epoch: 9, batch: 912, loss: 0.2629200220108032\n",
      "epoch: 9, batch: 913, loss: 0.7270802855491638\n",
      "epoch: 9, batch: 914, loss: 0.3045124411582947\n",
      "epoch: 9, batch: 915, loss: 0.25321143865585327\n",
      "epoch: 9, batch: 916, loss: 0.32432857155799866\n",
      "epoch: 9, batch: 917, loss: 0.4178538918495178\n",
      "epoch: 9, batch: 918, loss: 0.6273970007896423\n",
      "epoch: 9, batch: 919, loss: 0.5465815663337708\n",
      "epoch: 9, batch: 920, loss: 0.8870744705200195\n",
      "epoch: 9, batch: 921, loss: 0.6189124584197998\n",
      "epoch: 9, batch: 922, loss: 0.3140489459037781\n",
      "epoch: 9, batch: 923, loss: 0.7780977487564087\n",
      "epoch: 9, batch: 924, loss: 0.3801172375679016\n",
      "epoch: 9, batch: 925, loss: 0.47367721796035767\n",
      "epoch: 9, batch: 926, loss: 0.6877298355102539\n",
      "epoch: 9, batch: 927, loss: 0.5692044496536255\n",
      "epoch: 9, batch: 928, loss: 0.6689227223396301\n",
      "epoch: 9, batch: 929, loss: 0.4272720515727997\n",
      "epoch: 9, batch: 930, loss: 0.3236190974712372\n",
      "epoch: 9, batch: 931, loss: 0.4659140408039093\n",
      "epoch: 9, batch: 932, loss: 0.43618014454841614\n",
      "epoch: 9, batch: 933, loss: 0.3879571557044983\n",
      "epoch: 9, batch: 934, loss: 0.574351966381073\n",
      "epoch: 9, batch: 935, loss: 0.3491899073123932\n",
      "epoch: 9, batch: 936, loss: 0.37244436144828796\n",
      "epoch: 9, batch: 937, loss: 0.544998049736023\n",
      "epoch: 9, batch: 938, loss: 0.5118662118911743\n",
      "epoch: 9, batch: 939, loss: 0.5185497403144836\n",
      "epoch: 9, batch: 940, loss: 0.4060528576374054\n",
      "epoch: 9, batch: 941, loss: 0.38361042737960815\n",
      "epoch: 9, batch: 942, loss: 0.6242501139640808\n",
      "epoch: 9, batch: 943, loss: 0.39599359035491943\n",
      "epoch: 9, batch: 944, loss: 0.645811140537262\n",
      "epoch: 9, batch: 945, loss: 0.33250752091407776\n",
      "epoch: 9, batch: 946, loss: 0.3901847004890442\n",
      "epoch: 9, batch: 947, loss: 0.5518566966056824\n",
      "epoch: 9, batch: 948, loss: 0.5681187510490417\n",
      "epoch: 9, batch: 949, loss: 0.4367964267730713\n",
      "epoch: 9, batch: 950, loss: 0.756406843662262\n",
      "epoch: 9, batch: 951, loss: 0.3658604025840759\n",
      "epoch: 9, batch: 952, loss: 0.5014587044715881\n",
      "epoch: 9, batch: 953, loss: 0.45935115218162537\n",
      "epoch: 9, batch: 954, loss: 0.24718447029590607\n",
      "epoch: 9, batch: 955, loss: 0.5540730357170105\n",
      "epoch: 9, batch: 956, loss: 0.3353970944881439\n",
      "epoch: 9, batch: 957, loss: 0.41025015711784363\n",
      "epoch: 9, batch: 958, loss: 0.6369995474815369\n",
      "epoch: 9, batch: 959, loss: 0.43120837211608887\n",
      "epoch: 9, batch: 960, loss: 0.3381217420101166\n",
      "epoch: 9, batch: 961, loss: 0.4082253873348236\n",
      "epoch: 9, batch: 962, loss: 0.4986012876033783\n",
      "epoch: 9, batch: 963, loss: 0.6518765091896057\n",
      "epoch: 9, batch: 964, loss: 0.2440621256828308\n",
      "epoch: 9, batch: 965, loss: 0.41182366013526917\n",
      "epoch: 9, batch: 966, loss: 0.28548067808151245\n",
      "epoch: 9, batch: 967, loss: 0.4508526921272278\n",
      "epoch: 9, batch: 968, loss: 0.2902956008911133\n",
      "epoch: 9, batch: 969, loss: 0.3737378716468811\n",
      "epoch: 9, batch: 970, loss: 0.5892195701599121\n",
      "epoch: 9, batch: 971, loss: 0.41397786140441895\n",
      "epoch: 9, batch: 972, loss: 0.5531742572784424\n",
      "epoch: 9, batch: 973, loss: 0.4994995594024658\n",
      "epoch: 9, batch: 974, loss: 0.49078118801116943\n",
      "epoch: 9, batch: 975, loss: 0.38711801171302795\n",
      "epoch: 9, batch: 976, loss: 0.5115589499473572\n",
      "epoch: 9, batch: 977, loss: 0.5189977288246155\n",
      "epoch: 9, batch: 978, loss: 0.3583294451236725\n",
      "epoch: 9, batch: 979, loss: 0.4961753785610199\n",
      "epoch: 9, batch: 980, loss: 0.3509785532951355\n",
      "epoch: 9, batch: 981, loss: 0.4358340799808502\n",
      "epoch: 9, batch: 982, loss: 0.6228247880935669\n",
      "epoch: 9, batch: 983, loss: 0.3785555362701416\n",
      "epoch: 9, batch: 984, loss: 0.7107623219490051\n",
      "epoch: 9, batch: 985, loss: 0.4676494002342224\n",
      "epoch: 9, batch: 986, loss: 0.22611886262893677\n",
      "epoch: 9, batch: 987, loss: 0.7729590535163879\n",
      "epoch: 9, batch: 988, loss: 0.5849806070327759\n",
      "epoch: 9, batch: 989, loss: 0.30999955534935\n",
      "epoch: 9, batch: 990, loss: 0.6045807600021362\n",
      "epoch: 9, batch: 991, loss: 0.5168489217758179\n",
      "epoch: 9, batch: 992, loss: 0.3788203001022339\n",
      "epoch: 9, batch: 993, loss: 0.48965975642204285\n",
      "epoch: 9, batch: 994, loss: 0.599687933921814\n",
      "epoch: 9, batch: 995, loss: 0.17739304900169373\n",
      "epoch: 9, batch: 996, loss: 0.578001081943512\n",
      "epoch: 9, batch: 997, loss: 0.5953859090805054\n",
      "epoch: 9, batch: 998, loss: 0.3067439794540405\n",
      "epoch: 9, batch: 999, loss: 0.5031092166900635\n",
      "epoch: 9, batch: 1000, loss: 0.27384456992149353\n",
      "epoch: 9, batch: 1001, loss: 0.5231496691703796\n",
      "epoch: 9, batch: 1002, loss: 0.3084873855113983\n",
      "epoch: 9, batch: 1003, loss: 0.3944968581199646\n",
      "epoch: 9, batch: 1004, loss: 0.6717446446418762\n",
      "epoch: 9, batch: 1005, loss: 0.5176200270652771\n",
      "epoch: 9, batch: 1006, loss: 0.3474207818508148\n",
      "epoch: 9, batch: 1007, loss: 0.45316269993782043\n",
      "epoch: 9, batch: 1008, loss: 0.367225706577301\n",
      "epoch: 9, batch: 1009, loss: 0.3248958885669708\n",
      "epoch: 9, batch: 1010, loss: 0.3363056778907776\n",
      "epoch: 9, batch: 1011, loss: 0.4778057932853699\n",
      "epoch: 9, batch: 1012, loss: 0.2038697898387909\n",
      "epoch: 9, batch: 1013, loss: 0.5412965416908264\n",
      "epoch: 9, batch: 1014, loss: 0.26514697074890137\n",
      "epoch: 9, batch: 1015, loss: 0.8256821036338806\n",
      "epoch: 9, batch: 1016, loss: 0.49517104029655457\n",
      "epoch: 9, batch: 1017, loss: 0.3559192717075348\n",
      "epoch: 9, batch: 1018, loss: 0.3351078927516937\n",
      "epoch: 9, batch: 1019, loss: 0.333734929561615\n",
      "epoch: 9, batch: 1020, loss: 0.42030152678489685\n",
      "epoch: 9, batch: 1021, loss: 0.4047781825065613\n",
      "epoch: 9, batch: 1022, loss: 0.33967864513397217\n",
      "epoch: 9, batch: 1023, loss: 0.6105942130088806\n",
      "epoch: 9, batch: 1024, loss: 0.3790140151977539\n",
      "epoch: 9, batch: 1025, loss: 0.3347635567188263\n",
      "epoch: 9, batch: 1026, loss: 0.5747128129005432\n",
      "epoch: 9, batch: 1027, loss: 0.4647899568080902\n",
      "epoch: 9, batch: 1028, loss: 0.4120851457118988\n",
      "epoch: 9, batch: 1029, loss: 0.487125426530838\n",
      "epoch: 9, batch: 1030, loss: 0.9758527874946594\n",
      "epoch: 9, batch: 1031, loss: 0.41775503754615784\n",
      "epoch: 9, batch: 1032, loss: 0.22757825255393982\n",
      "epoch: 9, batch: 1033, loss: 0.40184783935546875\n",
      "epoch: 9, batch: 1034, loss: 0.4857097268104553\n",
      "epoch: 9, batch: 1035, loss: 0.29452043771743774\n",
      "epoch: 9, batch: 1036, loss: 0.3205174505710602\n",
      "epoch: 9, batch: 1037, loss: 0.4707910120487213\n",
      "epoch: 9, batch: 1038, loss: 0.6332874298095703\n",
      "epoch: 9, batch: 1039, loss: 0.32053959369659424\n",
      "epoch: 9, batch: 1040, loss: 0.41967684030532837\n",
      "epoch: 9, batch: 1041, loss: 0.36270228028297424\n",
      "epoch: 9, batch: 1042, loss: 0.6822546124458313\n",
      "epoch: 9, batch: 1043, loss: 0.4072166085243225\n",
      "epoch: 9, batch: 1044, loss: 0.40700241923332214\n",
      "epoch: 9, batch: 1045, loss: 0.26266637444496155\n",
      "epoch: 9, batch: 1046, loss: 0.3194894790649414\n",
      "epoch: 9, batch: 1047, loss: 0.7457465529441833\n",
      "epoch: 9, batch: 1048, loss: 0.6579395532608032\n",
      "epoch: 9, batch: 1049, loss: 0.5261600017547607\n",
      "epoch: 9, batch: 1050, loss: 0.3691866099834442\n",
      "epoch: 9, batch: 1051, loss: 0.6509917378425598\n",
      "epoch: 9, batch: 1052, loss: 0.5022876858711243\n",
      "epoch: 9, batch: 1053, loss: 0.5425710082054138\n",
      "epoch: 9, batch: 1054, loss: 0.4160880744457245\n",
      "epoch: 9, batch: 1055, loss: 0.3520294725894928\n",
      "epoch: 9, batch: 1056, loss: 0.4013023376464844\n",
      "epoch: 9, batch: 1057, loss: 0.7892066240310669\n",
      "epoch: 9, batch: 1058, loss: 0.5123026371002197\n",
      "epoch: 9, batch: 1059, loss: 0.3546607792377472\n",
      "epoch: 9, batch: 1060, loss: 0.3770804703235626\n",
      "epoch: 9, batch: 1061, loss: 0.29182788729667664\n",
      "epoch: 9, batch: 1062, loss: 0.4395121932029724\n",
      "epoch: 9, batch: 1063, loss: 0.3290911614894867\n",
      "epoch: 9, batch: 1064, loss: 0.19763530790805817\n",
      "epoch: 9, batch: 1065, loss: 0.5495774745941162\n",
      "epoch: 9, batch: 1066, loss: 0.3871607184410095\n",
      "epoch: 9, batch: 1067, loss: 0.4470239281654358\n",
      "epoch: 9, batch: 1068, loss: 0.47545385360717773\n",
      "epoch: 9, batch: 1069, loss: 0.3914037048816681\n",
      "epoch: 9, batch: 1070, loss: 0.2998461425304413\n",
      "epoch: 9, batch: 1071, loss: 0.3592803478240967\n",
      "epoch: 9, batch: 1072, loss: 0.34477001428604126\n",
      "epoch: 9, batch: 1073, loss: 0.6881564855575562\n",
      "epoch: 9, batch: 1074, loss: 0.48055338859558105\n",
      "epoch: 9, batch: 1075, loss: 0.3802407681941986\n",
      "epoch: 9, batch: 1076, loss: 0.5718634724617004\n",
      "epoch: 9, batch: 1077, loss: 0.2606743574142456\n",
      "epoch: 9, batch: 1078, loss: 0.38133445382118225\n",
      "epoch: 9, batch: 1079, loss: 0.4649384319782257\n",
      "epoch: 9, batch: 1080, loss: 0.407260537147522\n",
      "epoch: 9, batch: 1081, loss: 0.2233533412218094\n",
      "epoch: 9, batch: 1082, loss: 0.509788453578949\n",
      "epoch: 9, batch: 1083, loss: 0.2795878052711487\n",
      "epoch: 9, batch: 1084, loss: 0.3461102545261383\n",
      "epoch: 9, batch: 1085, loss: 0.5521945357322693\n",
      "epoch: 9, batch: 1086, loss: 0.3221012353897095\n",
      "epoch: 9, batch: 1087, loss: 0.5380624532699585\n",
      "epoch: 9, batch: 1088, loss: 0.5452280044555664\n",
      "epoch: 9, batch: 1089, loss: 0.48813074827194214\n",
      "epoch: 9, batch: 1090, loss: 0.5004629492759705\n",
      "epoch: 9, batch: 1091, loss: 0.6492995023727417\n",
      "epoch: 9, batch: 1092, loss: 0.39572322368621826\n",
      "epoch: 9, batch: 1093, loss: 0.3892771899700165\n",
      "epoch: 9, batch: 1094, loss: 0.468180388212204\n",
      "epoch: 9, batch: 1095, loss: 0.4139770567417145\n",
      "epoch: 9, batch: 1096, loss: 0.33871573209762573\n",
      "epoch: 9, batch: 1097, loss: 0.2708054780960083\n",
      "epoch: 9, batch: 1098, loss: 0.2889438271522522\n",
      "epoch: 9, batch: 1099, loss: 0.6987849473953247\n",
      "epoch: 9, batch: 1100, loss: 0.6911134719848633\n",
      "epoch: 9, batch: 1101, loss: 0.21726654469966888\n",
      "epoch: 9, batch: 1102, loss: 0.2685822546482086\n",
      "epoch: 9, batch: 1103, loss: 0.3148174285888672\n",
      "epoch: 9, batch: 1104, loss: 0.7424685955047607\n",
      "epoch: 9, batch: 1105, loss: 0.3501541018486023\n",
      "epoch: 9, batch: 1106, loss: 0.38522931933403015\n",
      "epoch: 9, batch: 1107, loss: 0.5488801002502441\n",
      "epoch: 9, batch: 1108, loss: 0.7314071655273438\n",
      "epoch: 9, batch: 1109, loss: 0.3860359489917755\n",
      "epoch: 9, batch: 1110, loss: 0.44879433512687683\n",
      "epoch: 9, batch: 1111, loss: 0.4452541768550873\n",
      "epoch: 9, batch: 1112, loss: 0.25221535563468933\n",
      "epoch: 9, batch: 1113, loss: 0.37943023443222046\n",
      "epoch: 9, batch: 1114, loss: 0.44140103459358215\n",
      "epoch: 9, batch: 1115, loss: 0.5056223273277283\n",
      "epoch: 9, batch: 1116, loss: 0.6164150238037109\n",
      "epoch: 9, batch: 1117, loss: 0.42324885725975037\n",
      "epoch: 9, batch: 1118, loss: 0.26252707839012146\n",
      "epoch: 9, batch: 1119, loss: 0.6285127997398376\n",
      "epoch: 9, batch: 1120, loss: 0.4209870398044586\n",
      "epoch: 9, batch: 1121, loss: 0.2784365713596344\n",
      "epoch: 9, batch: 1122, loss: 0.4617932140827179\n",
      "epoch: 9, batch: 1123, loss: 0.367227703332901\n",
      "epoch: 9, batch: 1124, loss: 0.3753701448440552\n",
      "epoch: 9, batch: 1125, loss: 0.4097459316253662\n",
      "epoch: 9, batch: 1126, loss: 0.5147161483764648\n",
      "epoch: 9, batch: 1127, loss: 0.36998316645622253\n",
      "epoch: 9, batch: 1128, loss: 0.43009841442108154\n",
      "epoch: 9, batch: 1129, loss: 0.45056360960006714\n",
      "epoch: 9, batch: 1130, loss: 0.4977248013019562\n",
      "epoch: 9, batch: 1131, loss: 0.49626749753952026\n",
      "epoch: 9, batch: 1132, loss: 0.6691379547119141\n",
      "epoch: 9, batch: 1133, loss: 0.2555755078792572\n",
      "epoch: 9, batch: 1134, loss: 0.4961363971233368\n",
      "epoch: 9, batch: 1135, loss: 0.6677954196929932\n",
      "epoch: 9, batch: 1136, loss: 0.3727641701698303\n",
      "epoch: 9, batch: 1137, loss: 0.46873950958251953\n",
      "epoch: 9, batch: 1138, loss: 0.8457698822021484\n",
      "epoch: 9, batch: 1139, loss: 0.27982503175735474\n",
      "epoch: 9, batch: 1140, loss: 0.6316334009170532\n",
      "epoch: 9, batch: 1141, loss: 0.288206547498703\n",
      "epoch: 9, batch: 1142, loss: 0.3744802474975586\n",
      "epoch: 9, batch: 1143, loss: 0.37623539566993713\n",
      "epoch: 9, batch: 1144, loss: 0.44325923919677734\n",
      "epoch: 9, batch: 1145, loss: 0.3275257647037506\n",
      "epoch: 9, batch: 1146, loss: 0.36804312467575073\n",
      "epoch: 9, batch: 1147, loss: 0.5833309292793274\n",
      "epoch: 9, batch: 1148, loss: 0.6853122115135193\n",
      "epoch: 9, batch: 1149, loss: 0.7729682922363281\n",
      "epoch: 9, batch: 1150, loss: 0.27259597182273865\n",
      "epoch: 9, batch: 1151, loss: 0.3659329414367676\n",
      "epoch: 9, batch: 1152, loss: 0.3610643148422241\n",
      "epoch: 9, batch: 1153, loss: 0.31518539786338806\n",
      "epoch: 9, batch: 1154, loss: 0.4984607398509979\n",
      "epoch: 9, batch: 1155, loss: 0.42347607016563416\n",
      "epoch: 9, batch: 1156, loss: 0.26477038860321045\n",
      "epoch: 9, batch: 1157, loss: 0.4592277407646179\n",
      "epoch: 9, batch: 1158, loss: 0.4896373450756073\n",
      "epoch: 9, batch: 1159, loss: 0.48199495673179626\n",
      "epoch: 9, batch: 1160, loss: 0.4479670226573944\n",
      "epoch: 9, batch: 1161, loss: 0.5668189525604248\n",
      "epoch: 9, batch: 1162, loss: 0.34294572472572327\n",
      "epoch: 9, batch: 1163, loss: 0.4735616147518158\n",
      "epoch: 9, batch: 1164, loss: 0.28483816981315613\n",
      "epoch: 9, batch: 1165, loss: 0.5951392650604248\n",
      "epoch: 9, batch: 1166, loss: 0.2552274763584137\n",
      "epoch: 9, batch: 1167, loss: 0.4721006751060486\n",
      "epoch: 9, batch: 1168, loss: 0.4181748032569885\n",
      "epoch: 9, batch: 1169, loss: 0.702186644077301\n",
      "epoch: 9, batch: 1170, loss: 0.35148340463638306\n",
      "epoch: 9, batch: 1171, loss: 0.45056024193763733\n",
      "epoch: 9, batch: 1172, loss: 0.33342573046684265\n",
      "epoch: 9, batch: 1173, loss: 0.36690187454223633\n",
      "epoch: 9, batch: 1174, loss: 0.6424211263656616\n",
      "epoch: 9, batch: 1175, loss: 0.4209030568599701\n",
      "epoch: 9, batch: 1176, loss: 0.3973793685436249\n",
      "epoch: 9, batch: 1177, loss: 0.4954570531845093\n",
      "epoch: 9, batch: 1178, loss: 0.36994680762290955\n",
      "epoch: 9, batch: 1179, loss: 0.4457542896270752\n",
      "epoch: 9, batch: 1180, loss: 0.23817774653434753\n",
      "epoch: 9, batch: 1181, loss: 0.44437849521636963\n",
      "epoch: 9, batch: 1182, loss: 0.5476987361907959\n",
      "epoch: 9, batch: 1183, loss: 0.44073954224586487\n",
      "epoch: 9, batch: 1184, loss: 0.29806771874427795\n",
      "epoch: 9, batch: 1185, loss: 0.3758864104747772\n",
      "epoch: 9, batch: 1186, loss: 0.48115772008895874\n",
      "epoch: 9, batch: 1187, loss: 0.6972166299819946\n",
      "epoch: 9, batch: 1188, loss: 0.3929181694984436\n",
      "epoch: 9, batch: 1189, loss: 0.7318137288093567\n",
      "epoch: 9, batch: 1190, loss: 0.3073444962501526\n",
      "epoch: 9, batch: 1191, loss: 0.530766487121582\n",
      "epoch: 9, batch: 1192, loss: 0.45867037773132324\n",
      "epoch: 9, batch: 1193, loss: 0.5643753409385681\n",
      "epoch: 9, batch: 1194, loss: 0.38010725378990173\n",
      "epoch: 9, batch: 1195, loss: 0.26554426550865173\n",
      "epoch: 9, batch: 1196, loss: 0.41779351234436035\n",
      "epoch: 9, batch: 1197, loss: 0.4975526034832001\n",
      "epoch: 9, batch: 1198, loss: 0.21292905509471893\n",
      "epoch: 9, batch: 1199, loss: 0.20653916895389557\n",
      "epoch: 9, batch: 1200, loss: 0.7710260152816772\n",
      "epoch: 9, batch: 1201, loss: 0.4811785817146301\n",
      "epoch: 9, batch: 1202, loss: 0.5022938251495361\n",
      "epoch: 9, batch: 1203, loss: 0.530735969543457\n",
      "epoch: 9, batch: 1204, loss: 0.6434630155563354\n",
      "epoch: 9, batch: 1205, loss: 0.5240709781646729\n",
      "epoch: 9, batch: 1206, loss: 0.538686215877533\n",
      "epoch: 9, batch: 1207, loss: 0.4530498683452606\n",
      "epoch: 9, batch: 1208, loss: 0.5409186482429504\n",
      "epoch: 9, batch: 1209, loss: 0.3886580467224121\n",
      "epoch: 9, batch: 1210, loss: 0.228158637881279\n",
      "epoch: 9, batch: 1211, loss: 0.5490404963493347\n",
      "epoch: 9, batch: 1212, loss: 0.5916158556938171\n",
      "epoch: 9, batch: 1213, loss: 0.5687696933746338\n",
      "epoch: 9, batch: 1214, loss: 0.5176897048950195\n",
      "epoch: 9, batch: 1215, loss: 0.4200398623943329\n",
      "epoch: 9, batch: 1216, loss: 0.28130263090133667\n",
      "epoch: 9, batch: 1217, loss: 0.35632801055908203\n",
      "epoch: 9, batch: 1218, loss: 0.3309006989002228\n",
      "epoch: 9, batch: 1219, loss: 0.6398298144340515\n",
      "epoch: 9, batch: 1220, loss: 0.35913363099098206\n",
      "epoch: 9, batch: 1221, loss: 0.34623080492019653\n",
      "epoch: 9, batch: 1222, loss: 0.3063734173774719\n",
      "epoch: 9, batch: 1223, loss: 0.5504704117774963\n",
      "epoch: 9, batch: 1224, loss: 0.29509568214416504\n",
      "epoch: 9, batch: 1225, loss: 0.2568892538547516\n",
      "epoch: 9, batch: 1226, loss: 0.4873972535133362\n",
      "epoch: 9, batch: 1227, loss: 0.30265793204307556\n",
      "epoch: 9, batch: 1228, loss: 0.48036107420921326\n",
      "epoch: 9, batch: 1229, loss: 0.42483699321746826\n",
      "epoch: 9, batch: 1230, loss: 0.26639458537101746\n",
      "epoch: 9, batch: 1231, loss: 0.307089239358902\n",
      "epoch: 9, batch: 1232, loss: 0.4346896708011627\n",
      "epoch: 9, batch: 1233, loss: 0.49128350615501404\n",
      "epoch: 9, batch: 1234, loss: 0.34566742181777954\n",
      "epoch: 9, batch: 1235, loss: 0.23442524671554565\n",
      "epoch: 9, batch: 1236, loss: 0.3558834195137024\n",
      "epoch: 9, batch: 1237, loss: 0.5118563175201416\n",
      "epoch: 9, batch: 1238, loss: 0.7043853998184204\n",
      "epoch: 9, batch: 1239, loss: 0.29713889956474304\n",
      "epoch: 9, batch: 1240, loss: 0.46465471386909485\n",
      "epoch: 9, batch: 1241, loss: 0.40749391913414\n",
      "epoch: 9, batch: 1242, loss: 0.4225042462348938\n",
      "epoch: 9, batch: 1243, loss: 0.530519425868988\n",
      "epoch: 9, batch: 1244, loss: 0.771362841129303\n",
      "epoch: 9, batch: 1245, loss: 0.7306686043739319\n",
      "epoch: 9, batch: 1246, loss: 0.48802873492240906\n",
      "epoch: 9, batch: 1247, loss: 0.30650731921195984\n",
      "epoch: 9, batch: 1248, loss: 0.4139687716960907\n",
      "epoch: 9, batch: 1249, loss: 0.4300587475299835\n",
      "epoch: 9, batch: 1250, loss: 0.49867746233940125\n",
      "epoch: 9, batch: 1251, loss: 0.5157296657562256\n",
      "epoch: 9, batch: 1252, loss: 0.5468549132347107\n",
      "epoch: 9, batch: 1253, loss: 0.6201611757278442\n",
      "epoch: 9, batch: 1254, loss: 0.557237982749939\n",
      "epoch: 9, batch: 1255, loss: 0.38996586203575134\n",
      "epoch: 9, batch: 1256, loss: 0.26517945528030396\n",
      "epoch: 9, batch: 1257, loss: 0.28654828667640686\n",
      "epoch: 9, batch: 1258, loss: 0.7042111158370972\n",
      "epoch: 9, batch: 1259, loss: 0.3954351246356964\n",
      "epoch: 9, batch: 1260, loss: 0.4982191026210785\n",
      "epoch: 9, batch: 1261, loss: 0.3047444224357605\n",
      "epoch: 9, batch: 1262, loss: 0.4059211015701294\n",
      "epoch: 9, batch: 1263, loss: 0.3559824824333191\n",
      "epoch: 9, batch: 1264, loss: 0.4444941282272339\n",
      "epoch: 9, batch: 1265, loss: 0.6048114895820618\n",
      "epoch: 9, batch: 1266, loss: 0.30007198452949524\n",
      "epoch: 9, batch: 1267, loss: 0.28879159688949585\n",
      "epoch: 9, batch: 1268, loss: 0.48744821548461914\n",
      "epoch: 9, batch: 1269, loss: 0.5507923364639282\n",
      "epoch: 9, batch: 1270, loss: 0.3847661316394806\n",
      "epoch: 9, batch: 1271, loss: 0.3472643792629242\n",
      "epoch: 9, batch: 1272, loss: 0.35357603430747986\n",
      "epoch: 9, batch: 1273, loss: 0.36794018745422363\n",
      "epoch: 9, batch: 1274, loss: 0.34833475947380066\n",
      "epoch: 9, batch: 1275, loss: 0.4749547839164734\n",
      "epoch: 9, batch: 1276, loss: 0.3688383400440216\n",
      "epoch: 9, batch: 1277, loss: 0.5676852464675903\n",
      "epoch: 9, batch: 1278, loss: 0.3748002052307129\n",
      "epoch: 9, batch: 1279, loss: 0.3198612332344055\n",
      "epoch: 9, batch: 1280, loss: 0.4985353648662567\n",
      "epoch: 9, batch: 1281, loss: 0.41085121035575867\n",
      "epoch: 9, batch: 1282, loss: 0.3732391595840454\n",
      "epoch: 9, batch: 1283, loss: 0.5157933235168457\n",
      "epoch: 9, batch: 1284, loss: 0.3159039318561554\n",
      "epoch: 9, batch: 1285, loss: 0.3062569200992584\n",
      "epoch: 9, batch: 1286, loss: 0.6717495918273926\n",
      "epoch: 9, batch: 1287, loss: 0.5511199235916138\n",
      "epoch: 9, batch: 1288, loss: 0.4340839385986328\n",
      "epoch: 9, batch: 1289, loss: 0.5699650645256042\n",
      "epoch: 9, batch: 1290, loss: 0.4932776093482971\n",
      "epoch: 9, batch: 1291, loss: 0.33084240555763245\n",
      "epoch: 9, batch: 1292, loss: 0.8426242470741272\n",
      "epoch: 9, batch: 1293, loss: 0.6268860697746277\n",
      "epoch: 9, batch: 1294, loss: 0.34505343437194824\n",
      "epoch: 9, batch: 1295, loss: 0.44280314445495605\n",
      "epoch: 9, batch: 1296, loss: 0.22010792791843414\n",
      "epoch: 9, batch: 1297, loss: 0.49335548281669617\n",
      "epoch: 9, batch: 1298, loss: 0.5939545035362244\n",
      "epoch: 9, batch: 1299, loss: 0.45369577407836914\n",
      "epoch: 9, batch: 1300, loss: 0.6213849782943726\n",
      "epoch: 9, batch: 1301, loss: 0.5652230381965637\n",
      "epoch: 9, batch: 1302, loss: 0.5046437978744507\n",
      "epoch: 9, batch: 1303, loss: 0.42688053846359253\n",
      "epoch: 9, batch: 1304, loss: 0.3898443579673767\n",
      "epoch: 9, batch: 1305, loss: 0.49547648429870605\n",
      "epoch: 9, batch: 1306, loss: 0.44891634583473206\n",
      "epoch: 9, batch: 1307, loss: 0.4064764976501465\n",
      "epoch: 9, batch: 1308, loss: 0.45888543128967285\n",
      "epoch: 9, batch: 1309, loss: 0.5864622592926025\n",
      "epoch: 9, batch: 1310, loss: 0.43898165225982666\n",
      "epoch: 9, batch: 1311, loss: 0.4162236154079437\n",
      "epoch: 9, batch: 1312, loss: 0.5731452703475952\n",
      "epoch: 9, batch: 1313, loss: 0.3174499571323395\n",
      "epoch: 9, batch: 1314, loss: 0.41971954703330994\n",
      "epoch: 9, batch: 1315, loss: 0.3055858910083771\n",
      "epoch: 9, batch: 1316, loss: 0.32344573736190796\n",
      "epoch: 9, batch: 1317, loss: 0.37517455220222473\n",
      "epoch: 9, batch: 1318, loss: 0.5766385793685913\n",
      "epoch: 9, batch: 1319, loss: 0.31292569637298584\n",
      "epoch: 9, batch: 1320, loss: 0.31845054030418396\n",
      "epoch: 9, batch: 1321, loss: 0.3283676505088806\n",
      "epoch: 9, batch: 1322, loss: 0.29775044322013855\n",
      "epoch: 9, batch: 1323, loss: 0.3798752427101135\n",
      "epoch: 9, batch: 1324, loss: 0.5272584557533264\n",
      "epoch: 9, batch: 1325, loss: 0.5492693781852722\n",
      "epoch: 9, batch: 1326, loss: 0.48474952578544617\n",
      "epoch: 9, batch: 1327, loss: 0.5239933729171753\n",
      "epoch: 9, batch: 1328, loss: 0.4756773114204407\n",
      "epoch: 9, batch: 1329, loss: 0.4128129184246063\n",
      "epoch: 9, batch: 1330, loss: 0.43740370869636536\n",
      "epoch: 9, batch: 1331, loss: 0.4572105407714844\n",
      "epoch: 9, batch: 1332, loss: 0.5156815052032471\n",
      "epoch: 9, batch: 1333, loss: 0.5249409675598145\n",
      "epoch: 9, batch: 1334, loss: 0.4873935580253601\n",
      "epoch: 9, batch: 1335, loss: 0.3706311285495758\n",
      "epoch: 9, batch: 1336, loss: 0.4182254672050476\n",
      "epoch: 9, batch: 1337, loss: 0.6781784296035767\n",
      "epoch: 9, batch: 1338, loss: 0.5550926327705383\n",
      "epoch: 9, batch: 1339, loss: 0.563073992729187\n",
      "epoch: 9, batch: 1340, loss: 0.5919367671012878\n",
      "epoch: 9, batch: 1341, loss: 0.4015272855758667\n",
      "epoch: 9, batch: 1342, loss: 0.2781659662723541\n",
      "epoch: 9, batch: 1343, loss: 0.34801337122917175\n",
      "epoch: 9, batch: 1344, loss: 0.44469746947288513\n",
      "epoch: 9, batch: 1345, loss: 0.480930894613266\n",
      "epoch: 9, batch: 1346, loss: 0.5445534586906433\n",
      "epoch: 9, batch: 1347, loss: 0.5111814141273499\n",
      "epoch: 9, batch: 1348, loss: 0.5737473964691162\n",
      "epoch: 9, batch: 1349, loss: 0.43215617537498474\n",
      "epoch: 9, batch: 1350, loss: 0.42866241931915283\n",
      "epoch: 9, batch: 1351, loss: 0.5379050970077515\n",
      "epoch: 9, batch: 1352, loss: 0.4321972727775574\n",
      "epoch: 9, batch: 1353, loss: 0.4561205208301544\n",
      "epoch: 9, batch: 1354, loss: 0.5882490277290344\n",
      "epoch: 9, batch: 1355, loss: 0.36964312195777893\n",
      "epoch: 9, batch: 1356, loss: 0.6970980167388916\n",
      "epoch: 9, batch: 1357, loss: 0.39539995789527893\n",
      "epoch: 9, batch: 1358, loss: 0.45901790261268616\n",
      "epoch: 9, batch: 1359, loss: 0.3425443470478058\n",
      "epoch: 9, batch: 1360, loss: 0.5241537094116211\n",
      "epoch: 9, batch: 1361, loss: 0.4140946865081787\n",
      "epoch: 9, batch: 1362, loss: 0.2994232177734375\n",
      "epoch: 9, batch: 1363, loss: 0.27208462357521057\n",
      "epoch: 9, batch: 1364, loss: 0.5528451800346375\n",
      "epoch: 9, batch: 1365, loss: 0.3477851152420044\n",
      "epoch: 9, batch: 1366, loss: 0.3342651426792145\n",
      "epoch: 9, batch: 1367, loss: 0.6406016945838928\n",
      "epoch: 9, batch: 1368, loss: 0.5850488543510437\n",
      "epoch: 9, batch: 1369, loss: 0.4574342370033264\n",
      "epoch: 9, batch: 1370, loss: 0.3251246511936188\n",
      "epoch: 9, batch: 1371, loss: 0.2686975300312042\n",
      "epoch: 9, batch: 1372, loss: 0.5623328685760498\n",
      "epoch: 9, batch: 1373, loss: 0.3028714954853058\n",
      "epoch: 9, batch: 1374, loss: 0.3603242039680481\n",
      "epoch: 9, batch: 1375, loss: 0.33817821741104126\n",
      "epoch: 9, batch: 1376, loss: 0.30561983585357666\n",
      "epoch: 9, batch: 1377, loss: 0.45041313767433167\n",
      "epoch: 9, batch: 1378, loss: 0.6500476598739624\n",
      "epoch: 9, batch: 1379, loss: 0.6861883401870728\n",
      "epoch: 9, batch: 1380, loss: 0.2700944244861603\n",
      "epoch: 9, batch: 1381, loss: 0.516242265701294\n",
      "epoch: 9, batch: 1382, loss: 0.4632367491722107\n",
      "epoch: 9, batch: 1383, loss: 0.40877866744995117\n",
      "epoch: 9, batch: 1384, loss: 0.4763554632663727\n",
      "epoch: 9, batch: 1385, loss: 0.31781142950057983\n",
      "epoch: 9, batch: 1386, loss: 0.4595199525356293\n",
      "epoch: 9, batch: 1387, loss: 0.3723217844963074\n",
      "epoch: 9, batch: 1388, loss: 0.7685965299606323\n",
      "epoch: 9, batch: 1389, loss: 0.2976617217063904\n",
      "epoch: 9, batch: 1390, loss: 0.4020329415798187\n",
      "epoch: 9, batch: 1391, loss: 0.4196697175502777\n",
      "epoch: 9, batch: 1392, loss: 0.277871698141098\n",
      "epoch: 9, batch: 1393, loss: 0.548576295375824\n",
      "epoch: 9, batch: 1394, loss: 0.41292837262153625\n",
      "epoch: 9, batch: 1395, loss: 0.44939878582954407\n",
      "epoch: 9, batch: 1396, loss: 0.43220025300979614\n",
      "epoch: 9, batch: 1397, loss: 0.6761141419410706\n",
      "epoch: 9, batch: 1398, loss: 0.3635672628879547\n",
      "epoch: 9, batch: 1399, loss: 0.335391104221344\n",
      "epoch: 9, batch: 1400, loss: 0.4739570617675781\n",
      "epoch: 9, batch: 1401, loss: 0.5113051533699036\n",
      "epoch: 9, batch: 1402, loss: 0.4342283010482788\n",
      "epoch: 9, batch: 1403, loss: 0.5203359723091125\n",
      "epoch: 9, batch: 1404, loss: 0.8122156858444214\n",
      "epoch: 9, batch: 1405, loss: 0.32597416639328003\n",
      "epoch: 9, batch: 1406, loss: 0.2609547972679138\n",
      "epoch: 9, batch: 1407, loss: 0.5466004014015198\n",
      "epoch: 9, batch: 1408, loss: 0.48302847146987915\n",
      "epoch: 9, batch: 1409, loss: 0.5286173224449158\n",
      "epoch: 9, batch: 1410, loss: 0.46897584199905396\n",
      "epoch: 9, batch: 1411, loss: 0.48529985547065735\n",
      "epoch: 9, batch: 1412, loss: 0.2772865295410156\n",
      "epoch: 9, batch: 1413, loss: 0.32831189036369324\n",
      "epoch: 9, batch: 1414, loss: 0.5519220232963562\n",
      "epoch: 9, batch: 1415, loss: 0.39789026975631714\n",
      "epoch: 9, batch: 1416, loss: 0.3990531265735626\n",
      "epoch: 9, batch: 1417, loss: 0.2577707767486572\n",
      "epoch: 9, batch: 1418, loss: 0.18097250163555145\n",
      "epoch: 9, batch: 1419, loss: 0.5140558481216431\n",
      "epoch: 9, batch: 1420, loss: 0.5267981886863708\n",
      "epoch: 9, batch: 1421, loss: 0.3041353225708008\n",
      "epoch: 9, batch: 1422, loss: 0.3411371111869812\n",
      "epoch: 9, batch: 1423, loss: 0.49118342995643616\n",
      "epoch: 9, batch: 1424, loss: 0.5473403334617615\n",
      "epoch: 9, batch: 1425, loss: 0.4590522348880768\n",
      "epoch: 9, batch: 1426, loss: 0.5170037150382996\n",
      "epoch: 9, batch: 1427, loss: 0.515299379825592\n",
      "epoch: 9, batch: 1428, loss: 0.6192883253097534\n",
      "epoch: 9, batch: 1429, loss: 0.5896636247634888\n",
      "epoch: 9, batch: 1430, loss: 0.5216447710990906\n",
      "epoch: 9, batch: 1431, loss: 0.8403783440589905\n",
      "epoch: 9, batch: 1432, loss: 0.20641446113586426\n",
      "epoch: 9, batch: 1433, loss: 0.24800576269626617\n",
      "epoch: 9, batch: 1434, loss: 0.40335944294929504\n",
      "epoch: 9, batch: 1435, loss: 0.7135769128799438\n",
      "epoch: 9, batch: 1436, loss: 0.27903175354003906\n",
      "epoch: 9, batch: 1437, loss: 0.35081568360328674\n",
      "epoch: 9, batch: 1438, loss: 0.5435705780982971\n",
      "epoch: 9, batch: 1439, loss: 0.27040135860443115\n",
      "epoch: 9, batch: 1440, loss: 0.175400048494339\n",
      "epoch: 9, batch: 1441, loss: 0.3173687756061554\n",
      "epoch: 9, batch: 1442, loss: 0.575600802898407\n",
      "epoch: 9, batch: 1443, loss: 0.4212091267108917\n",
      "epoch: 9, batch: 1444, loss: 0.42252418398857117\n",
      "epoch: 9, batch: 1445, loss: 0.316969633102417\n",
      "epoch: 9, batch: 1446, loss: 0.2048465609550476\n",
      "epoch: 9, batch: 1447, loss: 0.2509317100048065\n",
      "epoch: 9, batch: 1448, loss: 0.39968839287757874\n",
      "epoch: 9, batch: 1449, loss: 0.30172115564346313\n",
      "epoch: 9, batch: 1450, loss: 0.3045586943626404\n",
      "epoch: 9, batch: 1451, loss: 0.12792907655239105\n",
      "epoch: 9, batch: 1452, loss: 0.4625069499015808\n",
      "epoch: 9, batch: 1453, loss: 0.7061936855316162\n",
      "epoch: 9, batch: 1454, loss: 0.6520715355873108\n",
      "epoch: 9, batch: 1455, loss: 0.4228988289833069\n",
      "epoch: 9, batch: 1456, loss: 0.4344823360443115\n",
      "epoch: 9, batch: 1457, loss: 0.3879910409450531\n",
      "epoch: 9, batch: 1458, loss: 0.5123067498207092\n",
      "epoch: 9, batch: 1459, loss: 0.5456031560897827\n",
      "epoch: 9, batch: 1460, loss: 0.3793148100376129\n",
      "epoch: 9, batch: 1461, loss: 0.46821126341819763\n",
      "epoch: 9, batch: 1462, loss: 0.6409581303596497\n",
      "epoch: 9, batch: 1463, loss: 0.5536003708839417\n",
      "epoch: 9, batch: 1464, loss: 0.29549315571784973\n",
      "epoch: 9, batch: 1465, loss: 0.25580456852912903\n",
      "epoch: 9, batch: 1466, loss: 0.5124550461769104\n",
      "epoch: 9, batch: 1467, loss: 0.46821868419647217\n",
      "epoch: 9, batch: 1468, loss: 0.339487761259079\n",
      "epoch: 9, batch: 1469, loss: 0.43972131609916687\n",
      "epoch: 9, batch: 1470, loss: 0.42188793420791626\n",
      "epoch: 9, batch: 1471, loss: 0.46809133887290955\n",
      "epoch: 9, batch: 1472, loss: 0.4394940137863159\n",
      "epoch: 9, batch: 1473, loss: 0.38699644804000854\n",
      "epoch: 9, batch: 1474, loss: 0.3856540024280548\n",
      "epoch: 9, batch: 1475, loss: 0.4946307837963104\n",
      "epoch: 9, batch: 1476, loss: 0.44350123405456543\n",
      "epoch: 9, batch: 1477, loss: 0.43611574172973633\n",
      "epoch: 9, batch: 1478, loss: 0.475408136844635\n",
      "epoch: 9, batch: 1479, loss: 0.4465978443622589\n",
      "epoch: 9, batch: 1480, loss: 0.5760957598686218\n",
      "epoch: 9, batch: 1481, loss: 0.5574861168861389\n",
      "epoch: 9, batch: 1482, loss: 0.704500675201416\n",
      "epoch: 9, batch: 1483, loss: 0.531356692314148\n",
      "epoch: 9, batch: 1484, loss: 0.5790599584579468\n",
      "epoch: 9, batch: 1485, loss: 0.4850471019744873\n",
      "epoch: 9, batch: 1486, loss: 0.18414904177188873\n",
      "epoch: 9, batch: 1487, loss: 0.22906939685344696\n",
      "epoch: 9, batch: 1488, loss: 0.3845515251159668\n",
      "epoch: 9, batch: 1489, loss: 0.4393886923789978\n",
      "epoch: 9, batch: 1490, loss: 0.5027911067008972\n",
      "epoch: 9, batch: 1491, loss: 0.3441375494003296\n",
      "epoch: 9, batch: 1492, loss: 0.7148284316062927\n",
      "epoch: 9, batch: 1493, loss: 0.4656873047351837\n",
      "epoch: 9, batch: 1494, loss: 0.1701541692018509\n",
      "epoch: 9, batch: 1495, loss: 0.2667014002799988\n",
      "epoch: 9, batch: 1496, loss: 0.3274633288383484\n",
      "epoch: 9, batch: 1497, loss: 0.44895365834236145\n",
      "epoch: 9, batch: 1498, loss: 0.5371515154838562\n",
      "epoch: 9, batch: 1499, loss: 0.4418293833732605\n",
      "epoch: 9, batch: 1500, loss: 0.3040546178817749\n",
      "epoch: 9, batch: 1501, loss: 0.719601571559906\n",
      "epoch: 9, batch: 1502, loss: 0.4348330497741699\n",
      "epoch: 9, batch: 1503, loss: 0.30776193737983704\n",
      "epoch: 9, batch: 1504, loss: 0.3866453468799591\n",
      "epoch: 9, batch: 1505, loss: 0.2587966322898865\n",
      "epoch: 9, batch: 1506, loss: 0.37002837657928467\n",
      "epoch: 9, batch: 1507, loss: 0.6769526600837708\n",
      "epoch: 9, batch: 1508, loss: 0.22188818454742432\n",
      "epoch: 9, batch: 1509, loss: 0.4883940815925598\n",
      "epoch: 9, batch: 1510, loss: 0.38207343220710754\n",
      "epoch: 9, batch: 1511, loss: 0.5562491416931152\n",
      "epoch: 9, batch: 1512, loss: 0.35840997099876404\n",
      "epoch: 9, batch: 1513, loss: 0.8082607388496399\n",
      "epoch: 9, batch: 1514, loss: 0.4812261462211609\n",
      "epoch: 9, batch: 1515, loss: 0.2846834361553192\n",
      "epoch: 9, batch: 1516, loss: 0.29900237917900085\n",
      "epoch: 9, batch: 1517, loss: 0.5820982456207275\n",
      "epoch: 9, batch: 1518, loss: 0.46438732743263245\n",
      "epoch: 9, batch: 1519, loss: 0.4519856572151184\n",
      "epoch: 9, batch: 1520, loss: 0.20932021737098694\n",
      "epoch: 9, batch: 1521, loss: 0.39722052216529846\n",
      "epoch: 9, batch: 1522, loss: 0.3423093557357788\n",
      "epoch: 9, batch: 1523, loss: 0.6949295997619629\n",
      "epoch: 9, batch: 1524, loss: 0.30533403158187866\n",
      "epoch: 9, batch: 1525, loss: 0.5013841390609741\n",
      "epoch: 9, batch: 1526, loss: 0.3787592649459839\n",
      "epoch: 9, batch: 1527, loss: 0.33967068791389465\n",
      "epoch: 9, batch: 1528, loss: 0.35139790177345276\n",
      "epoch: 9, batch: 1529, loss: 0.6585690379142761\n",
      "epoch: 9, batch: 1530, loss: 0.8165072202682495\n",
      "epoch: 9, batch: 1531, loss: 0.44733700156211853\n",
      "epoch: 9, batch: 1532, loss: 0.2842281460762024\n",
      "epoch: 9, batch: 1533, loss: 0.7361633777618408\n",
      "epoch: 9, batch: 1534, loss: 0.28254902362823486\n",
      "epoch: 9, batch: 1535, loss: 0.8500159382820129\n",
      "epoch: 9, batch: 1536, loss: 0.3405616581439972\n",
      "epoch: 9, batch: 1537, loss: 0.32966139912605286\n",
      "epoch: 9, batch: 1538, loss: 0.29418832063674927\n",
      "epoch: 9, batch: 1539, loss: 0.6336395740509033\n",
      "epoch: 9, batch: 1540, loss: 0.40886837244033813\n",
      "epoch: 9, batch: 1541, loss: 0.6707494258880615\n",
      "epoch: 9, batch: 1542, loss: 0.3622666299343109\n",
      "epoch: 9, batch: 1543, loss: 0.4356471598148346\n",
      "epoch: 9, batch: 1544, loss: 0.613541841506958\n",
      "epoch: 9, batch: 1545, loss: 0.39207491278648376\n",
      "epoch: 9, batch: 1546, loss: 0.48410582542419434\n",
      "epoch: 9, batch: 1547, loss: 0.28375983238220215\n",
      "epoch: 9, batch: 1548, loss: 0.402414470911026\n",
      "epoch: 9, batch: 1549, loss: 0.2583865523338318\n",
      "epoch: 9, batch: 1550, loss: 0.34040066599845886\n",
      "epoch: 9, batch: 1551, loss: 0.29243990778923035\n",
      "epoch: 9, batch: 1552, loss: 0.47311314940452576\n",
      "epoch: 9, batch: 1553, loss: 0.3098296523094177\n",
      "epoch: 9, batch: 1554, loss: 0.2912522554397583\n",
      "epoch: 9, batch: 1555, loss: 0.2229045331478119\n",
      "epoch: 9, batch: 1556, loss: 0.6899850964546204\n",
      "epoch: 9, batch: 1557, loss: 0.5549046397209167\n",
      "epoch: 9, batch: 1558, loss: 0.49817532300949097\n",
      "epoch: 9, batch: 1559, loss: 0.43574199080467224\n",
      "epoch: 9, batch: 1560, loss: 0.271914541721344\n",
      "epoch: 9, batch: 1561, loss: 0.36696332693099976\n",
      "epoch: 9, batch: 1562, loss: 0.4081191122531891\n",
      "epoch: 9, batch: 1563, loss: 0.18190360069274902\n",
      "epoch: 9, batch: 1564, loss: 0.4607231616973877\n",
      "epoch: 9, batch: 1565, loss: 0.3196215033531189\n",
      "epoch: 9, batch: 1566, loss: 0.5541915893554688\n",
      "epoch: 9, batch: 1567, loss: 0.37116539478302\n",
      "epoch: 9, batch: 1568, loss: 0.38220494985580444\n",
      "epoch: 9, batch: 1569, loss: 0.2752448320388794\n",
      "epoch: 9, batch: 1570, loss: 0.5422998666763306\n",
      "epoch: 9, batch: 1571, loss: 0.5642914772033691\n",
      "epoch: 9, batch: 1572, loss: 0.42035311460494995\n",
      "epoch: 9, batch: 1573, loss: 0.7195909023284912\n",
      "epoch: 9, batch: 1574, loss: 0.3963688910007477\n",
      "epoch: 9, batch: 1575, loss: 0.1978076845407486\n",
      "epoch: 9, batch: 1576, loss: 0.7804028987884521\n",
      "epoch: 9, batch: 1577, loss: 0.5192140340805054\n",
      "epoch: 9, batch: 1578, loss: 0.7543078660964966\n",
      "epoch: 9, batch: 1579, loss: 0.5447148680686951\n",
      "epoch: 9, batch: 1580, loss: 0.46693480014801025\n",
      "epoch: 9, batch: 1581, loss: 0.3977592885494232\n",
      "epoch: 9, batch: 1582, loss: 0.4852740168571472\n",
      "epoch: 9, batch: 1583, loss: 0.26920467615127563\n",
      "epoch: 9, batch: 1584, loss: 0.273142546415329\n",
      "epoch: 9, batch: 1585, loss: 0.7720415592193604\n",
      "epoch: 9, batch: 1586, loss: 0.4770069718360901\n",
      "epoch: 9, batch: 1587, loss: 0.40661144256591797\n",
      "epoch: 9, batch: 1588, loss: 0.5000437498092651\n",
      "epoch: 9, batch: 1589, loss: 0.3095841109752655\n",
      "epoch: 9, batch: 1590, loss: 0.3276163339614868\n",
      "epoch: 9, batch: 1591, loss: 0.6742704510688782\n",
      "epoch: 9, batch: 1592, loss: 0.5581966042518616\n",
      "epoch: 9, batch: 1593, loss: 0.4213469326496124\n",
      "epoch: 9, batch: 1594, loss: 0.4945352077484131\n",
      "epoch: 9, batch: 1595, loss: 0.45200690627098083\n",
      "epoch: 9, batch: 1596, loss: 0.40405628085136414\n",
      "epoch: 9, batch: 1597, loss: 0.18126429617404938\n",
      "epoch: 9, batch: 1598, loss: 0.2761648893356323\n",
      "epoch: 9, batch: 1599, loss: 0.38928234577178955\n",
      "epoch: 9, batch: 1600, loss: 0.42374372482299805\n",
      "epoch: 9, batch: 1601, loss: 0.5513085126876831\n",
      "epoch: 9, batch: 1602, loss: 0.34948310256004333\n",
      "epoch: 9, batch: 1603, loss: 0.5265280604362488\n",
      "epoch: 9, batch: 1604, loss: 0.2299078404903412\n",
      "epoch: 9, batch: 1605, loss: 0.5271741151809692\n",
      "epoch: 9, batch: 1606, loss: 0.3658052384853363\n",
      "epoch: 9, batch: 1607, loss: 0.45030832290649414\n",
      "epoch: 9, batch: 1608, loss: 0.4091556966304779\n",
      "epoch: 9, batch: 1609, loss: 0.2763707637786865\n",
      "epoch: 9, batch: 1610, loss: 0.6135525107383728\n",
      "epoch: 9, batch: 1611, loss: 0.5049265027046204\n",
      "epoch: 9, batch: 1612, loss: 0.4762696623802185\n",
      "epoch: 9, batch: 1613, loss: 0.7496190071105957\n",
      "epoch: 9, batch: 1614, loss: 0.48935189843177795\n",
      "epoch: 9, batch: 1615, loss: 0.32106488943099976\n",
      "epoch: 9, batch: 1616, loss: 0.31358107924461365\n",
      "epoch: 9, batch: 1617, loss: 0.3310506343841553\n",
      "epoch: 9, batch: 1618, loss: 0.5352047085762024\n",
      "epoch: 9, batch: 1619, loss: 0.7187706232070923\n",
      "epoch: 9, batch: 1620, loss: 0.42996135354042053\n",
      "epoch: 9, batch: 1621, loss: 0.3519606590270996\n",
      "epoch: 9, batch: 1622, loss: 0.7409495711326599\n",
      "epoch: 9, batch: 1623, loss: 0.4422498047351837\n",
      "epoch: 9, batch: 1624, loss: 0.23445110023021698\n",
      "epoch: 9, batch: 1625, loss: 0.47406449913978577\n",
      "epoch: 9, batch: 1626, loss: 0.363138347864151\n",
      "epoch: 9, batch: 1627, loss: 0.5846314430236816\n",
      "epoch: 9, batch: 1628, loss: 0.6109241247177124\n",
      "epoch: 9, batch: 1629, loss: 0.46338415145874023\n",
      "epoch: 9, batch: 1630, loss: 0.17681437730789185\n",
      "epoch: 9, batch: 1631, loss: 0.36487969756126404\n",
      "epoch: 9, batch: 1632, loss: 0.36694157123565674\n",
      "epoch: 9, batch: 1633, loss: 0.4374362528324127\n",
      "epoch: 9, batch: 1634, loss: 0.47242793440818787\n",
      "epoch: 9, batch: 1635, loss: 0.31405460834503174\n",
      "epoch: 9, batch: 1636, loss: 0.2964230477809906\n",
      "epoch: 9, batch: 1637, loss: 0.27852576971054077\n",
      "epoch: 9, batch: 1638, loss: 0.5735507011413574\n",
      "epoch: 9, batch: 1639, loss: 0.2499447464942932\n",
      "epoch: 9, batch: 1640, loss: 0.2704050838947296\n",
      "epoch: 9, batch: 1641, loss: 0.5894011855125427\n",
      "epoch: 9, batch: 1642, loss: 0.4092198610305786\n",
      "epoch: 9, batch: 1643, loss: 0.5890615582466125\n",
      "epoch: 9, batch: 1644, loss: 0.35847142338752747\n",
      "epoch: 9, batch: 1645, loss: 0.33663618564605713\n",
      "epoch: 9, batch: 1646, loss: 0.4009137451648712\n",
      "epoch: 9, batch: 1647, loss: 0.2420741766691208\n",
      "epoch: 9, batch: 1648, loss: 0.41367483139038086\n",
      "epoch: 9, batch: 1649, loss: 0.40982481837272644\n",
      "epoch: 9, batch: 1650, loss: 0.41619873046875\n",
      "epoch: 9, batch: 1651, loss: 0.49080127477645874\n",
      "epoch: 9, batch: 1652, loss: 0.3277713358402252\n",
      "epoch: 9, batch: 1653, loss: 0.2891353964805603\n",
      "epoch: 9, batch: 1654, loss: 0.433086097240448\n",
      "epoch: 9, batch: 1655, loss: 0.40774592757225037\n",
      "epoch: 9, batch: 1656, loss: 0.6061522960662842\n",
      "epoch: 9, batch: 1657, loss: 0.3843314051628113\n",
      "epoch: 9, batch: 1658, loss: 0.24405606091022491\n",
      "epoch: 9, batch: 1659, loss: 0.15690213441848755\n",
      "epoch: 9, batch: 1660, loss: 0.7568827867507935\n",
      "epoch: 9, batch: 1661, loss: 0.31276413798332214\n",
      "epoch: 9, batch: 1662, loss: 0.30218958854675293\n",
      "epoch: 9, batch: 1663, loss: 0.4776511788368225\n",
      "epoch: 9, batch: 1664, loss: 0.42438364028930664\n",
      "epoch: 9, batch: 1665, loss: 0.2820679545402527\n",
      "epoch: 9, batch: 1666, loss: 0.579934298992157\n",
      "epoch: 9, batch: 1667, loss: 0.4923158884048462\n",
      "epoch: 9, batch: 1668, loss: 0.3824695348739624\n",
      "epoch: 9, batch: 1669, loss: 0.43304523825645447\n",
      "epoch: 9, batch: 1670, loss: 0.41545769572257996\n",
      "epoch: 9, batch: 1671, loss: 0.48553067445755005\n",
      "epoch: 9, batch: 1672, loss: 0.4889567494392395\n",
      "epoch: 9, batch: 1673, loss: 0.3241410553455353\n",
      "epoch: 9, batch: 1674, loss: 0.24370694160461426\n",
      "epoch: 9, batch: 1675, loss: 0.7389914989471436\n",
      "epoch: 9, batch: 1676, loss: 0.4031524956226349\n",
      "epoch: 9, batch: 1677, loss: 0.44053277373313904\n",
      "epoch: 9, batch: 1678, loss: 0.26972830295562744\n",
      "epoch: 9, batch: 1679, loss: 0.16931602358818054\n",
      "epoch: 9, batch: 1680, loss: 0.2918393015861511\n",
      "epoch: 9, batch: 1681, loss: 0.4481675922870636\n",
      "epoch: 9, batch: 1682, loss: 0.47659528255462646\n",
      "epoch: 9, batch: 1683, loss: 0.415620893239975\n",
      "epoch: 9, batch: 1684, loss: 0.494039922952652\n",
      "epoch: 9, batch: 1685, loss: 0.34671053290367126\n",
      "epoch: 9, batch: 1686, loss: 0.3810645043849945\n",
      "epoch: 9, batch: 1687, loss: 0.40279319882392883\n",
      "epoch: 9, batch: 1688, loss: 0.5365728735923767\n",
      "epoch: 9, batch: 1689, loss: 0.5517370700836182\n",
      "epoch: 9, batch: 1690, loss: 0.22572602331638336\n",
      "epoch: 9, batch: 1691, loss: 0.21798822283744812\n",
      "epoch: 9, batch: 1692, loss: 0.42240989208221436\n",
      "epoch: 9, batch: 1693, loss: 0.3847544193267822\n",
      "epoch: 9, batch: 1694, loss: 0.5912873148918152\n",
      "epoch: 9, batch: 1695, loss: 0.38520175218582153\n",
      "epoch: 9, batch: 1696, loss: 0.445671021938324\n",
      "epoch: 9, batch: 1697, loss: 0.4191237688064575\n",
      "epoch: 9, batch: 1698, loss: 0.4453262388706207\n",
      "epoch: 9, batch: 1699, loss: 0.39455080032348633\n",
      "epoch: 9, batch: 1700, loss: 0.7091776728630066\n",
      "epoch: 9, batch: 1701, loss: 0.8119646906852722\n",
      "epoch: 9, batch: 1702, loss: 0.45671871304512024\n",
      "epoch: 9, batch: 1703, loss: 0.33629298210144043\n",
      "epoch: 9, batch: 1704, loss: 0.520435094833374\n",
      "epoch: 9, batch: 1705, loss: 0.3817596435546875\n",
      "epoch: 9, batch: 1706, loss: 0.5145161747932434\n",
      "epoch: 9, batch: 1707, loss: 0.5807687640190125\n",
      "epoch: 9, batch: 1708, loss: 0.2622685432434082\n",
      "epoch: 9, batch: 1709, loss: 0.5191401839256287\n",
      "epoch: 9, batch: 1710, loss: 0.25058645009994507\n",
      "epoch: 9, batch: 1711, loss: 0.2773596942424774\n",
      "epoch: 9, batch: 1712, loss: 0.25673234462738037\n",
      "epoch: 9, batch: 1713, loss: 0.4676888585090637\n",
      "epoch: 9, batch: 1714, loss: 0.2818762958049774\n",
      "epoch: 9, batch: 1715, loss: 0.31882715225219727\n",
      "epoch: 9, batch: 1716, loss: 0.39878129959106445\n",
      "epoch: 9, batch: 1717, loss: 0.2979529798030853\n",
      "epoch: 9, batch: 1718, loss: 0.42376282811164856\n",
      "epoch: 9, batch: 1719, loss: 0.5328247547149658\n",
      "epoch: 9, batch: 1720, loss: 0.4719313383102417\n",
      "epoch: 9, batch: 1721, loss: 0.2983556389808655\n",
      "epoch: 9, batch: 1722, loss: 0.6491520404815674\n",
      "epoch: 9, batch: 1723, loss: 0.3058534860610962\n",
      "epoch: 9, batch: 1724, loss: 0.3839106559753418\n",
      "epoch: 9, batch: 1725, loss: 0.48760664463043213\n",
      "epoch: 9, batch: 1726, loss: 0.6974963545799255\n",
      "epoch: 9, batch: 1727, loss: 0.22079171240329742\n",
      "epoch: 9, batch: 1728, loss: 0.4154815077781677\n",
      "epoch: 9, batch: 1729, loss: 0.30260753631591797\n",
      "epoch: 9, batch: 1730, loss: 0.4076651334762573\n",
      "epoch: 9, batch: 1731, loss: 0.5159773826599121\n",
      "epoch: 9, batch: 1732, loss: 0.37215110659599304\n",
      "epoch: 9, batch: 1733, loss: 0.4172617197036743\n",
      "epoch: 9, batch: 1734, loss: 0.35074037313461304\n",
      "epoch: 9, batch: 1735, loss: 0.6402822732925415\n",
      "epoch: 9, batch: 1736, loss: 0.4512573778629303\n",
      "epoch: 9, batch: 1737, loss: 0.5201281905174255\n",
      "epoch: 9, batch: 1738, loss: 0.28921717405319214\n",
      "epoch: 9, batch: 1739, loss: 0.4429242014884949\n",
      "epoch: 9, batch: 1740, loss: 0.3312644362449646\n",
      "epoch: 9, batch: 1741, loss: 0.3974958062171936\n",
      "epoch: 9, batch: 1742, loss: 0.42108169198036194\n",
      "epoch: 9, batch: 1743, loss: 0.3816658854484558\n",
      "epoch: 9, batch: 1744, loss: 0.27915188670158386\n",
      "epoch: 9, batch: 1745, loss: 0.6113762855529785\n",
      "epoch: 9, batch: 1746, loss: 0.38804569840431213\n",
      "epoch: 9, batch: 1747, loss: 0.3730873167514801\n",
      "epoch: 9, batch: 1748, loss: 0.5813766121864319\n",
      "epoch: 9, batch: 1749, loss: 0.49530190229415894\n",
      "epoch: 9, batch: 1750, loss: 0.4133336842060089\n",
      "epoch: 9, batch: 1751, loss: 0.3042285442352295\n",
      "epoch: 9, batch: 1752, loss: 0.4365215301513672\n",
      "epoch: 9, batch: 1753, loss: 0.46615681052207947\n",
      "epoch: 9, batch: 1754, loss: 0.6121187210083008\n",
      "epoch: 9, batch: 1755, loss: 0.44397813081741333\n",
      "epoch: 9, batch: 1756, loss: 0.23726707696914673\n",
      "epoch: 9, batch: 1757, loss: 0.3437172770500183\n",
      "epoch: 9, batch: 1758, loss: 0.6111435890197754\n",
      "epoch: 9, batch: 1759, loss: 0.5206428170204163\n",
      "epoch: 9, batch: 1760, loss: 0.5211620330810547\n",
      "epoch: 9, batch: 1761, loss: 0.4607168734073639\n",
      "epoch: 9, batch: 1762, loss: 0.7009605169296265\n",
      "epoch: 9, batch: 1763, loss: 0.7140752673149109\n",
      "epoch: 9, batch: 1764, loss: 0.46781662106513977\n",
      "epoch: 9, batch: 1765, loss: 0.36061087250709534\n",
      "epoch: 9, batch: 1766, loss: 0.32905107736587524\n",
      "epoch: 9, batch: 1767, loss: 0.5695012807846069\n",
      "epoch: 9, batch: 1768, loss: 0.5846549868583679\n",
      "epoch: 9, batch: 1769, loss: 0.21407818794250488\n",
      "epoch: 9, batch: 1770, loss: 0.5586740970611572\n",
      "epoch: 9, batch: 1771, loss: 0.6864128708839417\n",
      "epoch: 9, batch: 1772, loss: 0.36349061131477356\n",
      "epoch: 9, batch: 1773, loss: 0.7092094421386719\n",
      "epoch: 9, batch: 1774, loss: 0.5581315159797668\n",
      "epoch: 9, batch: 1775, loss: 0.346855103969574\n",
      "epoch: 9, batch: 1776, loss: 0.4589692950248718\n",
      "epoch: 9, batch: 1777, loss: 0.6341502666473389\n",
      "epoch: 9, batch: 1778, loss: 0.24299873411655426\n",
      "epoch: 9, batch: 1779, loss: 0.2506568133831024\n",
      "epoch: 9, batch: 1780, loss: 0.3198510408401489\n",
      "epoch: 9, batch: 1781, loss: 0.3691076934337616\n",
      "epoch: 9, batch: 1782, loss: 0.7686944007873535\n",
      "epoch: 9, batch: 1783, loss: 0.4176331162452698\n",
      "epoch: 9, batch: 1784, loss: 0.4292377233505249\n",
      "epoch: 9, batch: 1785, loss: 0.4713057279586792\n",
      "epoch: 9, batch: 1786, loss: 0.48236584663391113\n",
      "epoch: 9, batch: 1787, loss: 0.5588187575340271\n",
      "epoch: 9, batch: 1788, loss: 0.21763072907924652\n",
      "epoch: 9, batch: 1789, loss: 0.32680895924568176\n",
      "epoch: 9, batch: 1790, loss: 0.2694350481033325\n",
      "epoch: 9, batch: 1791, loss: 0.5461267232894897\n",
      "epoch: 9, batch: 1792, loss: 0.2540711462497711\n",
      "epoch: 9, batch: 1793, loss: 0.4185789227485657\n",
      "epoch: 9, batch: 1794, loss: 0.4964725077152252\n",
      "epoch: 9, batch: 1795, loss: 0.2527085244655609\n",
      "epoch: 9, batch: 1796, loss: 0.5175910592079163\n",
      "epoch: 9, batch: 1797, loss: 0.3669296205043793\n",
      "epoch: 9, batch: 1798, loss: 0.3032202124595642\n",
      "epoch: 9, batch: 1799, loss: 0.4407658576965332\n",
      "epoch: 9, batch: 1800, loss: 0.5516054034233093\n",
      "epoch: 9, batch: 1801, loss: 0.43221256136894226\n",
      "epoch: 9, batch: 1802, loss: 0.4305471181869507\n",
      "epoch: 9, batch: 1803, loss: 0.4783638119697571\n",
      "epoch: 9, batch: 1804, loss: 0.2839631140232086\n",
      "epoch: 9, batch: 1805, loss: 0.4130552411079407\n",
      "epoch: 9, batch: 1806, loss: 0.4743046164512634\n",
      "epoch: 9, batch: 1807, loss: 0.33085986971855164\n",
      "epoch: 9, batch: 1808, loss: 0.3390223979949951\n",
      "epoch: 9, batch: 1809, loss: 0.26254746317863464\n",
      "epoch: 9, batch: 1810, loss: 0.2904737591743469\n",
      "epoch: 9, batch: 1811, loss: 0.5702791810035706\n",
      "epoch: 9, batch: 1812, loss: 0.3026641011238098\n",
      "epoch: 9, batch: 1813, loss: 0.46535298228263855\n",
      "epoch: 9, batch: 1814, loss: 0.410388708114624\n",
      "epoch: 9, batch: 1815, loss: 0.5084698796272278\n",
      "epoch: 9, batch: 1816, loss: 0.42043212056159973\n",
      "epoch: 9, batch: 1817, loss: 0.8287434577941895\n",
      "epoch: 9, batch: 1818, loss: 0.3465196192264557\n",
      "epoch: 9, batch: 1819, loss: 0.3693227171897888\n",
      "epoch: 9, batch: 1820, loss: 0.4799121618270874\n",
      "epoch: 9, batch: 1821, loss: 0.5438300371170044\n",
      "epoch: 9, batch: 1822, loss: 0.5568165183067322\n",
      "epoch: 9, batch: 1823, loss: 0.5602356195449829\n",
      "epoch: 9, batch: 1824, loss: 0.5197294354438782\n",
      "epoch: 9, batch: 1825, loss: 0.9883293509483337\n",
      "epoch: 9, batch: 1826, loss: 0.4396989047527313\n",
      "epoch: 9, batch: 1827, loss: 0.4436430037021637\n",
      "epoch: 9, batch: 1828, loss: 0.3455517292022705\n",
      "epoch: 9, batch: 1829, loss: 0.433370441198349\n",
      "epoch: 9, batch: 1830, loss: 0.8703635931015015\n",
      "epoch: 9, batch: 1831, loss: 0.3911868929862976\n",
      "epoch: 9, batch: 1832, loss: 0.30576425790786743\n",
      "epoch: 9, batch: 1833, loss: 0.35586264729499817\n",
      "epoch: 9, batch: 1834, loss: 0.2595055103302002\n",
      "epoch: 9, batch: 1835, loss: 0.27937328815460205\n",
      "epoch: 9, batch: 1836, loss: 0.4658490717411041\n",
      "epoch: 9, batch: 1837, loss: 0.4517555236816406\n",
      "epoch: 9, batch: 1838, loss: 0.4637775421142578\n",
      "epoch: 9, batch: 1839, loss: 0.2954261302947998\n",
      "epoch: 9, batch: 1840, loss: 0.22624148428440094\n",
      "epoch: 9, batch: 1841, loss: 0.335619181394577\n",
      "epoch: 9, batch: 1842, loss: 0.4265481233596802\n",
      "epoch: 9, batch: 1843, loss: 0.3182612657546997\n",
      "epoch: 9, batch: 1844, loss: 0.33327576518058777\n",
      "epoch: 9, batch: 1845, loss: 0.4296475350856781\n",
      "epoch: 9, batch: 1846, loss: 0.6185035109519958\n",
      "epoch: 9, batch: 1847, loss: 0.49281200766563416\n",
      "epoch: 9, batch: 1848, loss: 0.26162493228912354\n",
      "epoch: 9, batch: 1849, loss: 0.4028390347957611\n",
      "epoch: 9, batch: 1850, loss: 0.24145445227622986\n",
      "epoch: 9, batch: 1851, loss: 0.4964877665042877\n",
      "epoch: 9, batch: 1852, loss: 0.3560909628868103\n",
      "epoch: 9, batch: 1853, loss: 0.3540235757827759\n",
      "epoch: 9, batch: 1854, loss: 0.5745514631271362\n",
      "epoch: 9, batch: 1855, loss: 0.514015793800354\n",
      "epoch: 9, batch: 1856, loss: 0.5292534232139587\n",
      "epoch: 9, batch: 1857, loss: 0.5046115517616272\n",
      "epoch: 9, batch: 1858, loss: 0.5122187733650208\n",
      "epoch: 9, batch: 1859, loss: 0.3290632665157318\n",
      "epoch: 9, batch: 1860, loss: 0.46871331334114075\n",
      "epoch: 9, batch: 1861, loss: 0.6197696924209595\n",
      "epoch: 9, batch: 1862, loss: 0.397088885307312\n",
      "epoch: 9, batch: 1863, loss: 0.2687525451183319\n",
      "epoch: 9, batch: 1864, loss: 0.7988698482513428\n",
      "epoch: 9, batch: 1865, loss: 0.5264886617660522\n",
      "epoch: 9, batch: 1866, loss: 0.4615761935710907\n",
      "epoch: 9, batch: 1867, loss: 0.48133301734924316\n",
      "epoch: 9, batch: 1868, loss: 0.3626300096511841\n",
      "epoch: 9, batch: 1869, loss: 0.3899620473384857\n",
      "epoch: 9, batch: 1870, loss: 0.3749299943447113\n",
      "epoch: 9, batch: 1871, loss: 0.21946007013320923\n",
      "epoch: 9, batch: 1872, loss: 0.3341858685016632\n",
      "epoch: 9, batch: 1873, loss: 0.4261259436607361\n",
      "epoch: 9, batch: 1874, loss: 0.45745423436164856\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for batch_ix, (data, target) in enumerate(b_trainloader):\n",
    "        \n",
    "        # forward thru the model and compute loss\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(data)\n",
    "        loss = F.nll_loss(preds, target)\n",
    "\n",
    "        # backward pass and update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'epoch: {epoch}, batch: {batch_ix}, loss: {loss}')\n",
    "        \n",
    "# save the model\n",
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test out model\n",
    "model.eval()\n",
    "ix = torch.randint(low=0, high=len(b_testset), size=(1,)).item()\n",
    "test = b_trainset[ix][0]\n",
    "plt.imshow(test.squeeze(), cmap='gray')\n",
    "torch.argmax(model(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
